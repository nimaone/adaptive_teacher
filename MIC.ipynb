{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMl4ih6MetCURX3TVLZd85i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nimaone/adaptive_teacher/blob/main/MIC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "34ziyIjQkWd4",
        "outputId": "9006b045-fb37-45ca-8926-829a69b570d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jan 27 14:12:34 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P0    28W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "!gcc --version"
      ],
      "metadata": {
        "id": "6rSV67T7kbMH",
        "outputId": "caf53d10-6b3b-4f1e-b60c-e1b0952d6772",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.13.1+cu116 True\n",
            "gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n",
            "Copyright (C) 2019 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.12.0+cu113 torchvision==0.13.0+cu113 torchaudio==0.12.0 --extra-index-url https://download.pytorch.org/whl/cu113\n"
      ],
      "metadata": {
        "id": "Op0R5460r6pu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "!gcc --version"
      ],
      "metadata": {
        "id": "D_AzhFiYszFw",
        "outputId": "881b574c-e817-480d-e330-0b171c4839a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.12.0+cu113 True\n",
            "gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n",
            "Copyright (C) 2019 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ninja==1.10.2.3 yacs==0.1.8 cython==0.29.28 matplotlib==3.5.1 tqdm==4.63.0 opencv-python==4.5.5.64\n"
      ],
      "metadata": {
        "id": "5scgehCjsN4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm==0.6.11 kornia==0.5.8 einops==0.4.1\n"
      ],
      "metadata": {
        "id": "OYUfcCsHsP-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ],
      "metadata": {
        "id": "NmxUj_p4sk5Q",
        "outputId": "10b25c31-fc07-4bad-c451-6bf72152572b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "!git clone https://github.com/cocodataset/cocoapi.git\n",
        "%cd cocoapi/PythonAPI\n",
        "!python setup.py build_ext install"
      ],
      "metadata": {
        "id": "O3xePoZYsUaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "!git clone https://github.com/mcordts/cityscapesScripts.git\n",
        "%cd cityscapesScripts/\n",
        "!python setup.py build_ext install"
      ],
      "metadata": {
        "id": "PKvv135FtC4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "!git clone https://github.com/lhoyer/MIC\n",
        "%cd MIC/det\n",
        "# the following will install the lib with\n",
        "# symbolic links, so that you can modify\n",
        "# the files if you want and won't need to\n",
        "# re-build it\n",
        "!python setup.py build develop"
      ],
      "metadata": {
        "id": "zOc-a8vetRsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "2vV5D1gFtnlH",
        "outputId": "081059e2-a1b1-4308-8253-6194303f2147",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "build\t\t INSTALL.md\t     maskrcnn_benchmark.egg-info  tests\n",
            "configs\t\t LICENSE\t     README.md\t\t\t  tools\n",
            "environment.yml  maskrcnn_benchmark  setup.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "\n",
        "# copy required file to cityscapesScripts toolkit\n",
        "!cp tool/cityscapes/instances2dict_with_polygons.py $INSTALL_DIR/cityscapesScripts/evaluation\n",
        "\n",
        "# recompile cityscapesScripts\n",
        "%cd cityscapesScripts/\n",
        "!python setup.py build_ext install\n",
        "\n",
        "!pip install h5py==3.6.0 scipy==1.8.0"
      ],
      "metadata": {
        "id": "W4RXjCYltiUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ueuI0V57kos6",
        "outputId": "38a3812d-9157-4c86-8aef-8345a8d16d23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget https://deepblue.lib.umich.edu/data/downloads/ks65hc58r"
      ],
      "metadata": {
        "id": "P6a2p55-p5cU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget http://droplab-files.engin.umich.edu/repro_10k_annotations.tgz"
      ],
      "metadata": {
        "id": "tBjmtt8Zp6mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget http://droplab-files.engin.umich.edu/repro_image_sets.tgz"
      ],
      "metadata": {
        "id": "PwpcWcVTp7yq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !gdown 1-1Iow33KqdaNQcrK4v9Zk568IZVYZ1UV\n",
        "# !gdown 1-0WQV7BerZb2ieF0LYzoFlO9NFjy4gy7\n",
        "# !gdown 1-1rhR_4ynP162kL1UrmWQex8tyj6Ki3F\n"
      ],
      "metadata": {
        "id": "jZMn_A-9krUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/datasets"
      ],
      "metadata": {
        "id": "AC6gwnLmlDyr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -zxvf /content/repro_10k_images.tgz -C /content/datasets\n",
        "!tar -zxvf /content/repro_10k_annotations.tgz -C /content/datasets\n",
        "!tar -zxvf /content/repro_image_sets.tgz -C /content/datasets"
      ],
      "metadata": {
        "id": "W76h5tfzkzwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/datasets/VOC2012 /content/datasets/Sim10k\n"
      ],
      "metadata": {
        "id": "dR2epK9emNPb"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --keep-session-cookies --save-cookies=cookies.txt --post-data 'username=kiaei&password=UtP8!pbXp8FsQs2&submit=Login' https://www.cityscapes-dataset.com/login/"
      ],
      "metadata": {
        "id": "m1K1YGIpmOR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=3"
      ],
      "metadata": {
        "id": "yGMnQjx8mOj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=1"
      ],
      "metadata": {
        "id": "gdX2_zs0mQZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/leftImg8bit_trainvaltest.zip -d /content/datasets"
      ],
      "metadata": {
        "id": "o8HEpyQnmR7Z"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/gtFine_trainvaltest.zip -d /content/datasets/cityscapes"
      ],
      "metadata": {
        "id": "CJv7EC_XmWBb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/datasets/leftImg8bit /content/datasets/cityscapes"
      ],
      "metadata": {
        "id": "0fwf9EgOmWrg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r  /content/leftImg8bit_trainvaltest.zip"
      ],
      "metadata": {
        "id": "uO6HuVa8mXzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fiftyone"
      ],
      "metadata": {
        "id": "uYfI-MBgmaiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fiftyone as fo\n",
        "from fiftyone import ViewField as F\n"
      ],
      "metadata": {
        "id": "88HOeIyema6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "imgs_path = \"/content/datasets/Sim10k/JPEGImages\"\n",
        "labels_path = \"/content/datasets/Sim10k/Annotations\"\n",
        "\n",
        "\n",
        "# name = 'visdrone'\n",
        "# The dataset or view to export\n",
        "dataset = fo.Dataset.from_dir(\n",
        "    dataset_type=fo.types.VOCDetectionDataset,\n",
        "    data_path=imgs_path,\n",
        "    labels_path=labels_path,\n",
        ")\n"
      ],
      "metadata": {
        "id": "6YUBzDBHmnjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# session = fo.launch_app(dataset)\n"
      ],
      "metadata": {
        "id": "Gvh_yDwYmsos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "car_view = dataset.filter_labels(\n",
        "    \"ground_truth\", (F(\"label\") == \"car\") \n",
        ")"
      ],
      "metadata": {
        "id": "g-JdEu9nmrtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "session = fo.launch_app(view=car_view)\n"
      ],
      "metadata": {
        "id": "HeC-w9z7muTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# export_dir = \"/content/datasets/Sim10k\"\n",
        "labels_path  = \"/content/datasets/Sim10k/train_only_car.json\"\n",
        "\n",
        "# The name of the sample field containing the label that you wish to export\n",
        "# Used when exporting labeled datasets (e.g., classification or detection)\n",
        "label_field = \"ground_truth\"\n",
        "dataset_type = fo.types.COCODetectionDataset  # for example\n",
        "\n",
        "car_view.export(\n",
        "    labels_path=labels_path,\n",
        "    dataset_type=dataset_type,\n",
        "    label_field=label_field,\n",
        "    export_media=False\n",
        ")"
      ],
      "metadata": {
        "id": "0LeUg38omw0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install cityscapesscripts"
      ],
      "metadata": {
        "id": "-y5IceSnm1KE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}"
      ],
      "metadata": {
        "id": "VOnvZh_DvJgk",
        "outputId": "192e36da-fa9c-466f-acfb-a947b6ce3e15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/MIC/det/tools/cityscapes"
      ],
      "metadata": {
        "id": "f_2x69mpvPGn",
        "outputId": "4b297af0-d056-4deb-d9d6-5ef1a814d233",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MIC/det/tools/cityscapes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python convert_cityscapes_to_caronly_coco.py --dataset cityscapes_car_only\\\n",
        "  --outdir '/content/datasets/cityscapes'\\\n",
        "  --datadir '/content/datasets/cityscapes/'"
      ],
      "metadata": {
        "id": "NhWgaQTPm4uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python convert_sim10k_to_coco.py --dataset sim10k\\\n",
        "  --outdir '/content/datasets/Sim10k/'\\\n",
        "  --datadir '/content/datasets/Sim10k/Annotations'"
      ],
      "metadata": {
        "id": "oUu4QcVzx_ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv  /content/datasets/cityscapes/leftImg8bit/train/*/*.png /content/datasets/cityscapes/leftImg8bit/train/\n",
        "!mv  /content/datasets/cityscapes/leftImg8bit/val/*/*.png /content/datasets/cityscapes/leftImg8bit/val/\n",
        "!mv  /content/datasets/cityscapes/leftImg8bit/test/*/*.png /content/datasets/cityscapes/leftImg8bit/test/\n"
      ],
      "metadata": {
        "id": "mu_G8ja0m7xV"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/MIC/det"
      ],
      "metadata": {
        "id": "7_BQpCdG069U",
        "outputId": "14af7205-7f34-4f63-96c6-189bb6039efe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '{HOME}'\n",
            "/content/MIC/det\n",
            "/content/MIC/det\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/train_net.py --config-file configs/da_faster_rcnn/e2e_da_faster_rcnn_R_50_FPN_masking_cs.yaml\n"
      ],
      "metadata": {
        "id": "tBWY-afk034w",
        "outputId": "faa970f7-b8e1-4e13-e5ba-7df54900a0b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-27 15:39:39,421 maskrcnn_benchmark INFO: Using 1 GPUs\n",
            "2023-01-27 15:39:39,421 maskrcnn_benchmark INFO: Namespace(config_file='configs/da_faster_rcnn/e2e_da_faster_rcnn_R_50_FPN_masking_cs.yaml', deterministic=False, distributed=False, local_rank=0, opts=[], seed=1, skip_test=False)\n",
            "2023-01-27 15:39:39,421 maskrcnn_benchmark INFO: Collecting env info (might take some time)\n",
            "2023-01-27 15:39:40,701 maskrcnn_benchmark INFO: \n",
            "PyTorch version: 1.12.0+cu113\n",
            "Is debug build: False\n",
            "CUDA used to build PyTorch: 11.3\n",
            "ROCM used to build PyTorch: N/A\n",
            "\n",
            "OS: Ubuntu 20.04.5 LTS (x86_64)\n",
            "GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n",
            "Clang version: 10.0.0-4ubuntu1 \n",
            "CMake version: version 3.22.6\n",
            "Libc version: glibc-2.31\n",
            "\n",
            "Python version: 3.8.10 (default, Nov 14 2022, 12:59:47)  [GCC 9.4.0] (64-bit runtime)\n",
            "Python platform: Linux-5.10.147+-x86_64-with-glibc2.29\n",
            "Is CUDA available: True\n",
            "CUDA runtime version: 11.2.152\n",
            "GPU models and configuration: GPU 0: Tesla T4\n",
            "Nvidia driver version: 510.47.03\n",
            "cuDNN version: Probably one of the following:\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.1.1\n",
            "HIP runtime version: N/A\n",
            "MIOpen runtime version: N/A\n",
            "Is XNNPACK available: True\n",
            "\n",
            "Versions of relevant libraries:\n",
            "[pip3] numpy==1.21.6\n",
            "[pip3] torch==1.12.0+cu113\n",
            "[pip3] torchaudio==0.12.0+cu113\n",
            "[pip3] torchsummary==1.5.1\n",
            "[pip3] torchtext==0.14.1\n",
            "[pip3] torchvision==0.13.0+cu113\n",
            "[conda] Could not collect\n",
            "        Pillow (7.1.2)\n",
            "2023-01-27 15:39:40,701 maskrcnn_benchmark INFO: Loaded configuration file configs/da_faster_rcnn/e2e_da_faster_rcnn_R_50_FPN_masking_cs.yaml\n",
            "2023-01-27 15:39:40,702 maskrcnn_benchmark INFO: \n",
            "MODEL:\n",
            "  META_ARCHITECTURE: \"GeneralizedRCNN\"\n",
            "  WEIGHT: \"catalog://ImageNetPretrained/MSRA/R-50\"\n",
            "  DOMAIN_ADAPTATION_ON: True\n",
            "  BACKBONE:\n",
            "    CONV_BODY: \"R-50-FPN\"\n",
            "    OUT_CHANNELS: 256\n",
            "  RPN:\n",
            "    USE_FPN: True\n",
            "    ANCHOR_STRIDE: (4, 8, 16, 32, 64)\n",
            "    PRE_NMS_TOP_N_TRAIN: 2000\n",
            "    PRE_NMS_TOP_N_TEST: 1000\n",
            "    POST_NMS_TOP_N_TEST: 1000\n",
            "    FPN_POST_NMS_TOP_N_TEST: 1000\n",
            "  ROI_HEADS:\n",
            "    USE_FPN: True\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "  ROI_BOX_HEAD:\n",
            "    NUM_CLASSES: 2\n",
            "    POOLER_RESOLUTION: 7\n",
            "    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n",
            "    POOLER_SAMPLING_RATIO: 2\n",
            "    FEATURE_EXTRACTOR: \"FPN2MLPFeatureExtractor\"\n",
            "    PREDICTOR: \"FPNPredictor\"\n",
            "  DA_HEADS:\n",
            "    DA_IMG_GRL_WEIGHT: 0.025\n",
            "    DA_INS_GRL_WEIGHT: 0.1\n",
            "    COS_WEIGHT: 0.1\n",
            "  MIC_ON: True\n",
            "  MASKING_AUGMENTATION: True\n",
            "  PSEUDO_LABEL_THRESHOLD: 0.8\n",
            "  PSEUDO_LABEL_LAMBDA: 1.0\n",
            "  PSEUDO_LABEL_WEIGHT: 'prob'\n",
            "  MASKING_BLOCK_SIZE: 32\n",
            "  MASKING_RATIO: 0.5\n",
            "  TEACHER_ALPHA: 0.9\n",
            "DATASETS:\n",
            "  SOURCE_TRAIN: (\"sim10k_cocostyle\",) #(\"cityscapes_fine_instanceonly_seg_train_cocostyle\",)\n",
            "  TARGET_TRAIN: (\"cityscapes_only_car_train_cocostyle\",) #(\"foggy_cityscapes_fine_instanceonly_seg_train_cocostyle\",)\n",
            "  TEST: (\"cityscapes_only_car_val_cocostyle\",) #(\"foggy_cityscapes_fine_instanceonly_seg_val_cocostyle\",)\n",
            "INPUT:\n",
            "  MIN_SIZE_TRAIN: (800,)\n",
            "  MAX_SIZE_TRAIN: 1600\n",
            "  MIN_SIZE_TEST: 800\n",
            "  MAX_SIZE_TEST: 1600\n",
            "DATALOADER:\n",
            "  SIZE_DIVISIBILITY: 32\n",
            "SOLVER:\n",
            "  CHECKPOINT_PERIOD: 2000\n",
            "  BASE_LR: 0.00125\n",
            "  WEIGHT_DECAY: 0.0001\n",
            "  STEPS: (30000, 40000)\n",
            "  MAX_ITER: 60000\n",
            "  IMS_PER_BATCH: 4\n",
            "TEST:\n",
            "  IMS_PER_BATCH: 1\n",
            "\n",
            "2023-01-27 15:39:40,702 maskrcnn_benchmark INFO: Running with config:\n",
            "DATALOADER:\n",
            "  ASPECT_RATIO_GROUPING: True\n",
            "  NUM_WORKERS: 4\n",
            "  SIZE_DIVISIBILITY: 32\n",
            "DATASETS:\n",
            "  SOURCE_TRAIN: ('sim10k_cocostyle',)\n",
            "  TARGET_TRAIN: ('cityscapes_only_car_train_cocostyle',)\n",
            "  TEST: ('cityscapes_only_car_val_cocostyle',)\n",
            "  TRAIN: ()\n",
            "INPUT:\n",
            "  MAX_SIZE_TEST: 1600\n",
            "  MAX_SIZE_TRAIN: 1600\n",
            "  MIN_SIZE_TEST: 800\n",
            "  MIN_SIZE_TRAIN: (800,)\n",
            "  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]\n",
            "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
            "  TO_BGR255: True\n",
            "MODEL:\n",
            "  BACKBONE:\n",
            "    CONV_BODY: R-50-FPN\n",
            "    FREEZE_CONV_BODY_AT: 2\n",
            "    OUT_CHANNELS: 256\n",
            "    USE_GN: False\n",
            "  CLS_AGNOSTIC_BBOX_REG: False\n",
            "  DA_HEADS:\n",
            "    COS_WEIGHT: 0.1\n",
            "    DA_IMG_GRL_WEIGHT: 0.025\n",
            "    DA_INS_GRL_WEIGHT: 0.1\n",
            "  DEVICE: cuda\n",
            "  DOMAIN_ADAPTATION_ON: True\n",
            "  FPN:\n",
            "    USE_GN: False\n",
            "    USE_RELU: False\n",
            "  GROUP_NORM:\n",
            "    DIM_PER_GP: -1\n",
            "    EPSILON: 1e-05\n",
            "    NUM_GROUPS: 32\n",
            "  KEYPOINT_ON: False\n",
            "  MASKING_AUGMENTATION: True\n",
            "  MASKING_BLOCK_SIZE: 32\n",
            "  MASKING_RATIO: 0.5\n",
            "  MASK_ON: False\n",
            "  META_ARCHITECTURE: GeneralizedRCNN\n",
            "  MIC_ON: True\n",
            "  PSEUDO_LABEL_LAMBDA: 1.0\n",
            "  PSEUDO_LABEL_THRESHOLD: 0.8\n",
            "  PSEUDO_LABEL_WEIGHT: prob\n",
            "  RESNETS:\n",
            "    NUM_GROUPS: 1\n",
            "    RES2_OUT_CHANNELS: 256\n",
            "    RES5_DILATION: 1\n",
            "    STEM_FUNC: StemWithFixedBatchNorm\n",
            "    STEM_OUT_CHANNELS: 64\n",
            "    STRIDE_IN_1X1: True\n",
            "    TRANS_FUNC: BottleneckWithFixedBatchNorm\n",
            "    WIDTH_PER_GROUP: 64\n",
            "  RETINANET:\n",
            "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
            "    ANCHOR_STRIDES: (8, 16, 32, 64, 128)\n",
            "    ASPECT_RATIOS: (0.5, 1.0, 2.0)\n",
            "    BBOX_REG_BETA: 0.11\n",
            "    BBOX_REG_WEIGHT: 4.0\n",
            "    BG_IOU_THRESHOLD: 0.4\n",
            "    FG_IOU_THRESHOLD: 0.5\n",
            "    INFERENCE_TH: 0.05\n",
            "    LOSS_ALPHA: 0.25\n",
            "    LOSS_GAMMA: 2.0\n",
            "    NMS_TH: 0.4\n",
            "    NUM_CLASSES: 81\n",
            "    NUM_CONVS: 4\n",
            "    OCTAVE: 2.0\n",
            "    PRE_NMS_TOP_N: 1000\n",
            "    PRIOR_PROB: 0.01\n",
            "    SCALES_PER_OCTAVE: 3\n",
            "    STRADDLE_THRESH: 0\n",
            "    USE_C5: True\n",
            "  RETINANET_ON: False\n",
            "  ROI_BOX_HEAD:\n",
            "    CONV_HEAD_DIM: 256\n",
            "    DILATION: 1\n",
            "    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n",
            "    MLP_HEAD_DIM: 1024\n",
            "    NUM_CLASSES: 2\n",
            "    NUM_STACKED_CONVS: 4\n",
            "    POOLER_RESOLUTION: 7\n",
            "    POOLER_SAMPLING_RATIO: 2\n",
            "    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n",
            "    PREDICTOR: FPNPredictor\n",
            "    USE_GN: False\n",
            "  ROI_HEADS:\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
            "    BG_IOU_THRESHOLD: 0.5\n",
            "    DETECTIONS_PER_IMG: 100\n",
            "    FG_IOU_THRESHOLD: 0.5\n",
            "    NMS: 0.5\n",
            "    POSITIVE_FRACTION: 0.25\n",
            "    SCORE_THRESH: 0.05\n",
            "    USE_FPN: True\n",
            "  ROI_KEYPOINT_HEAD:\n",
            "    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
            "    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor\n",
            "    MLP_HEAD_DIM: 1024\n",
            "    NUM_CLASSES: 17\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_SCALES: (0.0625,)\n",
            "    PREDICTOR: KeypointRCNNPredictor\n",
            "    RESOLUTION: 14\n",
            "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
            "  ROI_MASK_HEAD:\n",
            "    CONV_LAYERS: (256, 256, 256, 256)\n",
            "    DILATION: 1\n",
            "    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor\n",
            "    MLP_HEAD_DIM: 1024\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_SCALES: (0.0625,)\n",
            "    POSTPROCESS_MASKS: False\n",
            "    POSTPROCESS_MASKS_THRESHOLD: 0.5\n",
            "    PREDICTOR: MaskRCNNC4Predictor\n",
            "    RESOLUTION: 14\n",
            "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
            "    USE_GN: False\n",
            "  RPN:\n",
            "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
            "    ANCHOR_STRIDE: (4, 8, 16, 32, 64)\n",
            "    ASPECT_RATIOS: (0.5, 1.0, 2.0)\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "    BG_IOU_THRESHOLD: 0.3\n",
            "    FG_IOU_THRESHOLD: 0.7\n",
            "    FPN_POST_NMS_TOP_N_TEST: 1000\n",
            "    FPN_POST_NMS_TOP_N_TRAIN: 2000\n",
            "    MIN_SIZE: 0\n",
            "    NMS_THRESH: 0.7\n",
            "    POSITIVE_FRACTION: 0.5\n",
            "    POST_NMS_TOP_N_TEST: 1000\n",
            "    POST_NMS_TOP_N_TRAIN: 2000\n",
            "    PRE_NMS_TOP_N_TEST: 1000\n",
            "    PRE_NMS_TOP_N_TRAIN: 2000\n",
            "    RPN_HEAD: SingleConvRPNHead\n",
            "    STRADDLE_THRESH: 0\n",
            "    USE_FPN: True\n",
            "  RPN_ONLY: False\n",
            "  TEACHER_ALPHA: 0.9\n",
            "  WEIGHT: catalog://ImageNetPretrained/MSRA/R-50\n",
            "OUTPUT_DIR: .\n",
            "PATHS_CATALOG: /content/MIC/det/maskrcnn_benchmark/config/paths_catalog.py\n",
            "SOLVER:\n",
            "  BASE_LR: 0.00125\n",
            "  BIAS_LR_FACTOR: 2\n",
            "  CHECKPOINT_PERIOD: 2000\n",
            "  GAMMA: 0.1\n",
            "  IMS_PER_BATCH: 4\n",
            "  MAX_ITER: 60000\n",
            "  MOMENTUM: 0.9\n",
            "  STEPS: (30000, 40000)\n",
            "  WARMUP_FACTOR: 0.3333333333333333\n",
            "  WARMUP_ITERS: 500\n",
            "  WARMUP_METHOD: linear\n",
            "  WEIGHT_DECAY: 0.0001\n",
            "  WEIGHT_DECAY_BIAS: 0\n",
            "TEST:\n",
            "  DETECTIONS_PER_IMG: 100\n",
            "  EXPECTED_RESULTS: []\n",
            "  EXPECTED_RESULTS_SIGMA_TOL: 4\n",
            "  IMS_PER_BATCH: 1\n",
            "2023-01-27 15:39:40,702 maskrcnn_benchmark INFO: Set random seed to 1, deterministic: False\n",
            "2023-01-27 15:39:43,335 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from catalog://ImageNetPretrained/MSRA/R-50\n",
            "2023-01-27 15:39:43,337 maskrcnn_benchmark.utils.checkpoint INFO: catalog://ImageNetPretrained/MSRA/R-50 points to https://dl.fbaipublicfiles.com/detectron/ImageNetPretrained/MSRA/R-50.pkl\n",
            "2023-01-27 15:39:43,337 maskrcnn_benchmark.utils.checkpoint INFO: url https://dl.fbaipublicfiles.com/detectron/ImageNetPretrained/MSRA/R-50.pkl cached in /root/.torch/models/R-50.pkl\n",
            "2023-01-27 15:39:43,396 maskrcnn_benchmark.utils.c2_model_loading INFO: Remapping C2 weights\n",
            "2023-01-27 15:39:43,397 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: conv1_b              mapped name: conv1.bias\n",
            "2023-01-27 15:39:43,397 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: conv1_w              mapped name: conv1.weight\n",
            "2023-01-27 15:39:43,397 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: fc1000_b             mapped name: fc1000.bias\n",
            "2023-01-27 15:39:43,397 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: fc1000_w             mapped name: fc1000.weight\n",
            "2023-01-27 15:39:43,397 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch1_b     mapped name: layer1.0.downsample.0.bias\n",
            "2023-01-27 15:39:43,397 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch1_bn_b  mapped name: layer1.0.downsample.1.bias\n",
            "2023-01-27 15:39:43,397 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch1_bn_s  mapped name: layer1.0.downsample.1.weight\n",
            "2023-01-27 15:39:43,397 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch1_w     mapped name: layer1.0.downsample.0.weight\n",
            "2023-01-27 15:39:43,397 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_b    mapped name: layer1.0.conv1.bias\n",
            "2023-01-27 15:39:43,397 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_bn_b mapped name: layer1.0.bn1.bias\n",
            "2023-01-27 15:39:43,397 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_bn_s mapped name: layer1.0.bn1.weight\n",
            "2023-01-27 15:39:43,397 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_w    mapped name: layer1.0.conv1.weight\n",
            "2023-01-27 15:39:43,397 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_b    mapped name: layer1.0.conv2.bias\n",
            "2023-01-27 15:39:43,398 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_bn_b mapped name: layer1.0.bn2.bias\n",
            "2023-01-27 15:39:43,398 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_bn_s mapped name: layer1.0.bn2.weight\n",
            "2023-01-27 15:39:43,398 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_w    mapped name: layer1.0.conv2.weight\n",
            "2023-01-27 15:39:43,398 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_b    mapped name: layer1.0.conv3.bias\n",
            "2023-01-27 15:39:43,398 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_bn_b mapped name: layer1.0.bn3.bias\n",
            "2023-01-27 15:39:43,398 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_bn_s mapped name: layer1.0.bn3.weight\n",
            "2023-01-27 15:39:43,398 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_w    mapped name: layer1.0.conv3.weight\n",
            "2023-01-27 15:39:43,398 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_b    mapped name: layer1.1.conv1.bias\n",
            "2023-01-27 15:39:43,398 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_bn_b mapped name: layer1.1.bn1.bias\n",
            "2023-01-27 15:39:43,398 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_bn_s mapped name: layer1.1.bn1.weight\n",
            "2023-01-27 15:39:43,398 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_w    mapped name: layer1.1.conv1.weight\n",
            "2023-01-27 15:39:43,398 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_b    mapped name: layer1.1.conv2.bias\n",
            "2023-01-27 15:39:43,398 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_bn_b mapped name: layer1.1.bn2.bias\n",
            "2023-01-27 15:39:43,398 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_bn_s mapped name: layer1.1.bn2.weight\n",
            "2023-01-27 15:39:43,398 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_w    mapped name: layer1.1.conv2.weight\n",
            "2023-01-27 15:39:43,398 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_b    mapped name: layer1.1.conv3.bias\n",
            "2023-01-27 15:39:43,398 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_bn_b mapped name: layer1.1.bn3.bias\n",
            "2023-01-27 15:39:43,399 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_bn_s mapped name: layer1.1.bn3.weight\n",
            "2023-01-27 15:39:43,399 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_w    mapped name: layer1.1.conv3.weight\n",
            "2023-01-27 15:39:43,399 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_b    mapped name: layer1.2.conv1.bias\n",
            "2023-01-27 15:39:43,399 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_bn_b mapped name: layer1.2.bn1.bias\n",
            "2023-01-27 15:39:43,399 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_bn_s mapped name: layer1.2.bn1.weight\n",
            "2023-01-27 15:39:43,399 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_w    mapped name: layer1.2.conv1.weight\n",
            "2023-01-27 15:39:43,399 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_b    mapped name: layer1.2.conv2.bias\n",
            "2023-01-27 15:39:43,399 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_bn_b mapped name: layer1.2.bn2.bias\n",
            "2023-01-27 15:39:43,399 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_bn_s mapped name: layer1.2.bn2.weight\n",
            "2023-01-27 15:39:43,399 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_w    mapped name: layer1.2.conv2.weight\n",
            "2023-01-27 15:39:43,399 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_b    mapped name: layer1.2.conv3.bias\n",
            "2023-01-27 15:39:43,399 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_bn_b mapped name: layer1.2.bn3.bias\n",
            "2023-01-27 15:39:43,399 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_bn_s mapped name: layer1.2.bn3.weight\n",
            "2023-01-27 15:39:43,399 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_w    mapped name: layer1.2.conv3.weight\n",
            "2023-01-27 15:39:43,399 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch1_b     mapped name: layer2.0.downsample.0.bias\n",
            "2023-01-27 15:39:43,399 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch1_bn_b  mapped name: layer2.0.downsample.1.bias\n",
            "2023-01-27 15:39:43,399 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch1_bn_s  mapped name: layer2.0.downsample.1.weight\n",
            "2023-01-27 15:39:43,399 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch1_w     mapped name: layer2.0.downsample.0.weight\n",
            "2023-01-27 15:39:43,399 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_b    mapped name: layer2.0.conv1.bias\n",
            "2023-01-27 15:39:43,400 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_bn_b mapped name: layer2.0.bn1.bias\n",
            "2023-01-27 15:39:43,400 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_bn_s mapped name: layer2.0.bn1.weight\n",
            "2023-01-27 15:39:43,400 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_w    mapped name: layer2.0.conv1.weight\n",
            "2023-01-27 15:39:43,400 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_b    mapped name: layer2.0.conv2.bias\n",
            "2023-01-27 15:39:43,400 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_bn_b mapped name: layer2.0.bn2.bias\n",
            "2023-01-27 15:39:43,400 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_bn_s mapped name: layer2.0.bn2.weight\n",
            "2023-01-27 15:39:43,400 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_w    mapped name: layer2.0.conv2.weight\n",
            "2023-01-27 15:39:43,400 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_b    mapped name: layer2.0.conv3.bias\n",
            "2023-01-27 15:39:43,400 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_bn_b mapped name: layer2.0.bn3.bias\n",
            "2023-01-27 15:39:43,400 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_bn_s mapped name: layer2.0.bn3.weight\n",
            "2023-01-27 15:39:43,400 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_w    mapped name: layer2.0.conv3.weight\n",
            "2023-01-27 15:39:43,400 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_b    mapped name: layer2.1.conv1.bias\n",
            "2023-01-27 15:39:43,400 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_bn_b mapped name: layer2.1.bn1.bias\n",
            "2023-01-27 15:39:43,400 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_bn_s mapped name: layer2.1.bn1.weight\n",
            "2023-01-27 15:39:43,400 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_w    mapped name: layer2.1.conv1.weight\n",
            "2023-01-27 15:39:43,400 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_b    mapped name: layer2.1.conv2.bias\n",
            "2023-01-27 15:39:43,400 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_bn_b mapped name: layer2.1.bn2.bias\n",
            "2023-01-27 15:39:43,400 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_bn_s mapped name: layer2.1.bn2.weight\n",
            "2023-01-27 15:39:43,400 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_w    mapped name: layer2.1.conv2.weight\n",
            "2023-01-27 15:39:43,401 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_b    mapped name: layer2.1.conv3.bias\n",
            "2023-01-27 15:39:43,401 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_bn_b mapped name: layer2.1.bn3.bias\n",
            "2023-01-27 15:39:43,401 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_bn_s mapped name: layer2.1.bn3.weight\n",
            "2023-01-27 15:39:43,401 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_w    mapped name: layer2.1.conv3.weight\n",
            "2023-01-27 15:39:43,401 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_b    mapped name: layer2.2.conv1.bias\n",
            "2023-01-27 15:39:43,401 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_bn_b mapped name: layer2.2.bn1.bias\n",
            "2023-01-27 15:39:43,401 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_bn_s mapped name: layer2.2.bn1.weight\n",
            "2023-01-27 15:39:43,401 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_w    mapped name: layer2.2.conv1.weight\n",
            "2023-01-27 15:39:43,401 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_b    mapped name: layer2.2.conv2.bias\n",
            "2023-01-27 15:39:43,401 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_bn_b mapped name: layer2.2.bn2.bias\n",
            "2023-01-27 15:39:43,401 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_bn_s mapped name: layer2.2.bn2.weight\n",
            "2023-01-27 15:39:43,401 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_w    mapped name: layer2.2.conv2.weight\n",
            "2023-01-27 15:39:43,401 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_b    mapped name: layer2.2.conv3.bias\n",
            "2023-01-27 15:39:43,401 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_bn_b mapped name: layer2.2.bn3.bias\n",
            "2023-01-27 15:39:43,401 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_bn_s mapped name: layer2.2.bn3.weight\n",
            "2023-01-27 15:39:43,401 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_w    mapped name: layer2.2.conv3.weight\n",
            "2023-01-27 15:39:43,401 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_b    mapped name: layer2.3.conv1.bias\n",
            "2023-01-27 15:39:43,401 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_bn_b mapped name: layer2.3.bn1.bias\n",
            "2023-01-27 15:39:43,401 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_bn_s mapped name: layer2.3.bn1.weight\n",
            "2023-01-27 15:39:43,402 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_w    mapped name: layer2.3.conv1.weight\n",
            "2023-01-27 15:39:43,402 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_b    mapped name: layer2.3.conv2.bias\n",
            "2023-01-27 15:39:43,402 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_bn_b mapped name: layer2.3.bn2.bias\n",
            "2023-01-27 15:39:43,402 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_bn_s mapped name: layer2.3.bn2.weight\n",
            "2023-01-27 15:39:43,402 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_w    mapped name: layer2.3.conv2.weight\n",
            "2023-01-27 15:39:43,402 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_b    mapped name: layer2.3.conv3.bias\n",
            "2023-01-27 15:39:43,402 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_bn_b mapped name: layer2.3.bn3.bias\n",
            "2023-01-27 15:39:43,402 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_bn_s mapped name: layer2.3.bn3.weight\n",
            "2023-01-27 15:39:43,402 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_w    mapped name: layer2.3.conv3.weight\n",
            "2023-01-27 15:39:43,402 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch1_b     mapped name: layer3.0.downsample.0.bias\n",
            "2023-01-27 15:39:43,402 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch1_bn_b  mapped name: layer3.0.downsample.1.bias\n",
            "2023-01-27 15:39:43,402 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch1_bn_s  mapped name: layer3.0.downsample.1.weight\n",
            "2023-01-27 15:39:43,402 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch1_w     mapped name: layer3.0.downsample.0.weight\n",
            "2023-01-27 15:39:43,402 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_b    mapped name: layer3.0.conv1.bias\n",
            "2023-01-27 15:39:43,402 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_bn_b mapped name: layer3.0.bn1.bias\n",
            "2023-01-27 15:39:43,402 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_bn_s mapped name: layer3.0.bn1.weight\n",
            "2023-01-27 15:39:43,402 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_w    mapped name: layer3.0.conv1.weight\n",
            "2023-01-27 15:39:43,402 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_b    mapped name: layer3.0.conv2.bias\n",
            "2023-01-27 15:39:43,402 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_bn_b mapped name: layer3.0.bn2.bias\n",
            "2023-01-27 15:39:43,403 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_bn_s mapped name: layer3.0.bn2.weight\n",
            "2023-01-27 15:39:43,403 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_w    mapped name: layer3.0.conv2.weight\n",
            "2023-01-27 15:39:43,403 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_b    mapped name: layer3.0.conv3.bias\n",
            "2023-01-27 15:39:43,403 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_bn_b mapped name: layer3.0.bn3.bias\n",
            "2023-01-27 15:39:43,403 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_bn_s mapped name: layer3.0.bn3.weight\n",
            "2023-01-27 15:39:43,403 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_w    mapped name: layer3.0.conv3.weight\n",
            "2023-01-27 15:39:43,403 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_b    mapped name: layer3.1.conv1.bias\n",
            "2023-01-27 15:39:43,403 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_bn_b mapped name: layer3.1.bn1.bias\n",
            "2023-01-27 15:39:43,403 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_bn_s mapped name: layer3.1.bn1.weight\n",
            "2023-01-27 15:39:43,403 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_w    mapped name: layer3.1.conv1.weight\n",
            "2023-01-27 15:39:43,403 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_b    mapped name: layer3.1.conv2.bias\n",
            "2023-01-27 15:39:43,403 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_bn_b mapped name: layer3.1.bn2.bias\n",
            "2023-01-27 15:39:43,403 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_bn_s mapped name: layer3.1.bn2.weight\n",
            "2023-01-27 15:39:43,403 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_w    mapped name: layer3.1.conv2.weight\n",
            "2023-01-27 15:39:43,408 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_b    mapped name: layer3.1.conv3.bias\n",
            "2023-01-27 15:39:43,408 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_bn_b mapped name: layer3.1.bn3.bias\n",
            "2023-01-27 15:39:43,408 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_bn_s mapped name: layer3.1.bn3.weight\n",
            "2023-01-27 15:39:43,408 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_w    mapped name: layer3.1.conv3.weight\n",
            "2023-01-27 15:39:43,408 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_b    mapped name: layer3.2.conv1.bias\n",
            "2023-01-27 15:39:43,408 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_bn_b mapped name: layer3.2.bn1.bias\n",
            "2023-01-27 15:39:43,408 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_bn_s mapped name: layer3.2.bn1.weight\n",
            "2023-01-27 15:39:43,409 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_w    mapped name: layer3.2.conv1.weight\n",
            "2023-01-27 15:39:43,409 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_b    mapped name: layer3.2.conv2.bias\n",
            "2023-01-27 15:39:43,409 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_bn_b mapped name: layer3.2.bn2.bias\n",
            "2023-01-27 15:39:43,409 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_bn_s mapped name: layer3.2.bn2.weight\n",
            "2023-01-27 15:39:43,409 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_w    mapped name: layer3.2.conv2.weight\n",
            "2023-01-27 15:39:43,409 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_b    mapped name: layer3.2.conv3.bias\n",
            "2023-01-27 15:39:43,409 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_bn_b mapped name: layer3.2.bn3.bias\n",
            "2023-01-27 15:39:43,409 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_bn_s mapped name: layer3.2.bn3.weight\n",
            "2023-01-27 15:39:43,409 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_w    mapped name: layer3.2.conv3.weight\n",
            "2023-01-27 15:39:43,409 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_b    mapped name: layer3.3.conv1.bias\n",
            "2023-01-27 15:39:43,409 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_bn_b mapped name: layer3.3.bn1.bias\n",
            "2023-01-27 15:39:43,409 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_bn_s mapped name: layer3.3.bn1.weight\n",
            "2023-01-27 15:39:43,409 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_w    mapped name: layer3.3.conv1.weight\n",
            "2023-01-27 15:39:43,410 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_b    mapped name: layer3.3.conv2.bias\n",
            "2023-01-27 15:39:43,410 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_bn_b mapped name: layer3.3.bn2.bias\n",
            "2023-01-27 15:39:43,410 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_bn_s mapped name: layer3.3.bn2.weight\n",
            "2023-01-27 15:39:43,410 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_w    mapped name: layer3.3.conv2.weight\n",
            "2023-01-27 15:39:43,410 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_b    mapped name: layer3.3.conv3.bias\n",
            "2023-01-27 15:39:43,410 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_bn_b mapped name: layer3.3.bn3.bias\n",
            "2023-01-27 15:39:43,410 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_bn_s mapped name: layer3.3.bn3.weight\n",
            "2023-01-27 15:39:43,410 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_w    mapped name: layer3.3.conv3.weight\n",
            "2023-01-27 15:39:43,410 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_b    mapped name: layer3.4.conv1.bias\n",
            "2023-01-27 15:39:43,410 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_bn_b mapped name: layer3.4.bn1.bias\n",
            "2023-01-27 15:39:43,411 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_bn_s mapped name: layer3.4.bn1.weight\n",
            "2023-01-27 15:39:43,411 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_w    mapped name: layer3.4.conv1.weight\n",
            "2023-01-27 15:39:43,411 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_b    mapped name: layer3.4.conv2.bias\n",
            "2023-01-27 15:39:43,411 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_bn_b mapped name: layer3.4.bn2.bias\n",
            "2023-01-27 15:39:43,411 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_bn_s mapped name: layer3.4.bn2.weight\n",
            "2023-01-27 15:39:43,411 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_w    mapped name: layer3.4.conv2.weight\n",
            "2023-01-27 15:39:43,411 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_b    mapped name: layer3.4.conv3.bias\n",
            "2023-01-27 15:39:43,411 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_bn_b mapped name: layer3.4.bn3.bias\n",
            "2023-01-27 15:39:43,411 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_bn_s mapped name: layer3.4.bn3.weight\n",
            "2023-01-27 15:39:43,411 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_w    mapped name: layer3.4.conv3.weight\n",
            "2023-01-27 15:39:43,411 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_b    mapped name: layer3.5.conv1.bias\n",
            "2023-01-27 15:39:43,411 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_bn_b mapped name: layer3.5.bn1.bias\n",
            "2023-01-27 15:39:43,412 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_bn_s mapped name: layer3.5.bn1.weight\n",
            "2023-01-27 15:39:43,412 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_w    mapped name: layer3.5.conv1.weight\n",
            "2023-01-27 15:39:43,412 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_b    mapped name: layer3.5.conv2.bias\n",
            "2023-01-27 15:39:43,412 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_bn_b mapped name: layer3.5.bn2.bias\n",
            "2023-01-27 15:39:43,412 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_bn_s mapped name: layer3.5.bn2.weight\n",
            "2023-01-27 15:39:43,412 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_w    mapped name: layer3.5.conv2.weight\n",
            "2023-01-27 15:39:43,412 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_b    mapped name: layer3.5.conv3.bias\n",
            "2023-01-27 15:39:43,412 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_bn_b mapped name: layer3.5.bn3.bias\n",
            "2023-01-27 15:39:43,412 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_bn_s mapped name: layer3.5.bn3.weight\n",
            "2023-01-27 15:39:43,412 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_w    mapped name: layer3.5.conv3.weight\n",
            "2023-01-27 15:39:43,412 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch1_b     mapped name: layer4.0.downsample.0.bias\n",
            "2023-01-27 15:39:43,412 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch1_bn_b  mapped name: layer4.0.downsample.1.bias\n",
            "2023-01-27 15:39:43,413 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch1_bn_s  mapped name: layer4.0.downsample.1.weight\n",
            "2023-01-27 15:39:43,413 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch1_w     mapped name: layer4.0.downsample.0.weight\n",
            "2023-01-27 15:39:43,413 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_b    mapped name: layer4.0.conv1.bias\n",
            "2023-01-27 15:39:43,413 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_bn_b mapped name: layer4.0.bn1.bias\n",
            "2023-01-27 15:39:43,413 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_bn_s mapped name: layer4.0.bn1.weight\n",
            "2023-01-27 15:39:43,413 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_w    mapped name: layer4.0.conv1.weight\n",
            "2023-01-27 15:39:43,413 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_b    mapped name: layer4.0.conv2.bias\n",
            "2023-01-27 15:39:43,413 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_bn_b mapped name: layer4.0.bn2.bias\n",
            "2023-01-27 15:39:43,413 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_bn_s mapped name: layer4.0.bn2.weight\n",
            "2023-01-27 15:39:43,413 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_w    mapped name: layer4.0.conv2.weight\n",
            "2023-01-27 15:39:43,413 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_b    mapped name: layer4.0.conv3.bias\n",
            "2023-01-27 15:39:43,413 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_bn_b mapped name: layer4.0.bn3.bias\n",
            "2023-01-27 15:39:43,413 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_bn_s mapped name: layer4.0.bn3.weight\n",
            "2023-01-27 15:39:43,414 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_w    mapped name: layer4.0.conv3.weight\n",
            "2023-01-27 15:39:43,414 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_b    mapped name: layer4.1.conv1.bias\n",
            "2023-01-27 15:39:43,414 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_bn_b mapped name: layer4.1.bn1.bias\n",
            "2023-01-27 15:39:43,414 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_bn_s mapped name: layer4.1.bn1.weight\n",
            "2023-01-27 15:39:43,414 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_w    mapped name: layer4.1.conv1.weight\n",
            "2023-01-27 15:39:43,414 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_b    mapped name: layer4.1.conv2.bias\n",
            "2023-01-27 15:39:43,414 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_bn_b mapped name: layer4.1.bn2.bias\n",
            "2023-01-27 15:39:43,414 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_bn_s mapped name: layer4.1.bn2.weight\n",
            "2023-01-27 15:39:43,414 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_w    mapped name: layer4.1.conv2.weight\n",
            "2023-01-27 15:39:43,414 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_b    mapped name: layer4.1.conv3.bias\n",
            "2023-01-27 15:39:43,414 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_bn_b mapped name: layer4.1.bn3.bias\n",
            "2023-01-27 15:39:43,414 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_bn_s mapped name: layer4.1.bn3.weight\n",
            "2023-01-27 15:39:43,415 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_w    mapped name: layer4.1.conv3.weight\n",
            "2023-01-27 15:39:43,415 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_b    mapped name: layer4.2.conv1.bias\n",
            "2023-01-27 15:39:43,415 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_bn_b mapped name: layer4.2.bn1.bias\n",
            "2023-01-27 15:39:43,415 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_bn_s mapped name: layer4.2.bn1.weight\n",
            "2023-01-27 15:39:43,415 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_w    mapped name: layer4.2.conv1.weight\n",
            "2023-01-27 15:39:43,415 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_b    mapped name: layer4.2.conv2.bias\n",
            "2023-01-27 15:39:43,415 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_bn_b mapped name: layer4.2.bn2.bias\n",
            "2023-01-27 15:39:43,415 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_bn_s mapped name: layer4.2.bn2.weight\n",
            "2023-01-27 15:39:43,415 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_w    mapped name: layer4.2.conv2.weight\n",
            "2023-01-27 15:39:43,415 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_b    mapped name: layer4.2.conv3.bias\n",
            "2023-01-27 15:39:43,415 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_bn_b mapped name: layer4.2.bn3.bias\n",
            "2023-01-27 15:39:43,415 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_bn_s mapped name: layer4.2.bn3.weight\n",
            "2023-01-27 15:39:43,415 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_w    mapped name: layer4.2.conv3.weight\n",
            "2023-01-27 15:39:43,416 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res_conv1_bn_b       mapped name: bn1.bias\n",
            "2023-01-27 15:39:43,416 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res_conv1_bn_s       mapped name: bn1.weight\n",
            "2023-01-27 15:39:43,429 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.bias                  loaded from layer1.0.bn1.bias            of shape (64,)\n",
            "2023-01-27 15:39:43,430 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.weight                loaded from layer1.0.bn1.weight          of shape (64,)\n",
            "2023-01-27 15:39:43,430 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.bias                  loaded from layer1.0.bn2.bias            of shape (64,)\n",
            "2023-01-27 15:39:43,430 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.weight                loaded from layer1.0.bn2.weight          of shape (64,)\n",
            "2023-01-27 15:39:43,430 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.bias                  loaded from layer1.0.bn3.bias            of shape (256,)\n",
            "2023-01-27 15:39:43,430 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.weight                loaded from layer1.0.bn3.weight          of shape (256,)\n",
            "2023-01-27 15:39:43,430 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv1.weight              loaded from layer1.0.conv1.weight        of shape (64, 64, 1, 1)\n",
            "2023-01-27 15:39:43,430 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv2.weight              loaded from layer1.0.conv2.weight        of shape (64, 64, 3, 3)\n",
            "2023-01-27 15:39:43,430 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv3.weight              loaded from layer1.0.conv3.weight        of shape (256, 64, 1, 1)\n",
            "2023-01-27 15:39:43,430 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.0.weight       loaded from layer1.0.downsample.0.weight of shape (256, 64, 1, 1)\n",
            "2023-01-27 15:39:43,430 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.bias         loaded from layer1.0.downsample.1.bias   of shape (256,)\n",
            "2023-01-27 15:39:43,430 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.weight       loaded from layer1.0.downsample.1.weight of shape (256,)\n",
            "2023-01-27 15:39:43,430 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.bias                  loaded from layer1.1.bn1.bias            of shape (64,)\n",
            "2023-01-27 15:39:43,430 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.weight                loaded from layer1.1.bn1.weight          of shape (64,)\n",
            "2023-01-27 15:39:43,430 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.bias                  loaded from layer1.1.bn2.bias            of shape (64,)\n",
            "2023-01-27 15:39:43,430 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.weight                loaded from layer1.1.bn2.weight          of shape (64,)\n",
            "2023-01-27 15:39:43,430 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.bias                  loaded from layer1.1.bn3.bias            of shape (256,)\n",
            "2023-01-27 15:39:43,430 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.weight                loaded from layer1.1.bn3.weight          of shape (256,)\n",
            "2023-01-27 15:39:43,431 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv1.weight              loaded from layer1.1.conv1.weight        of shape (64, 256, 1, 1)\n",
            "2023-01-27 15:39:43,431 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv2.weight              loaded from layer1.1.conv2.weight        of shape (64, 64, 3, 3)\n",
            "2023-01-27 15:39:43,431 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv3.weight              loaded from layer1.1.conv3.weight        of shape (256, 64, 1, 1)\n",
            "2023-01-27 15:39:43,431 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.bias                  loaded from layer1.2.bn1.bias            of shape (64,)\n",
            "2023-01-27 15:39:43,431 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.weight                loaded from layer1.2.bn1.weight          of shape (64,)\n",
            "2023-01-27 15:39:43,431 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.bias                  loaded from layer1.2.bn2.bias            of shape (64,)\n",
            "2023-01-27 15:39:43,431 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.weight                loaded from layer1.2.bn2.weight          of shape (64,)\n",
            "2023-01-27 15:39:43,431 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.bias                  loaded from layer1.2.bn3.bias            of shape (256,)\n",
            "2023-01-27 15:39:43,431 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.weight                loaded from layer1.2.bn3.weight          of shape (256,)\n",
            "2023-01-27 15:39:43,431 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv1.weight              loaded from layer1.2.conv1.weight        of shape (64, 256, 1, 1)\n",
            "2023-01-27 15:39:43,431 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv2.weight              loaded from layer1.2.conv2.weight        of shape (64, 64, 3, 3)\n",
            "2023-01-27 15:39:43,431 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv3.weight              loaded from layer1.2.conv3.weight        of shape (256, 64, 1, 1)\n",
            "2023-01-27 15:39:43,432 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.bias                  loaded from layer2.0.bn1.bias            of shape (128,)\n",
            "2023-01-27 15:39:43,432 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.weight                loaded from layer2.0.bn1.weight          of shape (128,)\n",
            "2023-01-27 15:39:43,432 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.bias                  loaded from layer2.0.bn2.bias            of shape (128,)\n",
            "2023-01-27 15:39:43,432 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.weight                loaded from layer2.0.bn2.weight          of shape (128,)\n",
            "2023-01-27 15:39:43,432 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.bias                  loaded from layer2.0.bn3.bias            of shape (512,)\n",
            "2023-01-27 15:39:43,432 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.weight                loaded from layer2.0.bn3.weight          of shape (512,)\n",
            "2023-01-27 15:39:43,432 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv1.weight              loaded from layer2.0.conv1.weight        of shape (128, 256, 1, 1)\n",
            "2023-01-27 15:39:43,432 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv2.weight              loaded from layer2.0.conv2.weight        of shape (128, 128, 3, 3)\n",
            "2023-01-27 15:39:43,432 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv3.weight              loaded from layer2.0.conv3.weight        of shape (512, 128, 1, 1)\n",
            "2023-01-27 15:39:43,432 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.0.weight       loaded from layer2.0.downsample.0.weight of shape (512, 256, 1, 1)\n",
            "2023-01-27 15:39:43,432 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.bias         loaded from layer2.0.downsample.1.bias   of shape (512,)\n",
            "2023-01-27 15:39:43,432 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.weight       loaded from layer2.0.downsample.1.weight of shape (512,)\n",
            "2023-01-27 15:39:43,432 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.bias                  loaded from layer2.1.bn1.bias            of shape (128,)\n",
            "2023-01-27 15:39:43,432 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.weight                loaded from layer2.1.bn1.weight          of shape (128,)\n",
            "2023-01-27 15:39:43,433 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.bias                  loaded from layer2.1.bn2.bias            of shape (128,)\n",
            "2023-01-27 15:39:43,433 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.weight                loaded from layer2.1.bn2.weight          of shape (128,)\n",
            "2023-01-27 15:39:43,433 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.bias                  loaded from layer2.1.bn3.bias            of shape (512,)\n",
            "2023-01-27 15:39:43,433 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.weight                loaded from layer2.1.bn3.weight          of shape (512,)\n",
            "2023-01-27 15:39:43,433 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv1.weight              loaded from layer2.1.conv1.weight        of shape (128, 512, 1, 1)\n",
            "2023-01-27 15:39:43,433 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv2.weight              loaded from layer2.1.conv2.weight        of shape (128, 128, 3, 3)\n",
            "2023-01-27 15:39:43,433 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv3.weight              loaded from layer2.1.conv3.weight        of shape (512, 128, 1, 1)\n",
            "2023-01-27 15:39:43,433 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.bias                  loaded from layer2.2.bn1.bias            of shape (128,)\n",
            "2023-01-27 15:39:43,433 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.weight                loaded from layer2.2.bn1.weight          of shape (128,)\n",
            "2023-01-27 15:39:43,433 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.bias                  loaded from layer2.2.bn2.bias            of shape (128,)\n",
            "2023-01-27 15:39:43,433 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.weight                loaded from layer2.2.bn2.weight          of shape (128,)\n",
            "2023-01-27 15:39:43,433 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.bias                  loaded from layer2.2.bn3.bias            of shape (512,)\n",
            "2023-01-27 15:39:43,433 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.weight                loaded from layer2.2.bn3.weight          of shape (512,)\n",
            "2023-01-27 15:39:43,433 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv1.weight              loaded from layer2.2.conv1.weight        of shape (128, 512, 1, 1)\n",
            "2023-01-27 15:39:43,433 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv2.weight              loaded from layer2.2.conv2.weight        of shape (128, 128, 3, 3)\n",
            "2023-01-27 15:39:43,433 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv3.weight              loaded from layer2.2.conv3.weight        of shape (512, 128, 1, 1)\n",
            "2023-01-27 15:39:43,433 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.bias                  loaded from layer2.3.bn1.bias            of shape (128,)\n",
            "2023-01-27 15:39:43,433 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.weight                loaded from layer2.3.bn1.weight          of shape (128,)\n",
            "2023-01-27 15:39:43,433 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.bias                  loaded from layer2.3.bn2.bias            of shape (128,)\n",
            "2023-01-27 15:39:43,434 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.weight                loaded from layer2.3.bn2.weight          of shape (128,)\n",
            "2023-01-27 15:39:43,434 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.bias                  loaded from layer2.3.bn3.bias            of shape (512,)\n",
            "2023-01-27 15:39:43,434 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.weight                loaded from layer2.3.bn3.weight          of shape (512,)\n",
            "2023-01-27 15:39:43,434 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv1.weight              loaded from layer2.3.conv1.weight        of shape (128, 512, 1, 1)\n",
            "2023-01-27 15:39:43,434 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv2.weight              loaded from layer2.3.conv2.weight        of shape (128, 128, 3, 3)\n",
            "2023-01-27 15:39:43,434 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv3.weight              loaded from layer2.3.conv3.weight        of shape (512, 128, 1, 1)\n",
            "2023-01-27 15:39:43,434 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.bias                  loaded from layer3.0.bn1.bias            of shape (256,)\n",
            "2023-01-27 15:39:43,434 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.weight                loaded from layer3.0.bn1.weight          of shape (256,)\n",
            "2023-01-27 15:39:43,434 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.bias                  loaded from layer3.0.bn2.bias            of shape (256,)\n",
            "2023-01-27 15:39:43,434 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.weight                loaded from layer3.0.bn2.weight          of shape (256,)\n",
            "2023-01-27 15:39:43,434 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.bias                  loaded from layer3.0.bn3.bias            of shape (1024,)\n",
            "2023-01-27 15:39:43,434 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.weight                loaded from layer3.0.bn3.weight          of shape (1024,)\n",
            "2023-01-27 15:39:43,434 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv1.weight              loaded from layer3.0.conv1.weight        of shape (256, 512, 1, 1)\n",
            "2023-01-27 15:39:43,515 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv2.weight              loaded from layer3.0.conv2.weight        of shape (256, 256, 3, 3)\n",
            "2023-01-27 15:39:43,515 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv3.weight              loaded from layer3.0.conv3.weight        of shape (1024, 256, 1, 1)\n",
            "2023-01-27 15:39:43,515 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.0.weight       loaded from layer3.0.downsample.0.weight of shape (1024, 512, 1, 1)\n",
            "2023-01-27 15:39:43,515 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.bias         loaded from layer3.0.downsample.1.bias   of shape (1024,)\n",
            "2023-01-27 15:39:43,516 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.weight       loaded from layer3.0.downsample.1.weight of shape (1024,)\n",
            "2023-01-27 15:39:43,516 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.bias                  loaded from layer3.1.bn1.bias            of shape (256,)\n",
            "2023-01-27 15:39:43,516 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.weight                loaded from layer3.1.bn1.weight          of shape (256,)\n",
            "2023-01-27 15:39:43,516 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.bias                  loaded from layer3.1.bn2.bias            of shape (256,)\n",
            "2023-01-27 15:39:43,516 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.weight                loaded from layer3.1.bn2.weight          of shape (256,)\n",
            "2023-01-27 15:39:43,516 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.bias                  loaded from layer3.1.bn3.bias            of shape (1024,)\n",
            "2023-01-27 15:39:43,516 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.weight                loaded from layer3.1.bn3.weight          of shape (1024,)\n",
            "2023-01-27 15:39:43,516 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv1.weight              loaded from layer3.1.conv1.weight        of shape (256, 1024, 1, 1)\n",
            "2023-01-27 15:39:43,516 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv2.weight              loaded from layer3.1.conv2.weight        of shape (256, 256, 3, 3)\n",
            "2023-01-27 15:39:43,516 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv3.weight              loaded from layer3.1.conv3.weight        of shape (1024, 256, 1, 1)\n",
            "2023-01-27 15:39:43,516 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.bias                  loaded from layer3.2.bn1.bias            of shape (256,)\n",
            "2023-01-27 15:39:43,517 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.weight                loaded from layer3.2.bn1.weight          of shape (256,)\n",
            "2023-01-27 15:39:43,517 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.bias                  loaded from layer3.2.bn2.bias            of shape (256,)\n",
            "2023-01-27 15:39:43,517 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.weight                loaded from layer3.2.bn2.weight          of shape (256,)\n",
            "2023-01-27 15:39:43,517 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.bias                  loaded from layer3.2.bn3.bias            of shape (1024,)\n",
            "2023-01-27 15:39:43,517 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.weight                loaded from layer3.2.bn3.weight          of shape (1024,)\n",
            "2023-01-27 15:39:43,517 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv1.weight              loaded from layer3.2.conv1.weight        of shape (256, 1024, 1, 1)\n",
            "2023-01-27 15:39:43,517 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv2.weight              loaded from layer3.2.conv2.weight        of shape (256, 256, 3, 3)\n",
            "2023-01-27 15:39:43,517 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv3.weight              loaded from layer3.2.conv3.weight        of shape (1024, 256, 1, 1)\n",
            "2023-01-27 15:39:43,517 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.bias                  loaded from layer3.3.bn1.bias            of shape (256,)\n",
            "2023-01-27 15:39:43,517 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.weight                loaded from layer3.3.bn1.weight          of shape (256,)\n",
            "2023-01-27 15:39:43,517 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.bias                  loaded from layer3.3.bn2.bias            of shape (256,)\n",
            "2023-01-27 15:39:43,517 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.weight                loaded from layer3.3.bn2.weight          of shape (256,)\n",
            "2023-01-27 15:39:43,517 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.bias                  loaded from layer3.3.bn3.bias            of shape (1024,)\n",
            "2023-01-27 15:39:43,518 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.weight                loaded from layer3.3.bn3.weight          of shape (1024,)\n",
            "2023-01-27 15:39:43,518 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv1.weight              loaded from layer3.3.conv1.weight        of shape (256, 1024, 1, 1)\n",
            "2023-01-27 15:39:43,518 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv2.weight              loaded from layer3.3.conv2.weight        of shape (256, 256, 3, 3)\n",
            "2023-01-27 15:39:43,518 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv3.weight              loaded from layer3.3.conv3.weight        of shape (1024, 256, 1, 1)\n",
            "2023-01-27 15:39:43,518 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.bias                  loaded from layer3.4.bn1.bias            of shape (256,)\n",
            "2023-01-27 15:39:43,518 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.weight                loaded from layer3.4.bn1.weight          of shape (256,)\n",
            "2023-01-27 15:39:43,518 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.bias                  loaded from layer3.4.bn2.bias            of shape (256,)\n",
            "2023-01-27 15:39:43,518 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.weight                loaded from layer3.4.bn2.weight          of shape (256,)\n",
            "2023-01-27 15:39:43,518 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.bias                  loaded from layer3.4.bn3.bias            of shape (1024,)\n",
            "2023-01-27 15:39:43,518 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.weight                loaded from layer3.4.bn3.weight          of shape (1024,)\n",
            "2023-01-27 15:39:43,518 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv1.weight              loaded from layer3.4.conv1.weight        of shape (256, 1024, 1, 1)\n",
            "2023-01-27 15:39:43,518 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv2.weight              loaded from layer3.4.conv2.weight        of shape (256, 256, 3, 3)\n",
            "2023-01-27 15:39:43,518 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv3.weight              loaded from layer3.4.conv3.weight        of shape (1024, 256, 1, 1)\n",
            "2023-01-27 15:39:43,518 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.bias                  loaded from layer3.5.bn1.bias            of shape (256,)\n",
            "2023-01-27 15:39:43,518 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.weight                loaded from layer3.5.bn1.weight          of shape (256,)\n",
            "2023-01-27 15:39:43,518 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.bias                  loaded from layer3.5.bn2.bias            of shape (256,)\n",
            "2023-01-27 15:39:43,518 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.weight                loaded from layer3.5.bn2.weight          of shape (256,)\n",
            "2023-01-27 15:39:43,519 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.bias                  loaded from layer3.5.bn3.bias            of shape (1024,)\n",
            "2023-01-27 15:39:43,519 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.weight                loaded from layer3.5.bn3.weight          of shape (1024,)\n",
            "2023-01-27 15:39:43,519 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv1.weight              loaded from layer3.5.conv1.weight        of shape (256, 1024, 1, 1)\n",
            "2023-01-27 15:39:43,519 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv2.weight              loaded from layer3.5.conv2.weight        of shape (256, 256, 3, 3)\n",
            "2023-01-27 15:39:43,519 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv3.weight              loaded from layer3.5.conv3.weight        of shape (1024, 256, 1, 1)\n",
            "2023-01-27 15:39:43,519 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.bias                  loaded from layer4.0.bn1.bias            of shape (512,)\n",
            "2023-01-27 15:39:43,519 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.weight                loaded from layer4.0.bn1.weight          of shape (512,)\n",
            "2023-01-27 15:39:43,519 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.bias                  loaded from layer4.0.bn2.bias            of shape (512,)\n",
            "2023-01-27 15:39:43,519 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.weight                loaded from layer4.0.bn2.weight          of shape (512,)\n",
            "2023-01-27 15:39:43,519 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.bias                  loaded from layer4.0.bn3.bias            of shape (2048,)\n",
            "2023-01-27 15:39:43,519 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.weight                loaded from layer4.0.bn3.weight          of shape (2048,)\n",
            "2023-01-27 15:39:43,519 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv1.weight              loaded from layer4.0.conv1.weight        of shape (512, 1024, 1, 1)\n",
            "2023-01-27 15:39:43,519 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv2.weight              loaded from layer4.0.conv2.weight        of shape (512, 512, 3, 3)\n",
            "2023-01-27 15:39:43,519 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv3.weight              loaded from layer4.0.conv3.weight        of shape (2048, 512, 1, 1)\n",
            "2023-01-27 15:39:43,519 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.0.weight       loaded from layer4.0.downsample.0.weight of shape (2048, 1024, 1, 1)\n",
            "2023-01-27 15:39:43,519 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.bias         loaded from layer4.0.downsample.1.bias   of shape (2048,)\n",
            "2023-01-27 15:39:43,519 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.weight       loaded from layer4.0.downsample.1.weight of shape (2048,)\n",
            "2023-01-27 15:39:43,519 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.bias                  loaded from layer4.1.bn1.bias            of shape (512,)\n",
            "2023-01-27 15:39:43,519 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.weight                loaded from layer4.1.bn1.weight          of shape (512,)\n",
            "2023-01-27 15:39:43,520 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.bias                  loaded from layer4.1.bn2.bias            of shape (512,)\n",
            "2023-01-27 15:39:43,520 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.weight                loaded from layer4.1.bn2.weight          of shape (512,)\n",
            "2023-01-27 15:39:43,520 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.bias                  loaded from layer4.1.bn3.bias            of shape (2048,)\n",
            "2023-01-27 15:39:43,520 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.weight                loaded from layer4.1.bn3.weight          of shape (2048,)\n",
            "2023-01-27 15:39:43,520 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv1.weight              loaded from layer4.1.conv1.weight        of shape (512, 2048, 1, 1)\n",
            "2023-01-27 15:39:43,520 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv2.weight              loaded from layer4.1.conv2.weight        of shape (512, 512, 3, 3)\n",
            "2023-01-27 15:39:43,520 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv3.weight              loaded from layer4.1.conv3.weight        of shape (2048, 512, 1, 1)\n",
            "2023-01-27 15:39:43,520 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.bias                  loaded from layer4.2.bn1.bias            of shape (512,)\n",
            "2023-01-27 15:39:43,520 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.weight                loaded from layer4.2.bn1.weight          of shape (512,)\n",
            "2023-01-27 15:39:43,520 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.bias                  loaded from layer4.2.bn2.bias            of shape (512,)\n",
            "2023-01-27 15:39:43,520 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.weight                loaded from layer4.2.bn2.weight          of shape (512,)\n",
            "2023-01-27 15:39:43,520 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.bias                  loaded from layer4.2.bn3.bias            of shape (2048,)\n",
            "2023-01-27 15:39:43,520 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.weight                loaded from layer4.2.bn3.weight          of shape (2048,)\n",
            "2023-01-27 15:39:43,520 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv1.weight              loaded from layer4.2.conv1.weight        of shape (512, 2048, 1, 1)\n",
            "2023-01-27 15:39:43,520 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv2.weight              loaded from layer4.2.conv2.weight        of shape (512, 512, 3, 3)\n",
            "2023-01-27 15:39:43,520 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv3.weight              loaded from layer4.2.conv3.weight        of shape (2048, 512, 1, 1)\n",
            "2023-01-27 15:39:43,520 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.bias                      loaded from bn1.bias                     of shape (64,)\n",
            "2023-01-27 15:39:43,520 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.weight                    loaded from bn1.weight                   of shape (64,)\n",
            "2023-01-27 15:39:43,520 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.conv1.weight                  loaded from conv1.weight                 of shape (64, 3, 7, 7)\n",
            "2023-01-27 15:39:43,559 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
            "loading annotations into memory...\n",
            "Done (t=0.33s)\n",
            "creating index...\n",
            "index created!\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "2023-01-27 15:39:44,119 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
            "loading annotations into memory...\n",
            "Done (t=2.24s)\n",
            "creating index...\n",
            "index created!\n",
            "[Masking] Use color augmentation.\n",
            "2023-01-27 15:39:47,214 maskrcnn_benchmark.trainer INFO: Start training\n",
            "2023-01-27 15:39:47,214 maskrcnn_benchmark.trainer INFO: with_MIC: On\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/content/MIC/det/maskrcnn_benchmark/structures/bounding_box.py:206: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:27.)\n",
            "  bbox = BoxList(self.bbox[item], self.size, self.mode)\n",
            "/content/MIC/det/maskrcnn_benchmark/structures/bounding_box.py:208: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:27.)\n",
            "  bbox.add_field(k, v[item])\n",
            "/content/MIC/det/maskrcnn_benchmark/modeling/roi_heads/box_head/loss.py:195: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:27.)\n",
            "  class_logits = class_logits[domain_masks, :]\n",
            "/content/MIC/det/maskrcnn_benchmark/modeling/roi_heads/box_head/loss.py:196: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:27.)\n",
            "  box_regression = box_regression[domain_masks, :]\n",
            "/content/MIC/det/maskrcnn_benchmark/modeling/roi_heads/box_head/loss.py:197: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:27.)\n",
            "  labels = labels[domain_masks]\n",
            "/content/MIC/det/maskrcnn_benchmark/modeling/roi_heads/box_head/loss.py:198: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:27.)\n",
            "  regression_targets = regression_targets[domain_masks, :]\n",
            "/content/MIC/det/maskrcnn_benchmark/modeling/da_heads/loss.py:92: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/cuda/Indexing.cu:1239.)\n",
            "  da_img_label_per_level[masks, :] = 1\n",
            "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py:173: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:27.)\n",
            "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "2023-01-27 15:39:56,947 maskrcnn_benchmark.trainer INFO: eta: 6 days, 18:10:44 iter: 0 loss: 3.8684 (3.8684) loss_classifier: 0.7973 (0.7973) loss_box_reg: 0.0000 (0.0000) loss_objectness: 0.6994 (0.6994) loss_rpn_box_reg: 0.2377 (0.2377) loss_da_image: 0.6931 (0.6931) loss_da_instance: 0.6912 (0.6912) loss_da_consistency: 0.0103 (0.0103) loss_classifier_mask: 0.3938 (0.3938) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.3455 (0.3455) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 9.7307 (9.7307) data: 3.6973 (3.6973) lr: 0.000418 max mem: 7183\n",
            "2023-01-27 15:40:47,446 maskrcnn_benchmark.trainer INFO: eta: 1 day, 23:47:08 iter: 20 loss: 2.4494 (2.5736) loss_classifier: 0.2284 (0.2823) loss_box_reg: 0.0046 (0.0084) loss_objectness: 0.6344 (0.6235) loss_rpn_box_reg: 0.1391 (0.1817) loss_da_image: 0.6931 (0.6931) loss_da_instance: 0.6932 (0.6935) loss_da_consistency: 0.0057 (0.0065) loss_classifier_mask: 0.2419 (0.2489) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.3455 (0.3424) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 2.4787 (2.8681) data: 0.7513 (0.8849) lr: 0.000452 max mem: 8865\n",
            "2023-01-27 15:41:35,819 maskrcnn_benchmark.trainer INFO: eta: 1 day, 20:07:04 iter: 40 loss: 2.1015 (2.3371) loss_classifier: 0.1425 (0.2130) loss_box_reg: 0.0000 (0.0064) loss_objectness: 0.4503 (0.5356) loss_rpn_box_reg: 0.1117 (0.1485) loss_da_image: 0.6931 (0.6931) loss_da_instance: 0.6926 (0.6931) loss_da_consistency: 0.0016 (0.0041) loss_classifier_mask: 0.2419 (0.2489) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.3455 (0.3424) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 2.4112 (2.6488) data: 0.7288 (0.8104) lr: 0.000485 max mem: 8865\n",
            "2023-01-27 15:42:24,808 maskrcnn_benchmark.trainer INFO: eta: 1 day, 19:00:53 iter: 60 loss: 1.9251 (2.1977) loss_classifier: 0.1058 (0.1772) loss_box_reg: 0.0000 (0.0085) loss_objectness: 0.3287 (0.4620) loss_rpn_box_reg: 0.0948 (0.1316) loss_da_image: 0.6931 (0.6931) loss_da_instance: 0.6921 (0.6927) loss_da_consistency: 0.0017 (0.0034) loss_classifier_mask: 0.2419 (0.2489) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.3455 (0.3424) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 2.4353 (2.5835) data: 0.7429 (0.7893) lr: 0.000518 max mem: 8865\n",
            "2023-01-27 15:43:13,039 maskrcnn_benchmark.trainer INFO: eta: 1 day, 18:17:38 iter: 80 loss: 1.9074 (2.1370) loss_classifier: 0.1514 (0.1719) loss_box_reg: 0.0354 (0.0159) loss_objectness: 0.2211 (0.4106) loss_rpn_box_reg: 0.1106 (0.1274) loss_da_image: 0.6931 (0.6931) loss_da_instance: 0.6917 (0.6924) loss_da_consistency: 0.0047 (0.0037) loss_classifier_mask: 0.2419 (0.2489) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.3455 (0.3424) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 2.4110 (2.5410) data: 0.7326 (0.7756) lr: 0.000552 max mem: 8865\n",
            "2023-01-27 15:44:01,235 maskrcnn_benchmark.trainer INFO: eta: 1 day, 17:50:50 iter: 100 loss: 1.8500 (2.0833) loss_classifier: 0.1706 (0.1700) loss_box_reg: 0.0368 (0.0207) loss_objectness: 0.1709 (0.3656) loss_rpn_box_reg: 0.0775 (0.1201) loss_da_image: 0.6931 (0.6931) loss_da_instance: 0.6912 (0.6922) loss_da_consistency: 0.0054 (0.0040) loss_classifier_mask: 0.2419 (0.2489) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.3455 (0.3424) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 2.3980 (2.5150) data: 0.7274 (0.7668) lr: 0.000585 max mem: 8865\n",
            "2023-01-27 15:44:49,890 maskrcnn_benchmark.trainer INFO: eta: 1 day, 17:36:26 iter: 120 loss: 1.8556 (2.0467) loss_classifier: 0.1582 (0.1693) loss_box_reg: 0.0415 (0.0253) loss_objectness: 0.1384 (0.3310) loss_rpn_box_reg: 0.0895 (0.1175) loss_da_image: 0.6930 (0.6931) loss_da_instance: 0.6888 (0.6915) loss_da_consistency: 0.0061 (0.0044) loss_classifier_mask: 0.2419 (0.2489) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.3455 (0.3424) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 2.4178 (2.5014) data: 0.7282 (0.7616) lr: 0.000618 max mem: 8865\n",
            "2023-01-27 15:45:38,322 maskrcnn_benchmark.trainer INFO: eta: 1 day, 17:24:18 iter: 140 loss: 1.8055 (2.0189) loss_classifier: 0.1384 (0.1690) loss_box_reg: 0.0293 (0.0295) loss_objectness: 0.1121 (0.3033) loss_rpn_box_reg: 0.0943 (0.1153) loss_da_image: 0.6928 (0.6930) loss_da_instance: 0.6902 (0.6915) loss_da_consistency: 0.0060 (0.0046) loss_classifier_mask: 0.2419 (0.2489) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.3455 (0.3424) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 2.4075 (2.4901) data: 0.7312 (0.7580) lr: 0.000652 max mem: 8865\n",
            "2023-01-27 15:46:26,581 maskrcnn_benchmark.trainer INFO: eta: 1 day, 17:13:54 iter: 160 loss: 1.7016 (1.9872) loss_classifier: 0.1213 (0.1648) loss_box_reg: 0.0296 (0.0316) loss_objectness: 0.0893 (0.2783) loss_rpn_box_reg: 0.0599 (0.1123) loss_da_image: 0.6927 (0.6930) loss_da_instance: 0.6897 (0.6914) loss_da_consistency: 0.0059 (0.0048) loss_classifier_mask: 0.2419 (0.2489) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.3455 (0.3424) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 2.3961 (2.4805) data: 0.7267 (0.7550) lr: 0.000685 max mem: 8865\n",
            "2023-01-27 15:47:14,791 maskrcnn_benchmark.trainer INFO: eta: 1 day, 17:05:22 iter: 180 loss: 1.6492 (1.9568) loss_classifier: 0.1138 (0.1615) loss_box_reg: 0.0354 (0.0343) loss_objectness: 0.0677 (0.2552) loss_rpn_box_reg: 0.0516 (0.1069) loss_da_image: 0.6924 (0.6929) loss_da_instance: 0.6910 (0.6913) loss_da_consistency: 0.0060 (0.0049) loss_classifier_mask: 0.2419 (0.2489) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.3455 (0.3424) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 2.3980 (2.4728) data: 0.7217 (0.7525) lr: 0.000718 max mem: 8865\n",
            "2023-01-27 15:48:03,203 maskrcnn_benchmark.trainer INFO: eta: 1 day, 16:59:22 iter: 200 loss: 1.8237 (1.9472) loss_classifier: 0.1543 (0.1624) loss_box_reg: 0.0996 (0.0414) loss_objectness: 0.0739 (0.2411) loss_rpn_box_reg: 0.0528 (0.1045) loss_da_image: 0.6918 (0.6928) loss_da_instance: 0.6892 (0.6911) loss_da_consistency: 0.0061 (0.0051) loss_classifier_mask: 0.2419 (0.2489) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.3455 (0.3424) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 2.4102 (2.4676) data: 0.7302 (0.7510) lr: 0.000752 max mem: 8865\n",
            "2023-01-27 15:48:51,478 maskrcnn_benchmark.trainer INFO: eta: 1 day, 16:53:41 iter: 220 loss: 1.8410 (1.9427) loss_classifier: 0.1849 (0.1665) loss_box_reg: 0.0621 (0.0468) loss_objectness: 0.0877 (0.2283) loss_rpn_box_reg: 0.1086 (0.1044) loss_da_image: 0.6917 (0.6927) loss_da_instance: 0.6881 (0.6908) loss_da_consistency: 0.0061 (0.0051) loss_classifier_mask: 0.2419 (0.2489) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.3455 (0.3424) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 2.4049 (2.4627) data: 0.7343 (0.7497) lr: 0.000785 max mem: 8865\n",
            "2023-01-27 15:49:40,046 maskrcnn_benchmark.trainer INFO: eta: 1 day, 16:50:02 iter: 240 loss: 1.7796 (1.9350) loss_classifier: 0.1566 (0.1668) loss_box_reg: 0.0546 (0.0506) loss_objectness: 0.0925 (0.2188) loss_rpn_box_reg: 0.0742 (0.1031) loss_da_image: 0.6914 (0.6926) loss_da_instance: 0.6869 (0.6905) loss_da_consistency: 0.0054 (0.0052) loss_classifier_mask: 0.2419 (0.2489) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.3455 (0.3424) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 2.4320 (2.4599) data: 0.7338 (0.7486) lr: 0.000818 max mem: 8865\n",
            "2023-01-27 15:50:28,520 maskrcnn_benchmark.trainer INFO: eta: 1 day, 16:46:27 iter: 260 loss: 1.7890 (1.9245) loss_classifier: 0.1257 (0.1655) loss_box_reg: 0.0738 (0.0534) loss_objectness: 0.0751 (0.2089) loss_rpn_box_reg: 0.0694 (0.1020) loss_da_image: 0.6912 (0.6925) loss_da_instance: 0.6882 (0.6902) loss_da_consistency: 0.0050 (0.0052) loss_classifier_mask: 0.2419 (0.2489) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.3455 (0.3424) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 2.4160 (2.4571) data: 0.7326 (0.7477) lr: 0.000852 max mem: 8865\n",
            "2023-01-27 15:51:17,215 maskrcnn_benchmark.trainer INFO: eta: 1 day, 16:44:03 iter: 280 loss: 1.7737 (1.9154) loss_classifier: 0.1284 (0.1640) loss_box_reg: 0.0997 (0.0570) loss_objectness: 0.0610 (0.1997) loss_rpn_box_reg: 0.0693 (0.1003) loss_da_image: 0.6903 (0.6924) loss_da_instance: 0.6881 (0.6900) loss_da_consistency: 0.0054 (0.0052) loss_classifier_mask: 0.1108 (0.2138) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.3359 (0.2621) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 2.4070 (2.4555) data: 0.7260 (0.7469) lr: 0.000885 max mem: 8865\n",
            "2023-01-27 15:52:06,808 maskrcnn_benchmark.trainer INFO: eta: 1 day, 16:44:49 iter: 300 loss: 1.9292 (1.9141) loss_classifier: 0.1716 (0.1660) loss_box_reg: 0.1225 (0.0630) loss_objectness: 0.0622 (0.1914) loss_rpn_box_reg: 0.0683 (0.0995) loss_da_image: 0.6894 (0.6922) loss_da_instance: 0.6848 (0.6897) loss_da_consistency: 0.0058 (0.0052) loss_classifier_mask: 0.1087 (0.1482) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0210 (0.1524) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 2.4361 (2.4571) data: 0.7276 (0.7461) lr: 0.000918 max mem: 8865\n",
            "2023-01-27 15:53:00,656 maskrcnn_benchmark.trainer INFO: eta: 1 day, 16:58:35 iter: 320 loss: 1.8909 (1.9158) loss_classifier: 0.1663 (0.1660) loss_box_reg: 0.1313 (0.0675) loss_objectness: 0.0618 (0.1846) loss_rpn_box_reg: 0.1157 (0.1008) loss_da_image: 0.6881 (0.6919) loss_da_instance: 0.6875 (0.6896) loss_da_consistency: 0.0057 (0.0053) loss_classifier_mask: 0.0739 (0.1029) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0086 (0.0600) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 2.7195 (2.4718) data: 0.7238 (0.7451) lr: 0.000952 max mem: 8868\n",
            "2023-01-27 15:53:55,808 maskrcnn_benchmark.trainer INFO: eta: 1 day, 17:14:26 iter: 340 loss: 1.9342 (1.9174) loss_classifier: 0.1298 (0.1646) loss_box_reg: 0.1115 (0.0706) loss_objectness: 0.0920 (0.1806) loss_rpn_box_reg: 0.0853 (0.1010) loss_da_image: 0.6875 (0.6917) loss_da_instance: 0.6825 (0.6892) loss_da_consistency: 0.0062 (0.0053) loss_classifier_mask: 0.0787 (0.1023) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0132 (0.0427) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 2.7512 (2.4885) data: 0.7199 (0.7441) lr: 0.000985 max mem: 8868\n",
            "2023-01-27 15:54:52,698 maskrcnn_benchmark.trainer INFO: eta: 1 day, 17:33:12 iter: 360 loss: 1.8468 (1.9196) loss_classifier: 0.1668 (0.1660) loss_box_reg: 0.1595 (0.0770) loss_objectness: 0.0601 (0.1747) loss_rpn_box_reg: 0.0595 (0.0989) loss_da_image: 0.6861 (0.6914) loss_da_instance: 0.6849 (0.6888) loss_da_consistency: 0.0060 (0.0054) loss_classifier_mask: 0.0603 (0.0919) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0109 (0.0317) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 2.9875 (2.5083) data: 0.7039 (0.7425) lr: 0.001018 max mem: 8868\n",
            "2023-01-27 15:55:47,939 maskrcnn_benchmark.trainer INFO: eta: 1 day, 17:45:36 iter: 380 loss: 1.8484 (1.9198) loss_classifier: 0.1421 (0.1661) loss_box_reg: 0.1391 (0.0816) loss_objectness: 0.0601 (0.1689) loss_rpn_box_reg: 0.0578 (0.0974) loss_da_image: 0.6855 (0.6910) loss_da_instance: 0.6815 (0.6884) loss_da_consistency: 0.0059 (0.0054) loss_classifier_mask: 0.0794 (0.0904) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0071 (0.0259) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 2.7313 (2.5216) data: 0.7171 (0.7414) lr: 0.001052 max mem: 8868\n",
            "2023-01-27 15:56:45,806 maskrcnn_benchmark.trainer INFO: eta: 1 day, 18:03:11 iter: 400 loss: 1.9965 (1.9226) loss_classifier: 0.1641 (0.1679) loss_box_reg: 0.1581 (0.0864) loss_objectness: 0.0483 (0.1631) loss_rpn_box_reg: 0.0478 (0.0962) loss_da_image: 0.6845 (0.6908) loss_da_instance: 0.6760 (0.6879) loss_da_consistency: 0.0062 (0.0054) loss_classifier_mask: 0.0814 (0.0912) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0092 (0.0226) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 3.0162 (2.5401) data: 0.7114 (0.7404) lr: 0.001085 max mem: 8868\n",
            "2023-01-27 15:57:42,107 maskrcnn_benchmark.trainer INFO: eta: 1 day, 18:15:18 iter: 420 loss: 1.9179 (1.9250) loss_classifier: 0.1756 (0.1691) loss_box_reg: 0.1765 (0.0906) loss_objectness: 0.0762 (0.1588) loss_rpn_box_reg: 0.0717 (0.0967) loss_da_image: 0.6833 (0.6905) loss_da_instance: 0.6777 (0.6875) loss_da_consistency: 0.0065 (0.0055) loss_classifier_mask: 0.0398 (0.0855) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0053 (0.0201) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 2.7370 (2.5532) data: 0.7177 (0.7392) lr: 0.001118 max mem: 8868\n",
            "2023-01-27 15:58:40,381 maskrcnn_benchmark.trainer INFO: eta: 1 day, 18:30:41 iter: 440 loss: 1.8329 (1.9234) loss_classifier: 0.1526 (0.1692) loss_box_reg: 0.1351 (0.0931) loss_objectness: 0.0605 (0.1544) loss_rpn_box_reg: 0.0588 (0.0958) loss_da_image: 0.6828 (0.6903) loss_da_instance: 0.6762 (0.6869) loss_da_consistency: 0.0065 (0.0055) loss_classifier_mask: 0.0579 (0.0827) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0038 (0.0178) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 3.0212 (2.5695) data: 0.7157 (0.7384) lr: 0.001152 max mem: 8868\n",
            "2023-01-27 15:59:40,705 maskrcnn_benchmark.trainer INFO: eta: 1 day, 18:49:03 iter: 460 loss: 1.9657 (1.9268) loss_classifier: 0.1417 (0.1691) loss_box_reg: 0.1282 (0.0959) loss_objectness: 0.0590 (0.1504) loss_rpn_box_reg: 0.0530 (0.0943) loss_da_image: 0.6817 (0.6899) loss_da_instance: 0.6844 (0.6867) loss_da_consistency: 0.0067 (0.0056) loss_classifier_mask: 0.1629 (0.0945) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0129 (0.0172) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 3.0360 (2.5889) data: 0.7179 (0.7376) lr: 0.001185 max mem: 8868\n",
            "2023-01-27 16:00:41,435 maskrcnn_benchmark.trainer INFO: eta: 1 day, 19:06:39 iter: 480 loss: 2.0530 (1.9319) loss_classifier: 0.1909 (0.1702) loss_box_reg: 0.1784 (0.0991) loss_objectness: 0.0552 (0.1470) loss_rpn_box_reg: 0.0553 (0.0930) loss_da_image: 0.6826 (0.6897) loss_da_instance: 0.6748 (0.6861) loss_da_consistency: 0.0071 (0.0057) loss_classifier_mask: 0.1578 (0.1032) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0180 (0.0173) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 3.0328 (2.6075) data: 0.7092 (0.7367) lr: 0.001218 max mem: 8868\n",
            "2023-01-27 16:01:41,412 maskrcnn_benchmark.trainer INFO: eta: 1 day, 19:21:17 iter: 500 loss: 1.9950 (1.9349) loss_classifier: 0.1934 (0.1712) loss_box_reg: 0.2000 (0.1027) loss_objectness: 0.0497 (0.1433) loss_rpn_box_reg: 0.0775 (0.0927) loss_da_image: 0.6839 (0.6895) loss_da_instance: 0.6658 (0.6853) loss_da_consistency: 0.0079 (0.0058) loss_classifier_mask: 0.1044 (0.1044) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0089 (0.0165) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 3.0219 (2.6231) data: 0.7099 (0.7357) lr: 0.001250 max mem: 8868\n",
            "2023-01-27 16:02:41,894 maskrcnn_benchmark.trainer INFO: eta: 1 day, 19:35:40 iter: 520 loss: 2.0148 (1.9388) loss_classifier: 0.1942 (0.1736) loss_box_reg: 0.2196 (0.1072) loss_objectness: 0.0532 (0.1399) loss_rpn_box_reg: 0.0838 (0.0927) loss_da_image: 0.6848 (0.6893) loss_da_instance: 0.6644 (0.6845) loss_da_consistency: 0.0078 (0.0059) loss_classifier_mask: 0.0558 (0.1014) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0042 (0.0154) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 3.0320 (2.6385) data: 0.7162 (0.7350) lr: 0.001250 max mem: 8868\n",
            "2023-01-27 16:03:41,461 maskrcnn_benchmark.trainer INFO: eta: 1 day, 19:47:14 iter: 540 loss: 2.0283 (1.9429) loss_classifier: 0.1955 (0.1747) loss_box_reg: 0.1904 (0.1108) loss_objectness: 0.0440 (0.1378) loss_rpn_box_reg: 0.0661 (0.0926) loss_da_image: 0.6812 (0.6890) loss_da_instance: 0.6807 (0.6844) loss_da_consistency: 0.0083 (0.0060) loss_classifier_mask: 0.0794 (0.1003) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0054 (0.0146) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 3.0356 (2.6511) data: 0.7143 (0.7345) lr: 0.001250 max mem: 8868\n",
            "2023-01-27 16:04:41,128 maskrcnn_benchmark.trainer INFO: eta: 1 day, 19:58:05 iter: 560 loss: 1.8925 (1.9436) loss_classifier: 0.1654 (0.1753) loss_box_reg: 0.1569 (0.1136) loss_objectness: 0.0610 (0.1356) loss_rpn_box_reg: 0.0653 (0.0923) loss_da_image: 0.6834 (0.6887) loss_da_instance: 0.6652 (0.6835) loss_da_consistency: 0.0087 (0.0061) loss_classifier_mask: 0.0659 (0.0977) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0049 (0.0140) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 3.0293 (2.6629) data: 0.7168 (0.7340) lr: 0.001250 max mem: 8868\n",
            "2023-01-27 16:05:41,539 maskrcnn_benchmark.trainer INFO: eta: 1 day, 20:09:23 iter: 580 loss: 1.8431 (1.9422) loss_classifier: 0.1838 (0.1757) loss_box_reg: 0.1917 (0.1165) loss_objectness: 0.0571 (0.1328) loss_rpn_box_reg: 0.0494 (0.0916) loss_da_image: 0.6806 (0.6885) loss_da_instance: 0.6670 (0.6827) loss_da_consistency: 0.0101 (0.0062) loss_classifier_mask: 0.0351 (0.0933) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0025 (0.0132) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 3.0278 (2.6753) data: 0.7126 (0.7334) lr: 0.001250 max mem: 8868\n",
            "2023-01-27 16:06:42,112 maskrcnn_benchmark.trainer INFO: eta: 1 day, 20:20:08 iter: 600 loss: 2.0129 (1.9444) loss_classifier: 0.1859 (0.1765) loss_box_reg: 0.1747 (0.1189) loss_objectness: 0.0622 (0.1311) loss_rpn_box_reg: 0.0870 (0.0914) loss_da_image: 0.6816 (0.6883) loss_da_instance: 0.6579 (0.6818) loss_da_consistency: 0.0110 (0.0064) loss_classifier_mask: 0.0857 (0.0934) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0084 (0.0128) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 3.0272 (2.6870) data: 0.7102 (0.7327) lr: 0.001250 max mem: 8868\n",
            "2023-01-27 16:07:43,237 maskrcnn_benchmark.trainer INFO: eta: 1 day, 20:31:01 iter: 620 loss: 2.0024 (1.9464) loss_classifier: 0.2096 (0.1777) loss_box_reg: 0.2092 (0.1220) loss_objectness: 0.0521 (0.1289) loss_rpn_box_reg: 0.0956 (0.0918) loss_da_image: 0.6828 (0.6881) loss_da_instance: 0.6556 (0.6811) loss_da_consistency: 0.0099 (0.0065) loss_classifier_mask: 0.0440 (0.0908) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0027 (0.0122) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 3.0340 (2.6989) data: 0.7134 (0.7323) lr: 0.001250 max mem: 8868\n",
            "2023-01-27 16:08:42,941 maskrcnn_benchmark.trainer INFO: eta: 1 day, 20:38:57 iter: 640 loss: 1.9252 (1.9467) loss_classifier: 0.2072 (0.1788) loss_box_reg: 0.1750 (0.1243) loss_objectness: 0.0377 (0.1264) loss_rpn_box_reg: 0.0829 (0.0915) loss_da_image: 0.6830 (0.6880) loss_da_instance: 0.6678 (0.6805) loss_da_consistency: 0.0105 (0.0066) loss_classifier_mask: 0.0652 (0.0894) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0043 (0.0118) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 3.0448 (2.7078) data: 0.7106 (0.7318) lr: 0.001250 max mem: 8868\n",
            "2023-01-27 16:09:42,741 maskrcnn_benchmark.trainer INFO: eta: 1 day, 20:46:29 iter: 660 loss: 2.0010 (1.9489) loss_classifier: 0.2263 (0.1802) loss_box_reg: 0.2156 (0.1272) loss_objectness: 0.0478 (0.1242) loss_rpn_box_reg: 0.0622 (0.0912) loss_da_image: 0.6784 (0.6877) loss_da_instance: 0.6631 (0.6800) loss_da_consistency: 0.0107 (0.0067) loss_classifier_mask: 0.0700 (0.0885) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0034 (0.0114) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 3.0262 (2.7164) data: 0.7127 (0.7313) lr: 0.001250 max mem: 8868\n",
            "2023-01-27 16:10:43,275 maskrcnn_benchmark.trainer INFO: eta: 1 day, 20:54:36 iter: 680 loss: 1.9421 (1.9509) loss_classifier: 0.2269 (0.1817) loss_box_reg: 0.1940 (0.1297) loss_objectness: 0.0478 (0.1222) loss_rpn_box_reg: 0.0580 (0.0909) loss_da_image: 0.6787 (0.6875) loss_da_instance: 0.6669 (0.6795) loss_da_consistency: 0.0111 (0.0069) loss_classifier_mask: 0.0603 (0.0876) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0047 (0.0111) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 3.0355 (2.7255) data: 0.7152 (0.7310) lr: 0.001250 max mem: 8868\n",
            "2023-01-27 16:11:43,959 maskrcnn_benchmark.trainer INFO: eta: 1 day, 21:02:23 iter: 700 loss: 1.9039 (1.9507) loss_classifier: 0.1883 (0.1821) loss_box_reg: 0.1698 (0.1313) loss_objectness: 0.0507 (0.1206) loss_rpn_box_reg: 0.0881 (0.0909) loss_da_image: 0.6783 (0.6873) loss_da_instance: 0.6445 (0.6787) loss_da_consistency: 0.0126 (0.0070) loss_classifier_mask: 0.0449 (0.0861) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0028 (0.0107) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 3.0288 (2.7343) data: 0.7125 (0.7307) lr: 0.001250 max mem: 8868\n",
            "2023-01-27 16:12:43,999 maskrcnn_benchmark.trainer INFO: eta: 1 day, 21:08:49 iter: 720 loss: 1.8940 (1.9509) loss_classifier: 0.2136 (0.1832) loss_box_reg: 0.1950 (0.1334) loss_objectness: 0.0416 (0.1188) loss_rpn_box_reg: 0.0749 (0.0909) loss_da_image: 0.6789 (0.6870) loss_da_instance: 0.6511 (0.6778) loss_da_consistency: 0.0131 (0.0072) loss_classifier_mask: 0.0264 (0.0838) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0004 (0.0103) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 3.0410 (2.7417) data: 0.7118 (0.7305) lr: 0.001250 max mem: 8868\n",
            "2023-01-27 16:13:43,905 maskrcnn_benchmark.trainer INFO: eta: 1 day, 21:14:40 iter: 740 loss: 1.9104 (1.9499) loss_classifier: 0.2126 (0.1839) loss_box_reg: 0.2095 (0.1354) loss_objectness: 0.0442 (0.1170) loss_rpn_box_reg: 0.0589 (0.0901) loss_da_image: 0.6762 (0.6868) loss_da_instance: 0.6610 (0.6774) loss_da_consistency: 0.0147 (0.0074) loss_classifier_mask: 0.0192 (0.0811) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0007 (0.0099) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 3.0281 (2.7486) data: 0.7121 (0.7302) lr: 0.001250 max mem: 8868\n",
            "2023-01-27 16:14:43,970 maskrcnn_benchmark.trainer INFO: eta: 1 day, 21:20:21 iter: 760 loss: 1.9119 (1.9488) loss_classifier: 0.2029 (0.1845) loss_box_reg: 0.1873 (0.1368) loss_objectness: 0.0471 (0.1154) loss_rpn_box_reg: 0.0495 (0.0894) loss_da_image: 0.6722 (0.6864) loss_da_instance: 0.6443 (0.6766) loss_da_consistency: 0.0149 (0.0076) loss_classifier_mask: 0.0287 (0.0799) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0018 (0.0096) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 3.0257 (2.7553) data: 0.7095 (0.7298) lr: 0.001250 max mem: 8868\n",
            "2023-01-27 16:15:43,809 maskrcnn_benchmark.trainer INFO: eta: 1 day, 21:25:25 iter: 780 loss: 2.0083 (1.9492) loss_classifier: 0.2003 (0.1851) loss_box_reg: 0.1630 (0.1378) loss_objectness: 0.0483 (0.1140) loss_rpn_box_reg: 0.0565 (0.0889) loss_da_image: 0.6714 (0.6860) loss_da_instance: 0.6734 (0.6764) loss_da_consistency: 0.0151 (0.0078) loss_classifier_mask: 0.1005 (0.0805) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0065 (0.0095) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 3.0306 (2.7613) data: 0.7108 (0.7293) lr: 0.001250 max mem: 8868\n",
            "2023-01-27 16:16:43,893 maskrcnn_benchmark.trainer INFO: eta: 1 day, 21:30:29 iter: 800 loss: 1.8966 (1.9502) loss_classifier: 0.2026 (0.1858) loss_box_reg: 0.1507 (0.1387) loss_objectness: 0.0603 (0.1131) loss_rpn_box_reg: 0.0375 (0.0888) loss_da_image: 0.6738 (0.6858) loss_da_instance: 0.6742 (0.6763) loss_da_consistency: 0.0142 (0.0080) loss_classifier_mask: 0.0636 (0.0800) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0044 (0.0093) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 3.0331 (2.7674) data: 0.7125 (0.7289) lr: 0.001250 max mem: 8868\n",
            "2023-01-27 16:17:43,175 maskrcnn_benchmark.trainer INFO: eta: 1 day, 21:34:17 iter: 820 loss: 1.9532 (1.9507) loss_classifier: 0.2153 (0.1868) loss_box_reg: 0.2096 (0.1405) loss_objectness: 0.0407 (0.1116) loss_rpn_box_reg: 0.0717 (0.0884) loss_da_image: 0.6688 (0.6854) loss_da_instance: 0.6631 (0.6761) loss_da_consistency: 0.0147 (0.0082) loss_classifier_mask: 0.0405 (0.0788) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0030 (0.0091) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 3.0194 (2.7722) data: 0.7108 (0.7287) lr: 0.001250 max mem: 8868\n",
            "2023-01-27 16:18:43,381 maskrcnn_benchmark.trainer INFO: eta: 1 day, 21:38:57 iter: 840 loss: 1.9230 (1.9506) loss_classifier: 0.2376 (0.1878) loss_box_reg: 0.2184 (0.1425) loss_objectness: 0.0385 (0.1099) loss_rpn_box_reg: 0.0571 (0.0880) loss_da_image: 0.6635 (0.6849) loss_da_instance: 0.6622 (0.6757) loss_da_consistency: 0.0144 (0.0083) loss_classifier_mask: 0.0310 (0.0772) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0016 (0.0089) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 3.0422 (2.7778) data: 0.7099 (0.7286) lr: 0.001250 max mem: 8868\n",
            "2023-01-27 16:19:43,323 maskrcnn_benchmark.trainer INFO: eta: 1 day, 21:43:02 iter: 860 loss: 1.9703 (1.9511) loss_classifier: 0.2148 (0.1887) loss_box_reg: 0.1957 (0.1442) loss_objectness: 0.0327 (0.1085) loss_rpn_box_reg: 0.0925 (0.0881) loss_da_image: 0.6613 (0.6843) loss_da_instance: 0.6678 (0.6755) loss_da_consistency: 0.0159 (0.0085) loss_classifier_mask: 0.0426 (0.0761) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0033 (0.0087) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 3.0304 (2.7829) data: 0.7104 (0.7282) lr: 0.001250 max mem: 8868\n",
            "2023-01-27 16:20:43,057 maskrcnn_benchmark.trainer INFO: eta: 1 day, 21:46:40 iter: 880 loss: 1.8606 (1.9498) loss_classifier: 0.1947 (0.1889) loss_box_reg: 0.1805 (0.1450) loss_objectness: 0.0391 (0.1070) loss_rpn_box_reg: 0.0612 (0.0879) loss_da_image: 0.6614 (0.6838) loss_da_instance: 0.6693 (0.6753) loss_da_consistency: 0.0156 (0.0087) loss_classifier_mask: 0.0391 (0.0749) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0013 (0.0085) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 3.0229 (2.7876) data: 0.7123 (0.7280) lr: 0.001250 max mem: 8868\n",
            "2023-01-27 16:21:43,585 maskrcnn_benchmark.trainer INFO: eta: 1 day, 21:50:58 iter: 900 loss: 2.0236 (1.9520) loss_classifier: 0.2277 (0.1902) loss_box_reg: 0.2091 (0.1472) loss_objectness: 0.0352 (0.1056) loss_rpn_box_reg: 0.0729 (0.0877) loss_da_image: 0.6621 (0.6833) loss_da_instance: 0.6714 (0.6752) loss_da_consistency: 0.0154 (0.0088) loss_classifier_mask: 0.0819 (0.0752) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0064 (0.0084) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 3.0356 (2.7929) data: 0.7137 (0.7277) lr: 0.001250 max mem: 8868\n",
            "Traceback (most recent call last):\n",
            "  File \"tools/train_net.py\", line 270, in <module>\n",
            "    main()\n",
            "  File \"tools/train_net.py\", line 263, in main\n",
            "    model = train(cfg, args.local_rank, args.distributed)\n",
            "  File \"tools/train_net.py\", line 114, in train\n",
            "    do_mask_da_train(\n",
            "  File \"/content/MIC/det/maskrcnn_benchmark/engine/trainer.py\", line 240, in do_mask_da_train\n",
            "    record_dict = model(images, targets)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/MIC/det/maskrcnn_benchmark/modeling/detector/generalized_rcnn.py\", line 54, in forward\n",
            "    proposals, proposal_losses = self.rpn(images, features, targets, use_pseudo_labeling_weight=use_pseudo_labeling_weight)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/MIC/det/maskrcnn_benchmark/modeling/rpn/rpn.py\", line 100, in forward\n",
            "    return self._forward_train(anchors, objectness, rpn_box_regression, targets, use_pseudo_labeling_weight)\n",
            "  File \"/content/MIC/det/maskrcnn_benchmark/modeling/rpn/rpn.py\", line 115, in _forward_train\n",
            "    boxes = self.box_selector_train(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/MIC/det/maskrcnn_benchmark/modeling/rpn/inference.py\", line 138, in forward\n",
            "    sampled_boxes.append(self.forward_for_single_feature_map(a, o, b))\n",
            "  File \"/content/MIC/det/maskrcnn_benchmark/modeling/rpn/inference.py\", line 113, in forward_for_single_feature_map\n",
            "    boxlist = remove_small_boxes(boxlist, self.min_size)\n",
            "  File \"/content/MIC/det/maskrcnn_benchmark/structures/boxlist_ops.py\", line 45, in remove_small_boxes\n",
            "    keep = (\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}