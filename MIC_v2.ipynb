{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nimaone/adaptive_teacher/blob/main/MIC_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "34ziyIjQkWd4",
        "outputId": "96c2990b-3c22-470c-db3a-e707fe73e427",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Feb  5 17:47:01 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P0    26W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "!gcc --version"
      ],
      "metadata": {
        "id": "6rSV67T7kbMH",
        "outputId": "3a49c1d7-9d58-4481-c61e-062264822d43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.13.1+cu116 True\n",
            "gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n",
            "Copyright (C) 2019 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.12.0+cu113 torchvision==0.13.0+cu113 torchaudio==0.12.0 --extra-index-url https://download.pytorch.org/whl/cu113\n"
      ],
      "metadata": {
        "id": "Op0R5460r6pu",
        "outputId": "9b5b49c9-6d30-4736-8241-ba91cce407e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu113\n",
            "Collecting torch==1.12.0+cu113\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torch-1.12.0%2Bcu113-cp38-cp38-linux_x86_64.whl (1837.6 MB)\n",
            "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.8/1.8 GB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mtcmalloc: large alloc 1837596672 bytes == 0x354e000 @  0x7fa5f947b680 0x7fa5f949c824 0x5b3128 0x5bbc90 0x5f714c 0x64d800 0x527022 0x504866 0x56bbe1 0x569d8a 0x5f60c3 0x56bbe1 0x569d8a 0x5f60c3 0x56bbe1 0x569d8a 0x5f60c3 0x56bbe1 0x569d8a 0x5f60c3 0x56bbe1 0x569d8a 0x5f60c3 0x56bbe1 0x5f5ee6 0x56bbe1 0x569d8a 0x5f60c3 0x56cc92 0x569d8a 0x5f60c3\n",
            "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.8/1.8 GB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mtcmalloc: large alloc 2296995840 bytes == 0x70dc6000 @  0x7fa5f947b680 0x7fa5f949bda2 0x5f714c 0x64d800 0x527022 0x504866 0x56bbe1 0x569d8a 0x5f60c3 0x56bbe1 0x569d8a 0x5f60c3 0x56bbe1 0x569d8a 0x5f60c3 0x56bbe1 0x569d8a 0x5f60c3 0x56bbe1 0x569d8a 0x5f60c3 0x56bbe1 0x5f5ee6 0x56bbe1 0x569d8a 0x5f60c3 0x56cc92 0x569d8a 0x5f60c3 0x56bbe1 0x569d8a\n",
            "tcmalloc: large alloc 1837596672 bytes == 0x354e000 @  0x7fa5f947b680 0x7fa5f949c824 0x5f97c1 0x5f8ecc 0x504866 0x56bbe1 0x569d8a 0x5f60c3 0x56bbe1 0x569d8a 0x5f60c3 0x50b32c 0x5f6b7b 0x66731d 0x5f6706 0x571143 0x50b22e 0x570b82 0x569d8a 0x50b3a0 0x570b82 0x569d8a 0x50b3a0 0x56cc92 0x501044 0x56be83 0x501044 0x56be83 0x501044 0x56be83 0x5f5ee6\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 GB\u001b[0m \u001b[31m968.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.13.0+cu113\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torchvision-0.13.0%2Bcu113-cp38-cp38-linux_x86_64.whl (23.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.4/23.4 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==0.12.0\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torchaudio-0.12.0%2Bcu113-cp38-cp38-linux_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.12.0+cu113) (4.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision==0.13.0+cu113) (2.25.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision==0.13.0+cu113) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.13.0+cu113) (7.1.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.0+cu113) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.0+cu113) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.0+cu113) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.0+cu113) (4.0.0)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.1+cu116\n",
            "    Uninstalling torch-1.13.1+cu116:\n",
            "      Successfully uninstalled torch-1.13.1+cu116\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.14.1+cu116\n",
            "    Uninstalling torchvision-0.14.1+cu116:\n",
            "      Successfully uninstalled torchvision-0.14.1+cu116\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.13.1+cu116\n",
            "    Uninstalling torchaudio-0.13.1+cu116:\n",
            "      Successfully uninstalled torchaudio-0.13.1+cu116\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.14.1 requires torch==1.13.1, but you have torch 1.12.0+cu113 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.12.0+cu113 torchaudio-0.12.0+cu113 torchvision-0.13.0+cu113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "!gcc --version"
      ],
      "metadata": {
        "id": "D_AzhFiYszFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ninja==1.10.2.3 yacs==0.1.8 cython==0.29.28 matplotlib==3.5.1 tqdm==4.63.0 opencv-python==4.5.5.64\n"
      ],
      "metadata": {
        "id": "5scgehCjsN4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm==0.6.11 kornia==0.5.8 einops==0.4.1\n"
      ],
      "metadata": {
        "id": "OYUfcCsHsP-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ],
      "metadata": {
        "id": "NmxUj_p4sk5Q",
        "outputId": "5187b252-7f75-400c-9bef-0b577db34c46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "!git clone https://github.com/cocodataset/cocoapi.git\n",
        "%cd cocoapi/PythonAPI\n",
        "!python setup.py build_ext install"
      ],
      "metadata": {
        "id": "O3xePoZYsUaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "!git clone https://github.com/mcordts/cityscapesScripts.git\n",
        "%cd cityscapesScripts/\n",
        "!python setup.py build_ext install"
      ],
      "metadata": {
        "id": "PKvv135FtC4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "!git clone https://github.com/lhoyer/MIC\n",
        "%cd MIC/det\n",
        "# the following will install the lib with\n",
        "# symbolic links, so that you can modify\n",
        "# the files if you want and won't need to\n",
        "# re-build it\n",
        "!python setup.py build develop"
      ],
      "metadata": {
        "id": "zOc-a8vetRsZ",
        "outputId": "f78a8be2-5dd7-4374-e5ad-89ea4c969bac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'MIC'...\n",
            "remote: Enumerating objects: 455, done.\u001b[K\n",
            "remote: Counting objects: 100% (455/455), done.\u001b[K\n",
            "remote: Compressing objects: 100% (392/392), done.\u001b[K\n",
            "remote: Total 455 (delta 63), reused 444 (delta 56), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (455/455), 4.31 MiB | 9.24 MiB/s, done.\n",
            "Resolving deltas: 100% (63/63), done.\n",
            "/content/MIC/det\n",
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib.linux-x86_64-3.8\n",
            "creating build/lib.linux-x86_64-3.8/maskrcnn_benchmark\n",
            "copying maskrcnn_benchmark/__init__.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark\n",
            "creating build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling\n",
            "copying maskrcnn_benchmark/modeling/utils.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling\n",
            "copying maskrcnn_benchmark/modeling/make_layers.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling\n",
            "copying maskrcnn_benchmark/modeling/balanced_positive_negative_sampler.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling\n",
            "copying maskrcnn_benchmark/modeling/masking.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling\n",
            "copying maskrcnn_benchmark/modeling/poolers.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling\n",
            "copying maskrcnn_benchmark/modeling/__init__.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling\n",
            "copying maskrcnn_benchmark/modeling/registry.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling\n",
            "copying maskrcnn_benchmark/modeling/matcher.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling\n",
            "copying maskrcnn_benchmark/modeling/box_coder.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling\n",
            "copying maskrcnn_benchmark/modeling/teacher.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling\n",
            "creating build/lib.linux-x86_64-3.8/maskrcnn_benchmark/layers\n",
            "copying maskrcnn_benchmark/layers/roi_pool.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/layers\n",
            "copying maskrcnn_benchmark/layers/nms.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/layers\n",
            "copying maskrcnn_benchmark/layers/__init__.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/layers\n",
            "copying maskrcnn_benchmark/layers/sigmoid_focal_loss.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/layers\n",
            "copying maskrcnn_benchmark/layers/_utils.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/layers\n",
            "copying maskrcnn_benchmark/layers/smooth_l1_loss.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/layers\n",
            "copying maskrcnn_benchmark/layers/roi_align.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/layers\n",
            "copying maskrcnn_benchmark/layers/misc.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/layers\n",
            "copying maskrcnn_benchmark/layers/batch_norm.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/layers\n",
            "copying maskrcnn_benchmark/layers/consistency_loss.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/layers\n",
            "copying maskrcnn_benchmark/layers/gradient_scalar_layer.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/layers\n",
            "creating build/lib.linux-x86_64-3.8/maskrcnn_benchmark/data\n",
            "copying maskrcnn_benchmark/data/collate_batch.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/data\n",
            "copying maskrcnn_benchmark/data/__init__.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/data\n",
            "copying maskrcnn_benchmark/data/build.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/data\n",
            "creating build/lib.linux-x86_64-3.8/maskrcnn_benchmark/utils\n",
            "copying maskrcnn_benchmark/utils/imports.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/utils\n",
            "copying maskrcnn_benchmark/utils/comm.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/utils\n",
            "copying maskrcnn_benchmark/utils/checkpoint.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/utils\n",
            "copying maskrcnn_benchmark/utils/__init__.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/utils\n",
            "copying maskrcnn_benchmark/utils/registry.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/utils\n",
            "copying maskrcnn_benchmark/utils/cv2_util.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/utils\n",
            "copying maskrcnn_benchmark/utils/logger.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/utils\n",
            "copying maskrcnn_benchmark/utils/model_serialization.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/utils\n",
            "copying maskrcnn_benchmark/utils/model_zoo.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/utils\n",
            "copying maskrcnn_benchmark/utils/miscellaneous.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/utils\n",
            "copying maskrcnn_benchmark/utils/metric_logger.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/utils\n",
            "copying maskrcnn_benchmark/utils/collect_env.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/utils\n",
            "copying maskrcnn_benchmark/utils/c2_model_loading.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/utils\n",
            "copying maskrcnn_benchmark/utils/env.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/utils\n",
            "creating build/lib.linux-x86_64-3.8/maskrcnn_benchmark/solver\n",
            "copying maskrcnn_benchmark/solver/lr_scheduler.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/solver\n",
            "copying maskrcnn_benchmark/solver/__init__.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/solver\n",
            "copying maskrcnn_benchmark/solver/build.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/solver\n",
            "creating build/lib.linux-x86_64-3.8/maskrcnn_benchmark/config\n",
            "copying maskrcnn_benchmark/config/defaults.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/config\n",
            "copying maskrcnn_benchmark/config/__init__.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/config\n",
            "copying maskrcnn_benchmark/config/paths_catalog.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/config\n",
            "creating build/lib.linux-x86_64-3.8/maskrcnn_benchmark/engine\n",
            "copying maskrcnn_benchmark/engine/inference.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/engine\n",
            "copying maskrcnn_benchmark/engine/__init__.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/engine\n",
            "copying maskrcnn_benchmark/engine/trainer.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/engine\n",
            "creating build/lib.linux-x86_64-3.8/maskrcnn_benchmark/structures\n",
            "copying maskrcnn_benchmark/structures/boxlist_ops.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/structures\n",
            "copying maskrcnn_benchmark/structures/__init__.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/structures\n",
            "copying maskrcnn_benchmark/structures/bounding_box.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/structures\n",
            "copying maskrcnn_benchmark/structures/segmentation_mask.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/structures\n",
            "copying maskrcnn_benchmark/structures/image_list.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/structures\n",
            "copying maskrcnn_benchmark/structures/keypoint.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/structures\n",
            "creating build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/detector\n",
            "copying maskrcnn_benchmark/modeling/detector/__init__.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/detector\n",
            "copying maskrcnn_benchmark/modeling/detector/generalized_rcnn.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/detector\n",
            "copying maskrcnn_benchmark/modeling/detector/detectors.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/detector\n",
            "creating build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/backbone\n",
            "copying maskrcnn_benchmark/modeling/backbone/CustomLayers.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/backbone\n",
            "copying maskrcnn_benchmark/modeling/backbone/__init__.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/backbone\n",
            "copying maskrcnn_benchmark/modeling/backbone/resnet.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/backbone\n",
            "copying maskrcnn_benchmark/modeling/backbone/backbone.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/backbone\n",
            "copying maskrcnn_benchmark/modeling/backbone/fpn.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/backbone\n",
            "copying maskrcnn_benchmark/modeling/backbone/mixstyle.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/backbone\n",
            "creating build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/rpn\n",
            "copying maskrcnn_benchmark/modeling/rpn/utils.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/rpn\n",
            "copying maskrcnn_benchmark/modeling/rpn/inference.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/rpn\n",
            "copying maskrcnn_benchmark/modeling/rpn/loss.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/rpn\n",
            "copying maskrcnn_benchmark/modeling/rpn/__init__.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/rpn\n",
            "copying maskrcnn_benchmark/modeling/rpn/anchor_generator.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/rpn\n",
            "copying maskrcnn_benchmark/modeling/rpn/rpn.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/rpn\n",
            "creating build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/roi_heads\n",
            "copying maskrcnn_benchmark/modeling/roi_heads/__init__.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/roi_heads\n",
            "copying maskrcnn_benchmark/modeling/roi_heads/roi_heads.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/roi_heads\n",
            "creating build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/rpn/retinanet\n",
            "copying maskrcnn_benchmark/modeling/rpn/retinanet/inference.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/rpn/retinanet\n",
            "copying maskrcnn_benchmark/modeling/rpn/retinanet/loss.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/rpn/retinanet\n",
            "copying maskrcnn_benchmark/modeling/rpn/retinanet/__init__.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/rpn/retinanet\n",
            "copying maskrcnn_benchmark/modeling/rpn/retinanet/retinanet.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/rpn/retinanet\n",
            "creating build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/roi_heads/keypoint_head\n",
            "copying maskrcnn_benchmark/modeling/roi_heads/keypoint_head/inference.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/roi_heads/keypoint_head\n",
            "copying maskrcnn_benchmark/modeling/roi_heads/keypoint_head/loss.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/roi_heads/keypoint_head\n",
            "copying maskrcnn_benchmark/modeling/roi_heads/keypoint_head/roi_keypoint_feature_extractors.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/roi_heads/keypoint_head\n",
            "copying maskrcnn_benchmark/modeling/roi_heads/keypoint_head/__init__.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/roi_heads/keypoint_head\n",
            "copying maskrcnn_benchmark/modeling/roi_heads/keypoint_head/keypoint_head.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/roi_heads/keypoint_head\n",
            "copying maskrcnn_benchmark/modeling/roi_heads/keypoint_head/roi_keypoint_predictors.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/roi_heads/keypoint_head\n",
            "creating build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/roi_heads/box_head\n",
            "copying maskrcnn_benchmark/modeling/roi_heads/box_head/inference.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/roi_heads/box_head\n",
            "copying maskrcnn_benchmark/modeling/roi_heads/box_head/loss.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/roi_heads/box_head\n",
            "copying maskrcnn_benchmark/modeling/roi_heads/box_head/__init__.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/roi_heads/box_head\n",
            "copying maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_predictors.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/roi_heads/box_head\n",
            "copying maskrcnn_benchmark/modeling/roi_heads/box_head/box_head.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/roi_heads/box_head\n",
            "copying maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_feature_extractors.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/roi_heads/box_head\n",
            "creating build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/roi_heads/mask_head\n",
            "copying maskrcnn_benchmark/modeling/roi_heads/mask_head/inference.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/roi_heads/mask_head\n",
            "copying maskrcnn_benchmark/modeling/roi_heads/mask_head/loss.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/roi_heads/mask_head\n",
            "copying maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_predictors.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/roi_heads/mask_head\n",
            "copying maskrcnn_benchmark/modeling/roi_heads/mask_head/__init__.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/roi_heads/mask_head\n",
            "copying maskrcnn_benchmark/modeling/roi_heads/mask_head/mask_head.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/roi_heads/mask_head\n",
            "copying maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_feature_extractors.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/modeling/roi_heads/mask_head\n",
            "creating build/lib.linux-x86_64-3.8/maskrcnn_benchmark/data/samplers\n",
            "copying maskrcnn_benchmark/data/samplers/__init__.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/data/samplers\n",
            "copying maskrcnn_benchmark/data/samplers/grouped_batch_sampler.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/data/samplers\n",
            "copying maskrcnn_benchmark/data/samplers/iteration_based_batch_sampler.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/data/samplers\n",
            "copying maskrcnn_benchmark/data/samplers/distributed.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/data/samplers\n",
            "creating build/lib.linux-x86_64-3.8/maskrcnn_benchmark/data/transforms\n",
            "copying maskrcnn_benchmark/data/transforms/__init__.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/data/transforms\n",
            "copying maskrcnn_benchmark/data/transforms/build.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/data/transforms\n",
            "copying maskrcnn_benchmark/data/transforms/transforms.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/data/transforms\n",
            "creating build/lib.linux-x86_64-3.8/maskrcnn_benchmark/data/datasets\n",
            "copying maskrcnn_benchmark/data/datasets/__init__.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/data/datasets\n",
            "copying maskrcnn_benchmark/data/datasets/voc.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/data/datasets\n",
            "copying maskrcnn_benchmark/data/datasets/concat_dataset.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/data/datasets\n",
            "copying maskrcnn_benchmark/data/datasets/list_dataset.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/data/datasets\n",
            "copying maskrcnn_benchmark/data/datasets/coco.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/data/datasets\n",
            "creating build/lib.linux-x86_64-3.8/maskrcnn_benchmark/data/datasets/evaluation\n",
            "copying maskrcnn_benchmark/data/datasets/evaluation/__init__.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/data/datasets/evaluation\n",
            "creating build/lib.linux-x86_64-3.8/maskrcnn_benchmark/data/datasets/evaluation/voc\n",
            "copying maskrcnn_benchmark/data/datasets/evaluation/voc/__init__.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/data/datasets/evaluation/voc\n",
            "copying maskrcnn_benchmark/data/datasets/evaluation/voc/voc_eval.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/data/datasets/evaluation/voc\n",
            "creating build/lib.linux-x86_64-3.8/maskrcnn_benchmark/data/datasets/evaluation/coco\n",
            "copying maskrcnn_benchmark/data/datasets/evaluation/coco/__init__.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/data/datasets/evaluation/coco\n",
            "copying maskrcnn_benchmark/data/datasets/evaluation/coco/coco_eval.py -> build/lib.linux-x86_64-3.8/maskrcnn_benchmark/data/datasets/evaluation/coco\n",
            "running build_ext\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py:387: UserWarning: The detected CUDA version (11.2) has a minor version mismatch with the version that was used to compile PyTorch (11.6). Most likely this shouldn't be a problem.\n",
            "  warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
            "building 'maskrcnn_benchmark._C' extension\n",
            "creating build/temp.linux-x86_64-3.8\n",
            "creating build/temp.linux-x86_64-3.8/content\n",
            "creating build/temp.linux-x86_64-3.8/content/MIC\n",
            "creating build/temp.linux-x86_64-3.8/content/MIC/det\n",
            "creating build/temp.linux-x86_64-3.8/content/MIC/det/maskrcnn_benchmark\n",
            "creating build/temp.linux-x86_64-3.8/content/MIC/det/maskrcnn_benchmark/csrc\n",
            "creating build/temp.linux-x86_64-3.8/content/MIC/det/maskrcnn_benchmark/csrc/cpu\n",
            "creating build/temp.linux-x86_64-3.8/content/MIC/det/maskrcnn_benchmark/csrc/cuda\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/content/MIC/det/maskrcnn_benchmark/csrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c /content/MIC/det/maskrcnn_benchmark/csrc/vision.cpp -o build/temp.linux-x86_64-3.8/content/MIC/det/maskrcnn_benchmark/csrc/vision.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "In file included from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/vision.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/nms.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor nms(const at::Tensor&, const at::Tensor&, float)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/nms.h:14:17:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   14 |   if (dets.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.is_cuda()) {\n",
            "      |                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/nms.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/vision.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  216 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/ROIAlign.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor ROIAlign_forward(const at::Tensor&, const at::Tensor&, float, int, int, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/ROIAlign.h:17:18:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   17 |   if (input.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.is_cuda()) {\n",
            "      |                  \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/nms.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/vision.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  216 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/ROIAlign.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor ROIAlign_backward(const at::Tensor&, const at::Tensor&, float, int, int, int, int, int, int, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/ROIAlign.h:37:17:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   37 |   if (grad.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.is_cuda()) {\n",
            "      |                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/nms.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/vision.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  216 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/vision.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/ROIPool.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kstd::tuple<at::Tensor, at::Tensor> ROIPool_forward(const at::Tensor&, const at::Tensor&, float, int, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/ROIPool.h:16:18:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   16 |   if (input.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.is_cuda()) {\n",
            "      |                  \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/nms.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/vision.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  216 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/vision.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/ROIPool.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor ROIPool_backward(const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, float, int, int, int, int, int, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/ROIPool.h:37:17:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   37 |   if (grad.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.is_cuda()) {\n",
            "      |                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/nms.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/vision.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  216 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/vision.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/SigmoidFocalLoss.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor SigmoidFocalLoss_forward(const at::Tensor&, const at::Tensor&, int, float, float)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/SigmoidFocalLoss.h:16:19:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   16 |   if (logits.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.is_cuda()) {\n",
            "      |                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/nms.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/vision.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  216 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/vision.cpp:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/SigmoidFocalLoss.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor SigmoidFocalLoss_backward(const at::Tensor&, const at::Tensor&, const at::Tensor&, int, float, float)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/SigmoidFocalLoss.h:33:19:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   33 |   if (logits.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.is_cuda()) {\n",
            "      |                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/nms.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/vision.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  216 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/content/MIC/det/maskrcnn_benchmark/csrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c /content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp -o build/temp.linux-x86_64-3.8/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor ROIAlign_forward_cpu(const at::Tensor&, const at::Tensor&, float, int, int, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:227:26:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  227 |   AT_ASSERTM(!input.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.is_cuda(), \"input must be a CPU tensor\");\n",
            "      |                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:264:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KC10_EXPAND_MSVC_WORKAROUND\u001b[m\u001b[K’\n",
            "  264 | #define C10_EXPAND_MSVC_WORKAROUND(x) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K\n",
            "      |                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:284:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY\u001b[m\u001b[K’\n",
            "  284 | #define C10_UNLIKELY_OR_CONST(e) \u001b[01;36m\u001b[KC10_UNLIKELY\u001b[m\u001b[K(e)\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:336:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K’\n",
            "  336 |   if (\u001b[01;36m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K(!(cond))) {                                          \\\n",
            "      |       \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:631:32:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K’\n",
            "  631 |     C10_EXPAND_MSVC_WORKAROUND(\u001b[01;36m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K(cond, __VA_ARGS__)); \\\n",
            "      |                                \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:227:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_ASSERTM\u001b[m\u001b[K’\n",
            "  227 |   \u001b[01;36m\u001b[KAT_ASSERTM\u001b[m\u001b[K(!input.type().is_cuda(), \"input must be a CPU tensor\");\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  216 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:228:25:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  228 |   AT_ASSERTM(!rois.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.is_cuda(), \"rois must be a CPU tensor\");\n",
            "      |                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:264:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KC10_EXPAND_MSVC_WORKAROUND\u001b[m\u001b[K’\n",
            "  264 | #define C10_EXPAND_MSVC_WORKAROUND(x) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K\n",
            "      |                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:284:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY\u001b[m\u001b[K’\n",
            "  284 | #define C10_UNLIKELY_OR_CONST(e) \u001b[01;36m\u001b[KC10_UNLIKELY\u001b[m\u001b[K(e)\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:336:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K’\n",
            "  336 |   if (\u001b[01;36m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K(!(cond))) {                                          \\\n",
            "      |       \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:631:32:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K’\n",
            "  631 |     C10_EXPAND_MSVC_WORKAROUND(\u001b[01;36m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K(cond, __VA_ARGS__)); \\\n",
            "      |                                \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:228:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_ASSERTM\u001b[m\u001b[K’\n",
            "  228 |   \u001b[01;36m\u001b[KAT_ASSERTM\u001b[m\u001b[K(!rois.type().is_cuda(), \"rois must be a CPU tensor\");\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  216 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:242:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  242 |   AT_DISPATCH_FLOATING_TYPES(input.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K, \"ROIAlign_forward\", [&] {\n",
            "      |                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:238:28:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KAT_DISPATCH_SWITCH\u001b[m\u001b[K’\n",
            "  238 |     const auto& the_type = \u001b[01;36m\u001b[KTYPE\u001b[m\u001b[K;                                            \\\n",
            "      |                            \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:242:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K’\n",
            "  242 |   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K(input.type(), \"ROIAlign_forward\", [&] {\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  216 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:241:56:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  241 |     at::ScalarType _st = ::detail::scalar_type(the_type\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                   \\\n",
            "      |                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:260:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_SWITCH\u001b[m\u001b[K’\n",
            "  260 |   \u001b[01;36m\u001b[KAT_DISPATCH_SWITCH\u001b[m\u001b[K(TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__))\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:242:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K’\n",
            "  242 |   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K(input.type(), \"ROIAlign_forward\", [&] {\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:132:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  132 | inline at::ScalarType \u001b[01;36m\u001b[Kscalar_type\u001b[m\u001b[K(const at::DeprecatedTypeProperties& t) {\n",
            "      |                       \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:241:56:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  241 |     at::ScalarType _st = ::detail::scalar_type(the_type\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                   \\\n",
            "      |                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:260:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_SWITCH\u001b[m\u001b[K’\n",
            "  260 |   \u001b[01;36m\u001b[KAT_DISPATCH_SWITCH\u001b[m\u001b[K(TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__))\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:242:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K’\n",
            "  242 |   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K(input.type(), \"ROIAlign_forward\", [&] {\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:132:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  132 | inline at::ScalarType \u001b[01;36m\u001b[Kscalar_type\u001b[m\u001b[K(const at::DeprecatedTypeProperties& t) {\n",
            "      |                       \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:245:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  245 |          input.data<scalar_t>(\u001b[01;35m\u001b[K)\u001b[m\u001b[K,\n",
            "      |                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:244:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KAT_DISPATCH_SWITCH\u001b[m\u001b[K’\n",
            "  244 |       \u001b[01;36m\u001b[K__VA_ARGS__\u001b[m\u001b[K                                                           \\\n",
            "      |       \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:97:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_PRIVATE_CASE_TYPE_USING_HINT\u001b[m\u001b[K’\n",
            "   97 |   \u001b[01;36m\u001b[KAT_PRIVATE_CASE_TYPE_USING_HINT\u001b[m\u001b[K(enum_type, scalar_t, __VA_ARGS__)\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:256:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_CASE\u001b[m\u001b[K’\n",
            "  256 |   \u001b[01;36m\u001b[KAT_DISPATCH_CASE\u001b[m\u001b[K(at::ScalarType::Double, __VA_ARGS__) \\\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:260:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_CASE_FLOATING_TYPES\u001b[m\u001b[K’\n",
            "  260 |   AT_DISPATCH_SWITCH(TYPE, NAME, \u001b[01;36m\u001b[KAT_DISPATCH_CASE_FLOATING_TYPES\u001b[m\u001b[K(__VA_ARGS__))\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:242:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K’\n",
            "  242 |   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K(input.type(), \"ROIAlign_forward\", [&] {\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 |   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "      |       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:253:30:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  253 |          rois.data<scalar_t>(\u001b[01;35m\u001b[K)\u001b[m\u001b[K,\n",
            "      |                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:244:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KAT_DISPATCH_SWITCH\u001b[m\u001b[K’\n",
            "  244 |       \u001b[01;36m\u001b[K__VA_ARGS__\u001b[m\u001b[K                                                           \\\n",
            "      |       \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:97:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_PRIVATE_CASE_TYPE_USING_HINT\u001b[m\u001b[K’\n",
            "   97 |   \u001b[01;36m\u001b[KAT_PRIVATE_CASE_TYPE_USING_HINT\u001b[m\u001b[K(enum_type, scalar_t, __VA_ARGS__)\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:256:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_CASE\u001b[m\u001b[K’\n",
            "  256 |   \u001b[01;36m\u001b[KAT_DISPATCH_CASE\u001b[m\u001b[K(at::ScalarType::Double, __VA_ARGS__) \\\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:260:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_CASE_FLOATING_TYPES\u001b[m\u001b[K’\n",
            "  260 |   AT_DISPATCH_SWITCH(TYPE, NAME, \u001b[01;36m\u001b[KAT_DISPATCH_CASE_FLOATING_TYPES\u001b[m\u001b[K(__VA_ARGS__))\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:242:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K’\n",
            "  242 |   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K(input.type(), \"ROIAlign_forward\", [&] {\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 |   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "      |       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:254:32:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  254 |          output.data<scalar_t>(\u001b[01;35m\u001b[K)\u001b[m\u001b[K);\n",
            "      |                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:244:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KAT_DISPATCH_SWITCH\u001b[m\u001b[K’\n",
            "  244 |       \u001b[01;36m\u001b[K__VA_ARGS__\u001b[m\u001b[K                                                           \\\n",
            "      |       \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:97:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_PRIVATE_CASE_TYPE_USING_HINT\u001b[m\u001b[K’\n",
            "   97 |   \u001b[01;36m\u001b[KAT_PRIVATE_CASE_TYPE_USING_HINT\u001b[m\u001b[K(enum_type, scalar_t, __VA_ARGS__)\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:256:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_CASE\u001b[m\u001b[K’\n",
            "  256 |   \u001b[01;36m\u001b[KAT_DISPATCH_CASE\u001b[m\u001b[K(at::ScalarType::Double, __VA_ARGS__) \\\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:260:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_CASE_FLOATING_TYPES\u001b[m\u001b[K’\n",
            "  260 |   AT_DISPATCH_SWITCH(TYPE, NAME, \u001b[01;36m\u001b[KAT_DISPATCH_CASE_FLOATING_TYPES\u001b[m\u001b[K(__VA_ARGS__))\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:242:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K’\n",
            "  242 |   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K(input.type(), \"ROIAlign_forward\", [&] {\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 |   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "      |       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:245:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  245 |          input.data<scalar_t>(\u001b[01;35m\u001b[K)\u001b[m\u001b[K,\n",
            "      |                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:244:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KAT_DISPATCH_SWITCH\u001b[m\u001b[K’\n",
            "  244 |       \u001b[01;36m\u001b[K__VA_ARGS__\u001b[m\u001b[K                                                           \\\n",
            "      |       \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:97:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_PRIVATE_CASE_TYPE_USING_HINT\u001b[m\u001b[K’\n",
            "   97 |   \u001b[01;36m\u001b[KAT_PRIVATE_CASE_TYPE_USING_HINT\u001b[m\u001b[K(enum_type, scalar_t, __VA_ARGS__)\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:257:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_CASE\u001b[m\u001b[K’\n",
            "  257 |   \u001b[01;36m\u001b[KAT_DISPATCH_CASE\u001b[m\u001b[K(at::ScalarType::Float, __VA_ARGS__)\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:260:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_CASE_FLOATING_TYPES\u001b[m\u001b[K’\n",
            "  260 |   AT_DISPATCH_SWITCH(TYPE, NAME, \u001b[01;36m\u001b[KAT_DISPATCH_CASE_FLOATING_TYPES\u001b[m\u001b[K(__VA_ARGS__))\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:242:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K’\n",
            "  242 |   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K(input.type(), \"ROIAlign_forward\", [&] {\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 |   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "      |       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:253:30:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  253 |          rois.data<scalar_t>(\u001b[01;35m\u001b[K)\u001b[m\u001b[K,\n",
            "      |                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:244:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KAT_DISPATCH_SWITCH\u001b[m\u001b[K’\n",
            "  244 |       \u001b[01;36m\u001b[K__VA_ARGS__\u001b[m\u001b[K                                                           \\\n",
            "      |       \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:97:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_PRIVATE_CASE_TYPE_USING_HINT\u001b[m\u001b[K’\n",
            "   97 |   \u001b[01;36m\u001b[KAT_PRIVATE_CASE_TYPE_USING_HINT\u001b[m\u001b[K(enum_type, scalar_t, __VA_ARGS__)\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:257:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_CASE\u001b[m\u001b[K’\n",
            "  257 |   \u001b[01;36m\u001b[KAT_DISPATCH_CASE\u001b[m\u001b[K(at::ScalarType::Float, __VA_ARGS__)\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:260:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_CASE_FLOATING_TYPES\u001b[m\u001b[K’\n",
            "  260 |   AT_DISPATCH_SWITCH(TYPE, NAME, \u001b[01;36m\u001b[KAT_DISPATCH_CASE_FLOATING_TYPES\u001b[m\u001b[K(__VA_ARGS__))\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:242:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K’\n",
            "  242 |   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K(input.type(), \"ROIAlign_forward\", [&] {\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 |   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "      |       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:254:32:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  254 |          output.data<scalar_t>(\u001b[01;35m\u001b[K)\u001b[m\u001b[K);\n",
            "      |                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:244:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KAT_DISPATCH_SWITCH\u001b[m\u001b[K’\n",
            "  244 |       \u001b[01;36m\u001b[K__VA_ARGS__\u001b[m\u001b[K                                                           \\\n",
            "      |       \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:97:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_PRIVATE_CASE_TYPE_USING_HINT\u001b[m\u001b[K’\n",
            "   97 |   \u001b[01;36m\u001b[KAT_PRIVATE_CASE_TYPE_USING_HINT\u001b[m\u001b[K(enum_type, scalar_t, __VA_ARGS__)\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:257:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_CASE\u001b[m\u001b[K’\n",
            "  257 |   \u001b[01;36m\u001b[KAT_DISPATCH_CASE\u001b[m\u001b[K(at::ScalarType::Float, __VA_ARGS__)\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:260:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_CASE_FLOATING_TYPES\u001b[m\u001b[K’\n",
            "  260 |   AT_DISPATCH_SWITCH(TYPE, NAME, \u001b[01;36m\u001b[KAT_DISPATCH_CASE_FLOATING_TYPES\u001b[m\u001b[K(__VA_ARGS__))\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:242:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K’\n",
            "  242 |   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K(input.type(), \"ROIAlign_forward\", [&] {\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 |   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "      |       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/content/MIC/det/maskrcnn_benchmark/csrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c /content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp -o build/temp.linux-x86_64-3.8/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:71:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   71 |   AT_DISPATCH_FLOATING_TYPES(dets.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K, \"nms\", [&] {\n",
            "      |                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:238:28:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KAT_DISPATCH_SWITCH\u001b[m\u001b[K’\n",
            "  238 |     const auto& the_type = \u001b[01;36m\u001b[KTYPE\u001b[m\u001b[K;                                            \\\n",
            "      |                            \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:71:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K’\n",
            "   71 |   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K(dets.type(), \"nms\", [&] {\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  216 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:241:56:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  241 |     at::ScalarType _st = ::detail::scalar_type(the_type\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                   \\\n",
            "      |                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:260:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_SWITCH\u001b[m\u001b[K’\n",
            "  260 |   \u001b[01;36m\u001b[KAT_DISPATCH_SWITCH\u001b[m\u001b[K(TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__))\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:71:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K’\n",
            "   71 |   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K(dets.type(), \"nms\", [&] {\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:132:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  132 | inline at::ScalarType \u001b[01;36m\u001b[Kscalar_type\u001b[m\u001b[K(const at::DeprecatedTypeProperties& t) {\n",
            "      |                       \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:241:56:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  241 |     at::ScalarType _st = ::detail::scalar_type(the_type\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                   \\\n",
            "      |                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:260:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_SWITCH\u001b[m\u001b[K’\n",
            "  260 |   \u001b[01;36m\u001b[KAT_DISPATCH_SWITCH\u001b[m\u001b[K(TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__))\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:71:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K’\n",
            "   71 |   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K(dets.type(), \"nms\", [&] {\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:132:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  132 | inline at::ScalarType \u001b[01;36m\u001b[Kscalar_type\u001b[m\u001b[K(const at::DeprecatedTypeProperties& t) {\n",
            "      |                       \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp: In instantiation of ‘\u001b[01m\u001b[Kat::Tensor nms_cpu_kernel(const at::Tensor&, const at::Tensor&, float) [with scalar_t = double]\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:71:3:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:9:24:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "    9 |   AT_ASSERTM(!\u001b[01;35m\u001b[Kdets.type()\u001b[m\u001b[K.is_cuda(), \"dets must be a CPU tensor\");\n",
            "      |               \u001b[01;35m\u001b[K~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:264:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KC10_EXPAND_MSVC_WORKAROUND\u001b[m\u001b[K’\n",
            "  264 | #define C10_EXPAND_MSVC_WORKAROUND(x) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K\n",
            "      |                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:284:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY\u001b[m\u001b[K’\n",
            "  284 | #define C10_UNLIKELY_OR_CONST(e) \u001b[01;36m\u001b[KC10_UNLIKELY\u001b[m\u001b[K(e)\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:336:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K’\n",
            "  336 |   if (\u001b[01;36m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K(!(cond))) {                                          \\\n",
            "      |       \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:631:32:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K’\n",
            "  631 |     C10_EXPAND_MSVC_WORKAROUND(\u001b[01;36m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K(cond, __VA_ARGS__)); \\\n",
            "      |                                \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:9:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_ASSERTM\u001b[m\u001b[K’\n",
            "    9 |   \u001b[01;36m\u001b[KAT_ASSERTM\u001b[m\u001b[K(!dets.type().is_cuda(), \"dets must be a CPU tensor\");\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  216 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:9:24:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "    9 |   AT_ASSERTM(!\u001b[01;35m\u001b[Kdets.type()\u001b[m\u001b[K.is_cuda(), \"dets must be a CPU tensor\");\n",
            "      |               \u001b[01;35m\u001b[K~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:264:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KC10_EXPAND_MSVC_WORKAROUND\u001b[m\u001b[K’\n",
            "  264 | #define C10_EXPAND_MSVC_WORKAROUND(x) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K\n",
            "      |                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:284:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY\u001b[m\u001b[K’\n",
            "  284 | #define C10_UNLIKELY_OR_CONST(e) \u001b[01;36m\u001b[KC10_UNLIKELY\u001b[m\u001b[K(e)\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:336:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K’\n",
            "  336 |   if (\u001b[01;36m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K(!(cond))) {                                          \\\n",
            "      |       \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:631:32:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K’\n",
            "  631 |     C10_EXPAND_MSVC_WORKAROUND(\u001b[01;36m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K(cond, __VA_ARGS__)); \\\n",
            "      |                                \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:9:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_ASSERTM\u001b[m\u001b[K’\n",
            "    9 |   \u001b[01;36m\u001b[KAT_ASSERTM\u001b[m\u001b[K(!dets.type().is_cuda(), \"dets must be a CPU tensor\");\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  216 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:10:26:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   10 |   AT_ASSERTM(!\u001b[01;35m\u001b[Kscores.type()\u001b[m\u001b[K.is_cuda(), \"scores must be a CPU tensor\");\n",
            "      |               \u001b[01;35m\u001b[K~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:264:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KC10_EXPAND_MSVC_WORKAROUND\u001b[m\u001b[K’\n",
            "  264 | #define C10_EXPAND_MSVC_WORKAROUND(x) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K\n",
            "      |                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:284:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY\u001b[m\u001b[K’\n",
            "  284 | #define C10_UNLIKELY_OR_CONST(e) \u001b[01;36m\u001b[KC10_UNLIKELY\u001b[m\u001b[K(e)\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:336:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K’\n",
            "  336 |   if (\u001b[01;36m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K(!(cond))) {                                          \\\n",
            "      |       \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:631:32:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K’\n",
            "  631 |     C10_EXPAND_MSVC_WORKAROUND(\u001b[01;36m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K(cond, __VA_ARGS__)); \\\n",
            "      |                                \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:10:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_ASSERTM\u001b[m\u001b[K’\n",
            "   10 |   \u001b[01;36m\u001b[KAT_ASSERTM\u001b[m\u001b[K(!scores.type().is_cuda(), \"scores must be a CPU tensor\");\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  216 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:10:26:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   10 |   AT_ASSERTM(!\u001b[01;35m\u001b[Kscores.type()\u001b[m\u001b[K.is_cuda(), \"scores must be a CPU tensor\");\n",
            "      |               \u001b[01;35m\u001b[K~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:264:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KC10_EXPAND_MSVC_WORKAROUND\u001b[m\u001b[K’\n",
            "  264 | #define C10_EXPAND_MSVC_WORKAROUND(x) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K\n",
            "      |                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:284:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY\u001b[m\u001b[K’\n",
            "  284 | #define C10_UNLIKELY_OR_CONST(e) \u001b[01;36m\u001b[KC10_UNLIKELY\u001b[m\u001b[K(e)\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:336:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K’\n",
            "  336 |   if (\u001b[01;36m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K(!(cond))) {                                          \\\n",
            "      |       \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:631:32:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K’\n",
            "  631 |     C10_EXPAND_MSVC_WORKAROUND(\u001b[01;36m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K(cond, __VA_ARGS__)); \\\n",
            "      |                                \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:10:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_ASSERTM\u001b[m\u001b[K’\n",
            "   10 |   \u001b[01;36m\u001b[KAT_ASSERTM\u001b[m\u001b[K(!scores.type().is_cuda(), \"scores must be a CPU tensor\");\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  216 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:23:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   11 |   AT_ASSERTM(\u001b[01;35m\u001b[Kdets.type()\u001b[m\u001b[K == scores.type(), \"dets should have the same type as scores\");\n",
            "      |              \u001b[01;35m\u001b[K~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:264:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KC10_EXPAND_MSVC_WORKAROUND\u001b[m\u001b[K’\n",
            "  264 | #define C10_EXPAND_MSVC_WORKAROUND(x) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K\n",
            "      |                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:284:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY\u001b[m\u001b[K’\n",
            "  284 | #define C10_UNLIKELY_OR_CONST(e) \u001b[01;36m\u001b[KC10_UNLIKELY\u001b[m\u001b[K(e)\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:336:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K’\n",
            "  336 |   if (\u001b[01;36m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K(!(cond))) {                                          \\\n",
            "      |       \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:631:32:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K’\n",
            "  631 |     C10_EXPAND_MSVC_WORKAROUND(\u001b[01;36m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K(cond, __VA_ARGS__)); \\\n",
            "      |                                \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_ASSERTM\u001b[m\u001b[K’\n",
            "   11 |   \u001b[01;36m\u001b[KAT_ASSERTM\u001b[m\u001b[K(dets.type() == scores.type(), \"dets should have the same type as scores\");\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  216 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:23:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   11 |   AT_ASSERTM(\u001b[01;35m\u001b[Kdets.type()\u001b[m\u001b[K == scores.type(), \"dets should have the same type as scores\");\n",
            "      |              \u001b[01;35m\u001b[K~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:264:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KC10_EXPAND_MSVC_WORKAROUND\u001b[m\u001b[K’\n",
            "  264 | #define C10_EXPAND_MSVC_WORKAROUND(x) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K\n",
            "      |                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:284:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY\u001b[m\u001b[K’\n",
            "  284 | #define C10_UNLIKELY_OR_CONST(e) \u001b[01;36m\u001b[KC10_UNLIKELY\u001b[m\u001b[K(e)\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:336:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K’\n",
            "  336 |   if (\u001b[01;36m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K(!(cond))) {                                          \\\n",
            "      |       \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:631:32:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K’\n",
            "  631 |     C10_EXPAND_MSVC_WORKAROUND(\u001b[01;36m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K(cond, __VA_ARGS__)); \\\n",
            "      |                                \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_ASSERTM\u001b[m\u001b[K’\n",
            "   11 |   \u001b[01;36m\u001b[KAT_ASSERTM\u001b[m\u001b[K(dets.type() == scores.type(), \"dets should have the same type as scores\");\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  216 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   11 |   AT_ASSERTM(dets.type() == \u001b[01;35m\u001b[Kscores.type()\u001b[m\u001b[K, \"dets should have the same type as scores\");\n",
            "      |                             \u001b[01;35m\u001b[K~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:264:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KC10_EXPAND_MSVC_WORKAROUND\u001b[m\u001b[K’\n",
            "  264 | #define C10_EXPAND_MSVC_WORKAROUND(x) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K\n",
            "      |                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:284:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY\u001b[m\u001b[K’\n",
            "  284 | #define C10_UNLIKELY_OR_CONST(e) \u001b[01;36m\u001b[KC10_UNLIKELY\u001b[m\u001b[K(e)\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:336:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K’\n",
            "  336 |   if (\u001b[01;36m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K(!(cond))) {                                          \\\n",
            "      |       \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:631:32:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K’\n",
            "  631 |     C10_EXPAND_MSVC_WORKAROUND(\u001b[01;36m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K(cond, __VA_ARGS__)); \\\n",
            "      |                                \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_ASSERTM\u001b[m\u001b[K’\n",
            "   11 |   \u001b[01;36m\u001b[KAT_ASSERTM\u001b[m\u001b[K(dets.type() == scores.type(), \"dets should have the same type as scores\");\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  216 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   11 |   AT_ASSERTM(dets.type() == \u001b[01;35m\u001b[Kscores.type()\u001b[m\u001b[K, \"dets should have the same type as scores\");\n",
            "      |                             \u001b[01;35m\u001b[K~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:264:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KC10_EXPAND_MSVC_WORKAROUND\u001b[m\u001b[K’\n",
            "  264 | #define C10_EXPAND_MSVC_WORKAROUND(x) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K\n",
            "      |                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:284:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY\u001b[m\u001b[K’\n",
            "  284 | #define C10_UNLIKELY_OR_CONST(e) \u001b[01;36m\u001b[KC10_UNLIKELY\u001b[m\u001b[K(e)\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:336:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K’\n",
            "  336 |   if (\u001b[01;36m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K(!(cond))) {                                          \\\n",
            "      |       \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:631:32:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K’\n",
            "  631 |     C10_EXPAND_MSVC_WORKAROUND(\u001b[01;36m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K(cond, __VA_ARGS__)); \\\n",
            "      |                                \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_ASSERTM\u001b[m\u001b[K’\n",
            "   11 |   \u001b[01;36m\u001b[KAT_ASSERTM\u001b[m\u001b[K(dets.type() == scores.type(), \"dets should have the same type as scores\");\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  216 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:29:47:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = unsigned char]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   29 |   auto suppressed = \u001b[01;35m\u001b[Ksuppressed_t.data<uint8_t>()\u001b[m\u001b[K;\n",
            "      |                     \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 |   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "      |       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:30:37:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   30 |   auto order = \u001b[01;35m\u001b[Korder_t.data<int64_t>()\u001b[m\u001b[K;\n",
            "      |                \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 |   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "      |       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:31:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   31 |   auto \u001b[01;35m\u001b[Kx1\u001b[m\u001b[K = x1_t.data<scalar_t>();\n",
            "      |        \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 |   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "      |       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:32:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   32 |   auto \u001b[01;35m\u001b[Ky1\u001b[m\u001b[K = y1_t.data<scalar_t>();\n",
            "      |        \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 |   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "      |       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:33:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   33 |   auto \u001b[01;35m\u001b[Kx2\u001b[m\u001b[K = x2_t.data<scalar_t>();\n",
            "      |        \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 |   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "      |       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:34:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   34 |   auto \u001b[01;35m\u001b[Ky2\u001b[m\u001b[K = y2_t.data<scalar_t>();\n",
            "      |        \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 |   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "      |       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:35:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   35 |   auto \u001b[01;35m\u001b[Kareas\u001b[m\u001b[K = areas_t.data<scalar_t>();\n",
            "      |        \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 |   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "      |       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp: In instantiation of ‘\u001b[01m\u001b[Kat::Tensor nms_cpu_kernel(const at::Tensor&, const at::Tensor&, float) [with scalar_t = float]\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:71:3:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:9:24:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "    9 |   AT_ASSERTM(!\u001b[01;35m\u001b[Kdets.type()\u001b[m\u001b[K.is_cuda(), \"dets must be a CPU tensor\");\n",
            "      |               \u001b[01;35m\u001b[K~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:264:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KC10_EXPAND_MSVC_WORKAROUND\u001b[m\u001b[K’\n",
            "  264 | #define C10_EXPAND_MSVC_WORKAROUND(x) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K\n",
            "      |                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:284:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY\u001b[m\u001b[K’\n",
            "  284 | #define C10_UNLIKELY_OR_CONST(e) \u001b[01;36m\u001b[KC10_UNLIKELY\u001b[m\u001b[K(e)\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:336:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K’\n",
            "  336 |   if (\u001b[01;36m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K(!(cond))) {                                          \\\n",
            "      |       \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:631:32:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K’\n",
            "  631 |     C10_EXPAND_MSVC_WORKAROUND(\u001b[01;36m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K(cond, __VA_ARGS__)); \\\n",
            "      |                                \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:9:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_ASSERTM\u001b[m\u001b[K’\n",
            "    9 |   \u001b[01;36m\u001b[KAT_ASSERTM\u001b[m\u001b[K(!dets.type().is_cuda(), \"dets must be a CPU tensor\");\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  216 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:9:24:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "    9 |   AT_ASSERTM(!\u001b[01;35m\u001b[Kdets.type()\u001b[m\u001b[K.is_cuda(), \"dets must be a CPU tensor\");\n",
            "      |               \u001b[01;35m\u001b[K~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:264:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KC10_EXPAND_MSVC_WORKAROUND\u001b[m\u001b[K’\n",
            "  264 | #define C10_EXPAND_MSVC_WORKAROUND(x) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K\n",
            "      |                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:284:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY\u001b[m\u001b[K’\n",
            "  284 | #define C10_UNLIKELY_OR_CONST(e) \u001b[01;36m\u001b[KC10_UNLIKELY\u001b[m\u001b[K(e)\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:336:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K’\n",
            "  336 |   if (\u001b[01;36m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K(!(cond))) {                                          \\\n",
            "      |       \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:631:32:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K’\n",
            "  631 |     C10_EXPAND_MSVC_WORKAROUND(\u001b[01;36m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K(cond, __VA_ARGS__)); \\\n",
            "      |                                \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:9:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_ASSERTM\u001b[m\u001b[K’\n",
            "    9 |   \u001b[01;36m\u001b[KAT_ASSERTM\u001b[m\u001b[K(!dets.type().is_cuda(), \"dets must be a CPU tensor\");\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  216 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:10:26:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   10 |   AT_ASSERTM(!\u001b[01;35m\u001b[Kscores.type()\u001b[m\u001b[K.is_cuda(), \"scores must be a CPU tensor\");\n",
            "      |               \u001b[01;35m\u001b[K~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:264:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KC10_EXPAND_MSVC_WORKAROUND\u001b[m\u001b[K’\n",
            "  264 | #define C10_EXPAND_MSVC_WORKAROUND(x) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K\n",
            "      |                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:284:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY\u001b[m\u001b[K’\n",
            "  284 | #define C10_UNLIKELY_OR_CONST(e) \u001b[01;36m\u001b[KC10_UNLIKELY\u001b[m\u001b[K(e)\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:336:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K’\n",
            "  336 |   if (\u001b[01;36m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K(!(cond))) {                                          \\\n",
            "      |       \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:631:32:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K’\n",
            "  631 |     C10_EXPAND_MSVC_WORKAROUND(\u001b[01;36m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K(cond, __VA_ARGS__)); \\\n",
            "      |                                \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:10:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_ASSERTM\u001b[m\u001b[K’\n",
            "   10 |   \u001b[01;36m\u001b[KAT_ASSERTM\u001b[m\u001b[K(!scores.type().is_cuda(), \"scores must be a CPU tensor\");\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  216 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:10:26:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   10 |   AT_ASSERTM(!\u001b[01;35m\u001b[Kscores.type()\u001b[m\u001b[K.is_cuda(), \"scores must be a CPU tensor\");\n",
            "      |               \u001b[01;35m\u001b[K~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:264:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KC10_EXPAND_MSVC_WORKAROUND\u001b[m\u001b[K’\n",
            "  264 | #define C10_EXPAND_MSVC_WORKAROUND(x) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K\n",
            "      |                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:284:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY\u001b[m\u001b[K’\n",
            "  284 | #define C10_UNLIKELY_OR_CONST(e) \u001b[01;36m\u001b[KC10_UNLIKELY\u001b[m\u001b[K(e)\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:336:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K’\n",
            "  336 |   if (\u001b[01;36m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K(!(cond))) {                                          \\\n",
            "      |       \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:631:32:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K’\n",
            "  631 |     C10_EXPAND_MSVC_WORKAROUND(\u001b[01;36m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K(cond, __VA_ARGS__)); \\\n",
            "      |                                \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:10:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_ASSERTM\u001b[m\u001b[K’\n",
            "   10 |   \u001b[01;36m\u001b[KAT_ASSERTM\u001b[m\u001b[K(!scores.type().is_cuda(), \"scores must be a CPU tensor\");\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  216 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:23:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   11 |   AT_ASSERTM(\u001b[01;35m\u001b[Kdets.type()\u001b[m\u001b[K == scores.type(), \"dets should have the same type as scores\");\n",
            "      |              \u001b[01;35m\u001b[K~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:264:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KC10_EXPAND_MSVC_WORKAROUND\u001b[m\u001b[K’\n",
            "  264 | #define C10_EXPAND_MSVC_WORKAROUND(x) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K\n",
            "      |                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:284:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY\u001b[m\u001b[K’\n",
            "  284 | #define C10_UNLIKELY_OR_CONST(e) \u001b[01;36m\u001b[KC10_UNLIKELY\u001b[m\u001b[K(e)\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:336:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K’\n",
            "  336 |   if (\u001b[01;36m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K(!(cond))) {                                          \\\n",
            "      |       \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:631:32:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K’\n",
            "  631 |     C10_EXPAND_MSVC_WORKAROUND(\u001b[01;36m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K(cond, __VA_ARGS__)); \\\n",
            "      |                                \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_ASSERTM\u001b[m\u001b[K’\n",
            "   11 |   \u001b[01;36m\u001b[KAT_ASSERTM\u001b[m\u001b[K(dets.type() == scores.type(), \"dets should have the same type as scores\");\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  216 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:23:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   11 |   AT_ASSERTM(\u001b[01;35m\u001b[Kdets.type()\u001b[m\u001b[K == scores.type(), \"dets should have the same type as scores\");\n",
            "      |              \u001b[01;35m\u001b[K~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:264:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KC10_EXPAND_MSVC_WORKAROUND\u001b[m\u001b[K’\n",
            "  264 | #define C10_EXPAND_MSVC_WORKAROUND(x) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K\n",
            "      |                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:284:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY\u001b[m\u001b[K’\n",
            "  284 | #define C10_UNLIKELY_OR_CONST(e) \u001b[01;36m\u001b[KC10_UNLIKELY\u001b[m\u001b[K(e)\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:336:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K’\n",
            "  336 |   if (\u001b[01;36m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K(!(cond))) {                                          \\\n",
            "      |       \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:631:32:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K’\n",
            "  631 |     C10_EXPAND_MSVC_WORKAROUND(\u001b[01;36m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K(cond, __VA_ARGS__)); \\\n",
            "      |                                \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_ASSERTM\u001b[m\u001b[K’\n",
            "   11 |   \u001b[01;36m\u001b[KAT_ASSERTM\u001b[m\u001b[K(dets.type() == scores.type(), \"dets should have the same type as scores\");\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  216 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   11 |   AT_ASSERTM(dets.type() == \u001b[01;35m\u001b[Kscores.type()\u001b[m\u001b[K, \"dets should have the same type as scores\");\n",
            "      |                             \u001b[01;35m\u001b[K~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:264:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KC10_EXPAND_MSVC_WORKAROUND\u001b[m\u001b[K’\n",
            "  264 | #define C10_EXPAND_MSVC_WORKAROUND(x) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K\n",
            "      |                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:284:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY\u001b[m\u001b[K’\n",
            "  284 | #define C10_UNLIKELY_OR_CONST(e) \u001b[01;36m\u001b[KC10_UNLIKELY\u001b[m\u001b[K(e)\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:336:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K’\n",
            "  336 |   if (\u001b[01;36m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K(!(cond))) {                                          \\\n",
            "      |       \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:631:32:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K’\n",
            "  631 |     C10_EXPAND_MSVC_WORKAROUND(\u001b[01;36m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K(cond, __VA_ARGS__)); \\\n",
            "      |                                \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_ASSERTM\u001b[m\u001b[K’\n",
            "   11 |   \u001b[01;36m\u001b[KAT_ASSERTM\u001b[m\u001b[K(dets.type() == scores.type(), \"dets should have the same type as scores\");\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  216 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   11 |   AT_ASSERTM(dets.type() == \u001b[01;35m\u001b[Kscores.type()\u001b[m\u001b[K, \"dets should have the same type as scores\");\n",
            "      |                             \u001b[01;35m\u001b[K~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:264:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KC10_EXPAND_MSVC_WORKAROUND\u001b[m\u001b[K’\n",
            "  264 | #define C10_EXPAND_MSVC_WORKAROUND(x) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K\n",
            "      |                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:284:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY\u001b[m\u001b[K’\n",
            "  284 | #define C10_UNLIKELY_OR_CONST(e) \u001b[01;36m\u001b[KC10_UNLIKELY\u001b[m\u001b[K(e)\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:336:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K’\n",
            "  336 |   if (\u001b[01;36m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K(!(cond))) {                                          \\\n",
            "      |       \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:631:32:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K’\n",
            "  631 |     C10_EXPAND_MSVC_WORKAROUND(\u001b[01;36m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K(cond, __VA_ARGS__)); \\\n",
            "      |                                \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:11:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_ASSERTM\u001b[m\u001b[K’\n",
            "   11 |   \u001b[01;36m\u001b[KAT_ASSERTM\u001b[m\u001b[K(dets.type() == scores.type(), \"dets should have the same type as scores\");\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  216 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:29:47:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = unsigned char]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   29 |   auto suppressed = \u001b[01;35m\u001b[Ksuppressed_t.data<uint8_t>()\u001b[m\u001b[K;\n",
            "      |                     \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 |   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "      |       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:30:37:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   30 |   auto order = \u001b[01;35m\u001b[Korder_t.data<int64_t>()\u001b[m\u001b[K;\n",
            "      |                \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 |   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "      |       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:31:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   31 |   auto \u001b[01;35m\u001b[Kx1\u001b[m\u001b[K = x1_t.data<scalar_t>();\n",
            "      |        \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 |   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "      |       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:32:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   32 |   auto \u001b[01;35m\u001b[Ky1\u001b[m\u001b[K = y1_t.data<scalar_t>();\n",
            "      |        \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 |   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "      |       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:33:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   33 |   auto \u001b[01;35m\u001b[Kx2\u001b[m\u001b[K = x2_t.data<scalar_t>();\n",
            "      |        \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 |   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "      |       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:34:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   34 |   auto \u001b[01;35m\u001b[Ky2\u001b[m\u001b[K = y2_t.data<scalar_t>();\n",
            "      |        \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 |   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "      |       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:35:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   35 |   auto \u001b[01;35m\u001b[Kareas\u001b[m\u001b[K = areas_t.data<scalar_t>();\n",
            "      |        \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 |   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "      |       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/MIC/det/maskrcnn_benchmark/csrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c /content/MIC/det/maskrcnn_benchmark/csrc/cuda/deform_pool_cuda.cu -o build/temp.linux-x86_64-3.8/content/MIC/det/maskrcnn_benchmark/csrc/cuda/deform_pool_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/MIC/det/maskrcnn_benchmark/csrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c /content/MIC/det/maskrcnn_benchmark/csrc/cuda/ROIPool_cuda.cu -o build/temp.linux-x86_64-3.8/content/MIC/det/maskrcnn_benchmark/csrc/cuda/ROIPool_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/MIC/det/maskrcnn_benchmark/csrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c /content/MIC/det/maskrcnn_benchmark/csrc/cuda/deform_conv_kernel_cuda.cu -o build/temp.linux-x86_64-3.8/content/MIC/det/maskrcnn_benchmark/csrc/cuda/deform_conv_kernel_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/MIC/det/maskrcnn_benchmark/csrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c /content/MIC/det/maskrcnn_benchmark/csrc/cuda/ROIAlign_cuda.cu -o build/temp.linux-x86_64-3.8/content/MIC/det/maskrcnn_benchmark/csrc/cuda/ROIAlign_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/MIC/det/maskrcnn_benchmark/csrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c /content/MIC/det/maskrcnn_benchmark/csrc/cuda/SigmoidFocalLoss_cuda.cu -o build/temp.linux-x86_64-3.8/content/MIC/det/maskrcnn_benchmark/csrc/cuda/SigmoidFocalLoss_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/MIC/det/maskrcnn_benchmark/csrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c /content/MIC/det/maskrcnn_benchmark/csrc/cuda/nms.cu -o build/temp.linux-x86_64-3.8/content/MIC/det/maskrcnn_benchmark/csrc/cuda/nms.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/MIC/det/maskrcnn_benchmark/csrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c /content/MIC/det/maskrcnn_benchmark/csrc/cuda/deform_pool_kernel_cuda.cu -o build/temp.linux-x86_64-3.8/content/MIC/det/maskrcnn_benchmark/csrc/cuda/deform_pool_kernel_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/MIC/det/maskrcnn_benchmark/csrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c /content/MIC/det/maskrcnn_benchmark/csrc/cuda/deform_conv_cuda.cu -o build/temp.linux-x86_64-3.8/content/MIC/det/maskrcnn_benchmark/csrc/cuda/deform_conv_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/content/MIC/det/maskrcnn_benchmark/csrc/vision.o build/temp.linux-x86_64-3.8/content/MIC/det/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.o build/temp.linux-x86_64-3.8/content/MIC/det/maskrcnn_benchmark/csrc/cpu/nms_cpu.o build/temp.linux-x86_64-3.8/content/MIC/det/maskrcnn_benchmark/csrc/cuda/deform_pool_cuda.o build/temp.linux-x86_64-3.8/content/MIC/det/maskrcnn_benchmark/csrc/cuda/ROIPool_cuda.o build/temp.linux-x86_64-3.8/content/MIC/det/maskrcnn_benchmark/csrc/cuda/deform_conv_kernel_cuda.o build/temp.linux-x86_64-3.8/content/MIC/det/maskrcnn_benchmark/csrc/cuda/ROIAlign_cuda.o build/temp.linux-x86_64-3.8/content/MIC/det/maskrcnn_benchmark/csrc/cuda/SigmoidFocalLoss_cuda.o build/temp.linux-x86_64-3.8/content/MIC/det/maskrcnn_benchmark/csrc/cuda/nms.o build/temp.linux-x86_64-3.8/content/MIC/det/maskrcnn_benchmark/csrc/cuda/deform_pool_kernel_cuda.o build/temp.linux-x86_64-3.8/content/MIC/det/maskrcnn_benchmark/csrc/cuda/deform_conv_cuda.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/maskrcnn_benchmark/_C.cpython-38-x86_64-linux-gnu.so\n",
            "running develop\n",
            "running egg_info\n",
            "creating maskrcnn_benchmark.egg-info\n",
            "writing maskrcnn_benchmark.egg-info/PKG-INFO\n",
            "writing dependency_links to maskrcnn_benchmark.egg-info/dependency_links.txt\n",
            "writing top-level names to maskrcnn_benchmark.egg-info/top_level.txt\n",
            "writing manifest file 'maskrcnn_benchmark.egg-info/SOURCES.txt'\n",
            "reading manifest file 'maskrcnn_benchmark.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'maskrcnn_benchmark.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py:387: UserWarning: The detected CUDA version (11.2) has a minor version mismatch with the version that was used to compile PyTorch (11.6). Most likely this shouldn't be a problem.\n",
            "  warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
            "copying build/lib.linux-x86_64-3.8/maskrcnn_benchmark/_C.cpython-38-x86_64-linux-gnu.so -> maskrcnn_benchmark\n",
            "Creating /usr/local/lib/python3.8/dist-packages/maskrcnn-benchmark.egg-link (link to .)\n",
            "Adding maskrcnn-benchmark 0.1 to easy-install.pth file\n",
            "\n",
            "Installed /content/MIC/det\n",
            "Processing dependencies for maskrcnn-benchmark==0.1\n",
            "Finished processing dependencies for maskrcnn-benchmark==0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "2vV5D1gFtnlH",
        "outputId": "ecb5bae5-3e15-4b3f-daf2-85e9bdf9032a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "build\t\t INSTALL.md\t     maskrcnn_benchmark.egg-info  tests\n",
            "configs\t\t LICENSE\t     README.md\t\t\t  tools\n",
            "environment.yml  maskrcnn_benchmark  setup.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "\n",
        "# copy required file to cityscapesScripts toolkit\n",
        "!cp tool/cityscapes/instances2dict_with_polygons.py $INSTALL_DIR/cityscapesScripts/evaluation\n",
        "\n",
        "# recompile cityscapesScripts\n",
        "%cd cityscapesScripts/\n",
        "!python setup.py build_ext install\n",
        "\n",
        "!pip install h5py==3.6.0 scipy==1.8.0"
      ],
      "metadata": {
        "id": "W4RXjCYltiUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ueuI0V57kos6",
        "outputId": "35ffd431-189e-4834-84b9-7c145b6f8a99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/"
      ],
      "metadata": {
        "id": "nyoKaoKtEKXP",
        "outputId": "8e9d05da-43d7-4ac1-f285-cc83a733c16a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1-1Iow33KqdaNQcrK4v9Zk568IZVYZ1UV\n",
        "!gdown 1-0WQV7BerZb2ieF0LYzoFlO9NFjy4gy7\n",
        "!gdown 1-1rhR_4ynP162kL1UrmWQex8tyj6Ki3F\n"
      ],
      "metadata": {
        "id": "jZMn_A-9krUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://deepblue.lib.umich.edu/data/downloads/ks65hc58r"
      ],
      "metadata": {
        "id": "P6a2p55-p5cU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget http://droplab-files.engin.umich.edu/repro_10k_annotations.tgz"
      ],
      "metadata": {
        "id": "tBjmtt8Zp6mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget http://droplab-files.engin.umich.edu/repro_image_sets.tgz"
      ],
      "metadata": {
        "id": "PwpcWcVTp7yq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/datasets"
      ],
      "metadata": {
        "id": "AC6gwnLmlDyr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -zxvf /content/repro_10k_images.tgz -C /content/datasets\n",
        "!tar -zxvf /content/repro_10k_annotations.tgz -C /content/datasets\n",
        "!tar -zxvf /content/repro_image_sets.tgz -C /content/datasets"
      ],
      "metadata": {
        "id": "W76h5tfzkzwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/datasets/VOC2012 /content/datasets/Sim10k\n"
      ],
      "metadata": {
        "id": "dR2epK9emNPb"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --keep-session-cookies --save-cookies=cookies.txt --post-data 'username=kiaei&password=UtP8!pbXp8FsQs2&submit=Login' https://www.cityscapes-dataset.com/login/"
      ],
      "metadata": {
        "id": "m1K1YGIpmOR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=3"
      ],
      "metadata": {
        "id": "yGMnQjx8mOj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=1"
      ],
      "metadata": {
        "id": "gdX2_zs0mQZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/leftImg8bit_trainvaltest.zip -d /content/datasets"
      ],
      "metadata": {
        "id": "o8HEpyQnmR7Z"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/gtFine_trainvaltest.zip -d /content/datasets/cityscapes"
      ],
      "metadata": {
        "id": "CJv7EC_XmWBb"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/datasets/leftImg8bit /content/datasets/cityscapes"
      ],
      "metadata": {
        "id": "0fwf9EgOmWrg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r  /content/leftImg8bit_trainvaltest.zip"
      ],
      "metadata": {
        "id": "uO6HuVa8mXzr"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1a2oHjcEcwXP8oUF95qiwrqzACb2YlUhn -O  /content/datasets/visdrone\n",
        "!gdown 1bxK5zgLn0_L8x276eKkuYA_FzwCIjb59 -O  /content/datasets/visdrone\n",
        "!gdown 1PFdW_VFSCfZ_sTSZAGjQdifF_Xd5mf0V -O  /content/datasets/visdrone"
      ],
      "metadata": {
        "id": "aSWHBPRl2-kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip -q /content/datasets/visdrone/VisDrone2019-DET-train.zip -d /content/datasets/visdrone/train\n",
        "# !unzip -q /content/datasets/visdrone/VisDrone2019-DET-val.zip -d /content/datasets/visdrone/val\n",
        "# !unzip -q /content/datasets/visdrone/VisDrone2019-DET-test-challenge -d /content/datasets/visdrone/test"
      ],
      "metadata": {
        "id": "gL7i9S5O3pjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/datasets/visdrone"
      ],
      "metadata": {
        "id": "dhsnO0_Z5mvu"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/drive/MyDrive/UDA/VisDrone2019-DET-train.zip -d /content/datasets/visdrone\n",
        "!unzip -q /content/drive/MyDrive/UDA/VisDrone2019-DET-val.zip -d /content/datasets/visdrone\n",
        "!unzip -q /content/drive/MyDrive/UDA/VisDrone2019-DET-test-dev.zip -d /content/datasets/visdrone/test"
      ],
      "metadata": {
        "id": "JpafH1r_5UAM"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(len(os.listdir('/content/datasets/visdrone/train/VisDrone2019-DET-train/images')))\n",
        "print(len(os.listdir('/content/datasets/visdrone/train/VisDrone2019-DET-train/annotations')))\n",
        "print(len(os.listdir('/content/datasets/visdrone/val/VisDrone2019-DET-val/images')))\n",
        "print(len(os.listdir('/content/datasets/visdrone/val/VisDrone2019-DET-val/annotations')))"
      ],
      "metadata": {
        "id": "FLBQq5nU6wNW",
        "outputId": "a7a40307-5bf0-45cd-f37b-c6b64a44b32f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6471\n",
            "6471\n",
            "548\n",
            "548\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "EoVrhu2o7oO7"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "path= \"/content/datasets/visdrone\"  # dataset root dir\n",
        "train= \"VisDrone2019-DET-train/images\"  # train images (relative to 'path')  6471 images\n",
        "val= \"VisDrone2019-DET-val/images\"  # val images (relative to 'path')  548 images\n",
        "test= \"VisDrone2019-DET-test-dev/images\"  # test images (optional)  1610 images\n",
        "\n",
        "# Classes\n",
        "names={\n",
        "  0: \"pedestrian\",\n",
        "  1: \"people\",\n",
        "  2: \"bicycle\",\n",
        "  3: \"car\",\n",
        "  4: \"van\",\n",
        "  5: \"truck\",\n",
        "  6: \"tricycle\",\n",
        "  7: \"awning-tricycle\",\n",
        "  8: \"bus\",\n",
        "  9: \"motor\"}\n",
        "\n",
        "\n",
        "# Download script/URL (optional) ---------------------------------------------------------------------------------------\n",
        "def visdrone2yolo(dir):\n",
        "    from PIL import Image\n",
        "    from tqdm import tqdm\n",
        "    def convert_box(size, box):\n",
        "        # Convert VisDrone box to YOLO xywh box\n",
        "        dw = 1. / size[0]\n",
        "        dh = 1. / size[1]\n",
        "        return (box[0] + box[2] / 2) * dw, (box[1] + box[3] / 2) * dh, box[2] * dw, box[3] * dh\n",
        "    (dir / 'labels').mkdir(parents=True, exist_ok=True)  # make labels directory\n",
        "    pbar = tqdm((dir / 'annotations').glob('*.txt'), desc=f'Converting {dir}')\n",
        "    for f in pbar:\n",
        "        img_size = Image.open((dir / 'images' / f.name).with_suffix('.jpg')).size\n",
        "        lines = []\n",
        "        with open(f, 'r') as file:  # read annotation.txt\n",
        "            for row in [x.split(',') for x in file.read().strip().splitlines()]:\n",
        "                if row[4] == '0':  # VisDrone 'ignored regions' class 0\n",
        "                    continue\n",
        "                cls = int(row[5]) - 1\n",
        "                box = convert_box(img_size, tuple(map(int, row[:4])))\n",
        "                lines.append(f\"{cls} {' '.join(f'{x:.6f}' for x in box)}\\n\")\n",
        "                with open(str(f).replace(os.sep + 'annotations' + os.sep, os.sep + 'labels' + os.sep), 'w') as fl:\n",
        "                    fl.writelines(lines)  # write label.txt\n",
        "  # Download\n",
        "dir = Path(path)  # dataset root dir\n",
        "  # urls = ['https://github.com/ultralytics/yolov5/releases/download/v1.0/VisDrone2019-DET-train.zip',\n",
        "  #         'https://github.com/ultralytics/yolov5/releases/download/v1.0/VisDrone2019-DET-val.zip',\n",
        "  #         'https://github.com/ultralytics/yolov5/releases/download/v1.0/VisDrone2019-DET-test-dev.zip',\n",
        "  #         'https://github.com/ultralytics/yolov5/releases/download/v1.0/VisDrone2019-DET-test-challenge.zip']\n",
        "  # download(urls, dir=dir, curl=True, threads=4)\n",
        "  # Convert\n",
        "for d in 'VisDrone2019-DET-train', 'VisDrone2019-DET-val', 'VisDrone2019-DET-test-dev':\n",
        "     visdrone2yolo(dir / d)  # convert VisDrone annotations to YOLO labels"
      ],
      "metadata": {
        "id": "K6JzQgKa7JNR",
        "outputId": "7f6352b3-3a32-4377-e18f-31e0be1b6425",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Converting /content/datasets/visdrone/VisDrone2019-DET-train: 6471it [00:39, 163.29it/s]\n",
            "Converting /content/datasets/visdrone/VisDrone2019-DET-val: 548it [00:04, 122.49it/s]\n",
            "Converting /content/datasets/visdrone/VisDrone2019-DET-test-dev: 0it [00:00, ?it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "CuTfm2kd_wiH",
        "outputId": "f225dcd4-3c32-49b7-d5aa-83e803fcca28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cityscapesScripts\t\t       instances2dict_with_polygons.py\n",
            "convert_cityscapes_to_caronly_coco.py  leftImg8bit_trainvaltest.zip\n",
            "convert_sim10k_to_coco.py\t       MIC\n",
            "cookies.txt\t\t\t       __pycache__\n",
            "datasets\t\t\t       repro_10k_annotations.tgz\n",
            "drive\t\t\t\t       repro_10k_images.tgz\n",
            "gtFine_trainvaltest.zip\t\t       repro_image_sets.tgz\n",
            "index.html\t\t\t       sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fiftyone"
      ],
      "metadata": {
        "id": "uYfI-MBgmaiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fiftyone as fo\n",
        "from fiftyone import ViewField as F\n"
      ],
      "metadata": {
        "id": "wVT930xuEpFw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "imgs_path_train = \"/content/datasets/visdrone/VisDrone2019-DET-train/images\"\n",
        "labels_path_train = \"/content/datasets/visdrone/VisDrone2019-DET-train/labels\"\n",
        "\n",
        "imgs_path_val = \"/content/datasets/visdrone/VisDrone2019-DET-val/images\"\n",
        "labels_path_val = \"/content/datasets/visdrone/VisDrone2019-DET-val/labels\"\n",
        "\n",
        "# name = 'visdrone'\n",
        "# The dataset or view to export\n",
        "dataset_train = fo.Dataset.from_dir(\n",
        "    dataset_type=fo.types.YOLOv4Dataset,\n",
        "    data_path=imgs_path_train,\n",
        "    labels_path=labels_path_train,\n",
        ")\n",
        "# session = fo.launch_app(dataset)\n",
        "dataset_val = fo.Dataset.from_dir(\n",
        "    dataset_type=fo.types.YOLOv4Dataset,\n",
        "    data_path=imgs_path_val,\n",
        "    labels_path=labels_path_val,\n",
        ")"
      ],
      "metadata": {
        "id": "crokhHL-Efx4",
        "outputId": "2b43069d-086a-4995-c76b-8e4f9b06644f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |███████████████| 6471/6471 [2.8m elapsed, 0s remaining, 22.6 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |███████████████| 6471/6471 [2.8m elapsed, 0s remaining, 22.6 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |█████████████████| 548/548 [19.0s elapsed, 0s remaining, 29.2 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |█████████████████| 548/548 [19.0s elapsed, 0s remaining, 29.2 samples/s]      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ANIMALS = [\n",
        "#     \"Sedan\", \"Truck\",\n",
        "# ]\n",
        "\n",
        "# Replace all animal detection's labels with \"animal\"\n",
        "# mapping = {k: \"car\" for k in ANIMALS}\n",
        "\n",
        "# name_s = {k:k for k,v in names.items()}\n",
        "\n",
        "names={\n",
        "  '0': \"pedestrian\",\n",
        "  '1': \"people\",\n",
        "  '2': \"bicycle\",\n",
        "  '3': \"car\",\n",
        "  '4': \"van\",\n",
        "  '5': \"truck\",\n",
        "  '6': \"tricycle\",\n",
        "  '7': \"awning-tricycle\",\n",
        "  '8': \"bus\",\n",
        "  '9': \"motor\"}\n",
        "\n",
        "car_view_train = dataset_train.map_labels(\"ground_truth\", names)\n",
        "car_view_val = dataset_val.map_labels(\"ground_truth\", names)"
      ],
      "metadata": {
        "id": "e6nDuWnVE9dY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "session = fo.launch_app(car_view_val)\n"
      ],
      "metadata": {
        "id": "pqJlwkVLF9rD",
        "outputId": "2fbb0ac3-3373-4b75-c084-36438121b896",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "@import url(\"https://fonts.googleapis.com/css2?family=Palanquin&display=swap\");\n",
              "\n",
              "#focontainer-7b79d0d7-ccb7-4051-a4e6-e9f8fa5c00e9 {\n",
              "  position: relative;\n",
              "  height: px;\n",
              "  display: block !important;\n",
              "}\n",
              "#foactivate-7b79d0d7-ccb7-4051-a4e6-e9f8fa5c00e9 {\n",
              "  font-weight: bold;\n",
              "  cursor: pointer;\n",
              "  font-size: 24px;\n",
              "  border-radius: 3px;\n",
              "  text-align: center;\n",
              "  padding: 0.5em;\n",
              "  color: rgb(255, 255, 255);\n",
              "  font-family: \"Palanquin\", sans-serif;\n",
              "  position: absolute;\n",
              "  left: 50%;\n",
              "  top: 50%;\n",
              "  width: 160px;\n",
              "  margin-left: -80px;\n",
              "  margin-top: -23px;\n",
              "  background: hsla(210,11%,15%, 0.8);\n",
              "  border: none;\n",
              "}\n",
              "#foactivate-7b79d0d7-ccb7-4051-a4e6-e9f8fa5c00e9:focus {\n",
              "  outline: none;\n",
              "}\n",
              "#fooverlay-7b79d0d7-ccb7-4051-a4e6-e9f8fa5c00e9 {\n",
              "  width: 100%;\n",
              "  height: 100%;\n",
              "  background: hsla(208, 7%, 46%, 0.7);\n",
              "  position: absolute;\n",
              "  top: 0;\n",
              "  left: 0;\n",
              "  display: none;\n",
              "  cursor: pointer;\n",
              "}\n",
              "</style>\n",
              "<div id=\"focontainer-7b79d0d7-ccb7-4051-a4e6-e9f8fa5c00e9\" style=\"display: none;\">\n",
              "   <div id=\"fooverlay-7b79d0d7-ccb7-4051-a4e6-e9f8fa5c00e9\">\n",
              "      <button id=\"foactivate-7b79d0d7-ccb7-4051-a4e6-e9f8fa5c00e9\" >Activate</button>\n",
              "   </div>\n",
              "</div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fiftyone import ViewField as F\n",
        "\n",
        "car_view_train = car_view_train.filter_labels(\n",
        "    \"ground_truth\", (F(\"label\") == \"car\") \n",
        ")\n",
        "car_view_val = car_view_val.filter_labels(\n",
        "    \"ground_truth\", (F(\"label\") == \"car\") \n",
        ")"
      ],
      "metadata": {
        "id": "7OkMU3h8FFvY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fo.pprint(car_view_train.stats(include_media=True))\n",
        "fo.pprint(car_view_val.stats(include_media=True))"
      ],
      "metadata": {
        "id": "z8fs4RAhFMMw",
        "outputId": "ed4ce694-b1c6-4639-fda0-b82700891e15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing metadata...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.core.metadata:Computing metadata...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |███████████████| 6133/6133 [26.9s elapsed, 0s remaining, 284.0 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |███████████████| 6133/6133 [26.9s elapsed, 0s remaining, 284.0 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    'samples_count': 6133,\n",
            "    'samples_bytes': 23361933,\n",
            "    'samples_size': '22.3MB',\n",
            "    'media_bytes': 1481450812,\n",
            "    'media_size': '1.4GB',\n",
            "    'total_bytes': 1504812745,\n",
            "    'total_size': '1.4GB',\n",
            "}\n",
            "Computing metadata...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.core.metadata:Computing metadata...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |█████████████████| 515/515 [2.1s elapsed, 0s remaining, 276.1 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |█████████████████| 515/515 [2.1s elapsed, 0s remaining, 276.1 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    'samples_count': 515,\n",
            "    'samples_bytes': 2248960,\n",
            "    'samples_size': '2.1MB',\n",
            "    'media_bytes': 78288320,\n",
            "    'media_size': '74.7MB',\n",
            "    'total_bytes': 80537280,\n",
            "    'total_size': '76.8MB',\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "session = fo.launch_app(car_view_val)\n"
      ],
      "metadata": {
        "id": "O93MWQekFq3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# export_dir = \"/content/dataset/Sim10k\"\n",
        "labels_path_train  = \"/content/datasets/visdrone/VisDrone2019-DET-train/train_only_car.json\"\n",
        "labels_path_val  = \"/content/datasets/visdrone/VisDrone2019-DET-val/val_only_car.json\"\n",
        "\n",
        "# The name of the sample field containing the label that you wish to export\n",
        "# Used when exporting labeled datasets (e.g., classification or detection)\n",
        "label_field = \"ground_truth\"\n",
        "dataset_type = fo.types.COCODetectionDataset  # for example\n",
        "\n",
        "car_view_train.export(\n",
        "    labels_path=labels_path_train,\n",
        "    dataset_type=dataset_type,\n",
        "    label_field=label_field,\n",
        "    export_media=False\n",
        ")\n",
        "car_view_val.export(\n",
        "    labels_path=labels_path_val,\n",
        "    dataset_type=dataset_type,\n",
        "    label_field=label_field,\n",
        "    export_media=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "jYNS05NaFReh",
        "outputId": "f6ab2da4-c941-4af7-8995-bb6b62dba55c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |███████████████| 6133/6133 [38.7s elapsed, 0s remaining, 102.9 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |███████████████| 6133/6133 [38.7s elapsed, 0s remaining, 102.9 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |█████████████████| 515/515 [3.6s elapsed, 0s remaining, 165.9 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |█████████████████| 515/515 [3.6s elapsed, 0s remaining, 165.9 samples/s]      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fiftyone as fo\n",
        "from fiftyone import ViewField as F\n"
      ],
      "metadata": {
        "id": "88HOeIyema6I"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "imgs_path = \"/content/datasets/Sim10k/JPEGImages\"\n",
        "labels_path = \"/content/datasets/Sim10k/Annotations\"\n",
        "\n",
        "\n",
        "# name = 'visdrone'\n",
        "# The dataset or view to export\n",
        "dataset = fo.Dataset.from_dir(\n",
        "    dataset_type=fo.types.YOLOv4Dataset,\n",
        "    data_path=imgs_path,\n",
        "    labels_path=labels_path,\n",
        ")\n"
      ],
      "metadata": {
        "id": "6YUBzDBHmnjs",
        "outputId": "805d08f6-eb67-47d1-8775-185462523ad7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |███████████████| 6471/6471 [2.8m elapsed, 0s remaining, 27.2 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |███████████████| 6471/6471 [2.8m elapsed, 0s remaining, 27.2 samples/s]      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "session = fo.launch_app(dataset)\n"
      ],
      "metadata": {
        "id": "Gvh_yDwYmsos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "car_view = dataset.filter_labels(\n",
        "    \"ground_truth\", (F(\"label\") == \"car\") \n",
        ")"
      ],
      "metadata": {
        "id": "g-JdEu9nmrtF"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "session = fo.launch_app(view=car_view)\n"
      ],
      "metadata": {
        "id": "HeC-w9z7muTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# export_dir = \"/content/datasets/Sim10k\"\n",
        "labels_path  = \"/content/datasets/Sim10k/train_only_car.json\"\n",
        "\n",
        "# The name of the sample field containing the label that you wish to export\n",
        "# Used when exporting labeled datasets (e.g., classification or detection)\n",
        "label_field = \"ground_truth\"\n",
        "dataset_type = fo.types.COCODetectionDataset  # for example\n",
        "\n",
        "car_view.export(\n",
        "    labels_path=labels_path,\n",
        "    dataset_type=dataset_type,\n",
        "    label_field=label_field,\n",
        "    export_media=False\n",
        ")"
      ],
      "metadata": {
        "id": "0LeUg38omw0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/datasets/cityscapes/caronly_filtered_gtFine_test.json /content/drive/MyDrive/AI/dataset/cityscapes\n",
        "!cp /content/datasets/cityscapes/caronly_filtered_gtFine_train.json /content/drive/MyDrive/AI/dataset/cityscapes\n",
        "!cp /content/datasets/cityscapes/caronly_filtered_gtFine_val.json /content/drive/MyDrive/AI/dataset/cityscapes"
      ],
      "metadata": {
        "id": "pvIZCPrTKk7n"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/datasets/Sim10k/car_instances.json /content/drive/MyDrive/AI/dataset/sim10k\n",
        "!cp /content/datasets/Sim10k/train_only_car.json /content/drive/MyDrive/AI/dataset/sim10k"
      ],
      "metadata": {
        "id": "Bpuvh2-LK3wB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/datasets/visdrone/VisDrone2019-DET-train/train_only_car.json /content/drive/MyDrive/AI/dataset/visdrone\n",
        "!cp /content/datasets/visdrone/VisDrone2019-DET-val/val_only_car.json /content/drive/MyDrive/AI/dataset/visdrone"
      ],
      "metadata": {
        "id": "xVyYh-_lLslf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/"
      ],
      "metadata": {
        "id": "5JrtW48hE8PY",
        "outputId": "27aa1a40-363e-4fd9-dd76-e3e5423ee8ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python convert_cityscapes_to_caronly_coco.py --dataset cityscapes_car_only\\\n",
        "  --outdir '/content/datasets/cityscapes'\\\n",
        "  --datadir '/content/datasets/cityscapes/'"
      ],
      "metadata": {
        "id": "NhWgaQTPm4uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python convert_sim10k_to_coco.py --dataset sim10k\\\n",
        "  --outdir '/content/datasets/Sim10k/'\\\n",
        "  --datadir '/content/datasets/Sim10k/Annotations'"
      ],
      "metadata": {
        "id": "oUu4QcVzx_ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('/content/datasets/Sim10k/train_only_car.json') as user_file:\n",
        "  file_contents = user_file.read()\n",
        "  \n",
        "parsed_json = json.loads(file_contents)\n",
        "print(parsed_json.keys())\n",
        "print(len(parsed_json[\"images\"]))\n",
        "print(len(parsed_json[\"annotations\"]))"
      ],
      "metadata": {
        "id": "LVaJZmHnxPH1",
        "outputId": "2eba22c5-c582-40cc-c09d-e2ffb2770a73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['info', 'licenses', 'categories', 'images', 'annotations'])\n",
            "9975\n",
            "57776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('/content/datasets/Sim10k/car_instances.json') as user_file:\n",
        "  file_contents = user_file.read()\n",
        "  \n",
        "parsed_json = json.loads(file_contents)\n",
        "print(parsed_json.keys())\n",
        "print(len(parsed_json[\"images\"]))\n",
        "print(len(parsed_json[\"annotations\"]))"
      ],
      "metadata": {
        "id": "RQ4mkOn3yADm",
        "outputId": "5c34deae-6542-46ac-a6d5-2f6dc19294d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['images', 'type', 'annotations', 'categories'])\n",
            "10000\n",
            "57776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/mic.zip -d /content/sample_data"
      ],
      "metadata": {
        "id": "CCFi0zc_JX96"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv  /content/datasets/cityscapes/leftImg8bit/train/*/*.png /content/datasets/cityscapes/leftImg8bit/train/\n",
        "!mv  /content/datasets/cityscapes/leftImg8bit/val/*/*.png /content/datasets/cityscapes/leftImg8bit/val/\n",
        "!mv  /content/datasets/cityscapes/leftImg8bit/test/*/*.png /content/datasets/cityscapes/leftImg8bit/test/\n"
      ],
      "metadata": {
        "id": "mu_G8ja0m7xV"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/MIC/det"
      ],
      "metadata": {
        "id": "7_BQpCdG069U",
        "outputId": "c96949f7-9576-412c-9a1e-4c2871306ec3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MIC/det\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/train_net.py --config-file /content/MIC/det/configs/fff.yaml"
      ],
      "metadata": {
        "id": "VrJwZ0ilIyMk",
        "outputId": "4bbe6024-b5d7-40e1-ef14-cd4307df1689",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-04 16:08:26,097 maskrcnn_benchmark INFO: Using 1 GPUs\n",
            "2023-02-04 16:08:26,098 maskrcnn_benchmark INFO: Namespace(config_file='/content/MIC/det/configs/fff.yaml', deterministic=False, distributed=False, local_rank=0, opts=[], seed=1, skip_test=False)\n",
            "2023-02-04 16:08:26,098 maskrcnn_benchmark INFO: Collecting env info (might take some time)\n",
            "2023-02-04 16:08:27,434 maskrcnn_benchmark INFO: \n",
            "PyTorch version: 1.12.0+cu113\n",
            "Is debug build: False\n",
            "CUDA used to build PyTorch: 11.3\n",
            "ROCM used to build PyTorch: N/A\n",
            "\n",
            "OS: Ubuntu 20.04.5 LTS (x86_64)\n",
            "GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n",
            "Clang version: 10.0.0-4ubuntu1 \n",
            "CMake version: version 3.22.6\n",
            "Libc version: glibc-2.31\n",
            "\n",
            "Python version: 3.8.10 (default, Nov 14 2022, 12:59:47)  [GCC 9.4.0] (64-bit runtime)\n",
            "Python platform: Linux-5.10.147+-x86_64-with-glibc2.29\n",
            "Is CUDA available: True\n",
            "CUDA runtime version: 11.2.152\n",
            "GPU models and configuration: GPU 0: Tesla T4\n",
            "Nvidia driver version: 510.47.03\n",
            "cuDNN version: Probably one of the following:\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.1.1\n",
            "HIP runtime version: N/A\n",
            "MIOpen runtime version: N/A\n",
            "Is XNNPACK available: True\n",
            "\n",
            "Versions of relevant libraries:\n",
            "[pip3] numpy==1.21.6\n",
            "[pip3] torch==1.12.0+cu113\n",
            "[pip3] torchaudio==0.12.0+cu113\n",
            "[pip3] torchsummary==1.5.1\n",
            "[pip3] torchtext==0.14.1\n",
            "[pip3] torchvision==0.13.0+cu113\n",
            "[conda] Could not collect\n",
            "        Pillow (7.1.2)\n",
            "2023-02-04 16:08:27,435 maskrcnn_benchmark INFO: Loaded configuration file /content/MIC/det/configs/fff.yaml\n",
            "2023-02-04 16:08:27,435 maskrcnn_benchmark INFO: \n",
            "MODEL:\n",
            "  META_ARCHITECTURE: \"GeneralizedRCNN\"\n",
            "  #WEIGHT: \"catalog://ImageNetPretrained/MSRA/R-50\"\n",
            "  WEIGHT: \"/content/drive/MyDrive/AI/mic/model_0003000.pth\"\n",
            "  DOMAIN_ADAPTATION_ON: True\n",
            "  BACKBONE:\n",
            "    CONV_BODY: \"R-50-FPN\"\n",
            "    OUT_CHANNELS: 256\n",
            "  RPN:\n",
            "    USE_FPN: True\n",
            "    ANCHOR_STRIDE: (4, 8, 16, 32, 64)\n",
            "    PRE_NMS_TOP_N_TRAIN: 2000\n",
            "    PRE_NMS_TOP_N_TEST: 1000\n",
            "    POST_NMS_TOP_N_TEST: 1000\n",
            "    FPN_POST_NMS_TOP_N_TEST: 1000\n",
            "  ROI_HEADS:\n",
            "    USE_FPN: True\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "  ROI_BOX_HEAD:\n",
            "    NUM_CLASSES: 2\n",
            "    POOLER_RESOLUTION: 7\n",
            "    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n",
            "    POOLER_SAMPLING_RATIO: 2\n",
            "    FEATURE_EXTRACTOR: \"FPN2MLPFeatureExtractor\"\n",
            "    PREDICTOR: \"FPNPredictor\"\n",
            "  DA_HEADS:\n",
            "    DA_IMG_GRL_WEIGHT: 0.01\n",
            "    DA_INS_GRL_WEIGHT: 0.1\n",
            "    COS_WEIGHT: 0.1\n",
            "  MIC_ON: True\n",
            "  MASKING_AUGMENTATION: True\n",
            "  PSEUDO_LABEL_THRESHOLD: 0.8\n",
            "  PSEUDO_LABEL_LAMBDA: 1.0\n",
            "  PSEUDO_LABEL_WEIGHT: 'prob'\n",
            "  MASKING_BLOCK_SIZE: 32\n",
            "  MASKING_RATIO: 0.5\n",
            "  TEACHER_ALPHA: 0.9\n",
            "DATASETS:\n",
            "  SOURCE_TRAIN: (\"sim10k_cocostyle\",) #(\"cityscapes_fine_instanceonly_seg_train_cocostyle\",)\n",
            "  TARGET_TRAIN: (\"cityscapes_only_car_train_cocostyle\",) #(\"foggy_cityscapes_fine_instanceonly_seg_train_cocostyle\",)\n",
            "  TEST: (\"cityscapes_only_car_val_cocostyle\",) #(\"foggy_cityscapes_fine_instanceonly_seg_val_cocostyle\",)\n",
            "INPUT:\n",
            "  MIN_SIZE_TRAIN: (800,)\n",
            "  MAX_SIZE_TRAIN: 1600\n",
            "  MIN_SIZE_TEST: 800\n",
            "  MAX_SIZE_TEST: 1600\n",
            "DATALOADER:\n",
            "  SIZE_DIVISIBILITY: 32\n",
            "SOLVER:\n",
            "  CHECKPOINT_PERIOD: 1000\n",
            "  WARMUP_ITERS: 1000\n",
            "  BASE_LR: 0.001\n",
            "  WEIGHT_DECAY: 0.0001\n",
            "  STEPS: (30000, 40000)\n",
            "  MAX_ITER: 60000\n",
            "  IMS_PER_BATCH: 2\n",
            "TEST:\n",
            "  IMS_PER_BATCH: 1\n",
            "OUTPUT_DIR: \"/content/drive/MyDrive/AI/mic\"\n",
            "\n",
            "2023-02-04 16:08:27,436 maskrcnn_benchmark INFO: Running with config:\n",
            "DATALOADER:\n",
            "  ASPECT_RATIO_GROUPING: True\n",
            "  NUM_WORKERS: 4\n",
            "  SIZE_DIVISIBILITY: 32\n",
            "DATASETS:\n",
            "  SOURCE_TRAIN: ('sim10k_cocostyle',)\n",
            "  TARGET_TRAIN: ('cityscapes_only_car_train_cocostyle',)\n",
            "  TEST: ('cityscapes_only_car_val_cocostyle',)\n",
            "  TRAIN: ()\n",
            "INPUT:\n",
            "  MAX_SIZE_TEST: 1600\n",
            "  MAX_SIZE_TRAIN: 1600\n",
            "  MIN_SIZE_TEST: 800\n",
            "  MIN_SIZE_TRAIN: (800,)\n",
            "  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]\n",
            "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
            "  TO_BGR255: True\n",
            "MODEL:\n",
            "  BACKBONE:\n",
            "    CONV_BODY: R-50-FPN\n",
            "    FREEZE_CONV_BODY_AT: 2\n",
            "    OUT_CHANNELS: 256\n",
            "    USE_GN: False\n",
            "  CLS_AGNOSTIC_BBOX_REG: False\n",
            "  DA_HEADS:\n",
            "    COS_WEIGHT: 0.1\n",
            "    DA_IMG_GRL_WEIGHT: 0.01\n",
            "    DA_INS_GRL_WEIGHT: 0.1\n",
            "  DEVICE: cuda\n",
            "  DOMAIN_ADAPTATION_ON: True\n",
            "  FPN:\n",
            "    USE_GN: False\n",
            "    USE_RELU: False\n",
            "  GROUP_NORM:\n",
            "    DIM_PER_GP: -1\n",
            "    EPSILON: 1e-05\n",
            "    NUM_GROUPS: 32\n",
            "  KEYPOINT_ON: False\n",
            "  MASKING_AUGMENTATION: True\n",
            "  MASKING_BLOCK_SIZE: 32\n",
            "  MASKING_RATIO: 0.5\n",
            "  MASK_ON: False\n",
            "  META_ARCHITECTURE: GeneralizedRCNN\n",
            "  MIC_ON: True\n",
            "  PSEUDO_LABEL_LAMBDA: 1.0\n",
            "  PSEUDO_LABEL_THRESHOLD: 0.8\n",
            "  PSEUDO_LABEL_WEIGHT: prob\n",
            "  RESNETS:\n",
            "    NUM_GROUPS: 1\n",
            "    RES2_OUT_CHANNELS: 256\n",
            "    RES5_DILATION: 1\n",
            "    STEM_FUNC: StemWithFixedBatchNorm\n",
            "    STEM_OUT_CHANNELS: 64\n",
            "    STRIDE_IN_1X1: True\n",
            "    TRANS_FUNC: BottleneckWithFixedBatchNorm\n",
            "    WIDTH_PER_GROUP: 64\n",
            "  RETINANET:\n",
            "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
            "    ANCHOR_STRIDES: (8, 16, 32, 64, 128)\n",
            "    ASPECT_RATIOS: (0.5, 1.0, 2.0)\n",
            "    BBOX_REG_BETA: 0.11\n",
            "    BBOX_REG_WEIGHT: 4.0\n",
            "    BG_IOU_THRESHOLD: 0.4\n",
            "    FG_IOU_THRESHOLD: 0.5\n",
            "    INFERENCE_TH: 0.05\n",
            "    LOSS_ALPHA: 0.25\n",
            "    LOSS_GAMMA: 2.0\n",
            "    NMS_TH: 0.4\n",
            "    NUM_CLASSES: 81\n",
            "    NUM_CONVS: 4\n",
            "    OCTAVE: 2.0\n",
            "    PRE_NMS_TOP_N: 1000\n",
            "    PRIOR_PROB: 0.01\n",
            "    SCALES_PER_OCTAVE: 3\n",
            "    STRADDLE_THRESH: 0\n",
            "    USE_C5: True\n",
            "  RETINANET_ON: False\n",
            "  ROI_BOX_HEAD:\n",
            "    CONV_HEAD_DIM: 256\n",
            "    DILATION: 1\n",
            "    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n",
            "    MLP_HEAD_DIM: 1024\n",
            "    NUM_CLASSES: 2\n",
            "    NUM_STACKED_CONVS: 4\n",
            "    POOLER_RESOLUTION: 7\n",
            "    POOLER_SAMPLING_RATIO: 2\n",
            "    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n",
            "    PREDICTOR: FPNPredictor\n",
            "    USE_GN: False\n",
            "  ROI_HEADS:\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
            "    BG_IOU_THRESHOLD: 0.5\n",
            "    DETECTIONS_PER_IMG: 100\n",
            "    FG_IOU_THRESHOLD: 0.5\n",
            "    NMS: 0.5\n",
            "    POSITIVE_FRACTION: 0.25\n",
            "    SCORE_THRESH: 0.05\n",
            "    USE_FPN: True\n",
            "  ROI_KEYPOINT_HEAD:\n",
            "    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
            "    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor\n",
            "    MLP_HEAD_DIM: 1024\n",
            "    NUM_CLASSES: 17\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_SCALES: (0.0625,)\n",
            "    PREDICTOR: KeypointRCNNPredictor\n",
            "    RESOLUTION: 14\n",
            "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
            "  ROI_MASK_HEAD:\n",
            "    CONV_LAYERS: (256, 256, 256, 256)\n",
            "    DILATION: 1\n",
            "    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor\n",
            "    MLP_HEAD_DIM: 1024\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_SCALES: (0.0625,)\n",
            "    POSTPROCESS_MASKS: False\n",
            "    POSTPROCESS_MASKS_THRESHOLD: 0.5\n",
            "    PREDICTOR: MaskRCNNC4Predictor\n",
            "    RESOLUTION: 14\n",
            "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
            "    USE_GN: False\n",
            "  RPN:\n",
            "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
            "    ANCHOR_STRIDE: (4, 8, 16, 32, 64)\n",
            "    ASPECT_RATIOS: (0.5, 1.0, 2.0)\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "    BG_IOU_THRESHOLD: 0.3\n",
            "    FG_IOU_THRESHOLD: 0.7\n",
            "    FPN_POST_NMS_TOP_N_TEST: 1000\n",
            "    FPN_POST_NMS_TOP_N_TRAIN: 2000\n",
            "    MIN_SIZE: 0\n",
            "    NMS_THRESH: 0.7\n",
            "    POSITIVE_FRACTION: 0.5\n",
            "    POST_NMS_TOP_N_TEST: 1000\n",
            "    POST_NMS_TOP_N_TRAIN: 2000\n",
            "    PRE_NMS_TOP_N_TEST: 1000\n",
            "    PRE_NMS_TOP_N_TRAIN: 2000\n",
            "    RPN_HEAD: SingleConvRPNHead\n",
            "    STRADDLE_THRESH: 0\n",
            "    USE_FPN: True\n",
            "  RPN_ONLY: False\n",
            "  TEACHER_ALPHA: 0.9\n",
            "  WEIGHT: /content/drive/MyDrive/AI/mic/model_0003000.pth\n",
            "OUTPUT_DIR: /content/drive/MyDrive/AI/mic\n",
            "PATHS_CATALOG: /content/MIC/det/maskrcnn_benchmark/config/paths_catalog.py\n",
            "SOLVER:\n",
            "  BASE_LR: 0.001\n",
            "  BIAS_LR_FACTOR: 2\n",
            "  CHECKPOINT_PERIOD: 1000\n",
            "  GAMMA: 0.1\n",
            "  IMS_PER_BATCH: 2\n",
            "  MAX_ITER: 60000\n",
            "  MOMENTUM: 0.9\n",
            "  STEPS: (30000, 40000)\n",
            "  WARMUP_FACTOR: 0.3333333333333333\n",
            "  WARMUP_ITERS: 1000\n",
            "  WARMUP_METHOD: linear\n",
            "  WEIGHT_DECAY: 0.0001\n",
            "  WEIGHT_DECAY_BIAS: 0\n",
            "TEST:\n",
            "  DETECTIONS_PER_IMG: 100\n",
            "  EXPECTED_RESULTS: []\n",
            "  EXPECTED_RESULTS_SIGMA_TOL: 4\n",
            "  IMS_PER_BATCH: 1\n",
            "2023-02-04 16:08:27,436 maskrcnn_benchmark INFO: Set random seed to 1, deterministic: False\n",
            "2023-02-04 16:08:31,122 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from /content/drive/MyDrive/AI/mic/model_0003000.pth\n",
            "2023-02-04 16:08:31,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.bias                  loaded from backbone.body.layer1.0.bn1.bias                  of shape (64,)\n",
            "2023-02-04 16:08:31,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.running_mean          loaded from backbone.body.layer1.0.bn1.running_mean          of shape (64,)\n",
            "2023-02-04 16:08:31,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.running_var           loaded from backbone.body.layer1.0.bn1.running_var           of shape (64,)\n",
            "2023-02-04 16:08:31,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.weight                loaded from backbone.body.layer1.0.bn1.weight                of shape (64,)\n",
            "2023-02-04 16:08:31,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.bias                  loaded from backbone.body.layer1.0.bn2.bias                  of shape (64,)\n",
            "2023-02-04 16:08:31,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.running_mean          loaded from backbone.body.layer1.0.bn2.running_mean          of shape (64,)\n",
            "2023-02-04 16:08:31,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.running_var           loaded from backbone.body.layer1.0.bn2.running_var           of shape (64,)\n",
            "2023-02-04 16:08:31,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.weight                loaded from backbone.body.layer1.0.bn2.weight                of shape (64,)\n",
            "2023-02-04 16:08:31,986 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.bias                  loaded from backbone.body.layer1.0.bn3.bias                  of shape (256,)\n",
            "2023-02-04 16:08:31,986 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.running_mean          loaded from backbone.body.layer1.0.bn3.running_mean          of shape (256,)\n",
            "2023-02-04 16:08:31,986 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.running_var           loaded from backbone.body.layer1.0.bn3.running_var           of shape (256,)\n",
            "2023-02-04 16:08:31,986 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.weight                loaded from backbone.body.layer1.0.bn3.weight                of shape (256,)\n",
            "2023-02-04 16:08:31,986 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv1.weight              loaded from backbone.body.layer1.0.conv1.weight              of shape (64, 64, 1, 1)\n",
            "2023-02-04 16:08:31,986 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv2.weight              loaded from backbone.body.layer1.0.conv2.weight              of shape (64, 64, 3, 3)\n",
            "2023-02-04 16:08:31,987 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv3.weight              loaded from backbone.body.layer1.0.conv3.weight              of shape (256, 64, 1, 1)\n",
            "2023-02-04 16:08:31,987 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.0.weight       loaded from backbone.body.layer1.0.downsample.0.weight       of shape (256, 64, 1, 1)\n",
            "2023-02-04 16:08:31,987 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.bias         loaded from backbone.body.layer1.0.downsample.1.bias         of shape (256,)\n",
            "2023-02-04 16:08:31,987 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.running_mean loaded from backbone.body.layer1.0.downsample.1.running_mean of shape (256,)\n",
            "2023-02-04 16:08:31,987 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.running_var  loaded from backbone.body.layer1.0.downsample.1.running_var  of shape (256,)\n",
            "2023-02-04 16:08:31,988 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.weight       loaded from backbone.body.layer1.0.downsample.1.weight       of shape (256,)\n",
            "2023-02-04 16:08:31,988 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.bias                  loaded from backbone.body.layer1.1.bn1.bias                  of shape (64,)\n",
            "2023-02-04 16:08:31,988 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.running_mean          loaded from backbone.body.layer1.1.bn1.running_mean          of shape (64,)\n",
            "2023-02-04 16:08:31,988 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.running_var           loaded from backbone.body.layer1.1.bn1.running_var           of shape (64,)\n",
            "2023-02-04 16:08:31,989 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.weight                loaded from backbone.body.layer1.1.bn1.weight                of shape (64,)\n",
            "2023-02-04 16:08:31,989 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.bias                  loaded from backbone.body.layer1.1.bn2.bias                  of shape (64,)\n",
            "2023-02-04 16:08:31,989 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.running_mean          loaded from backbone.body.layer1.1.bn2.running_mean          of shape (64,)\n",
            "2023-02-04 16:08:31,989 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.running_var           loaded from backbone.body.layer1.1.bn2.running_var           of shape (64,)\n",
            "2023-02-04 16:08:31,989 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.weight                loaded from backbone.body.layer1.1.bn2.weight                of shape (64,)\n",
            "2023-02-04 16:08:31,989 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.bias                  loaded from backbone.body.layer1.1.bn3.bias                  of shape (256,)\n",
            "2023-02-04 16:08:31,990 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.running_mean          loaded from backbone.body.layer1.1.bn3.running_mean          of shape (256,)\n",
            "2023-02-04 16:08:31,990 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.running_var           loaded from backbone.body.layer1.1.bn3.running_var           of shape (256,)\n",
            "2023-02-04 16:08:31,990 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.weight                loaded from backbone.body.layer1.1.bn3.weight                of shape (256,)\n",
            "2023-02-04 16:08:31,990 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv1.weight              loaded from backbone.body.layer1.1.conv1.weight              of shape (64, 256, 1, 1)\n",
            "2023-02-04 16:08:31,990 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv2.weight              loaded from backbone.body.layer1.1.conv2.weight              of shape (64, 64, 3, 3)\n",
            "2023-02-04 16:08:31,991 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv3.weight              loaded from backbone.body.layer1.1.conv3.weight              of shape (256, 64, 1, 1)\n",
            "2023-02-04 16:08:31,991 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.bias                  loaded from backbone.body.layer1.2.bn1.bias                  of shape (64,)\n",
            "2023-02-04 16:08:31,991 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.running_mean          loaded from backbone.body.layer1.2.bn1.running_mean          of shape (64,)\n",
            "2023-02-04 16:08:31,991 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.running_var           loaded from backbone.body.layer1.2.bn1.running_var           of shape (64,)\n",
            "2023-02-04 16:08:31,991 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.weight                loaded from backbone.body.layer1.2.bn1.weight                of shape (64,)\n",
            "2023-02-04 16:08:31,992 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.bias                  loaded from backbone.body.layer1.2.bn2.bias                  of shape (64,)\n",
            "2023-02-04 16:08:31,992 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.running_mean          loaded from backbone.body.layer1.2.bn2.running_mean          of shape (64,)\n",
            "2023-02-04 16:08:31,992 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.running_var           loaded from backbone.body.layer1.2.bn2.running_var           of shape (64,)\n",
            "2023-02-04 16:08:31,992 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.weight                loaded from backbone.body.layer1.2.bn2.weight                of shape (64,)\n",
            "2023-02-04 16:08:31,992 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.bias                  loaded from backbone.body.layer1.2.bn3.bias                  of shape (256,)\n",
            "2023-02-04 16:08:31,993 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.running_mean          loaded from backbone.body.layer1.2.bn3.running_mean          of shape (256,)\n",
            "2023-02-04 16:08:31,993 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.running_var           loaded from backbone.body.layer1.2.bn3.running_var           of shape (256,)\n",
            "2023-02-04 16:08:31,993 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.weight                loaded from backbone.body.layer1.2.bn3.weight                of shape (256,)\n",
            "2023-02-04 16:08:31,993 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv1.weight              loaded from backbone.body.layer1.2.conv1.weight              of shape (64, 256, 1, 1)\n",
            "2023-02-04 16:08:31,993 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv2.weight              loaded from backbone.body.layer1.2.conv2.weight              of shape (64, 64, 3, 3)\n",
            "2023-02-04 16:08:31,994 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv3.weight              loaded from backbone.body.layer1.2.conv3.weight              of shape (256, 64, 1, 1)\n",
            "2023-02-04 16:08:31,994 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.bias                  loaded from backbone.body.layer2.0.bn1.bias                  of shape (128,)\n",
            "2023-02-04 16:08:31,994 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.running_mean          loaded from backbone.body.layer2.0.bn1.running_mean          of shape (128,)\n",
            "2023-02-04 16:08:31,994 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.running_var           loaded from backbone.body.layer2.0.bn1.running_var           of shape (128,)\n",
            "2023-02-04 16:08:31,994 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.weight                loaded from backbone.body.layer2.0.bn1.weight                of shape (128,)\n",
            "2023-02-04 16:08:31,995 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.bias                  loaded from backbone.body.layer2.0.bn2.bias                  of shape (128,)\n",
            "2023-02-04 16:08:31,995 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.running_mean          loaded from backbone.body.layer2.0.bn2.running_mean          of shape (128,)\n",
            "2023-02-04 16:08:31,995 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.running_var           loaded from backbone.body.layer2.0.bn2.running_var           of shape (128,)\n",
            "2023-02-04 16:08:31,995 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.weight                loaded from backbone.body.layer2.0.bn2.weight                of shape (128,)\n",
            "2023-02-04 16:08:31,995 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.bias                  loaded from backbone.body.layer2.0.bn3.bias                  of shape (512,)\n",
            "2023-02-04 16:08:31,996 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.running_mean          loaded from backbone.body.layer2.0.bn3.running_mean          of shape (512,)\n",
            "2023-02-04 16:08:31,996 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.running_var           loaded from backbone.body.layer2.0.bn3.running_var           of shape (512,)\n",
            "2023-02-04 16:08:31,996 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.weight                loaded from backbone.body.layer2.0.bn3.weight                of shape (512,)\n",
            "2023-02-04 16:08:31,996 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv1.weight              loaded from backbone.body.layer2.0.conv1.weight              of shape (128, 256, 1, 1)\n",
            "2023-02-04 16:08:31,996 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv2.weight              loaded from backbone.body.layer2.0.conv2.weight              of shape (128, 128, 3, 3)\n",
            "2023-02-04 16:08:31,997 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv3.weight              loaded from backbone.body.layer2.0.conv3.weight              of shape (512, 128, 1, 1)\n",
            "2023-02-04 16:08:31,997 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.0.weight       loaded from backbone.body.layer2.0.downsample.0.weight       of shape (512, 256, 1, 1)\n",
            "2023-02-04 16:08:31,997 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.bias         loaded from backbone.body.layer2.0.downsample.1.bias         of shape (512,)\n",
            "2023-02-04 16:08:31,997 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.running_mean loaded from backbone.body.layer2.0.downsample.1.running_mean of shape (512,)\n",
            "2023-02-04 16:08:31,997 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.running_var  loaded from backbone.body.layer2.0.downsample.1.running_var  of shape (512,)\n",
            "2023-02-04 16:08:31,998 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.weight       loaded from backbone.body.layer2.0.downsample.1.weight       of shape (512,)\n",
            "2023-02-04 16:08:31,998 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.bias                  loaded from backbone.body.layer2.1.bn1.bias                  of shape (128,)\n",
            "2023-02-04 16:08:31,998 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.running_mean          loaded from backbone.body.layer2.1.bn1.running_mean          of shape (128,)\n",
            "2023-02-04 16:08:31,998 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.running_var           loaded from backbone.body.layer2.1.bn1.running_var           of shape (128,)\n",
            "2023-02-04 16:08:31,998 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.weight                loaded from backbone.body.layer2.1.bn1.weight                of shape (128,)\n",
            "2023-02-04 16:08:31,998 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.bias                  loaded from backbone.body.layer2.1.bn2.bias                  of shape (128,)\n",
            "2023-02-04 16:08:31,999 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.running_mean          loaded from backbone.body.layer2.1.bn2.running_mean          of shape (128,)\n",
            "2023-02-04 16:08:31,999 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.running_var           loaded from backbone.body.layer2.1.bn2.running_var           of shape (128,)\n",
            "2023-02-04 16:08:31,999 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.weight                loaded from backbone.body.layer2.1.bn2.weight                of shape (128,)\n",
            "2023-02-04 16:08:32,000 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.bias                  loaded from backbone.body.layer2.1.bn3.bias                  of shape (512,)\n",
            "2023-02-04 16:08:32,000 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.running_mean          loaded from backbone.body.layer2.1.bn3.running_mean          of shape (512,)\n",
            "2023-02-04 16:08:32,000 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.running_var           loaded from backbone.body.layer2.1.bn3.running_var           of shape (512,)\n",
            "2023-02-04 16:08:32,000 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.weight                loaded from backbone.body.layer2.1.bn3.weight                of shape (512,)\n",
            "2023-02-04 16:08:32,000 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv1.weight              loaded from backbone.body.layer2.1.conv1.weight              of shape (128, 512, 1, 1)\n",
            "2023-02-04 16:08:32,065 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv2.weight              loaded from backbone.body.layer2.1.conv2.weight              of shape (128, 128, 3, 3)\n",
            "2023-02-04 16:08:32,066 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv3.weight              loaded from backbone.body.layer2.1.conv3.weight              of shape (512, 128, 1, 1)\n",
            "2023-02-04 16:08:32,066 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.bias                  loaded from backbone.body.layer2.2.bn1.bias                  of shape (128,)\n",
            "2023-02-04 16:08:32,066 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.running_mean          loaded from backbone.body.layer2.2.bn1.running_mean          of shape (128,)\n",
            "2023-02-04 16:08:32,067 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.running_var           loaded from backbone.body.layer2.2.bn1.running_var           of shape (128,)\n",
            "2023-02-04 16:08:32,067 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.weight                loaded from backbone.body.layer2.2.bn1.weight                of shape (128,)\n",
            "2023-02-04 16:08:32,067 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.bias                  loaded from backbone.body.layer2.2.bn2.bias                  of shape (128,)\n",
            "2023-02-04 16:08:32,067 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.running_mean          loaded from backbone.body.layer2.2.bn2.running_mean          of shape (128,)\n",
            "2023-02-04 16:08:32,067 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.running_var           loaded from backbone.body.layer2.2.bn2.running_var           of shape (128,)\n",
            "2023-02-04 16:08:32,068 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.weight                loaded from backbone.body.layer2.2.bn2.weight                of shape (128,)\n",
            "2023-02-04 16:08:32,068 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.bias                  loaded from backbone.body.layer2.2.bn3.bias                  of shape (512,)\n",
            "2023-02-04 16:08:32,068 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.running_mean          loaded from backbone.body.layer2.2.bn3.running_mean          of shape (512,)\n",
            "2023-02-04 16:08:32,068 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.running_var           loaded from backbone.body.layer2.2.bn3.running_var           of shape (512,)\n",
            "2023-02-04 16:08:32,068 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.weight                loaded from backbone.body.layer2.2.bn3.weight                of shape (512,)\n",
            "2023-02-04 16:08:32,068 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv1.weight              loaded from backbone.body.layer2.2.conv1.weight              of shape (128, 512, 1, 1)\n",
            "2023-02-04 16:08:32,069 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv2.weight              loaded from backbone.body.layer2.2.conv2.weight              of shape (128, 128, 3, 3)\n",
            "2023-02-04 16:08:32,069 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv3.weight              loaded from backbone.body.layer2.2.conv3.weight              of shape (512, 128, 1, 1)\n",
            "2023-02-04 16:08:32,069 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.bias                  loaded from backbone.body.layer2.3.bn1.bias                  of shape (128,)\n",
            "2023-02-04 16:08:32,069 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.running_mean          loaded from backbone.body.layer2.3.bn1.running_mean          of shape (128,)\n",
            "2023-02-04 16:08:32,069 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.running_var           loaded from backbone.body.layer2.3.bn1.running_var           of shape (128,)\n",
            "2023-02-04 16:08:32,070 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.weight                loaded from backbone.body.layer2.3.bn1.weight                of shape (128,)\n",
            "2023-02-04 16:08:32,070 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.bias                  loaded from backbone.body.layer2.3.bn2.bias                  of shape (128,)\n",
            "2023-02-04 16:08:32,070 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.running_mean          loaded from backbone.body.layer2.3.bn2.running_mean          of shape (128,)\n",
            "2023-02-04 16:08:32,070 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.running_var           loaded from backbone.body.layer2.3.bn2.running_var           of shape (128,)\n",
            "2023-02-04 16:08:32,070 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.weight                loaded from backbone.body.layer2.3.bn2.weight                of shape (128,)\n",
            "2023-02-04 16:08:32,070 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.bias                  loaded from backbone.body.layer2.3.bn3.bias                  of shape (512,)\n",
            "2023-02-04 16:08:32,071 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.running_mean          loaded from backbone.body.layer2.3.bn3.running_mean          of shape (512,)\n",
            "2023-02-04 16:08:32,071 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.running_var           loaded from backbone.body.layer2.3.bn3.running_var           of shape (512,)\n",
            "2023-02-04 16:08:32,071 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.weight                loaded from backbone.body.layer2.3.bn3.weight                of shape (512,)\n",
            "2023-02-04 16:08:32,071 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv1.weight              loaded from backbone.body.layer2.3.conv1.weight              of shape (128, 512, 1, 1)\n",
            "2023-02-04 16:08:32,071 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv2.weight              loaded from backbone.body.layer2.3.conv2.weight              of shape (128, 128, 3, 3)\n",
            "2023-02-04 16:08:32,072 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv3.weight              loaded from backbone.body.layer2.3.conv3.weight              of shape (512, 128, 1, 1)\n",
            "2023-02-04 16:08:32,072 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.bias                  loaded from backbone.body.layer3.0.bn1.bias                  of shape (256,)\n",
            "2023-02-04 16:08:32,072 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.running_mean          loaded from backbone.body.layer3.0.bn1.running_mean          of shape (256,)\n",
            "2023-02-04 16:08:32,072 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.running_var           loaded from backbone.body.layer3.0.bn1.running_var           of shape (256,)\n",
            "2023-02-04 16:08:32,072 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.weight                loaded from backbone.body.layer3.0.bn1.weight                of shape (256,)\n",
            "2023-02-04 16:08:32,072 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.bias                  loaded from backbone.body.layer3.0.bn2.bias                  of shape (256,)\n",
            "2023-02-04 16:08:32,073 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.running_mean          loaded from backbone.body.layer3.0.bn2.running_mean          of shape (256,)\n",
            "2023-02-04 16:08:32,073 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.running_var           loaded from backbone.body.layer3.0.bn2.running_var           of shape (256,)\n",
            "2023-02-04 16:08:32,073 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.weight                loaded from backbone.body.layer3.0.bn2.weight                of shape (256,)\n",
            "2023-02-04 16:08:32,073 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.bias                  loaded from backbone.body.layer3.0.bn3.bias                  of shape (1024,)\n",
            "2023-02-04 16:08:32,073 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.running_mean          loaded from backbone.body.layer3.0.bn3.running_mean          of shape (1024,)\n",
            "2023-02-04 16:08:32,074 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.running_var           loaded from backbone.body.layer3.0.bn3.running_var           of shape (1024,)\n",
            "2023-02-04 16:08:32,074 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.weight                loaded from backbone.body.layer3.0.bn3.weight                of shape (1024,)\n",
            "2023-02-04 16:08:32,074 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv1.weight              loaded from backbone.body.layer3.0.conv1.weight              of shape (256, 512, 1, 1)\n",
            "2023-02-04 16:08:32,074 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv2.weight              loaded from backbone.body.layer3.0.conv2.weight              of shape (256, 256, 3, 3)\n",
            "2023-02-04 16:08:32,074 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv3.weight              loaded from backbone.body.layer3.0.conv3.weight              of shape (1024, 256, 1, 1)\n",
            "2023-02-04 16:08:32,075 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.0.weight       loaded from backbone.body.layer3.0.downsample.0.weight       of shape (1024, 512, 1, 1)\n",
            "2023-02-04 16:08:32,075 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.bias         loaded from backbone.body.layer3.0.downsample.1.bias         of shape (1024,)\n",
            "2023-02-04 16:08:32,075 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.running_mean loaded from backbone.body.layer3.0.downsample.1.running_mean of shape (1024,)\n",
            "2023-02-04 16:08:32,075 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.running_var  loaded from backbone.body.layer3.0.downsample.1.running_var  of shape (1024,)\n",
            "2023-02-04 16:08:32,075 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.weight       loaded from backbone.body.layer3.0.downsample.1.weight       of shape (1024,)\n",
            "2023-02-04 16:08:32,075 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.bias                  loaded from backbone.body.layer3.1.bn1.bias                  of shape (256,)\n",
            "2023-02-04 16:08:32,076 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.running_mean          loaded from backbone.body.layer3.1.bn1.running_mean          of shape (256,)\n",
            "2023-02-04 16:08:32,076 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.running_var           loaded from backbone.body.layer3.1.bn1.running_var           of shape (256,)\n",
            "2023-02-04 16:08:32,076 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.weight                loaded from backbone.body.layer3.1.bn1.weight                of shape (256,)\n",
            "2023-02-04 16:08:32,076 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.bias                  loaded from backbone.body.layer3.1.bn2.bias                  of shape (256,)\n",
            "2023-02-04 16:08:32,076 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.running_mean          loaded from backbone.body.layer3.1.bn2.running_mean          of shape (256,)\n",
            "2023-02-04 16:08:32,077 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.running_var           loaded from backbone.body.layer3.1.bn2.running_var           of shape (256,)\n",
            "2023-02-04 16:08:32,077 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.weight                loaded from backbone.body.layer3.1.bn2.weight                of shape (256,)\n",
            "2023-02-04 16:08:32,077 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.bias                  loaded from backbone.body.layer3.1.bn3.bias                  of shape (1024,)\n",
            "2023-02-04 16:08:32,077 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.running_mean          loaded from backbone.body.layer3.1.bn3.running_mean          of shape (1024,)\n",
            "2023-02-04 16:08:32,077 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.running_var           loaded from backbone.body.layer3.1.bn3.running_var           of shape (1024,)\n",
            "2023-02-04 16:08:32,077 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.weight                loaded from backbone.body.layer3.1.bn3.weight                of shape (1024,)\n",
            "2023-02-04 16:08:32,078 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv1.weight              loaded from backbone.body.layer3.1.conv1.weight              of shape (256, 1024, 1, 1)\n",
            "2023-02-04 16:08:32,078 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv2.weight              loaded from backbone.body.layer3.1.conv2.weight              of shape (256, 256, 3, 3)\n",
            "2023-02-04 16:08:32,078 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv3.weight              loaded from backbone.body.layer3.1.conv3.weight              of shape (1024, 256, 1, 1)\n",
            "2023-02-04 16:08:32,078 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.bias                  loaded from backbone.body.layer3.2.bn1.bias                  of shape (256,)\n",
            "2023-02-04 16:08:32,078 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.running_mean          loaded from backbone.body.layer3.2.bn1.running_mean          of shape (256,)\n",
            "2023-02-04 16:08:32,079 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.running_var           loaded from backbone.body.layer3.2.bn1.running_var           of shape (256,)\n",
            "2023-02-04 16:08:32,079 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.weight                loaded from backbone.body.layer3.2.bn1.weight                of shape (256,)\n",
            "2023-02-04 16:08:32,079 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.bias                  loaded from backbone.body.layer3.2.bn2.bias                  of shape (256,)\n",
            "2023-02-04 16:08:32,079 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.running_mean          loaded from backbone.body.layer3.2.bn2.running_mean          of shape (256,)\n",
            "2023-02-04 16:08:32,079 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.running_var           loaded from backbone.body.layer3.2.bn2.running_var           of shape (256,)\n",
            "2023-02-04 16:08:32,079 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.weight                loaded from backbone.body.layer3.2.bn2.weight                of shape (256,)\n",
            "2023-02-04 16:08:32,080 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.bias                  loaded from backbone.body.layer3.2.bn3.bias                  of shape (1024,)\n",
            "2023-02-04 16:08:32,080 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.running_mean          loaded from backbone.body.layer3.2.bn3.running_mean          of shape (1024,)\n",
            "2023-02-04 16:08:32,080 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.running_var           loaded from backbone.body.layer3.2.bn3.running_var           of shape (1024,)\n",
            "2023-02-04 16:08:32,080 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.weight                loaded from backbone.body.layer3.2.bn3.weight                of shape (1024,)\n",
            "2023-02-04 16:08:32,080 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv1.weight              loaded from backbone.body.layer3.2.conv1.weight              of shape (256, 1024, 1, 1)\n",
            "2023-02-04 16:08:32,081 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv2.weight              loaded from backbone.body.layer3.2.conv2.weight              of shape (256, 256, 3, 3)\n",
            "2023-02-04 16:08:32,081 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv3.weight              loaded from backbone.body.layer3.2.conv3.weight              of shape (1024, 256, 1, 1)\n",
            "2023-02-04 16:08:32,081 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.bias                  loaded from backbone.body.layer3.3.bn1.bias                  of shape (256,)\n",
            "2023-02-04 16:08:32,081 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.running_mean          loaded from backbone.body.layer3.3.bn1.running_mean          of shape (256,)\n",
            "2023-02-04 16:08:32,169 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.running_var           loaded from backbone.body.layer3.3.bn1.running_var           of shape (256,)\n",
            "2023-02-04 16:08:32,169 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.weight                loaded from backbone.body.layer3.3.bn1.weight                of shape (256,)\n",
            "2023-02-04 16:08:32,169 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.bias                  loaded from backbone.body.layer3.3.bn2.bias                  of shape (256,)\n",
            "2023-02-04 16:08:32,169 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.running_mean          loaded from backbone.body.layer3.3.bn2.running_mean          of shape (256,)\n",
            "2023-02-04 16:08:32,169 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.running_var           loaded from backbone.body.layer3.3.bn2.running_var           of shape (256,)\n",
            "2023-02-04 16:08:32,170 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.weight                loaded from backbone.body.layer3.3.bn2.weight                of shape (256,)\n",
            "2023-02-04 16:08:32,170 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.bias                  loaded from backbone.body.layer3.3.bn3.bias                  of shape (1024,)\n",
            "2023-02-04 16:08:32,170 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.running_mean          loaded from backbone.body.layer3.3.bn3.running_mean          of shape (1024,)\n",
            "2023-02-04 16:08:32,170 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.running_var           loaded from backbone.body.layer3.3.bn3.running_var           of shape (1024,)\n",
            "2023-02-04 16:08:32,170 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.weight                loaded from backbone.body.layer3.3.bn3.weight                of shape (1024,)\n",
            "2023-02-04 16:08:32,170 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv1.weight              loaded from backbone.body.layer3.3.conv1.weight              of shape (256, 1024, 1, 1)\n",
            "2023-02-04 16:08:32,171 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv2.weight              loaded from backbone.body.layer3.3.conv2.weight              of shape (256, 256, 3, 3)\n",
            "2023-02-04 16:08:32,171 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv3.weight              loaded from backbone.body.layer3.3.conv3.weight              of shape (1024, 256, 1, 1)\n",
            "2023-02-04 16:08:32,171 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.bias                  loaded from backbone.body.layer3.4.bn1.bias                  of shape (256,)\n",
            "2023-02-04 16:08:32,171 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.running_mean          loaded from backbone.body.layer3.4.bn1.running_mean          of shape (256,)\n",
            "2023-02-04 16:08:32,171 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.running_var           loaded from backbone.body.layer3.4.bn1.running_var           of shape (256,)\n",
            "2023-02-04 16:08:32,172 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.weight                loaded from backbone.body.layer3.4.bn1.weight                of shape (256,)\n",
            "2023-02-04 16:08:32,172 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.bias                  loaded from backbone.body.layer3.4.bn2.bias                  of shape (256,)\n",
            "2023-02-04 16:08:32,172 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.running_mean          loaded from backbone.body.layer3.4.bn2.running_mean          of shape (256,)\n",
            "2023-02-04 16:08:32,172 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.running_var           loaded from backbone.body.layer3.4.bn2.running_var           of shape (256,)\n",
            "2023-02-04 16:08:32,172 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.weight                loaded from backbone.body.layer3.4.bn2.weight                of shape (256,)\n",
            "2023-02-04 16:08:32,172 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.bias                  loaded from backbone.body.layer3.4.bn3.bias                  of shape (1024,)\n",
            "2023-02-04 16:08:32,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.running_mean          loaded from backbone.body.layer3.4.bn3.running_mean          of shape (1024,)\n",
            "2023-02-04 16:08:32,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.running_var           loaded from backbone.body.layer3.4.bn3.running_var           of shape (1024,)\n",
            "2023-02-04 16:08:32,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.weight                loaded from backbone.body.layer3.4.bn3.weight                of shape (1024,)\n",
            "2023-02-04 16:08:32,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv1.weight              loaded from backbone.body.layer3.4.conv1.weight              of shape (256, 1024, 1, 1)\n",
            "2023-02-04 16:08:32,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv2.weight              loaded from backbone.body.layer3.4.conv2.weight              of shape (256, 256, 3, 3)\n",
            "2023-02-04 16:08:32,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv3.weight              loaded from backbone.body.layer3.4.conv3.weight              of shape (1024, 256, 1, 1)\n",
            "2023-02-04 16:08:32,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.bias                  loaded from backbone.body.layer3.5.bn1.bias                  of shape (256,)\n",
            "2023-02-04 16:08:32,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.running_mean          loaded from backbone.body.layer3.5.bn1.running_mean          of shape (256,)\n",
            "2023-02-04 16:08:32,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.running_var           loaded from backbone.body.layer3.5.bn1.running_var           of shape (256,)\n",
            "2023-02-04 16:08:32,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.weight                loaded from backbone.body.layer3.5.bn1.weight                of shape (256,)\n",
            "2023-02-04 16:08:32,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.bias                  loaded from backbone.body.layer3.5.bn2.bias                  of shape (256,)\n",
            "2023-02-04 16:08:32,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.running_mean          loaded from backbone.body.layer3.5.bn2.running_mean          of shape (256,)\n",
            "2023-02-04 16:08:32,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.running_var           loaded from backbone.body.layer3.5.bn2.running_var           of shape (256,)\n",
            "2023-02-04 16:08:32,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.weight                loaded from backbone.body.layer3.5.bn2.weight                of shape (256,)\n",
            "2023-02-04 16:08:32,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.bias                  loaded from backbone.body.layer3.5.bn3.bias                  of shape (1024,)\n",
            "2023-02-04 16:08:32,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.running_mean          loaded from backbone.body.layer3.5.bn3.running_mean          of shape (1024,)\n",
            "2023-02-04 16:08:32,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.running_var           loaded from backbone.body.layer3.5.bn3.running_var           of shape (1024,)\n",
            "2023-02-04 16:08:32,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.weight                loaded from backbone.body.layer3.5.bn3.weight                of shape (1024,)\n",
            "2023-02-04 16:08:32,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv1.weight              loaded from backbone.body.layer3.5.conv1.weight              of shape (256, 1024, 1, 1)\n",
            "2023-02-04 16:08:32,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv2.weight              loaded from backbone.body.layer3.5.conv2.weight              of shape (256, 256, 3, 3)\n",
            "2023-02-04 16:08:32,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv3.weight              loaded from backbone.body.layer3.5.conv3.weight              of shape (1024, 256, 1, 1)\n",
            "2023-02-04 16:08:32,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.bias                  loaded from backbone.body.layer4.0.bn1.bias                  of shape (512,)\n",
            "2023-02-04 16:08:32,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.running_mean          loaded from backbone.body.layer4.0.bn1.running_mean          of shape (512,)\n",
            "2023-02-04 16:08:32,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.running_var           loaded from backbone.body.layer4.0.bn1.running_var           of shape (512,)\n",
            "2023-02-04 16:08:32,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.weight                loaded from backbone.body.layer4.0.bn1.weight                of shape (512,)\n",
            "2023-02-04 16:08:32,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.bias                  loaded from backbone.body.layer4.0.bn2.bias                  of shape (512,)\n",
            "2023-02-04 16:08:32,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.running_mean          loaded from backbone.body.layer4.0.bn2.running_mean          of shape (512,)\n",
            "2023-02-04 16:08:32,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.running_var           loaded from backbone.body.layer4.0.bn2.running_var           of shape (512,)\n",
            "2023-02-04 16:08:32,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.weight                loaded from backbone.body.layer4.0.bn2.weight                of shape (512,)\n",
            "2023-02-04 16:08:32,178 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.bias                  loaded from backbone.body.layer4.0.bn3.bias                  of shape (2048,)\n",
            "2023-02-04 16:08:32,178 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.running_mean          loaded from backbone.body.layer4.0.bn3.running_mean          of shape (2048,)\n",
            "2023-02-04 16:08:32,178 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.running_var           loaded from backbone.body.layer4.0.bn3.running_var           of shape (2048,)\n",
            "2023-02-04 16:08:32,178 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.weight                loaded from backbone.body.layer4.0.bn3.weight                of shape (2048,)\n",
            "2023-02-04 16:08:32,178 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv1.weight              loaded from backbone.body.layer4.0.conv1.weight              of shape (512, 1024, 1, 1)\n",
            "2023-02-04 16:08:32,178 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv2.weight              loaded from backbone.body.layer4.0.conv2.weight              of shape (512, 512, 3, 3)\n",
            "2023-02-04 16:08:32,179 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv3.weight              loaded from backbone.body.layer4.0.conv3.weight              of shape (2048, 512, 1, 1)\n",
            "2023-02-04 16:08:32,179 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.0.weight       loaded from backbone.body.layer4.0.downsample.0.weight       of shape (2048, 1024, 1, 1)\n",
            "2023-02-04 16:08:32,179 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.bias         loaded from backbone.body.layer4.0.downsample.1.bias         of shape (2048,)\n",
            "2023-02-04 16:08:32,179 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.running_mean loaded from backbone.body.layer4.0.downsample.1.running_mean of shape (2048,)\n",
            "2023-02-04 16:08:32,179 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.running_var  loaded from backbone.body.layer4.0.downsample.1.running_var  of shape (2048,)\n",
            "2023-02-04 16:08:32,179 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.weight       loaded from backbone.body.layer4.0.downsample.1.weight       of shape (2048,)\n",
            "2023-02-04 16:08:32,180 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.bias                  loaded from backbone.body.layer4.1.bn1.bias                  of shape (512,)\n",
            "2023-02-04 16:08:32,180 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.running_mean          loaded from backbone.body.layer4.1.bn1.running_mean          of shape (512,)\n",
            "2023-02-04 16:08:32,180 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.running_var           loaded from backbone.body.layer4.1.bn1.running_var           of shape (512,)\n",
            "2023-02-04 16:08:32,180 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.weight                loaded from backbone.body.layer4.1.bn1.weight                of shape (512,)\n",
            "2023-02-04 16:08:32,180 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.bias                  loaded from backbone.body.layer4.1.bn2.bias                  of shape (512,)\n",
            "2023-02-04 16:08:32,180 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.running_mean          loaded from backbone.body.layer4.1.bn2.running_mean          of shape (512,)\n",
            "2023-02-04 16:08:32,180 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.running_var           loaded from backbone.body.layer4.1.bn2.running_var           of shape (512,)\n",
            "2023-02-04 16:08:32,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.weight                loaded from backbone.body.layer4.1.bn2.weight                of shape (512,)\n",
            "2023-02-04 16:08:32,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.bias                  loaded from backbone.body.layer4.1.bn3.bias                  of shape (2048,)\n",
            "2023-02-04 16:08:32,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.running_mean          loaded from backbone.body.layer4.1.bn3.running_mean          of shape (2048,)\n",
            "2023-02-04 16:08:32,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.running_var           loaded from backbone.body.layer4.1.bn3.running_var           of shape (2048,)\n",
            "2023-02-04 16:08:32,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.weight                loaded from backbone.body.layer4.1.bn3.weight                of shape (2048,)\n",
            "2023-02-04 16:08:32,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv1.weight              loaded from backbone.body.layer4.1.conv1.weight              of shape (512, 2048, 1, 1)\n",
            "2023-02-04 16:08:32,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv2.weight              loaded from backbone.body.layer4.1.conv2.weight              of shape (512, 512, 3, 3)\n",
            "2023-02-04 16:08:32,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv3.weight              loaded from backbone.body.layer4.1.conv3.weight              of shape (2048, 512, 1, 1)\n",
            "2023-02-04 16:08:32,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.bias                  loaded from backbone.body.layer4.2.bn1.bias                  of shape (512,)\n",
            "2023-02-04 16:08:32,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.running_mean          loaded from backbone.body.layer4.2.bn1.running_mean          of shape (512,)\n",
            "2023-02-04 16:08:32,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.running_var           loaded from backbone.body.layer4.2.bn1.running_var           of shape (512,)\n",
            "2023-02-04 16:08:32,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.weight                loaded from backbone.body.layer4.2.bn1.weight                of shape (512,)\n",
            "2023-02-04 16:08:32,269 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.bias                  loaded from backbone.body.layer4.2.bn2.bias                  of shape (512,)\n",
            "2023-02-04 16:08:32,269 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.running_mean          loaded from backbone.body.layer4.2.bn2.running_mean          of shape (512,)\n",
            "2023-02-04 16:08:32,270 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.running_var           loaded from backbone.body.layer4.2.bn2.running_var           of shape (512,)\n",
            "2023-02-04 16:08:32,270 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.weight                loaded from backbone.body.layer4.2.bn2.weight                of shape (512,)\n",
            "2023-02-04 16:08:32,270 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.bias                  loaded from backbone.body.layer4.2.bn3.bias                  of shape (2048,)\n",
            "2023-02-04 16:08:32,271 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.running_mean          loaded from backbone.body.layer4.2.bn3.running_mean          of shape (2048,)\n",
            "2023-02-04 16:08:32,271 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.running_var           loaded from backbone.body.layer4.2.bn3.running_var           of shape (2048,)\n",
            "2023-02-04 16:08:32,271 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.weight                loaded from backbone.body.layer4.2.bn3.weight                of shape (2048,)\n",
            "2023-02-04 16:08:32,271 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv1.weight              loaded from backbone.body.layer4.2.conv1.weight              of shape (512, 2048, 1, 1)\n",
            "2023-02-04 16:08:32,271 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv2.weight              loaded from backbone.body.layer4.2.conv2.weight              of shape (512, 512, 3, 3)\n",
            "2023-02-04 16:08:32,271 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv3.weight              loaded from backbone.body.layer4.2.conv3.weight              of shape (2048, 512, 1, 1)\n",
            "2023-02-04 16:08:32,272 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.bias                      loaded from backbone.body.stem.bn1.bias                      of shape (64,)\n",
            "2023-02-04 16:08:32,272 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.running_mean              loaded from backbone.body.stem.bn1.running_mean              of shape (64,)\n",
            "2023-02-04 16:08:32,272 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.running_var               loaded from backbone.body.stem.bn1.running_var               of shape (64,)\n",
            "2023-02-04 16:08:32,272 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.weight                    loaded from backbone.body.stem.bn1.weight                    of shape (64,)\n",
            "2023-02-04 16:08:32,272 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.conv1.weight                  loaded from backbone.body.stem.conv1.weight                  of shape (64, 3, 7, 7)\n",
            "2023-02-04 16:08:32,272 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner1.bias                     loaded from backbone.fpn.fpn_inner1.bias                     of shape (256,)\n",
            "2023-02-04 16:08:32,273 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner1.weight                   loaded from backbone.fpn.fpn_inner1.weight                   of shape (256, 256, 1, 1)\n",
            "2023-02-04 16:08:32,273 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner2.bias                     loaded from backbone.fpn.fpn_inner2.bias                     of shape (256,)\n",
            "2023-02-04 16:08:32,273 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner2.weight                   loaded from backbone.fpn.fpn_inner2.weight                   of shape (256, 512, 1, 1)\n",
            "2023-02-04 16:08:32,273 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner3.bias                     loaded from backbone.fpn.fpn_inner3.bias                     of shape (256,)\n",
            "2023-02-04 16:08:32,275 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner3.weight                   loaded from backbone.fpn.fpn_inner3.weight                   of shape (256, 1024, 1, 1)\n",
            "2023-02-04 16:08:32,276 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner4.bias                     loaded from backbone.fpn.fpn_inner4.bias                     of shape (256,)\n",
            "2023-02-04 16:08:32,276 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner4.weight                   loaded from backbone.fpn.fpn_inner4.weight                   of shape (256, 2048, 1, 1)\n",
            "2023-02-04 16:08:32,276 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer1.bias                     loaded from backbone.fpn.fpn_layer1.bias                     of shape (256,)\n",
            "2023-02-04 16:08:32,276 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer1.weight                   loaded from backbone.fpn.fpn_layer1.weight                   of shape (256, 256, 3, 3)\n",
            "2023-02-04 16:08:32,276 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer2.bias                     loaded from backbone.fpn.fpn_layer2.bias                     of shape (256,)\n",
            "2023-02-04 16:08:32,276 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer2.weight                   loaded from backbone.fpn.fpn_layer2.weight                   of shape (256, 256, 3, 3)\n",
            "2023-02-04 16:08:32,277 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer3.bias                     loaded from backbone.fpn.fpn_layer3.bias                     of shape (256,)\n",
            "2023-02-04 16:08:32,277 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer3.weight                   loaded from backbone.fpn.fpn_layer3.weight                   of shape (256, 256, 3, 3)\n",
            "2023-02-04 16:08:32,277 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer4.bias                     loaded from backbone.fpn.fpn_layer4.bias                     of shape (256,)\n",
            "2023-02-04 16:08:32,277 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer4.weight                   loaded from backbone.fpn.fpn_layer4.weight                   of shape (256, 256, 3, 3)\n",
            "2023-02-04 16:08:32,277 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level0.bias        loaded from da_heads.imghead.da_img_conv1_level0.bias        of shape (512,)\n",
            "2023-02-04 16:08:32,277 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level0.weight      loaded from da_heads.imghead.da_img_conv1_level0.weight      of shape (512, 256, 1, 1)\n",
            "2023-02-04 16:08:32,278 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level1.bias        loaded from da_heads.imghead.da_img_conv1_level1.bias        of shape (512,)\n",
            "2023-02-04 16:08:32,278 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level1.weight      loaded from da_heads.imghead.da_img_conv1_level1.weight      of shape (512, 256, 1, 1)\n",
            "2023-02-04 16:08:32,278 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level2.bias        loaded from da_heads.imghead.da_img_conv1_level2.bias        of shape (512,)\n",
            "2023-02-04 16:08:32,278 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level2.weight      loaded from da_heads.imghead.da_img_conv1_level2.weight      of shape (512, 256, 1, 1)\n",
            "2023-02-04 16:08:32,278 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level3.bias        loaded from da_heads.imghead.da_img_conv1_level3.bias        of shape (512,)\n",
            "2023-02-04 16:08:32,278 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level3.weight      loaded from da_heads.imghead.da_img_conv1_level3.weight      of shape (512, 256, 1, 1)\n",
            "2023-02-04 16:08:32,278 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level4.bias        loaded from da_heads.imghead.da_img_conv1_level4.bias        of shape (512,)\n",
            "2023-02-04 16:08:32,279 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level4.weight      loaded from da_heads.imghead.da_img_conv1_level4.weight      of shape (512, 256, 1, 1)\n",
            "2023-02-04 16:08:32,279 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level0.bias        loaded from da_heads.imghead.da_img_conv2_level0.bias        of shape (1,)\n",
            "2023-02-04 16:08:32,279 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level0.weight      loaded from da_heads.imghead.da_img_conv2_level0.weight      of shape (1, 512, 1, 1)\n",
            "2023-02-04 16:08:32,279 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level1.bias        loaded from da_heads.imghead.da_img_conv2_level1.bias        of shape (1,)\n",
            "2023-02-04 16:08:32,279 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level1.weight      loaded from da_heads.imghead.da_img_conv2_level1.weight      of shape (1, 512, 1, 1)\n",
            "2023-02-04 16:08:32,279 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level2.bias        loaded from da_heads.imghead.da_img_conv2_level2.bias        of shape (1,)\n",
            "2023-02-04 16:08:32,280 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level2.weight      loaded from da_heads.imghead.da_img_conv2_level2.weight      of shape (1, 512, 1, 1)\n",
            "2023-02-04 16:08:32,281 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level3.bias        loaded from da_heads.imghead.da_img_conv2_level3.bias        of shape (1,)\n",
            "2023-02-04 16:08:32,281 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level3.weight      loaded from da_heads.imghead.da_img_conv2_level3.weight      of shape (1, 512, 1, 1)\n",
            "2023-02-04 16:08:32,281 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level4.bias        loaded from da_heads.imghead.da_img_conv2_level4.bias        of shape (1,)\n",
            "2023-02-04 16:08:32,281 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level4.weight      loaded from da_heads.imghead.da_img_conv2_level4.weight      of shape (1, 512, 1, 1)\n",
            "2023-02-04 16:08:32,282 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc1_level0.bias          loaded from da_heads.inshead.da_ins_fc1_level0.bias          of shape (1024,)\n",
            "2023-02-04 16:08:32,282 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc1_level0.weight        loaded from da_heads.inshead.da_ins_fc1_level0.weight        of shape (1024, 1024)\n",
            "2023-02-04 16:08:32,282 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc1_level1.bias          loaded from da_heads.inshead.da_ins_fc1_level1.bias          of shape (1024,)\n",
            "2023-02-04 16:08:32,282 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc1_level1.weight        loaded from da_heads.inshead.da_ins_fc1_level1.weight        of shape (1024, 1024)\n",
            "2023-02-04 16:08:32,282 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc1_level2.bias          loaded from da_heads.inshead.da_ins_fc1_level2.bias          of shape (1024,)\n",
            "2023-02-04 16:08:32,282 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc1_level2.weight        loaded from da_heads.inshead.da_ins_fc1_level2.weight        of shape (1024, 1024)\n",
            "2023-02-04 16:08:32,283 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc1_level3.bias          loaded from da_heads.inshead.da_ins_fc1_level3.bias          of shape (1024,)\n",
            "2023-02-04 16:08:32,283 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc1_level3.weight        loaded from da_heads.inshead.da_ins_fc1_level3.weight        of shape (1024, 1024)\n",
            "2023-02-04 16:08:32,283 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc2_level0.bias          loaded from da_heads.inshead.da_ins_fc2_level0.bias          of shape (1024,)\n",
            "2023-02-04 16:08:32,284 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc2_level0.weight        loaded from da_heads.inshead.da_ins_fc2_level0.weight        of shape (1024, 1024)\n",
            "2023-02-04 16:08:32,284 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc2_level1.bias          loaded from da_heads.inshead.da_ins_fc2_level1.bias          of shape (1024,)\n",
            "2023-02-04 16:08:32,284 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc2_level1.weight        loaded from da_heads.inshead.da_ins_fc2_level1.weight        of shape (1024, 1024)\n",
            "2023-02-04 16:08:32,285 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc2_level2.bias          loaded from da_heads.inshead.da_ins_fc2_level2.bias          of shape (1024,)\n",
            "2023-02-04 16:08:32,285 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc2_level2.weight        loaded from da_heads.inshead.da_ins_fc2_level2.weight        of shape (1024, 1024)\n",
            "2023-02-04 16:08:32,285 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc2_level3.bias          loaded from da_heads.inshead.da_ins_fc2_level3.bias          of shape (1024,)\n",
            "2023-02-04 16:08:32,285 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc2_level3.weight        loaded from da_heads.inshead.da_ins_fc2_level3.weight        of shape (1024, 1024)\n",
            "2023-02-04 16:08:32,285 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc3_level0.bias          loaded from da_heads.inshead.da_ins_fc3_level0.bias          of shape (1,)\n",
            "2023-02-04 16:08:32,286 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc3_level0.weight        loaded from da_heads.inshead.da_ins_fc3_level0.weight        of shape (1, 1024)\n",
            "2023-02-04 16:08:32,286 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc3_level1.bias          loaded from da_heads.inshead.da_ins_fc3_level1.bias          of shape (1,)\n",
            "2023-02-04 16:08:32,286 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc3_level1.weight        loaded from da_heads.inshead.da_ins_fc3_level1.weight        of shape (1, 1024)\n",
            "2023-02-04 16:08:32,286 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc3_level2.bias          loaded from da_heads.inshead.da_ins_fc3_level2.bias          of shape (1,)\n",
            "2023-02-04 16:08:32,287 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc3_level2.weight        loaded from da_heads.inshead.da_ins_fc3_level2.weight        of shape (1, 1024)\n",
            "2023-02-04 16:08:32,287 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc3_level3.bias          loaded from da_heads.inshead.da_ins_fc3_level3.bias          of shape (1,)\n",
            "2023-02-04 16:08:32,288 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc3_level3.weight        loaded from da_heads.inshead.da_ins_fc3_level3.weight        of shape (1, 1024)\n",
            "2023-02-04 16:08:32,288 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc6.bias         loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (1024,)\n",
            "2023-02-04 16:08:32,288 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc6.weight       loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (1024, 12544)\n",
            "2023-02-04 16:08:32,288 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc7.bias         loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (1024,)\n",
            "2023-02-04 16:08:32,288 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc7.weight       loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (1024, 1024)\n",
            "2023-02-04 16:08:32,288 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.bbox_pred.bias           loaded from roi_heads.box.predictor.bbox_pred.bias           of shape (8,)\n",
            "2023-02-04 16:08:32,289 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.bbox_pred.weight         loaded from roi_heads.box.predictor.bbox_pred.weight         of shape (8, 1024)\n",
            "2023-02-04 16:08:32,289 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.cls_score.bias           loaded from roi_heads.box.predictor.cls_score.bias           of shape (2,)\n",
            "2023-02-04 16:08:32,289 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.cls_score.weight         loaded from roi_heads.box.predictor.cls_score.weight         of shape (2, 1024)\n",
            "2023-02-04 16:08:32,289 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.0              loaded from rpn.anchor_generator.cell_anchors.0              of shape (3, 4)\n",
            "2023-02-04 16:08:32,289 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.1              loaded from rpn.anchor_generator.cell_anchors.1              of shape (3, 4)\n",
            "2023-02-04 16:08:32,371 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.2              loaded from rpn.anchor_generator.cell_anchors.2              of shape (3, 4)\n",
            "2023-02-04 16:08:32,372 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.3              loaded from rpn.anchor_generator.cell_anchors.3              of shape (3, 4)\n",
            "2023-02-04 16:08:32,372 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.4              loaded from rpn.anchor_generator.cell_anchors.4              of shape (3, 4)\n",
            "2023-02-04 16:08:32,373 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bbox_pred.bias                          loaded from rpn.head.bbox_pred.bias                          of shape (12,)\n",
            "2023-02-04 16:08:32,373 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bbox_pred.weight                        loaded from rpn.head.bbox_pred.weight                        of shape (12, 256, 1, 1)\n",
            "2023-02-04 16:08:32,373 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.cls_logits.bias                         loaded from rpn.head.cls_logits.bias                         of shape (3,)\n",
            "2023-02-04 16:08:32,373 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.cls_logits.weight                       loaded from rpn.head.cls_logits.weight                       of shape (3, 256, 1, 1)\n",
            "2023-02-04 16:08:32,373 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.conv.bias                               loaded from rpn.head.conv.bias                               of shape (256,)\n",
            "2023-02-04 16:08:32,374 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.conv.weight                             loaded from rpn.head.conv.weight                             of shape (256, 256, 3, 3)\n",
            "2023-02-04 16:08:32,461 maskrcnn_benchmark.utils.checkpoint INFO: Loading optimizer from /content/drive/MyDrive/AI/mic/model_0003000.pth\n",
            "2023-02-04 16:08:32,584 maskrcnn_benchmark.utils.checkpoint INFO: Loading scheduler from /content/drive/MyDrive/AI/mic/model_0003000.pth\n",
            "loading annotations into memory...\n",
            "Done (t=0.50s)\n",
            "creating index...\n",
            "index created!\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loading annotations into memory...\n",
            "Done (t=2.71s)\n",
            "creating index...\n",
            "index created!\n",
            "[Masking] Use color augmentation.\n",
            "2023-02-04 16:08:36,825 maskrcnn_benchmark.trainer INFO: Start training\n",
            "2023-02-04 16:08:36,825 maskrcnn_benchmark.trainer INFO: with_MIC: On\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/content/MIC/det/maskrcnn_benchmark/structures/bounding_box.py:206: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:27.)\n",
            "  bbox = BoxList(self.bbox[item], self.size, self.mode)\n",
            "/content/MIC/det/maskrcnn_benchmark/structures/bounding_box.py:208: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:27.)\n",
            "  bbox.add_field(k, v[item])\n",
            "/content/MIC/det/maskrcnn_benchmark/modeling/roi_heads/box_head/loss.py:195: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:27.)\n",
            "  class_logits = class_logits[domain_masks, :]\n",
            "/content/MIC/det/maskrcnn_benchmark/modeling/roi_heads/box_head/loss.py:196: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:27.)\n",
            "  box_regression = box_regression[domain_masks, :]\n",
            "/content/MIC/det/maskrcnn_benchmark/modeling/roi_heads/box_head/loss.py:197: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:27.)\n",
            "  labels = labels[domain_masks]\n",
            "/content/MIC/det/maskrcnn_benchmark/modeling/roi_heads/box_head/loss.py:198: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:27.)\n",
            "  regression_targets = regression_targets[domain_masks, :]\n",
            "/content/MIC/det/maskrcnn_benchmark/modeling/da_heads/loss.py:92: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/cuda/Indexing.cu:1239.)\n",
            "  da_img_label_per_level[masks, :] = 1\n",
            "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py:173: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:27.)\n",
            "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "2023-02-04 16:08:47,555 maskrcnn_benchmark.trainer INFO: eta: 7 days, 1:51:10 iter: 3000 loss: 3.6955 (3.6955) loss_classifier: 0.1506 (0.1506) loss_box_reg: 0.3253 (0.3253) loss_objectness: 0.0746 (0.0746) loss_rpn_box_reg: 0.0579 (0.0579) loss_da_image: 0.6104 (0.6104) loss_da_instance: 0.6880 (0.6880) loss_da_consistency: 0.0182 (0.0182) loss_classifier_mask: 1.7593 (1.7593) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0112 (0.0112) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 10.7276 (10.7276) data: 1.4747 (1.4747) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:08:47,559 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /content/drive/MyDrive/AI/mic/model_0003000.pth\n",
            "2023-02-04 16:09:14,163 maskrcnn_benchmark.trainer INFO: eta: 1 day, 4:08:24 iter: 3020 loss: 1.8920 (1.9753) loss_classifier: 0.1914 (0.2100) loss_box_reg: 0.1558 (0.1751) loss_objectness: 0.0449 (0.0593) loss_rpn_box_reg: 0.0678 (0.0887) loss_da_image: 0.5820 (0.5835) loss_da_instance: 0.6827 (0.6835) loss_da_consistency: 0.0152 (0.0161) loss_classifier_mask: 1.3516 (1.1051) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0112 (0.0081) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.2046 (1.7779) data: 0.3453 (0.4817) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:09:40,874 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:42:57 iter: 3040 loss: 1.8210 (1.8875) loss_classifier: 0.2069 (0.2043) loss_box_reg: 0.1735 (0.1697) loss_objectness: 0.0307 (0.0538) loss_rpn_box_reg: 0.0325 (0.0751) loss_da_image: 0.5704 (0.5782) loss_da_instance: 0.6861 (0.6844) loss_da_consistency: 0.0174 (0.0175) loss_classifier_mask: 0.1194 (0.4191) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0040 (0.0091) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.2495 (1.5621) data: 0.3479 (0.4196) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:10:12,440 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:47:29 iter: 3060 loss: 1.8784 (1.8990) loss_classifier: 0.1921 (0.2050) loss_box_reg: 0.2013 (0.1775) loss_objectness: 0.0459 (0.0509) loss_rpn_box_reg: 0.0592 (0.0742) loss_da_image: 0.5708 (0.5774) loss_da_instance: 0.6835 (0.6841) loss_da_consistency: 0.0203 (0.0189) loss_classifier_mask: 0.1144 (0.2253) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0070 (0.0082) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.5915 (1.5674) data: 0.3635 (0.4009) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:10:45,536 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:07:25 iter: 3080 loss: 1.8216 (1.8783) loss_classifier: 0.1569 (0.1938) loss_box_reg: 0.1475 (0.1710) loss_objectness: 0.0362 (0.0485) loss_rpn_box_reg: 0.0375 (0.0684) loss_da_image: 0.5688 (0.5765) loss_da_instance: 0.6813 (0.6838) loss_da_consistency: 0.0171 (0.0189) loss_classifier_mask: 0.1181 (0.1900) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0059 (0.0082) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6523 (1.5890) data: 0.3827 (0.3964) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:11:18,422 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:17:16 iter: 3100 loss: 1.7863 (1.8712) loss_classifier: 0.1787 (0.1901) loss_box_reg: 0.1630 (0.1687) loss_objectness: 0.0219 (0.0438) loss_rpn_box_reg: 0.0239 (0.0658) loss_da_image: 0.5595 (0.5746) loss_da_instance: 0.6840 (0.6840) loss_da_consistency: 0.0193 (0.0199) loss_classifier_mask: 0.1476 (0.1763) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0076 (0.0084) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6210 (1.5999) data: 0.3771 (0.3928) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:11:51,714 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:26:52 iter: 3120 loss: 1.7092 (1.8583) loss_classifier: 0.1574 (0.1861) loss_box_reg: 0.1657 (0.1665) loss_objectness: 0.0261 (0.0426) loss_rpn_box_reg: 0.0223 (0.0649) loss_da_image: 0.5602 (0.5720) loss_da_instance: 0.6847 (0.6843) loss_da_consistency: 0.0182 (0.0200) loss_classifier_mask: 0.0819 (0.1601) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0026 (0.0076) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6389 (1.6106) data: 0.3772 (0.3908) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:12:24,832 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:32:25 iter: 3140 loss: 1.6900 (1.8479) loss_classifier: 0.1169 (0.1811) loss_box_reg: 0.1014 (0.1622) loss_objectness: 0.0181 (0.0415) loss_rpn_box_reg: 0.0478 (0.0660) loss_da_image: 0.5328 (0.5677) loss_da_instance: 0.6821 (0.6840) loss_da_consistency: 0.0264 (0.0210) loss_classifier_mask: 0.1197 (0.1549) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0046 (0.0076) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6393 (1.6170) data: 0.3753 (0.3895) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:12:57,802 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:35:35 iter: 3160 loss: 1.8241 (1.8475) loss_classifier: 0.1713 (0.1786) loss_box_reg: 0.1777 (0.1636) loss_objectness: 0.0239 (0.0396) loss_rpn_box_reg: 0.0226 (0.0655) loss_da_image: 0.5600 (0.5676) loss_da_instance: 0.6825 (0.6838) loss_da_consistency: 0.0203 (0.0212) loss_classifier_mask: 0.1481 (0.1523) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0051 (0.0082) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6509 (1.6210) data: 0.3777 (0.3884) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:13:30,859 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:38:23 iter: 3180 loss: 1.8302 (1.8479) loss_classifier: 0.1471 (0.1775) loss_box_reg: 0.1589 (0.1640) loss_objectness: 0.0202 (0.0380) loss_rpn_box_reg: 0.0324 (0.0646) loss_da_image: 0.5572 (0.5676) loss_da_instance: 0.6825 (0.6840) loss_da_consistency: 0.0261 (0.0220) loss_classifier_mask: 0.1405 (0.1508) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0055 (0.0083) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6359 (1.6245) data: 0.3788 (0.3875) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:14:03,630 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:39:10 iter: 3200 loss: 1.8509 (1.8474) loss_classifier: 0.1625 (0.1763) loss_box_reg: 0.1439 (0.1649) loss_objectness: 0.0155 (0.0366) loss_rpn_box_reg: 0.0272 (0.0634) loss_da_image: 0.5599 (0.5666) loss_da_instance: 0.6807 (0.6837) loss_da_consistency: 0.0233 (0.0223) loss_classifier_mask: 0.1692 (0.1526) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0051 (0.0082) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6444 (1.6259) data: 0.3740 (0.3869) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:14:36,597 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:40:33 iter: 3220 loss: 1.9724 (1.8552) loss_classifier: 0.1884 (0.1782) loss_box_reg: 0.1802 (0.1664) loss_objectness: 0.0330 (0.0371) loss_rpn_box_reg: 0.0636 (0.0638) loss_da_image: 0.5576 (0.5666) loss_da_instance: 0.6848 (0.6839) loss_da_consistency: 0.0162 (0.0220) loss_classifier_mask: 0.1591 (0.1538) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0084 (0.0084) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6337 (1.6279) data: 0.3770 (0.3863) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:15:09,677 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:42:03 iter: 3240 loss: 1.7859 (1.8537) loss_classifier: 0.1530 (0.1773) loss_box_reg: 0.1920 (0.1663) loss_objectness: 0.0175 (0.0363) loss_rpn_box_reg: 0.0565 (0.0637) loss_da_image: 0.5592 (0.5665) loss_da_instance: 0.6830 (0.6840) loss_da_consistency: 0.0185 (0.0219) loss_classifier_mask: 0.1432 (0.1521) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0053 (0.0083) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6315 (1.6301) data: 0.3809 (0.3862) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:15:43,011 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:44:09 iter: 3260 loss: 1.8864 (1.8519) loss_classifier: 0.1858 (0.1763) loss_box_reg: 0.1694 (0.1647) loss_objectness: 0.0274 (0.0358) loss_rpn_box_reg: 0.0535 (0.0646) loss_da_image: 0.5566 (0.5661) loss_da_instance: 0.6822 (0.6840) loss_da_consistency: 0.0197 (0.0218) loss_classifier_mask: 0.1465 (0.1512) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0033 (0.0080) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6401 (1.6329) data: 0.3807 (0.3858) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:16:15,688 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:43:41 iter: 3280 loss: 1.8948 (1.8559) loss_classifier: 0.1823 (0.1768) loss_box_reg: 0.1905 (0.1666) loss_objectness: 0.0330 (0.0374) loss_rpn_box_reg: 0.0434 (0.0638) loss_da_image: 0.5628 (0.5664) loss_da_instance: 0.6831 (0.6842) loss_da_consistency: 0.0171 (0.0217) loss_classifier_mask: 0.1271 (0.1503) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0096 (0.0084) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6327 (1.6330) data: 0.3816 (0.3856) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:16:48,959 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:45:03 iter: 3300 loss: 1.7748 (1.8548) loss_classifier: 0.1524 (0.1763) loss_box_reg: 0.1733 (0.1670) loss_objectness: 0.0126 (0.0366) loss_rpn_box_reg: 0.0352 (0.0635) loss_da_image: 0.5600 (0.5655) loss_da_instance: 0.6844 (0.6841) loss_da_consistency: 0.0259 (0.0222) loss_classifier_mask: 0.1394 (0.1495) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0063 (0.0084) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6316 (1.6350) data: 0.3782 (0.3851) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:17:21,874 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:45:09 iter: 3320 loss: 1.8045 (1.8503) loss_classifier: 0.1230 (0.1741) loss_box_reg: 0.1440 (0.1648) loss_objectness: 0.0183 (0.0366) loss_rpn_box_reg: 0.0697 (0.0640) loss_da_image: 0.5514 (0.5649) loss_da_instance: 0.6772 (0.6837) loss_da_consistency: 0.0258 (0.0226) loss_classifier_mask: 0.1201 (0.1481) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0034 (0.0085) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6401 (1.6357) data: 0.3755 (0.3845) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:17:54,388 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:44:03 iter: 3340 loss: 1.6825 (1.8441) loss_classifier: 0.1246 (0.1717) loss_box_reg: 0.1267 (0.1627) loss_objectness: 0.0144 (0.0358) loss_rpn_box_reg: 0.0203 (0.0633) loss_da_image: 0.5650 (0.5647) loss_da_instance: 0.6837 (0.6839) loss_da_consistency: 0.0179 (0.0226) loss_classifier_mask: 0.1333 (0.1474) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0050 (0.0083) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6237 (1.6351) data: 0.3738 (0.3842) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:18:26,979 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:43:13 iter: 3360 loss: 1.6528 (1.8375) loss_classifier: 0.1056 (0.1691) loss_box_reg: 0.0845 (0.1608) loss_objectness: 0.0086 (0.0346) loss_rpn_box_reg: 0.0178 (0.0620) loss_da_image: 0.5734 (0.5650) loss_da_instance: 0.6828 (0.6839) loss_da_consistency: 0.0231 (0.0230) loss_classifier_mask: 0.1466 (0.1466) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0048 (0.0083) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6258 (1.6348) data: 0.3774 (0.3840) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:18:58,947 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:40:52 iter: 3380 loss: 1.6406 (1.8320) loss_classifier: 0.0974 (0.1669) loss_box_reg: 0.0874 (0.1594) loss_objectness: 0.0132 (0.0355) loss_rpn_box_reg: 0.0102 (0.0601) loss_da_image: 0.5551 (0.5647) loss_da_instance: 0.6848 (0.6840) loss_da_consistency: 0.0262 (0.0234) loss_classifier_mask: 0.1281 (0.1457) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0033 (0.0082) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6205 (1.6329) data: 0.3739 (0.3836) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:19:32,076 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:41:26 iter: 3400 loss: 1.9113 (1.8343) loss_classifier: 0.1445 (0.1664) loss_box_reg: 0.1978 (0.1601) loss_objectness: 0.0238 (0.0365) loss_rpn_box_reg: 0.0457 (0.0612) loss_da_image: 0.5530 (0.5643) loss_da_instance: 0.6833 (0.6839) loss_da_consistency: 0.0184 (0.0233) loss_classifier_mask: 0.1206 (0.1452) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0048 (0.0082) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6528 (1.6340) data: 0.3800 (0.3834) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:20:05,420 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:42:22 iter: 3420 loss: 1.9374 (1.8408) loss_classifier: 0.1852 (0.1677) loss_box_reg: 0.2130 (0.1629) loss_objectness: 0.0373 (0.0376) loss_rpn_box_reg: 0.0656 (0.0624) loss_da_image: 0.5662 (0.5645) loss_da_instance: 0.6841 (0.6840) loss_da_consistency: 0.0164 (0.0230) loss_classifier_mask: 0.1120 (0.1447) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0061 (0.0082) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6479 (1.6356) data: 0.3782 (0.3835) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:20:38,274 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:42:08 iter: 3440 loss: 1.7499 (1.8397) loss_classifier: 0.1470 (0.1671) loss_box_reg: 0.1775 (0.1629) loss_objectness: 0.0176 (0.0373) loss_rpn_box_reg: 0.0325 (0.0620) loss_da_image: 0.5486 (0.5642) loss_da_instance: 0.6852 (0.6840) loss_da_consistency: 0.0179 (0.0229) loss_classifier_mask: 0.1314 (0.1448) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0049 (0.0081) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6282 (1.6359) data: 0.3727 (0.3833) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:21:11,378 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:42:22 iter: 3460 loss: 1.8296 (1.8417) loss_classifier: 0.1869 (0.1682) loss_box_reg: 0.1793 (0.1647) loss_objectness: 0.0337 (0.0375) loss_rpn_box_reg: 0.0617 (0.0626) loss_da_image: 0.5564 (0.5640) loss_da_instance: 0.6841 (0.6841) loss_da_consistency: 0.0192 (0.0228) loss_classifier_mask: 0.0836 (0.1426) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0049 (0.0080) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6522 (1.6368) data: 0.3841 (0.3833) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:21:44,264 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:42:07 iter: 3480 loss: 1.7588 (1.8397) loss_classifier: 0.1297 (0.1673) loss_box_reg: 0.1518 (0.1636) loss_objectness: 0.0214 (0.0371) loss_rpn_box_reg: 0.0287 (0.0618) loss_da_image: 0.5603 (0.5643) loss_da_instance: 0.6836 (0.6840) loss_da_consistency: 0.0231 (0.0229) loss_classifier_mask: 0.1413 (0.1430) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0051 (0.0079) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6333 (1.6371) data: 0.3741 (0.3830) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:22:17,209 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:41:57 iter: 3500 loss: 1.6871 (1.8346) loss_classifier: 0.1014 (0.1656) loss_box_reg: 0.1024 (0.1615) loss_objectness: 0.0226 (0.0377) loss_rpn_box_reg: 0.0326 (0.0610) loss_da_image: 0.5431 (0.5636) loss_da_instance: 0.6816 (0.6839) loss_da_consistency: 0.0209 (0.0229) loss_classifier_mask: 0.1081 (0.1420) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0066 (0.0079) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6328 (1.6375) data: 0.3733 (0.3829) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:22:49,741 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:41:01 iter: 3520 loss: 1.9156 (1.8389) loss_classifier: 0.2163 (0.1674) loss_box_reg: 0.2007 (0.1635) loss_objectness: 0.0312 (0.0377) loss_rpn_box_reg: 0.0631 (0.0611) loss_da_image: 0.5648 (0.5637) loss_da_instance: 0.6824 (0.6839) loss_da_consistency: 0.0205 (0.0228) loss_classifier_mask: 0.1376 (0.1422) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0048 (0.0079) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6281 (1.6371) data: 0.3757 (0.3827) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:23:22,812 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:41:03 iter: 3540 loss: 1.8034 (1.8385) loss_classifier: 0.1575 (0.1675) loss_box_reg: 0.1559 (0.1634) loss_objectness: 0.0194 (0.0375) loss_rpn_box_reg: 0.0230 (0.0603) loss_da_image: 0.5623 (0.5637) loss_da_instance: 0.6785 (0.6838) loss_da_consistency: 0.0343 (0.0233) loss_classifier_mask: 0.1294 (0.1424) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0031 (0.0079) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6565 (1.6377) data: 0.3768 (0.3828) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:23:56,363 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:41:50 iter: 3560 loss: 1.8341 (1.8398) loss_classifier: 0.1490 (0.1676) loss_box_reg: 0.1462 (0.1632) loss_objectness: 0.0268 (0.0378) loss_rpn_box_reg: 0.0320 (0.0607) loss_da_image: 0.5619 (0.5639) loss_da_instance: 0.6788 (0.6837) loss_da_consistency: 0.0198 (0.0232) loss_classifier_mask: 0.1466 (0.1425) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0061 (0.0079) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6836 (1.6391) data: 0.3773 (0.3828) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:24:29,194 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:41:22 iter: 3580 loss: 1.7588 (1.8389) loss_classifier: 0.1416 (0.1672) loss_box_reg: 0.1518 (0.1632) loss_objectness: 0.0230 (0.0376) loss_rpn_box_reg: 0.0491 (0.0608) loss_da_image: 0.5783 (0.5647) loss_da_instance: 0.6787 (0.6836) loss_da_consistency: 0.0235 (0.0233) loss_classifier_mask: 0.0824 (0.1408) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0027 (0.0079) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6319 (1.6392) data: 0.3716 (0.3826) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:25:02,135 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:41:04 iter: 3600 loss: 1.7545 (1.8376) loss_classifier: 0.1464 (0.1665) loss_box_reg: 0.1631 (0.1632) loss_objectness: 0.0104 (0.0369) loss_rpn_box_reg: 0.0243 (0.0602) loss_da_image: 0.5501 (0.5642) loss_da_instance: 0.6805 (0.6835) loss_da_consistency: 0.0294 (0.0236) loss_classifier_mask: 0.1485 (0.1415) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0069 (0.0079) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6334 (1.6394) data: 0.3742 (0.3824) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:25:35,043 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:40:42 iter: 3620 loss: 1.7992 (1.8385) loss_classifier: 0.1519 (0.1672) loss_box_reg: 0.1603 (0.1636) loss_objectness: 0.0283 (0.0368) loss_rpn_box_reg: 0.0348 (0.0605) loss_da_image: 0.5698 (0.5644) loss_da_instance: 0.6832 (0.6834) loss_da_consistency: 0.0218 (0.0237) loss_classifier_mask: 0.1037 (0.1406) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0065 (0.0080) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6349 (1.6396) data: 0.3747 (0.3824) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:26:08,021 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:40:26 iter: 3640 loss: 1.8287 (1.8393) loss_classifier: 0.1590 (0.1669) loss_box_reg: 0.1538 (0.1634) loss_objectness: 0.0226 (0.0364) loss_rpn_box_reg: 0.0637 (0.0611) loss_da_image: 0.5721 (0.5648) loss_da_instance: 0.6783 (0.6833) loss_da_consistency: 0.0288 (0.0238) loss_classifier_mask: 0.1292 (0.1407) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0049 (0.0080) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6495 (1.6399) data: 0.3767 (0.3823) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:26:41,003 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:40:09 iter: 3660 loss: 1.7131 (1.8399) loss_classifier: 0.1572 (0.1672) loss_box_reg: 0.1326 (0.1638) loss_objectness: 0.0158 (0.0361) loss_rpn_box_reg: 0.0324 (0.0613) loss_da_image: 0.5705 (0.5651) loss_da_instance: 0.6821 (0.6832) loss_da_consistency: 0.0236 (0.0239) loss_classifier_mask: 0.1023 (0.1402) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0062 (0.0079) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6377 (1.6402) data: 0.3719 (0.3822) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:27:13,480 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:39:09 iter: 3680 loss: 1.8199 (1.8389) loss_classifier: 0.1572 (0.1669) loss_box_reg: 0.1560 (0.1635) loss_objectness: 0.0284 (0.0362) loss_rpn_box_reg: 0.0336 (0.0619) loss_da_image: 0.5635 (0.5650) loss_da_instance: 0.6829 (0.6832) loss_da_consistency: 0.0193 (0.0238) loss_classifier_mask: 0.1204 (0.1393) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0019 (0.0079) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6257 (1.6397) data: 0.3706 (0.3820) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:27:46,889 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:39:25 iter: 3700 loss: 1.7732 (1.8379) loss_classifier: 0.1467 (0.1665) loss_box_reg: 0.1645 (0.1638) loss_objectness: 0.0108 (0.0357) loss_rpn_box_reg: 0.0279 (0.0613) loss_da_image: 0.5791 (0.5652) loss_da_instance: 0.6836 (0.6832) loss_da_consistency: 0.0260 (0.0239) loss_classifier_mask: 0.1199 (0.1389) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0027 (0.0078) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6797 (1.6406) data: 0.3773 (0.3820) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:28:19,703 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:38:53 iter: 3720 loss: 1.6658 (1.8351) loss_classifier: 0.0994 (0.1654) loss_box_reg: 0.0976 (0.1628) loss_objectness: 0.0154 (0.0355) loss_rpn_box_reg: 0.0127 (0.0608) loss_da_image: 0.5757 (0.5658) loss_da_instance: 0.6786 (0.6831) loss_da_consistency: 0.0220 (0.0240) loss_classifier_mask: 0.1046 (0.1384) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0040 (0.0077) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6389 (1.6406) data: 0.3816 (0.3820) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:28:52,411 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:38:12 iter: 3740 loss: 1.6888 (1.8340) loss_classifier: 0.1303 (0.1653) loss_box_reg: 0.1056 (0.1624) loss_objectness: 0.0162 (0.0350) loss_rpn_box_reg: 0.0178 (0.0607) loss_da_image: 0.5827 (0.5664) loss_da_instance: 0.6837 (0.6832) loss_da_consistency: 0.0195 (0.0239) loss_classifier_mask: 0.1106 (0.1377) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0052 (0.0077) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6392 (1.6405) data: 0.3796 (0.3821) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:29:24,778 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:37:06 iter: 3760 loss: 1.6694 (1.8312) loss_classifier: 0.1033 (0.1642) loss_box_reg: 0.0714 (0.1611) loss_objectness: 0.0137 (0.0350) loss_rpn_box_reg: 0.0245 (0.0603) loss_da_image: 0.5659 (0.5665) loss_da_instance: 0.6797 (0.6831) loss_da_consistency: 0.0206 (0.0240) loss_classifier_mask: 0.0989 (0.1377) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0042 (0.0077) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6154 (1.6399) data: 0.3724 (0.3819) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:29:57,967 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:37:02 iter: 3780 loss: 1.7795 (1.8301) loss_classifier: 0.1253 (0.1638) loss_box_reg: 0.1251 (0.1604) loss_objectness: 0.0133 (0.0347) loss_rpn_box_reg: 0.0198 (0.0599) loss_da_image: 0.5878 (0.5672) loss_da_instance: 0.6878 (0.6831) loss_da_consistency: 0.0219 (0.0241) loss_classifier_mask: 0.1094 (0.1373) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0055 (0.0077) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6360 (1.6404) data: 0.3778 (0.3818) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:30:30,969 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:36:43 iter: 3800 loss: 1.7978 (1.8289) loss_classifier: 0.1527 (0.1636) loss_box_reg: 0.1385 (0.1599) loss_objectness: 0.0124 (0.0343) loss_rpn_box_reg: 0.0337 (0.0596) loss_da_image: 0.5827 (0.5678) loss_da_instance: 0.6805 (0.6831) loss_da_consistency: 0.0256 (0.0241) loss_classifier_mask: 0.1249 (0.1369) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0074 (0.0077) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6322 (1.6406) data: 0.3776 (0.3818) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:31:03,436 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:35:46 iter: 3820 loss: 1.7383 (1.8269) loss_classifier: 0.1217 (0.1628) loss_box_reg: 0.1124 (0.1593) loss_objectness: 0.0120 (0.0340) loss_rpn_box_reg: 0.0371 (0.0593) loss_da_image: 0.5621 (0.5679) loss_da_instance: 0.6843 (0.6831) loss_da_consistency: 0.0191 (0.0241) loss_classifier_mask: 0.1240 (0.1366) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0028 (0.0077) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6289 (1.6402) data: 0.3742 (0.3817) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:31:36,786 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:35:50 iter: 3840 loss: 1.9232 (1.8291) loss_classifier: 0.2195 (0.1641) loss_box_reg: 0.1887 (0.1598) loss_objectness: 0.0212 (0.0340) loss_rpn_box_reg: 0.0513 (0.0597) loss_da_image: 0.5762 (0.5682) loss_da_instance: 0.6861 (0.6832) loss_da_consistency: 0.0190 (0.0240) loss_classifier_mask: 0.1092 (0.1361) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0030 (0.0077) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6333 (1.6409) data: 0.3791 (0.3816) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:32:09,875 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:35:35 iter: 3860 loss: 1.8099 (1.8287) loss_classifier: 0.1686 (0.1637) loss_box_reg: 0.1552 (0.1595) loss_objectness: 0.0220 (0.0340) loss_rpn_box_reg: 0.0380 (0.0600) loss_da_image: 0.5754 (0.5687) loss_da_instance: 0.6806 (0.6832) loss_da_consistency: 0.0196 (0.0240) loss_classifier_mask: 0.1146 (0.1354) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0060 (0.0077) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6479 (1.6412) data: 0.3788 (0.3816) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:32:42,940 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:35:17 iter: 3880 loss: 1.6879 (1.8280) loss_classifier: 0.1395 (0.1635) loss_box_reg: 0.1120 (0.1589) loss_objectness: 0.0224 (0.0340) loss_rpn_box_reg: 0.0211 (0.0596) loss_da_image: 0.5706 (0.5689) loss_da_instance: 0.6819 (0.6831) loss_da_consistency: 0.0166 (0.0238) loss_classifier_mask: 0.1458 (0.1359) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0042 (0.0076) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6444 (1.6414) data: 0.3756 (0.3816) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:33:15,881 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:34:51 iter: 3900 loss: 1.5761 (1.8255) loss_classifier: 0.0895 (0.1626) loss_box_reg: 0.0647 (0.1576) loss_objectness: 0.0141 (0.0338) loss_rpn_box_reg: 0.0151 (0.0593) loss_da_image: 0.5731 (0.5691) loss_da_instance: 0.6820 (0.6831) loss_da_consistency: 0.0180 (0.0238) loss_classifier_mask: 0.1241 (0.1357) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0062 (0.0076) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6432 (1.6416) data: 0.3796 (0.3815) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:33:48,953 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:34:33 iter: 3920 loss: 1.7922 (1.8245) loss_classifier: 0.1170 (0.1622) loss_box_reg: 0.0877 (0.1570) loss_objectness: 0.0131 (0.0335) loss_rpn_box_reg: 0.0316 (0.0590) loss_da_image: 0.5758 (0.5693) loss_da_instance: 0.6766 (0.6831) loss_da_consistency: 0.0224 (0.0238) loss_classifier_mask: 0.1481 (0.1361) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0054 (0.0077) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6406 (1.6418) data: 0.3732 (0.3815) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:34:21,764 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:33:59 iter: 3940 loss: 1.6854 (1.8224) loss_classifier: 0.1566 (0.1617) loss_box_reg: 0.1018 (0.1564) loss_objectness: 0.0132 (0.0332) loss_rpn_box_reg: 0.0278 (0.0586) loss_da_image: 0.5941 (0.5697) loss_da_instance: 0.6790 (0.6830) loss_da_consistency: 0.0292 (0.0240) loss_classifier_mask: 0.0815 (0.1350) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0041 (0.0076) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6273 (1.6418) data: 0.3722 (0.3814) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:34:54,413 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:33:15 iter: 3960 loss: 1.7956 (1.8224) loss_classifier: 0.1323 (0.1616) loss_box_reg: 0.1362 (0.1564) loss_objectness: 0.0138 (0.0332) loss_rpn_box_reg: 0.0236 (0.0583) loss_da_image: 0.5721 (0.5699) loss_da_instance: 0.6828 (0.6830) loss_da_consistency: 0.0185 (0.0239) loss_classifier_mask: 0.1302 (0.1352) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0058 (0.0077) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6243 (1.6416) data: 0.3825 (0.3815) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:35:27,402 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:32:51 iter: 3980 loss: 1.7976 (1.8220) loss_classifier: 0.1500 (0.1613) loss_box_reg: 0.1391 (0.1565) loss_objectness: 0.0194 (0.0332) loss_rpn_box_reg: 0.0473 (0.0584) loss_da_image: 0.5773 (0.5701) loss_da_instance: 0.6812 (0.6830) loss_da_consistency: 0.0210 (0.0239) loss_classifier_mask: 0.1060 (0.1348) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0034 (0.0076) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6367 (1.6418) data: 0.3771 (0.3814) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:36:00,832 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:32:52 iter: 4000 loss: 1.8202 (1.8229) loss_classifier: 0.1548 (0.1614) loss_box_reg: 0.1353 (0.1565) loss_objectness: 0.0125 (0.0329) loss_rpn_box_reg: 0.0145 (0.0582) loss_da_image: 0.5675 (0.5703) loss_da_instance: 0.6801 (0.6830) loss_da_consistency: 0.0197 (0.0239) loss_classifier_mask: 0.1931 (0.1358) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0067 (0.0076) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6445 (1.6424) data: 0.3776 (0.3815) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:36:00,835 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /content/drive/MyDrive/AI/mic/model_0004000.pth\n",
            "2023-02-04 16:36:35,706 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:34:10 iter: 4020 loss: 1.7496 (1.8219) loss_classifier: 0.1368 (0.1610) loss_box_reg: 0.1198 (0.1560) loss_objectness: 0.0085 (0.0325) loss_rpn_box_reg: 0.0381 (0.0582) loss_da_image: 0.5780 (0.5704) loss_da_instance: 0.6823 (0.6830) loss_da_consistency: 0.0262 (0.0240) loss_classifier_mask: 0.1037 (0.1357) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0052 (0.0076) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6471 (1.6443) data: 0.3812 (0.3829) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:37:08,743 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:33:45 iter: 4040 loss: 1.9119 (1.8235) loss_classifier: 0.1944 (0.1614) loss_box_reg: 0.1714 (0.1563) loss_objectness: 0.0230 (0.0326) loss_rpn_box_reg: 0.0419 (0.0584) loss_da_image: 0.5903 (0.5708) loss_da_instance: 0.6840 (0.6830) loss_da_consistency: 0.0198 (0.0239) loss_classifier_mask: 0.1382 (0.1358) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0045 (0.0076) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6441 (1.6445) data: 0.3763 (0.3829) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:37:41,435 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:33:02 iter: 4060 loss: 1.7216 (1.8225) loss_classifier: 0.1363 (0.1610) loss_box_reg: 0.1295 (0.1560) loss_objectness: 0.0148 (0.0325) loss_rpn_box_reg: 0.0242 (0.0582) loss_da_image: 0.5769 (0.5710) loss_da_instance: 0.6835 (0.6830) loss_da_consistency: 0.0227 (0.0240) loss_classifier_mask: 0.1261 (0.1357) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0050 (0.0076) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6488 (1.6443) data: 0.3736 (0.3828) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:38:14,494 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:32:38 iter: 4080 loss: 1.8163 (1.8243) loss_classifier: 0.1937 (0.1614) loss_box_reg: 0.1528 (0.1562) loss_objectness: 0.0170 (0.0325) loss_rpn_box_reg: 0.0506 (0.0586) loss_da_image: 0.5753 (0.5711) loss_da_instance: 0.6810 (0.6830) loss_da_consistency: 0.0149 (0.0238) loss_classifier_mask: 0.1503 (0.1364) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0045 (0.0076) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6417 (1.6445) data: 0.3795 (0.3828) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:38:47,311 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:32:01 iter: 4100 loss: 1.7835 (1.8242) loss_classifier: 0.1429 (0.1613) loss_box_reg: 0.1403 (0.1560) loss_objectness: 0.0211 (0.0325) loss_rpn_box_reg: 0.0427 (0.0583) loss_da_image: 0.5854 (0.5713) loss_da_instance: 0.6787 (0.6829) loss_da_consistency: 0.0210 (0.0238) loss_classifier_mask: 0.1413 (0.1365) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0076 (0.0076) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6172 (1.6444) data: 0.3760 (0.3827) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:39:20,134 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:31:25 iter: 4120 loss: 1.7605 (1.8248) loss_classifier: 0.1333 (0.1613) loss_box_reg: 0.1224 (0.1562) loss_objectness: 0.0184 (0.0325) loss_rpn_box_reg: 0.0531 (0.0584) loss_da_image: 0.5771 (0.5715) loss_da_instance: 0.6801 (0.6829) loss_da_consistency: 0.0192 (0.0238) loss_classifier_mask: 0.1355 (0.1367) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0069 (0.0077) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6390 (1.6443) data: 0.3783 (0.3827) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:39:53,125 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:30:57 iter: 4140 loss: 1.8330 (1.8244) loss_classifier: 0.1810 (0.1615) loss_box_reg: 0.1702 (0.1562) loss_objectness: 0.0170 (0.0323) loss_rpn_box_reg: 0.0263 (0.0581) loss_da_image: 0.5559 (0.5714) loss_da_instance: 0.6812 (0.6828) loss_da_consistency: 0.0201 (0.0238) loss_classifier_mask: 0.1355 (0.1367) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0064 (0.0077) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6580 (1.6444) data: 0.3754 (0.3827) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:40:26,207 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:30:34 iter: 4160 loss: 1.7319 (1.8237) loss_classifier: 0.1293 (0.1612) loss_box_reg: 0.1470 (0.1560) loss_objectness: 0.0202 (0.0322) loss_rpn_box_reg: 0.0257 (0.0580) loss_da_image: 0.5817 (0.5716) loss_da_instance: 0.6817 (0.6828) loss_da_consistency: 0.0196 (0.0238) loss_classifier_mask: 0.0946 (0.1364) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0053 (0.0077) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6406 (1.6446) data: 0.3794 (0.3827) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:40:59,092 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:30:01 iter: 4180 loss: 1.7823 (1.8235) loss_classifier: 0.1630 (0.1612) loss_box_reg: 0.1504 (0.1561) loss_objectness: 0.0198 (0.0322) loss_rpn_box_reg: 0.0430 (0.0579) loss_da_image: 0.5671 (0.5716) loss_da_instance: 0.6822 (0.6828) loss_da_consistency: 0.0191 (0.0238) loss_classifier_mask: 0.1226 (0.1360) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0028 (0.0076) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6232 (1.6446) data: 0.3772 (0.3826) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:41:32,076 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:29:32 iter: 4200 loss: 1.8117 (1.8239) loss_classifier: 0.1316 (0.1610) loss_box_reg: 0.1739 (0.1564) loss_objectness: 0.0329 (0.0325) loss_rpn_box_reg: 0.0423 (0.0581) loss_da_image: 0.5706 (0.5717) loss_da_instance: 0.6817 (0.6828) loss_da_consistency: 0.0173 (0.0237) loss_classifier_mask: 0.1304 (0.1358) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0075 (0.0077) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6384 (1.6447) data: 0.3795 (0.3826) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:42:04,956 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:28:59 iter: 4220 loss: 1.9095 (1.8253) loss_classifier: 0.1566 (0.1613) loss_box_reg: 0.1964 (0.1570) loss_objectness: 0.0153 (0.0324) loss_rpn_box_reg: 0.0534 (0.0584) loss_da_image: 0.5812 (0.5720) loss_da_instance: 0.6849 (0.6828) loss_da_consistency: 0.0174 (0.0236) loss_classifier_mask: 0.1337 (0.1358) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0068 (0.0077) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6362 (1.6447) data: 0.3735 (0.3827) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:42:37,527 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:28:11 iter: 4240 loss: 1.8202 (1.8245) loss_classifier: 0.1536 (0.1610) loss_box_reg: 0.1593 (0.1569) loss_objectness: 0.0130 (0.0321) loss_rpn_box_reg: 0.0519 (0.0585) loss_da_image: 0.5686 (0.5720) loss_da_instance: 0.6783 (0.6828) loss_da_consistency: 0.0248 (0.0237) loss_classifier_mask: 0.1137 (0.1356) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0036 (0.0076) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6287 (1.6444) data: 0.3796 (0.3827) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:43:10,597 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:27:46 iter: 4260 loss: 1.7567 (1.8247) loss_classifier: 0.1203 (0.1610) loss_box_reg: 0.1217 (0.1565) loss_objectness: 0.0222 (0.0320) loss_rpn_box_reg: 0.0360 (0.0587) loss_da_image: 0.5666 (0.5721) loss_da_instance: 0.6795 (0.6827) loss_da_consistency: 0.0197 (0.0237) loss_classifier_mask: 0.1608 (0.1360) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0051 (0.0076) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6398 (1.6445) data: 0.3782 (0.3827) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:43:44,066 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:27:39 iter: 4280 loss: 1.8251 (1.8252) loss_classifier: 0.2004 (0.1615) loss_box_reg: 0.1490 (0.1566) loss_objectness: 0.0115 (0.0319) loss_rpn_box_reg: 0.0556 (0.0587) loss_da_image: 0.5574 (0.5720) loss_da_instance: 0.6791 (0.6827) loss_da_consistency: 0.0194 (0.0236) loss_classifier_mask: 0.1354 (0.1361) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0041 (0.0076) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6813 (1.6450) data: 0.3726 (0.3826) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:44:17,082 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:27:11 iter: 4300 loss: 1.8648 (1.8265) loss_classifier: 0.1937 (0.1618) loss_box_reg: 0.1656 (0.1569) loss_objectness: 0.0169 (0.0322) loss_rpn_box_reg: 0.0396 (0.0588) loss_da_image: 0.5691 (0.5720) loss_da_instance: 0.6814 (0.6826) loss_da_consistency: 0.0192 (0.0236) loss_classifier_mask: 0.1518 (0.1364) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0063 (0.0076) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6340 (1.6451) data: 0.3743 (0.3826) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:44:50,560 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:27:02 iter: 4320 loss: 1.8269 (1.8266) loss_classifier: 0.1501 (0.1617) loss_box_reg: 0.1702 (0.1571) loss_objectness: 0.0203 (0.0321) loss_rpn_box_reg: 0.0346 (0.0588) loss_da_image: 0.5886 (0.5721) loss_da_instance: 0.6799 (0.6827) loss_da_consistency: 0.0154 (0.0235) loss_classifier_mask: 0.1194 (0.1364) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0060 (0.0076) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6427 (1.6455) data: 0.3782 (0.3826) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:45:23,187 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:26:17 iter: 4340 loss: 1.7448 (1.8265) loss_classifier: 0.1559 (0.1617) loss_box_reg: 0.1355 (0.1569) loss_objectness: 0.0194 (0.0320) loss_rpn_box_reg: 0.0340 (0.0590) loss_da_image: 0.5817 (0.5722) loss_da_instance: 0.6845 (0.6827) loss_da_consistency: 0.0183 (0.0235) loss_classifier_mask: 0.1266 (0.1362) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0051 (0.0076) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6306 (1.6453) data: 0.3830 (0.3826) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:45:55,869 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:25:35 iter: 4360 loss: 1.7732 (1.8263) loss_classifier: 0.1801 (0.1616) loss_box_reg: 0.1480 (0.1568) loss_objectness: 0.0221 (0.0320) loss_rpn_box_reg: 0.0463 (0.0590) loss_da_image: 0.5711 (0.5723) loss_da_instance: 0.6839 (0.6827) loss_da_consistency: 0.0220 (0.0235) loss_classifier_mask: 0.1247 (0.1362) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0031 (0.0076) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6322 (1.6451) data: 0.3771 (0.3826) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:46:28,764 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:25:02 iter: 4380 loss: 1.7669 (1.8261) loss_classifier: 0.1545 (0.1615) loss_box_reg: 0.1171 (0.1567) loss_objectness: 0.0324 (0.0322) loss_rpn_box_reg: 0.0541 (0.0592) loss_da_image: 0.5677 (0.5723) loss_da_instance: 0.6842 (0.6827) loss_da_consistency: 0.0169 (0.0234) loss_classifier_mask: 0.0949 (0.1358) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0027 (0.0075) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6331 (1.6451) data: 0.3739 (0.3826) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:47:01,417 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:24:19 iter: 4400 loss: 1.8111 (1.8257) loss_classifier: 0.1400 (0.1613) loss_box_reg: 0.1341 (0.1565) loss_objectness: 0.0193 (0.0321) loss_rpn_box_reg: 0.0485 (0.0594) loss_da_image: 0.5710 (0.5724) loss_da_instance: 0.6851 (0.6828) loss_da_consistency: 0.0176 (0.0233) loss_classifier_mask: 0.1195 (0.1357) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0041 (0.0075) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6325 (1.6450) data: 0.3754 (0.3825) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:47:34,857 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:24:08 iter: 4420 loss: 1.8763 (1.8260) loss_classifier: 0.1582 (0.1614) loss_box_reg: 0.1619 (0.1566) loss_objectness: 0.0219 (0.0321) loss_rpn_box_reg: 0.0661 (0.0595) loss_da_image: 0.5736 (0.5725) loss_da_instance: 0.6867 (0.6828) loss_da_consistency: 0.0198 (0.0233) loss_classifier_mask: 0.1239 (0.1355) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0069 (0.0075) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6640 (1.6453) data: 0.3747 (0.3825) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:48:07,735 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:23:33 iter: 4440 loss: 1.8635 (1.8262) loss_classifier: 0.1587 (0.1615) loss_box_reg: 0.1562 (0.1565) loss_objectness: 0.0171 (0.0321) loss_rpn_box_reg: 0.0397 (0.0598) loss_da_image: 0.5676 (0.5725) loss_da_instance: 0.6866 (0.6829) loss_da_consistency: 0.0213 (0.0233) loss_classifier_mask: 0.1151 (0.1353) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0029 (0.0075) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6321 (1.6453) data: 0.3780 (0.3825) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:48:40,015 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:22:37 iter: 4460 loss: 1.7792 (1.8257) loss_classifier: 0.1366 (0.1614) loss_box_reg: 0.1524 (0.1564) loss_objectness: 0.0187 (0.0320) loss_rpn_box_reg: 0.0392 (0.0597) loss_da_image: 0.5592 (0.5724) loss_da_instance: 0.6830 (0.6829) loss_da_consistency: 0.0170 (0.0232) loss_classifier_mask: 0.1304 (0.1353) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0057 (0.0075) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6207 (1.6449) data: 0.3745 (0.3824) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:49:12,909 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:22:04 iter: 4480 loss: 1.6829 (1.8243) loss_classifier: 0.1207 (0.1611) loss_box_reg: 0.1196 (0.1560) loss_objectness: 0.0186 (0.0319) loss_rpn_box_reg: 0.0154 (0.0594) loss_da_image: 0.5565 (0.5723) loss_da_instance: 0.6801 (0.6829) loss_da_consistency: 0.0194 (0.0232) loss_classifier_mask: 0.1287 (0.1352) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0065 (0.0075) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6263 (1.6449) data: 0.3747 (0.3824) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:49:45,978 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:21:37 iter: 4500 loss: 1.8489 (1.8242) loss_classifier: 0.1835 (0.1613) loss_box_reg: 0.1470 (0.1560) loss_objectness: 0.0248 (0.0320) loss_rpn_box_reg: 0.0473 (0.0593) loss_da_image: 0.5607 (0.5721) loss_da_instance: 0.6809 (0.6828) loss_da_consistency: 0.0215 (0.0232) loss_classifier_mask: 0.1286 (0.1351) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0057 (0.0075) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6393 (1.6450) data: 0.3748 (0.3824) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:50:18,955 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:21:07 iter: 4520 loss: 1.6674 (1.8228) loss_classifier: 0.1279 (0.1610) loss_box_reg: 0.1105 (0.1555) loss_objectness: 0.0140 (0.0320) loss_rpn_box_reg: 0.0200 (0.0591) loss_da_image: 0.5742 (0.5720) loss_da_instance: 0.6835 (0.6828) loss_da_consistency: 0.0186 (0.0231) loss_classifier_mask: 0.1067 (0.1348) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0055 (0.0075) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6339 (1.6451) data: 0.3727 (0.3824) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:50:51,918 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:20:36 iter: 4540 loss: 1.7609 (1.8221) loss_classifier: 0.1388 (0.1608) loss_box_reg: 0.1230 (0.1552) loss_objectness: 0.0205 (0.0319) loss_rpn_box_reg: 0.0150 (0.0590) loss_da_image: 0.5784 (0.5722) loss_da_instance: 0.6865 (0.6829) loss_da_consistency: 0.0203 (0.0231) loss_classifier_mask: 0.1120 (0.1346) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0048 (0.0075) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6222 (1.6451) data: 0.3795 (0.3824) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:51:25,213 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:20:17 iter: 4560 loss: 1.8028 (1.8221) loss_classifier: 0.1344 (0.1608) loss_box_reg: 0.1186 (0.1551) loss_objectness: 0.0221 (0.0319) loss_rpn_box_reg: 0.0199 (0.0589) loss_da_image: 0.5586 (0.5723) loss_da_instance: 0.6853 (0.6829) loss_da_consistency: 0.0143 (0.0230) loss_classifier_mask: 0.1275 (0.1345) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0044 (0.0075) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6454 (1.6453) data: 0.3777 (0.3824) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:51:57,758 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:19:32 iter: 4580 loss: 1.6960 (1.8221) loss_classifier: 0.1353 (0.1607) loss_box_reg: 0.1434 (0.1551) loss_objectness: 0.0175 (0.0319) loss_rpn_box_reg: 0.0215 (0.0590) loss_da_image: 0.5776 (0.5724) loss_da_instance: 0.6833 (0.6829) loss_da_consistency: 0.0193 (0.0230) loss_classifier_mask: 0.1259 (0.1345) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0053 (0.0075) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6372 (1.6451) data: 0.3745 (0.3823) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:52:30,820 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:19:05 iter: 4600 loss: 1.7548 (1.8217) loss_classifier: 0.1375 (0.1605) loss_box_reg: 0.0996 (0.1547) loss_objectness: 0.0275 (0.0320) loss_rpn_box_reg: 0.0364 (0.0590) loss_da_image: 0.5714 (0.5724) loss_da_instance: 0.6849 (0.6830) loss_da_consistency: 0.0188 (0.0230) loss_classifier_mask: 0.1328 (0.1345) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0059 (0.0075) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6357 (1.6452) data: 0.3852 (0.3823) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:53:03,596 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:18:27 iter: 4620 loss: 1.8303 (1.8222) loss_classifier: 0.1593 (0.1607) loss_box_reg: 0.1821 (0.1551) loss_objectness: 0.0292 (0.0321) loss_rpn_box_reg: 0.0670 (0.0593) loss_da_image: 0.5681 (0.5724) loss_da_instance: 0.6784 (0.6829) loss_da_consistency: 0.0161 (0.0229) loss_classifier_mask: 0.1183 (0.1342) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0035 (0.0075) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6291 (1.6451) data: 0.3830 (0.3823) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:53:36,766 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:18:03 iter: 4640 loss: 1.7244 (1.8215) loss_classifier: 0.1600 (0.1608) loss_box_reg: 0.1508 (0.1552) loss_objectness: 0.0158 (0.0320) loss_rpn_box_reg: 0.0294 (0.0590) loss_da_image: 0.5527 (0.5722) loss_da_instance: 0.6842 (0.6830) loss_da_consistency: 0.0204 (0.0229) loss_classifier_mask: 0.1103 (0.1339) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0047 (0.0074) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6454 (1.6453) data: 0.3752 (0.3824) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:54:09,681 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:17:31 iter: 4660 loss: 1.7628 (1.8212) loss_classifier: 0.1372 (0.1607) loss_box_reg: 0.1414 (0.1550) loss_objectness: 0.0090 (0.0318) loss_rpn_box_reg: 0.0310 (0.0587) loss_da_image: 0.5671 (0.5722) loss_da_instance: 0.6822 (0.6830) loss_da_consistency: 0.0232 (0.0230) loss_classifier_mask: 0.1258 (0.1342) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0082 (0.0075) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6395 (1.6453) data: 0.3789 (0.3823) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:54:42,501 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:16:55 iter: 4680 loss: 1.7899 (1.8209) loss_classifier: 0.1548 (0.1606) loss_box_reg: 0.1564 (0.1550) loss_objectness: 0.0206 (0.0317) loss_rpn_box_reg: 0.0502 (0.0588) loss_da_image: 0.5687 (0.5722) loss_da_instance: 0.6809 (0.6829) loss_da_consistency: 0.0226 (0.0230) loss_classifier_mask: 0.1029 (0.1340) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0012 (0.0074) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6183 (1.6453) data: 0.3792 (0.3823) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:55:15,727 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:16:33 iter: 4700 loss: 1.7544 (1.8214) loss_classifier: 0.1563 (0.1608) loss_box_reg: 0.1577 (0.1552) loss_objectness: 0.0161 (0.0317) loss_rpn_box_reg: 0.0556 (0.0590) loss_da_image: 0.5687 (0.5723) loss_da_instance: 0.6785 (0.6829) loss_da_consistency: 0.0176 (0.0229) loss_classifier_mask: 0.1184 (0.1338) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0036 (0.0074) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6449 (1.6454) data: 0.3713 (0.3823) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:55:48,711 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:16:02 iter: 4720 loss: 1.7752 (1.8216) loss_classifier: 0.1580 (0.1610) loss_box_reg: 0.1676 (0.1554) loss_objectness: 0.0156 (0.0316) loss_rpn_box_reg: 0.0296 (0.0590) loss_da_image: 0.5797 (0.5724) loss_da_instance: 0.6817 (0.6829) loss_da_consistency: 0.0161 (0.0229) loss_classifier_mask: 0.1224 (0.1337) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0034 (0.0074) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6452 (1.6455) data: 0.3785 (0.3823) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:56:21,713 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:15:32 iter: 4740 loss: 1.7739 (1.8214) loss_classifier: 0.1318 (0.1607) loss_box_reg: 0.1197 (0.1550) loss_objectness: 0.0147 (0.0315) loss_rpn_box_reg: 0.0268 (0.0591) loss_da_image: 0.5809 (0.5725) loss_da_instance: 0.6839 (0.6829) loss_da_consistency: 0.0170 (0.0228) loss_classifier_mask: 0.1288 (0.1340) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0035 (0.0074) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6381 (1.6455) data: 0.3714 (0.3823) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:56:54,683 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:15:01 iter: 4760 loss: 1.7405 (1.8215) loss_classifier: 0.1311 (0.1605) loss_box_reg: 0.1032 (0.1548) loss_objectness: 0.0249 (0.0316) loss_rpn_box_reg: 0.0392 (0.0591) loss_da_image: 0.5898 (0.5727) loss_da_instance: 0.6817 (0.6829) loss_da_consistency: 0.0168 (0.0228) loss_classifier_mask: 0.1525 (0.1342) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0037 (0.0074) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6290 (1.6456) data: 0.3782 (0.3823) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:57:27,921 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:14:38 iter: 4780 loss: 1.7867 (1.8216) loss_classifier: 0.1556 (0.1605) loss_box_reg: 0.1664 (0.1549) loss_objectness: 0.0172 (0.0315) loss_rpn_box_reg: 0.0272 (0.0591) loss_da_image: 0.5944 (0.5729) loss_da_instance: 0.6809 (0.6829) loss_da_consistency: 0.0183 (0.0227) loss_classifier_mask: 0.1238 (0.1341) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0047 (0.0073) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6447 (1.6458) data: 0.3790 (0.3823) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:58:01,063 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:14:12 iter: 4800 loss: 1.8781 (1.8218) loss_classifier: 0.1492 (0.1605) loss_box_reg: 0.1709 (0.1549) loss_objectness: 0.0243 (0.0315) loss_rpn_box_reg: 0.0574 (0.0592) loss_da_image: 0.5644 (0.5729) loss_da_instance: 0.6825 (0.6829) loss_da_consistency: 0.0197 (0.0227) loss_classifier_mask: 0.1323 (0.1343) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0051 (0.0074) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6486 (1.6459) data: 0.3897 (0.3823) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:58:34,140 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:13:44 iter: 4820 loss: 1.8556 (1.8223) loss_classifier: 0.1630 (0.1606) loss_box_reg: 0.1655 (0.1550) loss_objectness: 0.0224 (0.0315) loss_rpn_box_reg: 0.0405 (0.0594) loss_da_image: 0.5763 (0.5730) loss_da_instance: 0.6806 (0.6829) loss_da_consistency: 0.0171 (0.0227) loss_classifier_mask: 0.1265 (0.1342) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0068 (0.0074) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6354 (1.6460) data: 0.3809 (0.3823) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:59:07,256 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:13:17 iter: 4840 loss: 1.7768 (1.8224) loss_classifier: 0.1373 (0.1604) loss_box_reg: 0.1454 (0.1549) loss_objectness: 0.0197 (0.0315) loss_rpn_box_reg: 0.0512 (0.0595) loss_da_image: 0.5867 (0.5732) loss_da_instance: 0.6811 (0.6829) loss_da_consistency: 0.0168 (0.0226) loss_classifier_mask: 0.1260 (0.1342) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0048 (0.0074) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6380 (1.6461) data: 0.3760 (0.3823) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 16:59:40,041 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:12:40 iter: 4860 loss: 1.7343 (1.8217) loss_classifier: 0.1049 (0.1601) loss_box_reg: 0.1103 (0.1544) loss_objectness: 0.0246 (0.0316) loss_rpn_box_reg: 0.0173 (0.0593) loss_da_image: 0.5755 (0.5733) loss_da_instance: 0.6825 (0.6829) loss_da_consistency: 0.0171 (0.0226) loss_classifier_mask: 0.1438 (0.1344) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0044 (0.0074) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6394 (1.6460) data: 0.3826 (0.3823) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:00:12,662 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:11:58 iter: 4880 loss: 1.8738 (1.8216) loss_classifier: 0.1433 (0.1600) loss_box_reg: 0.1625 (0.1545) loss_objectness: 0.0136 (0.0316) loss_rpn_box_reg: 0.0420 (0.0595) loss_da_image: 0.5757 (0.5733) loss_da_instance: 0.6791 (0.6829) loss_da_consistency: 0.0253 (0.0226) loss_classifier_mask: 0.1127 (0.1342) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0044 (0.0073) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6254 (1.6458) data: 0.3694 (0.3823) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:00:45,546 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:11:25 iter: 4900 loss: 1.7070 (1.8209) loss_classifier: 0.1036 (0.1597) loss_box_reg: 0.0990 (0.1541) loss_objectness: 0.0191 (0.0316) loss_rpn_box_reg: 0.0271 (0.0593) loss_da_image: 0.5642 (0.5732) loss_da_instance: 0.6818 (0.6829) loss_da_consistency: 0.0180 (0.0226) loss_classifier_mask: 0.1481 (0.1346) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0057 (0.0073) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6373 (1.6458) data: 0.3755 (0.3823) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:01:18,398 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:10:50 iter: 4920 loss: 1.8230 (1.8213) loss_classifier: 0.1483 (0.1597) loss_box_reg: 0.1490 (0.1542) loss_objectness: 0.0225 (0.0316) loss_rpn_box_reg: 0.0310 (0.0593) loss_da_image: 0.5714 (0.5733) loss_da_instance: 0.6827 (0.6829) loss_da_consistency: 0.0165 (0.0225) loss_classifier_mask: 0.1440 (0.1347) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0051 (0.0074) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6242 (1.6458) data: 0.3749 (0.3822) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:01:51,420 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:10:20 iter: 4940 loss: 1.8470 (1.8217) loss_classifier: 0.1614 (0.1597) loss_box_reg: 0.1556 (0.1544) loss_objectness: 0.0320 (0.0317) loss_rpn_box_reg: 0.0604 (0.0596) loss_da_image: 0.5773 (0.5733) loss_da_instance: 0.6795 (0.6829) loss_da_consistency: 0.0157 (0.0224) loss_classifier_mask: 0.1246 (0.1346) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0041 (0.0073) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6404 (1.6458) data: 0.3786 (0.3822) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:02:24,822 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:10:01 iter: 4960 loss: 1.7583 (1.8214) loss_classifier: 0.1537 (0.1598) loss_box_reg: 0.1467 (0.1543) loss_objectness: 0.0178 (0.0317) loss_rpn_box_reg: 0.0294 (0.0596) loss_da_image: 0.5684 (0.5733) loss_da_instance: 0.6820 (0.6829) loss_da_consistency: 0.0210 (0.0225) loss_classifier_mask: 0.0970 (0.1344) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0040 (0.0073) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6436 (1.6461) data: 0.3771 (0.3822) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:02:57,778 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:09:29 iter: 4980 loss: 1.7868 (1.8212) loss_classifier: 0.1463 (0.1597) loss_box_reg: 0.1289 (0.1541) loss_objectness: 0.0127 (0.0315) loss_rpn_box_reg: 0.0453 (0.0596) loss_da_image: 0.5719 (0.5733) loss_da_instance: 0.6813 (0.6828) loss_da_consistency: 0.0210 (0.0225) loss_classifier_mask: 0.1494 (0.1345) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0048 (0.0073) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6333 (1.6461) data: 0.3809 (0.3822) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:03:30,592 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:08:53 iter: 5000 loss: 1.7962 (1.8213) loss_classifier: 0.1531 (0.1597) loss_box_reg: 0.1636 (0.1542) loss_objectness: 0.0171 (0.0314) loss_rpn_box_reg: 0.0227 (0.0597) loss_da_image: 0.5799 (0.5734) loss_da_instance: 0.6812 (0.6828) loss_da_consistency: 0.0215 (0.0225) loss_classifier_mask: 0.1175 (0.1345) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0038 (0.0073) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6334 (1.6461) data: 0.3777 (0.3822) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:03:30,595 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /content/drive/MyDrive/AI/mic/model_0005000.pth\n",
            "2023-02-04 17:04:06,344 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:09:37 iter: 5020 loss: 1.7473 (1.8209) loss_classifier: 0.1322 (0.1596) loss_box_reg: 0.1304 (0.1540) loss_objectness: 0.0280 (0.0315) loss_rpn_box_reg: 0.0260 (0.0595) loss_da_image: 0.5696 (0.5734) loss_da_instance: 0.6763 (0.6828) loss_da_consistency: 0.0173 (0.0225) loss_classifier_mask: 0.1345 (0.1346) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0046 (0.0073) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6441 (1.6475) data: 0.3878 (0.3831) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:04:39,237 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:09:02 iter: 5040 loss: 1.7925 (1.8209) loss_classifier: 0.1315 (0.1595) loss_box_reg: 0.1507 (0.1541) loss_objectness: 0.0207 (0.0314) loss_rpn_box_reg: 0.0340 (0.0595) loss_da_image: 0.5746 (0.5734) loss_da_instance: 0.6851 (0.6828) loss_da_consistency: 0.0197 (0.0225) loss_classifier_mask: 0.1383 (0.1345) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0040 (0.0073) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6251 (1.6474) data: 0.3779 (0.3831) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:05:11,971 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:08:24 iter: 5060 loss: 1.8694 (1.8212) loss_classifier: 0.1824 (0.1597) loss_box_reg: 0.1563 (0.1542) loss_objectness: 0.0144 (0.0313) loss_rpn_box_reg: 0.0410 (0.0596) loss_da_image: 0.5704 (0.5734) loss_da_instance: 0.6815 (0.6828) loss_da_consistency: 0.0230 (0.0225) loss_classifier_mask: 0.1381 (0.1346) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0027 (0.0073) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6323 (1.6473) data: 0.3777 (0.3831) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:05:45,201 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:07:58 iter: 5080 loss: 1.7204 (1.8203) loss_classifier: 0.1299 (0.1595) loss_box_reg: 0.1177 (0.1538) loss_objectness: 0.0147 (0.0312) loss_rpn_box_reg: 0.0169 (0.0595) loss_da_image: 0.5673 (0.5734) loss_da_instance: 0.6850 (0.6828) loss_da_consistency: 0.0203 (0.0225) loss_classifier_mask: 0.0995 (0.1344) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0012 (0.0072) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6612 (1.6475) data: 0.3818 (0.3830) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:06:18,585 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:07:37 iter: 5100 loss: 1.8378 (1.8207) loss_classifier: 0.1449 (0.1595) loss_box_reg: 0.1670 (0.1538) loss_objectness: 0.0210 (0.0312) loss_rpn_box_reg: 0.0391 (0.0599) loss_da_image: 0.5763 (0.5734) loss_da_instance: 0.6791 (0.6828) loss_da_consistency: 0.0227 (0.0225) loss_classifier_mask: 0.1397 (0.1345) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0064 (0.0072) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6601 (1.6477) data: 0.3786 (0.3831) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:06:51,680 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:07:07 iter: 5120 loss: 1.8862 (1.8210) loss_classifier: 0.1517 (0.1595) loss_box_reg: 0.1459 (0.1538) loss_objectness: 0.0203 (0.0312) loss_rpn_box_reg: 0.0498 (0.0600) loss_da_image: 0.5684 (0.5735) loss_da_instance: 0.6778 (0.6827) loss_da_consistency: 0.0241 (0.0226) loss_classifier_mask: 0.1572 (0.1347) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0055 (0.0072) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6428 (1.6477) data: 0.3785 (0.3831) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:07:24,774 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:06:38 iter: 5140 loss: 1.7752 (1.8215) loss_classifier: 0.1324 (0.1595) loss_box_reg: 0.1692 (0.1540) loss_objectness: 0.0122 (0.0310) loss_rpn_box_reg: 0.0393 (0.0600) loss_da_image: 0.5733 (0.5735) loss_da_instance: 0.6788 (0.6827) loss_da_consistency: 0.0270 (0.0226) loss_classifier_mask: 0.1516 (0.1348) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0073 (0.0072) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6382 (1.6478) data: 0.3806 (0.3830) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:07:57,672 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:06:04 iter: 5160 loss: 1.8099 (1.8212) loss_classifier: 0.1497 (0.1594) loss_box_reg: 0.1122 (0.1539) loss_objectness: 0.0160 (0.0310) loss_rpn_box_reg: 0.0508 (0.0600) loss_da_image: 0.5810 (0.5737) loss_da_instance: 0.6822 (0.6827) loss_da_consistency: 0.0216 (0.0226) loss_classifier_mask: 0.1257 (0.1347) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0054 (0.0073) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6248 (1.6478) data: 0.3859 (0.3830) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:08:30,538 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:05:28 iter: 5180 loss: 1.7090 (1.8204) loss_classifier: 0.1022 (0.1590) loss_box_reg: 0.1142 (0.1537) loss_objectness: 0.0118 (0.0308) loss_rpn_box_reg: 0.0334 (0.0598) loss_da_image: 0.5732 (0.5736) loss_da_instance: 0.6804 (0.6827) loss_da_consistency: 0.0248 (0.0227) loss_classifier_mask: 0.1282 (0.1348) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0060 (0.0073) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6361 (1.6477) data: 0.3696 (0.3830) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:09:03,365 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:04:52 iter: 5200 loss: 1.8480 (1.8203) loss_classifier: 0.1426 (0.1589) loss_box_reg: 0.1365 (0.1536) loss_objectness: 0.0167 (0.0308) loss_rpn_box_reg: 0.0491 (0.0598) loss_da_image: 0.5829 (0.5738) loss_da_instance: 0.6830 (0.6827) loss_da_consistency: 0.0203 (0.0227) loss_classifier_mask: 0.1273 (0.1347) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0043 (0.0073) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6403 (1.6477) data: 0.3823 (0.3830) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:09:36,825 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:04:32 iter: 5220 loss: 1.5762 (1.8196) loss_classifier: 0.0838 (0.1586) loss_box_reg: 0.0915 (0.1534) loss_objectness: 0.0177 (0.0308) loss_rpn_box_reg: 0.0150 (0.0598) loss_da_image: 0.5728 (0.5738) loss_da_instance: 0.6835 (0.6827) loss_da_consistency: 0.0229 (0.0227) loss_classifier_mask: 0.1117 (0.1345) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0041 (0.0073) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6780 (1.6479) data: 0.3802 (0.3829) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:10:10,130 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:04:07 iter: 5240 loss: 1.7164 (1.8190) loss_classifier: 0.1157 (0.1582) loss_box_reg: 0.0807 (0.1530) loss_objectness: 0.0184 (0.0308) loss_rpn_box_reg: 0.0233 (0.0597) loss_da_image: 0.5657 (0.5738) loss_da_instance: 0.6824 (0.6827) loss_da_consistency: 0.0192 (0.0227) loss_classifier_mask: 0.1422 (0.1347) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0073 (0.0073) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6576 (1.6481) data: 0.3711 (0.3829) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:10:43,196 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:03:37 iter: 5260 loss: 1.7301 (1.8183) loss_classifier: 0.0965 (0.1579) loss_box_reg: 0.1095 (0.1528) loss_objectness: 0.0176 (0.0308) loss_rpn_box_reg: 0.0286 (0.0595) loss_da_image: 0.5717 (0.5738) loss_da_instance: 0.6867 (0.6827) loss_da_consistency: 0.0154 (0.0226) loss_classifier_mask: 0.1177 (0.1346) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0078 (0.0073) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6441 (1.6481) data: 0.3760 (0.3829) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:11:16,221 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:03:05 iter: 5280 loss: 1.7131 (1.8180) loss_classifier: 0.1318 (0.1578) loss_box_reg: 0.1156 (0.1526) loss_objectness: 0.0167 (0.0308) loss_rpn_box_reg: 0.0419 (0.0596) loss_da_image: 0.5688 (0.5738) loss_da_instance: 0.6860 (0.6827) loss_da_consistency: 0.0178 (0.0226) loss_classifier_mask: 0.1227 (0.1345) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0048 (0.0073) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6285 (1.6481) data: 0.3796 (0.3830) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:11:49,081 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:02:30 iter: 5300 loss: 1.6994 (1.8176) loss_classifier: 0.1341 (0.1577) loss_box_reg: 0.1045 (0.1523) loss_objectness: 0.0227 (0.0308) loss_rpn_box_reg: 0.0420 (0.0595) loss_da_image: 0.5727 (0.5738) loss_da_instance: 0.6830 (0.6827) loss_da_consistency: 0.0206 (0.0226) loss_classifier_mask: 0.1379 (0.1346) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0036 (0.0073) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6228 (1.6481) data: 0.3738 (0.3829) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:12:21,904 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:01:54 iter: 5320 loss: 1.8228 (1.8176) loss_classifier: 0.1342 (0.1576) loss_box_reg: 0.1486 (0.1524) loss_objectness: 0.0223 (0.0307) loss_rpn_box_reg: 0.0232 (0.0595) loss_da_image: 0.5729 (0.5739) loss_da_instance: 0.6854 (0.6828) loss_da_consistency: 0.0165 (0.0225) loss_classifier_mask: 0.1168 (0.1346) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0051 (0.0073) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6348 (1.6480) data: 0.3810 (0.3829) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:12:55,041 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:01:25 iter: 5340 loss: 1.7498 (1.8172) loss_classifier: 0.1175 (0.1574) loss_box_reg: 0.1102 (0.1523) loss_objectness: 0.0128 (0.0307) loss_rpn_box_reg: 0.0327 (0.0594) loss_da_image: 0.5731 (0.5739) loss_da_instance: 0.6855 (0.6828) loss_da_consistency: 0.0160 (0.0225) loss_classifier_mask: 0.1247 (0.1346) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0023 (0.0073) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6479 (1.6481) data: 0.3774 (0.3829) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:13:27,775 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:00:47 iter: 5360 loss: 1.7143 (1.8164) loss_classifier: 0.1137 (0.1572) loss_box_reg: 0.1116 (0.1521) loss_objectness: 0.0187 (0.0306) loss_rpn_box_reg: 0.0254 (0.0593) loss_da_image: 0.5639 (0.5738) loss_da_instance: 0.6838 (0.6828) loss_da_consistency: 0.0208 (0.0225) loss_classifier_mask: 0.1192 (0.1345) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0047 (0.0073) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6362 (1.6480) data: 0.3751 (0.3828) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:14:00,722 maskrcnn_benchmark.trainer INFO: eta: 1 day, 1:00:13 iter: 5380 loss: 1.7128 (1.8160) loss_classifier: 0.1244 (0.1571) loss_box_reg: 0.1165 (0.1518) loss_objectness: 0.0079 (0.0305) loss_rpn_box_reg: 0.0218 (0.0592) loss_da_image: 0.5629 (0.5738) loss_da_instance: 0.6818 (0.6828) loss_da_consistency: 0.0238 (0.0225) loss_classifier_mask: 0.1563 (0.1346) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0070 (0.0073) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6337 (1.6480) data: 0.3734 (0.3828) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:14:33,861 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:59:44 iter: 5400 loss: 1.7926 (1.8160) loss_classifier: 0.1118 (0.1570) loss_box_reg: 0.1401 (0.1516) loss_objectness: 0.0265 (0.0306) loss_rpn_box_reg: 0.0340 (0.0592) loss_da_image: 0.5604 (0.5737) loss_da_instance: 0.6823 (0.6828) loss_da_consistency: 0.0164 (0.0225) loss_classifier_mask: 0.1674 (0.1349) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0074 (0.0073) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6434 (1.6481) data: 0.3755 (0.3828) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:15:06,535 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:59:05 iter: 5420 loss: 1.8141 (1.8158) loss_classifier: 0.1370 (0.1570) loss_box_reg: 0.1402 (0.1516) loss_objectness: 0.0170 (0.0305) loss_rpn_box_reg: 0.0317 (0.0592) loss_da_image: 0.5800 (0.5738) loss_da_instance: 0.6797 (0.6828) loss_da_consistency: 0.0193 (0.0225) loss_classifier_mask: 0.1267 (0.1349) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0043 (0.0073) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6401 (1.6480) data: 0.3741 (0.3828) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:15:39,269 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:58:27 iter: 5440 loss: 1.7673 (1.8156) loss_classifier: 0.1449 (0.1570) loss_box_reg: 0.1463 (0.1515) loss_objectness: 0.0116 (0.0304) loss_rpn_box_reg: 0.0211 (0.0591) loss_da_image: 0.5802 (0.5738) loss_da_instance: 0.6797 (0.6827) loss_da_consistency: 0.0274 (0.0225) loss_classifier_mask: 0.1236 (0.1348) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0028 (0.0073) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6180 (1.6479) data: 0.3752 (0.3828) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:16:12,013 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:57:49 iter: 5460 loss: 1.6668 (1.8150) loss_classifier: 0.1225 (0.1567) loss_box_reg: 0.1243 (0.1513) loss_objectness: 0.0191 (0.0304) loss_rpn_box_reg: 0.0488 (0.0591) loss_da_image: 0.5655 (0.5738) loss_da_instance: 0.6814 (0.6827) loss_da_consistency: 0.0179 (0.0225) loss_classifier_mask: 0.1380 (0.1348) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0050 (0.0073) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6182 (1.6478) data: 0.3736 (0.3827) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:16:45,301 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:57:24 iter: 5480 loss: 1.6290 (1.8147) loss_classifier: 0.1026 (0.1565) loss_box_reg: 0.0916 (0.1512) loss_objectness: 0.0160 (0.0303) loss_rpn_box_reg: 0.0247 (0.0591) loss_da_image: 0.5657 (0.5737) loss_da_instance: 0.6791 (0.6827) loss_da_consistency: 0.0191 (0.0225) loss_classifier_mask: 0.1217 (0.1348) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0058 (0.0073) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6659 (1.6479) data: 0.3784 (0.3827) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:17:18,322 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:56:52 iter: 5500 loss: 1.9485 (1.8155) loss_classifier: 0.1770 (0.1567) loss_box_reg: 0.1801 (0.1513) loss_objectness: 0.0241 (0.0304) loss_rpn_box_reg: 0.0810 (0.0594) loss_da_image: 0.5914 (0.5739) loss_da_instance: 0.6786 (0.6827) loss_da_consistency: 0.0184 (0.0225) loss_classifier_mask: 0.1251 (0.1349) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0043 (0.0073) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6324 (1.6479) data: 0.3776 (0.3826) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:17:51,371 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:56:21 iter: 5520 loss: 1.6978 (1.8147) loss_classifier: 0.1079 (0.1565) loss_box_reg: 0.1157 (0.1510) loss_objectness: 0.0164 (0.0303) loss_rpn_box_reg: 0.0157 (0.0592) loss_da_image: 0.5765 (0.5739) loss_da_instance: 0.6868 (0.6827) loss_da_consistency: 0.0177 (0.0224) loss_classifier_mask: 0.1431 (0.1348) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0027 (0.0073) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6230 (1.6480) data: 0.3782 (0.3826) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:18:24,227 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:55:46 iter: 5540 loss: 1.8647 (1.8152) loss_classifier: 0.1654 (0.1566) loss_box_reg: 0.1565 (0.1512) loss_objectness: 0.0163 (0.0303) loss_rpn_box_reg: 0.0521 (0.0593) loss_da_image: 0.5778 (0.5739) loss_da_instance: 0.6798 (0.6827) loss_da_consistency: 0.0183 (0.0224) loss_classifier_mask: 0.1516 (0.1349) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0058 (0.0073) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6309 (1.6479) data: 0.3731 (0.3826) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:18:57,234 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:55:14 iter: 5560 loss: 1.7880 (1.8154) loss_classifier: 0.1692 (0.1566) loss_box_reg: 0.1403 (0.1513) loss_objectness: 0.0100 (0.0303) loss_rpn_box_reg: 0.0340 (0.0592) loss_da_image: 0.5894 (0.5741) loss_da_instance: 0.6810 (0.6827) loss_da_consistency: 0.0187 (0.0224) loss_classifier_mask: 0.1390 (0.1350) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0051 (0.0073) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6312 (1.6480) data: 0.3759 (0.3826) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:19:29,980 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:54:37 iter: 5580 loss: 1.8919 (1.8157) loss_classifier: 0.1623 (0.1568) loss_box_reg: 0.1715 (0.1514) loss_objectness: 0.0289 (0.0303) loss_rpn_box_reg: 0.0434 (0.0593) loss_da_image: 0.5637 (0.5741) loss_da_instance: 0.6809 (0.6827) loss_da_consistency: 0.0178 (0.0224) loss_classifier_mask: 0.1172 (0.1349) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0048 (0.0073) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6168 (1.6479) data: 0.3791 (0.3825) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:20:03,188 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:54:09 iter: 5600 loss: 1.7059 (1.8154) loss_classifier: 0.1307 (0.1567) loss_box_reg: 0.1180 (0.1513) loss_objectness: 0.0125 (0.0303) loss_rpn_box_reg: 0.0210 (0.0594) loss_da_image: 0.5842 (0.5742) loss_da_instance: 0.6831 (0.6827) loss_da_consistency: 0.0204 (0.0224) loss_classifier_mask: 0.0941 (0.1346) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0018 (0.0072) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6535 (1.6480) data: 0.3838 (0.3825) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:20:35,790 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:53:28 iter: 5620 loss: 1.5864 (1.8141) loss_classifier: 0.1184 (0.1565) loss_box_reg: 0.0927 (0.1509) loss_objectness: 0.0180 (0.0302) loss_rpn_box_reg: 0.0057 (0.0591) loss_da_image: 0.5579 (0.5741) loss_da_instance: 0.6867 (0.6828) loss_da_consistency: 0.0187 (0.0224) loss_classifier_mask: 0.1159 (0.1344) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0059 (0.0072) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6374 (1.6478) data: 0.3756 (0.3825) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:21:08,674 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:52:54 iter: 5640 loss: 1.7561 (1.8134) loss_classifier: 0.1368 (0.1563) loss_box_reg: 0.1283 (0.1507) loss_objectness: 0.0132 (0.0301) loss_rpn_box_reg: 0.0239 (0.0590) loss_da_image: 0.5565 (0.5740) loss_da_instance: 0.6834 (0.6828) loss_da_consistency: 0.0227 (0.0224) loss_classifier_mask: 0.1101 (0.1342) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0051 (0.0072) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6216 (1.6478) data: 0.3719 (0.3825) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:21:41,746 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:52:23 iter: 5660 loss: 1.7992 (1.8137) loss_classifier: 0.1446 (0.1564) loss_box_reg: 0.1346 (0.1506) loss_objectness: 0.0298 (0.0303) loss_rpn_box_reg: 0.0708 (0.0592) loss_da_image: 0.5847 (0.5741) loss_da_instance: 0.6841 (0.6828) loss_da_consistency: 0.0166 (0.0223) loss_classifier_mask: 0.1089 (0.1342) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0029 (0.0072) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6197 (1.6478) data: 0.3768 (0.3825) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:22:14,597 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:51:48 iter: 5680 loss: 1.7002 (1.8133) loss_classifier: 0.1239 (0.1562) loss_box_reg: 0.0949 (0.1505) loss_objectness: 0.0267 (0.0303) loss_rpn_box_reg: 0.0325 (0.0591) loss_da_image: 0.5793 (0.5741) loss_da_instance: 0.6841 (0.6828) loss_da_consistency: 0.0158 (0.0223) loss_classifier_mask: 0.1249 (0.1341) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0034 (0.0072) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6256 (1.6478) data: 0.3722 (0.3824) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:22:47,195 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:51:08 iter: 5700 loss: 1.7193 (1.8129) loss_classifier: 0.1264 (0.1561) loss_box_reg: 0.1096 (0.1503) loss_objectness: 0.0180 (0.0303) loss_rpn_box_reg: 0.0288 (0.0590) loss_da_image: 0.5862 (0.5742) loss_da_instance: 0.6836 (0.6828) loss_da_consistency: 0.0217 (0.0223) loss_classifier_mask: 0.1039 (0.1339) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0034 (0.0072) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6165 (1.6477) data: 0.3710 (0.3824) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:23:20,152 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:50:35 iter: 5720 loss: 1.7184 (1.8130) loss_classifier: 0.1264 (0.1561) loss_box_reg: 0.1149 (0.1503) loss_objectness: 0.0254 (0.0303) loss_rpn_box_reg: 0.0443 (0.0592) loss_da_image: 0.5560 (0.5742) loss_da_instance: 0.6855 (0.6828) loss_da_consistency: 0.0156 (0.0223) loss_classifier_mask: 0.1352 (0.1339) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0090 (0.0072) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6368 (1.6477) data: 0.3778 (0.3824) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:23:53,483 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:50:10 iter: 5740 loss: 1.7422 (1.8126) loss_classifier: 0.1284 (0.1560) loss_box_reg: 0.1071 (0.1502) loss_objectness: 0.0110 (0.0302) loss_rpn_box_reg: 0.0308 (0.0591) loss_da_image: 0.5692 (0.5742) loss_da_instance: 0.6839 (0.6828) loss_da_consistency: 0.0177 (0.0222) loss_classifier_mask: 0.1279 (0.1340) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0049 (0.0072) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6895 (1.6478) data: 0.3796 (0.3824) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:24:26,575 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:49:40 iter: 5760 loss: 1.7468 (1.8126) loss_classifier: 0.1458 (0.1560) loss_box_reg: 0.1422 (0.1502) loss_objectness: 0.0203 (0.0302) loss_rpn_box_reg: 0.0304 (0.0591) loss_da_image: 0.5858 (0.5743) loss_da_instance: 0.6788 (0.6828) loss_da_consistency: 0.0201 (0.0222) loss_classifier_mask: 0.1383 (0.1339) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0020 (0.0072) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6276 (1.6479) data: 0.3740 (0.3823) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:24:59,453 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:49:05 iter: 5780 loss: 1.7210 (1.8123) loss_classifier: 0.1494 (0.1559) loss_box_reg: 0.1402 (0.1501) loss_objectness: 0.0136 (0.0301) loss_rpn_box_reg: 0.0309 (0.0590) loss_da_image: 0.5592 (0.5742) loss_da_instance: 0.6820 (0.6828) loss_da_consistency: 0.0176 (0.0222) loss_classifier_mask: 0.1556 (0.1341) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0059 (0.0072) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6370 (1.6478) data: 0.3768 (0.3823) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:25:31,974 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:48:24 iter: 5800 loss: 1.7889 (1.8121) loss_classifier: 0.1333 (0.1558) loss_box_reg: 0.1451 (0.1499) loss_objectness: 0.0184 (0.0301) loss_rpn_box_reg: 0.0335 (0.0591) loss_da_image: 0.5869 (0.5742) loss_da_instance: 0.6835 (0.6828) loss_da_consistency: 0.0209 (0.0222) loss_classifier_mask: 0.1380 (0.1341) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0042 (0.0072) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6247 (1.6477) data: 0.3724 (0.3823) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:26:04,229 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:47:37 iter: 5820 loss: 1.8168 (1.8119) loss_classifier: 0.1496 (0.1557) loss_box_reg: 0.1379 (0.1498) loss_objectness: 0.0160 (0.0300) loss_rpn_box_reg: 0.0607 (0.0591) loss_da_image: 0.5884 (0.5743) loss_da_instance: 0.6826 (0.6828) loss_da_consistency: 0.0177 (0.0222) loss_classifier_mask: 0.1315 (0.1341) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0056 (0.0072) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6215 (1.6474) data: 0.3803 (0.3823) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:26:37,215 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:47:05 iter: 5840 loss: 1.7675 (1.8118) loss_classifier: 0.1433 (0.1557) loss_box_reg: 0.1366 (0.1497) loss_objectness: 0.0185 (0.0300) loss_rpn_box_reg: 0.0415 (0.0592) loss_da_image: 0.5823 (0.5743) loss_da_instance: 0.6836 (0.6828) loss_da_consistency: 0.0167 (0.0222) loss_classifier_mask: 0.1183 (0.1341) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0060 (0.0072) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6385 (1.6474) data: 0.3737 (0.3823) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:27:10,172 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:46:32 iter: 5860 loss: 1.8430 (1.8119) loss_classifier: 0.1435 (0.1557) loss_box_reg: 0.1616 (0.1497) loss_objectness: 0.0186 (0.0300) loss_rpn_box_reg: 0.0434 (0.0592) loss_da_image: 0.5772 (0.5744) loss_da_instance: 0.6805 (0.6828) loss_da_consistency: 0.0136 (0.0221) loss_classifier_mask: 0.1258 (0.1341) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0036 (0.0072) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6494 (1.6474) data: 0.3747 (0.3823) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:27:43,232 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:46:01 iter: 5880 loss: 1.7622 (1.8116) loss_classifier: 0.1185 (0.1556) loss_box_reg: 0.1138 (0.1496) loss_objectness: 0.0167 (0.0300) loss_rpn_box_reg: 0.0341 (0.0591) loss_da_image: 0.5810 (0.5745) loss_da_instance: 0.6856 (0.6829) loss_da_consistency: 0.0207 (0.0221) loss_classifier_mask: 0.1115 (0.1340) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0036 (0.0072) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6256 (1.6475) data: 0.3799 (0.3823) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:28:16,308 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:45:31 iter: 5900 loss: 1.8783 (1.8120) loss_classifier: 0.1717 (0.1558) loss_box_reg: 0.1532 (0.1497) loss_objectness: 0.0245 (0.0300) loss_rpn_box_reg: 0.0317 (0.0592) loss_da_image: 0.5781 (0.5746) loss_da_instance: 0.6831 (0.6829) loss_da_consistency: 0.0165 (0.0221) loss_classifier_mask: 0.1280 (0.1340) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0034 (0.0072) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6412 (1.6475) data: 0.3765 (0.3823) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:28:49,405 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:45:01 iter: 5920 loss: 1.7409 (1.8119) loss_classifier: 0.1021 (0.1556) loss_box_reg: 0.0992 (0.1495) loss_objectness: 0.0204 (0.0300) loss_rpn_box_reg: 0.0525 (0.0593) loss_da_image: 0.5839 (0.5747) loss_da_instance: 0.6815 (0.6828) loss_da_consistency: 0.0194 (0.0221) loss_classifier_mask: 0.1392 (0.1341) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0029 (0.0072) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6316 (1.6476) data: 0.3787 (0.3823) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:29:22,474 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:44:30 iter: 5940 loss: 1.8494 (1.8120) loss_classifier: 0.1575 (0.1557) loss_box_reg: 0.1399 (0.1495) loss_objectness: 0.0203 (0.0299) loss_rpn_box_reg: 0.0173 (0.0592) loss_da_image: 0.5799 (0.5747) loss_da_instance: 0.6807 (0.6828) loss_da_consistency: 0.0201 (0.0221) loss_classifier_mask: 0.1269 (0.1341) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0028 (0.0071) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6388 (1.6476) data: 0.3794 (0.3823) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:29:55,470 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:43:58 iter: 5960 loss: 1.8652 (1.8119) loss_classifier: 0.1493 (0.1557) loss_box_reg: 0.1562 (0.1494) loss_objectness: 0.0190 (0.0299) loss_rpn_box_reg: 0.0441 (0.0593) loss_da_image: 0.5798 (0.5747) loss_da_instance: 0.6784 (0.6828) loss_da_consistency: 0.0259 (0.0221) loss_classifier_mask: 0.1027 (0.1340) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0051 (0.0071) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6329 (1.6476) data: 0.3784 (0.3823) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:30:28,981 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:43:35 iter: 5980 loss: 1.7900 (1.8119) loss_classifier: 0.1427 (0.1557) loss_box_reg: 0.1079 (0.1493) loss_objectness: 0.0147 (0.0299) loss_rpn_box_reg: 0.0497 (0.0594) loss_da_image: 0.5722 (0.5747) loss_da_instance: 0.6764 (0.6828) loss_da_consistency: 0.0208 (0.0221) loss_classifier_mask: 0.1483 (0.1341) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0042 (0.0071) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6802 (1.6478) data: 0.3819 (0.3823) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:31:02,006 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:43:03 iter: 6000 loss: 1.7619 (1.8118) loss_classifier: 0.1492 (0.1557) loss_box_reg: 0.1371 (0.1493) loss_objectness: 0.0235 (0.0300) loss_rpn_box_reg: 0.0296 (0.0594) loss_da_image: 0.5879 (0.5748) loss_da_instance: 0.6801 (0.6828) loss_da_consistency: 0.0156 (0.0221) loss_classifier_mask: 0.1107 (0.1339) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0046 (0.0071) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6303 (1.6478) data: 0.3770 (0.3823) lr: 0.001000 max mem: 6765\n",
            "2023-02-04 17:31:02,010 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /content/drive/MyDrive/AI/mic/model_0006000.pth\n",
            "2023-02-04 17:31:36,586 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:42:59 iter: 6020 loss: 1.6621 (1.8114) loss_classifier: 0.1171 (0.1555) loss_box_reg: 0.1076 (0.1491) loss_objectness: 0.0193 (0.0299) loss_rpn_box_reg: 0.0263 (0.0594) loss_da_image: 0.5737 (0.5749) loss_da_instance: 0.6800 (0.6828) loss_da_consistency: 0.0196 (0.0221) loss_classifier_mask: 0.1217 (0.1339) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0025 (0.0071) loss_rpn_box_reg_mask: 0.0000 (0.0000) time: 1.6513 (1.6484) data: 0.3827 (0.3829) lr: 0.001000 max mem: 6765\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f23c8161e50>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 1445, in _shutdown_workers\n",
            "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 149, in join\n",
            "    res = self._popen.wait(timeout)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/popen_fork.py\", line 44, in wait\n",
            "    if not wait([self.sentinel], timeout):\n",
            "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 931, in wait\n",
            "    ready = selector.select(timeout)\n",
            "  File \"/usr/lib/python3.8/selectors.py\", line 415, in select\n",
            "    fd_event_list = self._selector.poll(timeout)\n",
            "KeyboardInterrupt: \n",
            "Traceback (most recent call last):\n",
            "  File \"tools/train_net.py\", line 270, in <module>\n",
            "    main()\n",
            "  File \"tools/train_net.py\", line 263, in main\n",
            "    model = train(cfg, args.local_rank, args.distributed)\n",
            "  File \"tools/train_net.py\", line 114, in train\n",
            "    do_mask_da_train(\n",
            "  File \"/content/MIC/det/maskrcnn_benchmark/engine/trainer.py\", line 225, in do_mask_da_train\n",
            "    for iteration, ((source_images, source_targets, idx1), (target_images, target_targets, idx2)) in enumerate(zip(source_data_loader, target_data_loader), start_iter):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 652, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 1330, in _next_data\n",
            "    idx, data = self._get_data()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 1296, in _get_data\n",
            "    success, data = self._try_get_data()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 1134, in _try_get_data\n",
            "    data = self._data_queue.get(timeout=timeout)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 116, in get\n",
            "    return _ForkingPickler.loads(res)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/reductions.py\", line 297, in rebuild_storage_fd\n",
            "    fd = df.detach()\n",
            "  File \"/usr/lib/python3.8/multiprocessing/resource_sharer.py\", line 57, in detach\n",
            "    with _resource_sharer.get_connection(self._id) as conn:\n",
            "  File \"/usr/lib/python3.8/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
            "    c = Client(address, authkey=process.current_process().authkey)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 502, in Client\n",
            "    c = SocketClient(address)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 630, in SocketClient\n",
            "    s.connect(address)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/train_net.py --config-file /content/sample_data/content/MIC/det/configs/da_faster_rcnn/fff.yaml\n"
      ],
      "metadata": {
        "id": "tBWY-afk034w",
        "outputId": "4a7867cc-f2a4-48ab-9b69-ac3b7b37ab98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-03 13:28:47,742 maskrcnn_benchmark INFO: Using 1 GPUs\n",
            "2023-02-03 13:28:47,742 maskrcnn_benchmark INFO: Namespace(config_file='/content/sample_data/content/MIC/det/configs/da_faster_rcnn/fff.yaml', deterministic=False, distributed=False, local_rank=0, opts=[], seed=1, skip_test=False)\n",
            "2023-02-03 13:28:47,742 maskrcnn_benchmark INFO: Collecting env info (might take some time)\n",
            "2023-02-03 13:28:49,324 maskrcnn_benchmark INFO: \n",
            "PyTorch version: 1.12.0+cu113\n",
            "Is debug build: False\n",
            "CUDA used to build PyTorch: 11.3\n",
            "ROCM used to build PyTorch: N/A\n",
            "\n",
            "OS: Ubuntu 20.04.5 LTS (x86_64)\n",
            "GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n",
            "Clang version: 10.0.0-4ubuntu1 \n",
            "CMake version: version 3.22.6\n",
            "Libc version: glibc-2.31\n",
            "\n",
            "Python version: 3.8.10 (default, Nov 14 2022, 12:59:47)  [GCC 9.4.0] (64-bit runtime)\n",
            "Python platform: Linux-5.10.147+-x86_64-with-glibc2.29\n",
            "Is CUDA available: True\n",
            "CUDA runtime version: 11.2.152\n",
            "GPU models and configuration: GPU 0: Tesla T4\n",
            "Nvidia driver version: 510.47.03\n",
            "cuDNN version: Probably one of the following:\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.1.1\n",
            "HIP runtime version: N/A\n",
            "MIOpen runtime version: N/A\n",
            "Is XNNPACK available: True\n",
            "\n",
            "Versions of relevant libraries:\n",
            "[pip3] numpy==1.21.6\n",
            "[pip3] torch==1.12.0+cu113\n",
            "[pip3] torchaudio==0.12.0+cu113\n",
            "[pip3] torchsummary==1.5.1\n",
            "[pip3] torchtext==0.14.1\n",
            "[pip3] torchvision==0.13.0+cu113\n",
            "[conda] Could not collect\n",
            "        Pillow (7.1.2)\n",
            "2023-02-03 13:28:49,325 maskrcnn_benchmark INFO: Loaded configuration file /content/sample_data/content/MIC/det/configs/da_faster_rcnn/fff.yaml\n",
            "2023-02-03 13:28:49,325 maskrcnn_benchmark INFO: \n",
            "MODEL:\n",
            "  META_ARCHITECTURE: \"GeneralizedRCNN\"\n",
            "  WEIGHT: \"catalog://ImageNetPretrained/MSRA/R-50\"\n",
            "  DOMAIN_ADAPTATION_ON: True\n",
            "  BACKBONE:\n",
            "    CONV_BODY: \"R-50-FPN\"\n",
            "    OUT_CHANNELS: 256\n",
            "  RPN:\n",
            "    USE_FPN: True\n",
            "    ANCHOR_STRIDE: (4, 8, 16, 32, 64)\n",
            "    PRE_NMS_TOP_N_TRAIN: 2000\n",
            "    PRE_NMS_TOP_N_TEST: 1000\n",
            "    POST_NMS_TOP_N_TEST: 1000\n",
            "    FPN_POST_NMS_TOP_N_TEST: 1000\n",
            "  ROI_HEADS:\n",
            "    USE_FPN: True\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "  ROI_BOX_HEAD:\n",
            "    NUM_CLASSES: 2\n",
            "    POOLER_RESOLUTION: 7\n",
            "    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n",
            "    POOLER_SAMPLING_RATIO: 2\n",
            "    FEATURE_EXTRACTOR: \"FPN2MLPFeatureExtractor\"\n",
            "    PREDICTOR: \"FPNPredictor\"\n",
            "  DA_HEADS:\n",
            "    DA_IMG_GRL_WEIGHT: 0.01\n",
            "    DA_INS_GRL_WEIGHT: 0.1\n",
            "    COS_WEIGHT: 0.1\n",
            "  MIC_ON: True\n",
            "  MASKING_AUGMENTATION: True\n",
            "  PSEUDO_LABEL_THRESHOLD: 0.8\n",
            "  PSEUDO_LABEL_LAMBDA: 1.0\n",
            "  PSEUDO_LABEL_WEIGHT: 'prob'\n",
            "  MASKING_BLOCK_SIZE: 32\n",
            "  MASKING_RATIO: 0.5\n",
            "  TEACHER_ALPHA: 0.9\n",
            "DATASETS:\n",
            "  SOURCE_TRAIN: (\"sim10k_cocostyle\",) #(\"cityscapes_fine_instanceonly_seg_train_cocostyle\",)\n",
            "  TARGET_TRAIN: (\"cityscapes_only_car_train_cocostyle\",) #(\"foggy_cityscapes_fine_instanceonly_seg_train_cocostyle\",)\n",
            "  TEST: (\"cityscapes_only_car_val_cocostyle\",) #(\"foggy_cityscapes_fine_instanceonly_seg_val_cocostyle\",)\n",
            "INPUT:\n",
            "  MIN_SIZE_TRAIN: (800,)\n",
            "  MAX_SIZE_TRAIN: 1600\n",
            "  MIN_SIZE_TEST: 800\n",
            "  MAX_SIZE_TEST: 1600\n",
            "DATALOADER:\n",
            "  SIZE_DIVISIBILITY: 32\n",
            "SOLVER:\n",
            "  CHECKPOINT_PERIOD: 1000\n",
            "  WARMUP_ITERS: 1000\n",
            "  BASE_LR: 0.001\n",
            "  WEIGHT_DECAY: 0.0001\n",
            "  STEPS: (30000, 40000)\n",
            "  MAX_ITER: 60000\n",
            "  IMS_PER_BATCH: 2\n",
            "TEST:\n",
            "  IMS_PER_BATCH: 1\n",
            "\n",
            "2023-02-03 13:28:49,325 maskrcnn_benchmark INFO: Running with config:\n",
            "DATALOADER:\n",
            "  ASPECT_RATIO_GROUPING: True\n",
            "  NUM_WORKERS: 4\n",
            "  SIZE_DIVISIBILITY: 32\n",
            "DATASETS:\n",
            "  SOURCE_TRAIN: ('sim10k_cocostyle',)\n",
            "  TARGET_TRAIN: ('cityscapes_only_car_train_cocostyle',)\n",
            "  TEST: ('cityscapes_only_car_val_cocostyle',)\n",
            "  TRAIN: ()\n",
            "INPUT:\n",
            "  MAX_SIZE_TEST: 1600\n",
            "  MAX_SIZE_TRAIN: 1600\n",
            "  MIN_SIZE_TEST: 800\n",
            "  MIN_SIZE_TRAIN: (800,)\n",
            "  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]\n",
            "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
            "  TO_BGR255: True\n",
            "MODEL:\n",
            "  BACKBONE:\n",
            "    CONV_BODY: R-50-FPN\n",
            "    FREEZE_CONV_BODY_AT: 2\n",
            "    OUT_CHANNELS: 256\n",
            "    USE_GN: False\n",
            "  CLS_AGNOSTIC_BBOX_REG: False\n",
            "  DA_HEADS:\n",
            "    COS_WEIGHT: 0.1\n",
            "    DA_IMG_GRL_WEIGHT: 0.01\n",
            "    DA_INS_GRL_WEIGHT: 0.1\n",
            "  DEVICE: cuda\n",
            "  DOMAIN_ADAPTATION_ON: True\n",
            "  FPN:\n",
            "    USE_GN: False\n",
            "    USE_RELU: False\n",
            "  GROUP_NORM:\n",
            "    DIM_PER_GP: -1\n",
            "    EPSILON: 1e-05\n",
            "    NUM_GROUPS: 32\n",
            "  KEYPOINT_ON: False\n",
            "  MASKING_AUGMENTATION: True\n",
            "  MASKING_BLOCK_SIZE: 32\n",
            "  MASKING_RATIO: 0.5\n",
            "  MASK_ON: False\n",
            "  META_ARCHITECTURE: GeneralizedRCNN\n",
            "  MIC_ON: True\n",
            "  PSEUDO_LABEL_LAMBDA: 1.0\n",
            "  PSEUDO_LABEL_THRESHOLD: 0.8\n",
            "  PSEUDO_LABEL_WEIGHT: prob\n",
            "  RESNETS:\n",
            "    NUM_GROUPS: 1\n",
            "    RES2_OUT_CHANNELS: 256\n",
            "    RES5_DILATION: 1\n",
            "    STEM_FUNC: StemWithFixedBatchNorm\n",
            "    STEM_OUT_CHANNELS: 64\n",
            "    STRIDE_IN_1X1: True\n",
            "    TRANS_FUNC: BottleneckWithFixedBatchNorm\n",
            "    WIDTH_PER_GROUP: 64\n",
            "  RETINANET:\n",
            "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
            "    ANCHOR_STRIDES: (8, 16, 32, 64, 128)\n",
            "    ASPECT_RATIOS: (0.5, 1.0, 2.0)\n",
            "    BBOX_REG_BETA: 0.11\n",
            "    BBOX_REG_WEIGHT: 4.0\n",
            "    BG_IOU_THRESHOLD: 0.4\n",
            "    FG_IOU_THRESHOLD: 0.5\n",
            "    INFERENCE_TH: 0.05\n",
            "    LOSS_ALPHA: 0.25\n",
            "    LOSS_GAMMA: 2.0\n",
            "    NMS_TH: 0.4\n",
            "    NUM_CLASSES: 81\n",
            "    NUM_CONVS: 4\n",
            "    OCTAVE: 2.0\n",
            "    PRE_NMS_TOP_N: 1000\n",
            "    PRIOR_PROB: 0.01\n",
            "    SCALES_PER_OCTAVE: 3\n",
            "    STRADDLE_THRESH: 0\n",
            "    USE_C5: True\n",
            "  RETINANET_ON: False\n",
            "  ROI_BOX_HEAD:\n",
            "    CONV_HEAD_DIM: 256\n",
            "    DILATION: 1\n",
            "    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n",
            "    MLP_HEAD_DIM: 1024\n",
            "    NUM_CLASSES: 2\n",
            "    NUM_STACKED_CONVS: 4\n",
            "    POOLER_RESOLUTION: 7\n",
            "    POOLER_SAMPLING_RATIO: 2\n",
            "    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n",
            "    PREDICTOR: FPNPredictor\n",
            "    USE_GN: False\n",
            "  ROI_HEADS:\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
            "    BG_IOU_THRESHOLD: 0.5\n",
            "    DETECTIONS_PER_IMG: 100\n",
            "    FG_IOU_THRESHOLD: 0.5\n",
            "    NMS: 0.5\n",
            "    POSITIVE_FRACTION: 0.25\n",
            "    SCORE_THRESH: 0.05\n",
            "    USE_FPN: True\n",
            "  ROI_KEYPOINT_HEAD:\n",
            "    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
            "    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor\n",
            "    MLP_HEAD_DIM: 1024\n",
            "    NUM_CLASSES: 17\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_SCALES: (0.0625,)\n",
            "    PREDICTOR: KeypointRCNNPredictor\n",
            "    RESOLUTION: 14\n",
            "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
            "  ROI_MASK_HEAD:\n",
            "    CONV_LAYERS: (256, 256, 256, 256)\n",
            "    DILATION: 1\n",
            "    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor\n",
            "    MLP_HEAD_DIM: 1024\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_SCALES: (0.0625,)\n",
            "    POSTPROCESS_MASKS: False\n",
            "    POSTPROCESS_MASKS_THRESHOLD: 0.5\n",
            "    PREDICTOR: MaskRCNNC4Predictor\n",
            "    RESOLUTION: 14\n",
            "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
            "    USE_GN: False\n",
            "  RPN:\n",
            "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
            "    ANCHOR_STRIDE: (4, 8, 16, 32, 64)\n",
            "    ASPECT_RATIOS: (0.5, 1.0, 2.0)\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "    BG_IOU_THRESHOLD: 0.3\n",
            "    FG_IOU_THRESHOLD: 0.7\n",
            "    FPN_POST_NMS_TOP_N_TEST: 1000\n",
            "    FPN_POST_NMS_TOP_N_TRAIN: 2000\n",
            "    MIN_SIZE: 0\n",
            "    NMS_THRESH: 0.7\n",
            "    POSITIVE_FRACTION: 0.5\n",
            "    POST_NMS_TOP_N_TEST: 1000\n",
            "    POST_NMS_TOP_N_TRAIN: 2000\n",
            "    PRE_NMS_TOP_N_TEST: 1000\n",
            "    PRE_NMS_TOP_N_TRAIN: 2000\n",
            "    RPN_HEAD: SingleConvRPNHead\n",
            "    STRADDLE_THRESH: 0\n",
            "    USE_FPN: True\n",
            "  RPN_ONLY: False\n",
            "  TEACHER_ALPHA: 0.9\n",
            "  WEIGHT: catalog://ImageNetPretrained/MSRA/R-50\n",
            "OUTPUT_DIR: .\n",
            "PATHS_CATALOG: /content/MIC/det/maskrcnn_benchmark/config/paths_catalog.py\n",
            "SOLVER:\n",
            "  BASE_LR: 0.001\n",
            "  BIAS_LR_FACTOR: 2\n",
            "  CHECKPOINT_PERIOD: 1000\n",
            "  GAMMA: 0.1\n",
            "  IMS_PER_BATCH: 2\n",
            "  MAX_ITER: 60000\n",
            "  MOMENTUM: 0.9\n",
            "  STEPS: (30000, 40000)\n",
            "  WARMUP_FACTOR: 0.3333333333333333\n",
            "  WARMUP_ITERS: 1000\n",
            "  WARMUP_METHOD: linear\n",
            "  WEIGHT_DECAY: 0.0001\n",
            "  WEIGHT_DECAY_BIAS: 0\n",
            "TEST:\n",
            "  DETECTIONS_PER_IMG: 100\n",
            "  EXPECTED_RESULTS: []\n",
            "  EXPECTED_RESULTS_SIGMA_TOL: 4\n",
            "  IMS_PER_BATCH: 1\n",
            "2023-02-03 13:28:49,326 maskrcnn_benchmark INFO: Set random seed to 1, deterministic: False\n",
            "2023-02-03 13:28:52,003 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from catalog://ImageNetPretrained/MSRA/R-50\n",
            "2023-02-03 13:28:52,004 maskrcnn_benchmark.utils.checkpoint INFO: catalog://ImageNetPretrained/MSRA/R-50 points to https://dl.fbaipublicfiles.com/detectron/ImageNetPretrained/MSRA/R-50.pkl\n",
            "2023-02-03 13:28:52,004 maskrcnn_benchmark.utils.checkpoint INFO: url https://dl.fbaipublicfiles.com/detectron/ImageNetPretrained/MSRA/R-50.pkl cached in /root/.torch/models/R-50.pkl\n",
            "2023-02-03 13:28:52,065 maskrcnn_benchmark.utils.c2_model_loading INFO: Remapping C2 weights\n",
            "2023-02-03 13:28:52,065 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: conv1_b              mapped name: conv1.bias\n",
            "2023-02-03 13:28:52,065 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: conv1_w              mapped name: conv1.weight\n",
            "2023-02-03 13:28:52,065 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: fc1000_b             mapped name: fc1000.bias\n",
            "2023-02-03 13:28:52,065 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: fc1000_w             mapped name: fc1000.weight\n",
            "2023-02-03 13:28:52,066 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch1_b     mapped name: layer1.0.downsample.0.bias\n",
            "2023-02-03 13:28:52,066 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch1_bn_b  mapped name: layer1.0.downsample.1.bias\n",
            "2023-02-03 13:28:52,066 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch1_bn_s  mapped name: layer1.0.downsample.1.weight\n",
            "2023-02-03 13:28:52,066 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch1_w     mapped name: layer1.0.downsample.0.weight\n",
            "2023-02-03 13:28:52,066 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_b    mapped name: layer1.0.conv1.bias\n",
            "2023-02-03 13:28:52,066 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_bn_b mapped name: layer1.0.bn1.bias\n",
            "2023-02-03 13:28:52,066 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_bn_s mapped name: layer1.0.bn1.weight\n",
            "2023-02-03 13:28:52,066 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_w    mapped name: layer1.0.conv1.weight\n",
            "2023-02-03 13:28:52,066 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_b    mapped name: layer1.0.conv2.bias\n",
            "2023-02-03 13:28:52,066 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_bn_b mapped name: layer1.0.bn2.bias\n",
            "2023-02-03 13:28:52,066 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_bn_s mapped name: layer1.0.bn2.weight\n",
            "2023-02-03 13:28:52,066 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_w    mapped name: layer1.0.conv2.weight\n",
            "2023-02-03 13:28:52,066 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_b    mapped name: layer1.0.conv3.bias\n",
            "2023-02-03 13:28:52,066 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_bn_b mapped name: layer1.0.bn3.bias\n",
            "2023-02-03 13:28:52,067 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_bn_s mapped name: layer1.0.bn3.weight\n",
            "2023-02-03 13:28:52,067 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_w    mapped name: layer1.0.conv3.weight\n",
            "2023-02-03 13:28:52,067 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_b    mapped name: layer1.1.conv1.bias\n",
            "2023-02-03 13:28:52,067 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_bn_b mapped name: layer1.1.bn1.bias\n",
            "2023-02-03 13:28:52,067 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_bn_s mapped name: layer1.1.bn1.weight\n",
            "2023-02-03 13:28:52,067 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_w    mapped name: layer1.1.conv1.weight\n",
            "2023-02-03 13:28:52,067 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_b    mapped name: layer1.1.conv2.bias\n",
            "2023-02-03 13:28:52,067 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_bn_b mapped name: layer1.1.bn2.bias\n",
            "2023-02-03 13:28:52,067 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_bn_s mapped name: layer1.1.bn2.weight\n",
            "2023-02-03 13:28:52,067 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_w    mapped name: layer1.1.conv2.weight\n",
            "2023-02-03 13:28:52,067 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_b    mapped name: layer1.1.conv3.bias\n",
            "2023-02-03 13:28:52,067 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_bn_b mapped name: layer1.1.bn3.bias\n",
            "2023-02-03 13:28:52,067 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_bn_s mapped name: layer1.1.bn3.weight\n",
            "2023-02-03 13:28:52,067 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_w    mapped name: layer1.1.conv3.weight\n",
            "2023-02-03 13:28:52,067 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_b    mapped name: layer1.2.conv1.bias\n",
            "2023-02-03 13:28:52,068 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_bn_b mapped name: layer1.2.bn1.bias\n",
            "2023-02-03 13:28:52,068 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_bn_s mapped name: layer1.2.bn1.weight\n",
            "2023-02-03 13:28:52,068 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_w    mapped name: layer1.2.conv1.weight\n",
            "2023-02-03 13:28:52,068 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_b    mapped name: layer1.2.conv2.bias\n",
            "2023-02-03 13:28:52,068 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_bn_b mapped name: layer1.2.bn2.bias\n",
            "2023-02-03 13:28:52,068 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_bn_s mapped name: layer1.2.bn2.weight\n",
            "2023-02-03 13:28:52,068 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_w    mapped name: layer1.2.conv2.weight\n",
            "2023-02-03 13:28:52,068 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_b    mapped name: layer1.2.conv3.bias\n",
            "2023-02-03 13:28:52,068 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_bn_b mapped name: layer1.2.bn3.bias\n",
            "2023-02-03 13:28:52,068 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_bn_s mapped name: layer1.2.bn3.weight\n",
            "2023-02-03 13:28:52,068 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_w    mapped name: layer1.2.conv3.weight\n",
            "2023-02-03 13:28:52,068 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch1_b     mapped name: layer2.0.downsample.0.bias\n",
            "2023-02-03 13:28:52,068 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch1_bn_b  mapped name: layer2.0.downsample.1.bias\n",
            "2023-02-03 13:28:52,068 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch1_bn_s  mapped name: layer2.0.downsample.1.weight\n",
            "2023-02-03 13:28:52,068 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch1_w     mapped name: layer2.0.downsample.0.weight\n",
            "2023-02-03 13:28:52,068 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_b    mapped name: layer2.0.conv1.bias\n",
            "2023-02-03 13:28:52,069 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_bn_b mapped name: layer2.0.bn1.bias\n",
            "2023-02-03 13:28:52,069 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_bn_s mapped name: layer2.0.bn1.weight\n",
            "2023-02-03 13:28:52,069 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_w    mapped name: layer2.0.conv1.weight\n",
            "2023-02-03 13:28:52,069 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_b    mapped name: layer2.0.conv2.bias\n",
            "2023-02-03 13:28:52,069 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_bn_b mapped name: layer2.0.bn2.bias\n",
            "2023-02-03 13:28:52,069 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_bn_s mapped name: layer2.0.bn2.weight\n",
            "2023-02-03 13:28:52,069 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_w    mapped name: layer2.0.conv2.weight\n",
            "2023-02-03 13:28:52,069 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_b    mapped name: layer2.0.conv3.bias\n",
            "2023-02-03 13:28:52,069 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_bn_b mapped name: layer2.0.bn3.bias\n",
            "2023-02-03 13:28:52,069 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_bn_s mapped name: layer2.0.bn3.weight\n",
            "2023-02-03 13:28:52,069 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_w    mapped name: layer2.0.conv3.weight\n",
            "2023-02-03 13:28:52,069 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_b    mapped name: layer2.1.conv1.bias\n",
            "2023-02-03 13:28:52,069 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_bn_b mapped name: layer2.1.bn1.bias\n",
            "2023-02-03 13:28:52,069 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_bn_s mapped name: layer2.1.bn1.weight\n",
            "2023-02-03 13:28:52,069 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_w    mapped name: layer2.1.conv1.weight\n",
            "2023-02-03 13:28:52,069 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_b    mapped name: layer2.1.conv2.bias\n",
            "2023-02-03 13:28:52,070 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_bn_b mapped name: layer2.1.bn2.bias\n",
            "2023-02-03 13:28:52,070 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_bn_s mapped name: layer2.1.bn2.weight\n",
            "2023-02-03 13:28:52,070 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_w    mapped name: layer2.1.conv2.weight\n",
            "2023-02-03 13:28:52,070 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_b    mapped name: layer2.1.conv3.bias\n",
            "2023-02-03 13:28:52,070 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_bn_b mapped name: layer2.1.bn3.bias\n",
            "2023-02-03 13:28:52,070 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_bn_s mapped name: layer2.1.bn3.weight\n",
            "2023-02-03 13:28:52,070 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_w    mapped name: layer2.1.conv3.weight\n",
            "2023-02-03 13:28:52,070 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_b    mapped name: layer2.2.conv1.bias\n",
            "2023-02-03 13:28:52,070 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_bn_b mapped name: layer2.2.bn1.bias\n",
            "2023-02-03 13:28:52,070 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_bn_s mapped name: layer2.2.bn1.weight\n",
            "2023-02-03 13:28:52,070 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_w    mapped name: layer2.2.conv1.weight\n",
            "2023-02-03 13:28:52,070 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_b    mapped name: layer2.2.conv2.bias\n",
            "2023-02-03 13:28:52,070 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_bn_b mapped name: layer2.2.bn2.bias\n",
            "2023-02-03 13:28:52,070 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_bn_s mapped name: layer2.2.bn2.weight\n",
            "2023-02-03 13:28:52,070 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_w    mapped name: layer2.2.conv2.weight\n",
            "2023-02-03 13:28:52,070 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_b    mapped name: layer2.2.conv3.bias\n",
            "2023-02-03 13:28:52,071 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_bn_b mapped name: layer2.2.bn3.bias\n",
            "2023-02-03 13:28:52,071 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_bn_s mapped name: layer2.2.bn3.weight\n",
            "2023-02-03 13:28:52,071 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_w    mapped name: layer2.2.conv3.weight\n",
            "2023-02-03 13:28:52,071 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_b    mapped name: layer2.3.conv1.bias\n",
            "2023-02-03 13:28:52,071 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_bn_b mapped name: layer2.3.bn1.bias\n",
            "2023-02-03 13:28:52,071 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_bn_s mapped name: layer2.3.bn1.weight\n",
            "2023-02-03 13:28:52,071 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_w    mapped name: layer2.3.conv1.weight\n",
            "2023-02-03 13:28:52,071 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_b    mapped name: layer2.3.conv2.bias\n",
            "2023-02-03 13:28:52,071 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_bn_b mapped name: layer2.3.bn2.bias\n",
            "2023-02-03 13:28:52,071 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_bn_s mapped name: layer2.3.bn2.weight\n",
            "2023-02-03 13:28:52,071 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_w    mapped name: layer2.3.conv2.weight\n",
            "2023-02-03 13:28:52,071 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_b    mapped name: layer2.3.conv3.bias\n",
            "2023-02-03 13:28:52,071 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_bn_b mapped name: layer2.3.bn3.bias\n",
            "2023-02-03 13:28:52,071 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_bn_s mapped name: layer2.3.bn3.weight\n",
            "2023-02-03 13:28:52,071 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_w    mapped name: layer2.3.conv3.weight\n",
            "2023-02-03 13:28:52,072 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch1_b     mapped name: layer3.0.downsample.0.bias\n",
            "2023-02-03 13:28:52,072 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch1_bn_b  mapped name: layer3.0.downsample.1.bias\n",
            "2023-02-03 13:28:52,072 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch1_bn_s  mapped name: layer3.0.downsample.1.weight\n",
            "2023-02-03 13:28:52,072 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch1_w     mapped name: layer3.0.downsample.0.weight\n",
            "2023-02-03 13:28:52,072 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_b    mapped name: layer3.0.conv1.bias\n",
            "2023-02-03 13:28:52,072 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_bn_b mapped name: layer3.0.bn1.bias\n",
            "2023-02-03 13:28:52,072 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_bn_s mapped name: layer3.0.bn1.weight\n",
            "2023-02-03 13:28:52,072 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_w    mapped name: layer3.0.conv1.weight\n",
            "2023-02-03 13:28:52,072 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_b    mapped name: layer3.0.conv2.bias\n",
            "2023-02-03 13:28:52,072 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_bn_b mapped name: layer3.0.bn2.bias\n",
            "2023-02-03 13:28:52,072 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_bn_s mapped name: layer3.0.bn2.weight\n",
            "2023-02-03 13:28:52,072 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_w    mapped name: layer3.0.conv2.weight\n",
            "2023-02-03 13:28:52,072 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_b    mapped name: layer3.0.conv3.bias\n",
            "2023-02-03 13:28:52,072 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_bn_b mapped name: layer3.0.bn3.bias\n",
            "2023-02-03 13:28:52,072 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_bn_s mapped name: layer3.0.bn3.weight\n",
            "2023-02-03 13:28:52,073 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_w    mapped name: layer3.0.conv3.weight\n",
            "2023-02-03 13:28:52,073 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_b    mapped name: layer3.1.conv1.bias\n",
            "2023-02-03 13:28:52,073 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_bn_b mapped name: layer3.1.bn1.bias\n",
            "2023-02-03 13:28:52,073 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_bn_s mapped name: layer3.1.bn1.weight\n",
            "2023-02-03 13:28:52,073 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_w    mapped name: layer3.1.conv1.weight\n",
            "2023-02-03 13:28:52,073 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_b    mapped name: layer3.1.conv2.bias\n",
            "2023-02-03 13:28:52,073 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_bn_b mapped name: layer3.1.bn2.bias\n",
            "2023-02-03 13:28:52,073 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_bn_s mapped name: layer3.1.bn2.weight\n",
            "2023-02-03 13:28:52,073 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_w    mapped name: layer3.1.conv2.weight\n",
            "2023-02-03 13:28:52,073 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_b    mapped name: layer3.1.conv3.bias\n",
            "2023-02-03 13:28:52,073 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_bn_b mapped name: layer3.1.bn3.bias\n",
            "2023-02-03 13:28:52,073 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_bn_s mapped name: layer3.1.bn3.weight\n",
            "2023-02-03 13:28:52,151 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_w    mapped name: layer3.1.conv3.weight\n",
            "2023-02-03 13:28:52,152 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_b    mapped name: layer3.2.conv1.bias\n",
            "2023-02-03 13:28:52,152 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_bn_b mapped name: layer3.2.bn1.bias\n",
            "2023-02-03 13:28:52,152 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_bn_s mapped name: layer3.2.bn1.weight\n",
            "2023-02-03 13:28:52,152 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_w    mapped name: layer3.2.conv1.weight\n",
            "2023-02-03 13:28:52,152 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_b    mapped name: layer3.2.conv2.bias\n",
            "2023-02-03 13:28:52,152 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_bn_b mapped name: layer3.2.bn2.bias\n",
            "2023-02-03 13:28:52,152 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_bn_s mapped name: layer3.2.bn2.weight\n",
            "2023-02-03 13:28:52,152 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_w    mapped name: layer3.2.conv2.weight\n",
            "2023-02-03 13:28:52,152 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_b    mapped name: layer3.2.conv3.bias\n",
            "2023-02-03 13:28:52,152 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_bn_b mapped name: layer3.2.bn3.bias\n",
            "2023-02-03 13:28:52,152 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_bn_s mapped name: layer3.2.bn3.weight\n",
            "2023-02-03 13:28:52,152 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_w    mapped name: layer3.2.conv3.weight\n",
            "2023-02-03 13:28:52,153 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_b    mapped name: layer3.3.conv1.bias\n",
            "2023-02-03 13:28:52,153 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_bn_b mapped name: layer3.3.bn1.bias\n",
            "2023-02-03 13:28:52,153 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_bn_s mapped name: layer3.3.bn1.weight\n",
            "2023-02-03 13:28:52,153 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_w    mapped name: layer3.3.conv1.weight\n",
            "2023-02-03 13:28:52,153 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_b    mapped name: layer3.3.conv2.bias\n",
            "2023-02-03 13:28:52,153 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_bn_b mapped name: layer3.3.bn2.bias\n",
            "2023-02-03 13:28:52,153 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_bn_s mapped name: layer3.3.bn2.weight\n",
            "2023-02-03 13:28:52,153 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_w    mapped name: layer3.3.conv2.weight\n",
            "2023-02-03 13:28:52,153 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_b    mapped name: layer3.3.conv3.bias\n",
            "2023-02-03 13:28:52,153 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_bn_b mapped name: layer3.3.bn3.bias\n",
            "2023-02-03 13:28:52,153 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_bn_s mapped name: layer3.3.bn3.weight\n",
            "2023-02-03 13:28:52,153 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_w    mapped name: layer3.3.conv3.weight\n",
            "2023-02-03 13:28:52,153 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_b    mapped name: layer3.4.conv1.bias\n",
            "2023-02-03 13:28:52,154 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_bn_b mapped name: layer3.4.bn1.bias\n",
            "2023-02-03 13:28:52,154 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_bn_s mapped name: layer3.4.bn1.weight\n",
            "2023-02-03 13:28:52,154 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_w    mapped name: layer3.4.conv1.weight\n",
            "2023-02-03 13:28:52,154 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_b    mapped name: layer3.4.conv2.bias\n",
            "2023-02-03 13:28:52,154 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_bn_b mapped name: layer3.4.bn2.bias\n",
            "2023-02-03 13:28:52,154 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_bn_s mapped name: layer3.4.bn2.weight\n",
            "2023-02-03 13:28:52,154 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_w    mapped name: layer3.4.conv2.weight\n",
            "2023-02-03 13:28:52,154 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_b    mapped name: layer3.4.conv3.bias\n",
            "2023-02-03 13:28:52,154 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_bn_b mapped name: layer3.4.bn3.bias\n",
            "2023-02-03 13:28:52,154 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_bn_s mapped name: layer3.4.bn3.weight\n",
            "2023-02-03 13:28:52,154 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_w    mapped name: layer3.4.conv3.weight\n",
            "2023-02-03 13:28:52,154 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_b    mapped name: layer3.5.conv1.bias\n",
            "2023-02-03 13:28:52,155 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_bn_b mapped name: layer3.5.bn1.bias\n",
            "2023-02-03 13:28:52,155 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_bn_s mapped name: layer3.5.bn1.weight\n",
            "2023-02-03 13:28:52,155 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_w    mapped name: layer3.5.conv1.weight\n",
            "2023-02-03 13:28:52,155 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_b    mapped name: layer3.5.conv2.bias\n",
            "2023-02-03 13:28:52,155 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_bn_b mapped name: layer3.5.bn2.bias\n",
            "2023-02-03 13:28:52,155 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_bn_s mapped name: layer3.5.bn2.weight\n",
            "2023-02-03 13:28:52,155 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_w    mapped name: layer3.5.conv2.weight\n",
            "2023-02-03 13:28:52,155 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_b    mapped name: layer3.5.conv3.bias\n",
            "2023-02-03 13:28:52,155 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_bn_b mapped name: layer3.5.bn3.bias\n",
            "2023-02-03 13:28:52,155 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_bn_s mapped name: layer3.5.bn3.weight\n",
            "2023-02-03 13:28:52,155 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_w    mapped name: layer3.5.conv3.weight\n",
            "2023-02-03 13:28:52,155 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch1_b     mapped name: layer4.0.downsample.0.bias\n",
            "2023-02-03 13:28:52,155 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch1_bn_b  mapped name: layer4.0.downsample.1.bias\n",
            "2023-02-03 13:28:52,156 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch1_bn_s  mapped name: layer4.0.downsample.1.weight\n",
            "2023-02-03 13:28:52,156 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch1_w     mapped name: layer4.0.downsample.0.weight\n",
            "2023-02-03 13:28:52,156 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_b    mapped name: layer4.0.conv1.bias\n",
            "2023-02-03 13:28:52,156 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_bn_b mapped name: layer4.0.bn1.bias\n",
            "2023-02-03 13:28:52,156 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_bn_s mapped name: layer4.0.bn1.weight\n",
            "2023-02-03 13:28:52,156 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_w    mapped name: layer4.0.conv1.weight\n",
            "2023-02-03 13:28:52,156 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_b    mapped name: layer4.0.conv2.bias\n",
            "2023-02-03 13:28:52,156 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_bn_b mapped name: layer4.0.bn2.bias\n",
            "2023-02-03 13:28:52,156 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_bn_s mapped name: layer4.0.bn2.weight\n",
            "2023-02-03 13:28:52,156 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_w    mapped name: layer4.0.conv2.weight\n",
            "2023-02-03 13:28:52,156 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_b    mapped name: layer4.0.conv3.bias\n",
            "2023-02-03 13:28:52,156 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_bn_b mapped name: layer4.0.bn3.bias\n",
            "2023-02-03 13:28:52,157 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_bn_s mapped name: layer4.0.bn3.weight\n",
            "2023-02-03 13:28:52,157 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_w    mapped name: layer4.0.conv3.weight\n",
            "2023-02-03 13:28:52,157 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_b    mapped name: layer4.1.conv1.bias\n",
            "2023-02-03 13:28:52,157 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_bn_b mapped name: layer4.1.bn1.bias\n",
            "2023-02-03 13:28:52,157 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_bn_s mapped name: layer4.1.bn1.weight\n",
            "2023-02-03 13:28:52,157 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_w    mapped name: layer4.1.conv1.weight\n",
            "2023-02-03 13:28:52,157 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_b    mapped name: layer4.1.conv2.bias\n",
            "2023-02-03 13:28:52,157 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_bn_b mapped name: layer4.1.bn2.bias\n",
            "2023-02-03 13:28:52,157 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_bn_s mapped name: layer4.1.bn2.weight\n",
            "2023-02-03 13:28:52,157 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_w    mapped name: layer4.1.conv2.weight\n",
            "2023-02-03 13:28:52,157 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_b    mapped name: layer4.1.conv3.bias\n",
            "2023-02-03 13:28:52,157 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_bn_b mapped name: layer4.1.bn3.bias\n",
            "2023-02-03 13:28:52,158 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_bn_s mapped name: layer4.1.bn3.weight\n",
            "2023-02-03 13:28:52,158 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_w    mapped name: layer4.1.conv3.weight\n",
            "2023-02-03 13:28:52,158 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_b    mapped name: layer4.2.conv1.bias\n",
            "2023-02-03 13:28:52,158 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_bn_b mapped name: layer4.2.bn1.bias\n",
            "2023-02-03 13:28:52,158 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_bn_s mapped name: layer4.2.bn1.weight\n",
            "2023-02-03 13:28:52,158 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_w    mapped name: layer4.2.conv1.weight\n",
            "2023-02-03 13:28:52,158 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_b    mapped name: layer4.2.conv2.bias\n",
            "2023-02-03 13:28:52,158 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_bn_b mapped name: layer4.2.bn2.bias\n",
            "2023-02-03 13:28:52,158 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_bn_s mapped name: layer4.2.bn2.weight\n",
            "2023-02-03 13:28:52,158 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_w    mapped name: layer4.2.conv2.weight\n",
            "2023-02-03 13:28:52,158 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_b    mapped name: layer4.2.conv3.bias\n",
            "2023-02-03 13:28:52,158 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_bn_b mapped name: layer4.2.bn3.bias\n",
            "2023-02-03 13:28:52,159 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_bn_s mapped name: layer4.2.bn3.weight\n",
            "2023-02-03 13:28:52,159 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_w    mapped name: layer4.2.conv3.weight\n",
            "2023-02-03 13:28:52,159 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res_conv1_bn_b       mapped name: bn1.bias\n",
            "2023-02-03 13:28:52,159 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res_conv1_bn_s       mapped name: bn1.weight\n",
            "2023-02-03 13:28:52,172 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.bias                  loaded from layer1.0.bn1.bias            of shape (64,)\n",
            "2023-02-03 13:28:52,172 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.weight                loaded from layer1.0.bn1.weight          of shape (64,)\n",
            "2023-02-03 13:28:52,172 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.bias                  loaded from layer1.0.bn2.bias            of shape (64,)\n",
            "2023-02-03 13:28:52,172 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.weight                loaded from layer1.0.bn2.weight          of shape (64,)\n",
            "2023-02-03 13:28:52,172 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.bias                  loaded from layer1.0.bn3.bias            of shape (256,)\n",
            "2023-02-03 13:28:52,172 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.weight                loaded from layer1.0.bn3.weight          of shape (256,)\n",
            "2023-02-03 13:28:52,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv1.weight              loaded from layer1.0.conv1.weight        of shape (64, 64, 1, 1)\n",
            "2023-02-03 13:28:52,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv2.weight              loaded from layer1.0.conv2.weight        of shape (64, 64, 3, 3)\n",
            "2023-02-03 13:28:52,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv3.weight              loaded from layer1.0.conv3.weight        of shape (256, 64, 1, 1)\n",
            "2023-02-03 13:28:52,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.0.weight       loaded from layer1.0.downsample.0.weight of shape (256, 64, 1, 1)\n",
            "2023-02-03 13:28:52,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.bias         loaded from layer1.0.downsample.1.bias   of shape (256,)\n",
            "2023-02-03 13:28:52,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.weight       loaded from layer1.0.downsample.1.weight of shape (256,)\n",
            "2023-02-03 13:28:52,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.bias                  loaded from layer1.1.bn1.bias            of shape (64,)\n",
            "2023-02-03 13:28:52,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.weight                loaded from layer1.1.bn1.weight          of shape (64,)\n",
            "2023-02-03 13:28:52,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.bias                  loaded from layer1.1.bn2.bias            of shape (64,)\n",
            "2023-02-03 13:28:52,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.weight                loaded from layer1.1.bn2.weight          of shape (64,)\n",
            "2023-02-03 13:28:52,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.bias                  loaded from layer1.1.bn3.bias            of shape (256,)\n",
            "2023-02-03 13:28:52,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.weight                loaded from layer1.1.bn3.weight          of shape (256,)\n",
            "2023-02-03 13:28:52,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv1.weight              loaded from layer1.1.conv1.weight        of shape (64, 256, 1, 1)\n",
            "2023-02-03 13:28:52,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv2.weight              loaded from layer1.1.conv2.weight        of shape (64, 64, 3, 3)\n",
            "2023-02-03 13:28:52,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv3.weight              loaded from layer1.1.conv3.weight        of shape (256, 64, 1, 1)\n",
            "2023-02-03 13:28:52,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.bias                  loaded from layer1.2.bn1.bias            of shape (64,)\n",
            "2023-02-03 13:28:52,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.weight                loaded from layer1.2.bn1.weight          of shape (64,)\n",
            "2023-02-03 13:28:52,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.bias                  loaded from layer1.2.bn2.bias            of shape (64,)\n",
            "2023-02-03 13:28:52,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.weight                loaded from layer1.2.bn2.weight          of shape (64,)\n",
            "2023-02-03 13:28:52,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.bias                  loaded from layer1.2.bn3.bias            of shape (256,)\n",
            "2023-02-03 13:28:52,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.weight                loaded from layer1.2.bn3.weight          of shape (256,)\n",
            "2023-02-03 13:28:52,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv1.weight              loaded from layer1.2.conv1.weight        of shape (64, 256, 1, 1)\n",
            "2023-02-03 13:28:52,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv2.weight              loaded from layer1.2.conv2.weight        of shape (64, 64, 3, 3)\n",
            "2023-02-03 13:28:52,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv3.weight              loaded from layer1.2.conv3.weight        of shape (256, 64, 1, 1)\n",
            "2023-02-03 13:28:52,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.bias                  loaded from layer2.0.bn1.bias            of shape (128,)\n",
            "2023-02-03 13:28:52,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.weight                loaded from layer2.0.bn1.weight          of shape (128,)\n",
            "2023-02-03 13:28:52,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.bias                  loaded from layer2.0.bn2.bias            of shape (128,)\n",
            "2023-02-03 13:28:52,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.weight                loaded from layer2.0.bn2.weight          of shape (128,)\n",
            "2023-02-03 13:28:52,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.bias                  loaded from layer2.0.bn3.bias            of shape (512,)\n",
            "2023-02-03 13:28:52,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.weight                loaded from layer2.0.bn3.weight          of shape (512,)\n",
            "2023-02-03 13:28:52,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv1.weight              loaded from layer2.0.conv1.weight        of shape (128, 256, 1, 1)\n",
            "2023-02-03 13:28:52,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv2.weight              loaded from layer2.0.conv2.weight        of shape (128, 128, 3, 3)\n",
            "2023-02-03 13:28:52,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv3.weight              loaded from layer2.0.conv3.weight        of shape (512, 128, 1, 1)\n",
            "2023-02-03 13:28:52,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.0.weight       loaded from layer2.0.downsample.0.weight of shape (512, 256, 1, 1)\n",
            "2023-02-03 13:28:52,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.bias         loaded from layer2.0.downsample.1.bias   of shape (512,)\n",
            "2023-02-03 13:28:52,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.weight       loaded from layer2.0.downsample.1.weight of shape (512,)\n",
            "2023-02-03 13:28:52,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.bias                  loaded from layer2.1.bn1.bias            of shape (128,)\n",
            "2023-02-03 13:28:52,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.weight                loaded from layer2.1.bn1.weight          of shape (128,)\n",
            "2023-02-03 13:28:52,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.bias                  loaded from layer2.1.bn2.bias            of shape (128,)\n",
            "2023-02-03 13:28:52,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.weight                loaded from layer2.1.bn2.weight          of shape (128,)\n",
            "2023-02-03 13:28:52,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.bias                  loaded from layer2.1.bn3.bias            of shape (512,)\n",
            "2023-02-03 13:28:52,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.weight                loaded from layer2.1.bn3.weight          of shape (512,)\n",
            "2023-02-03 13:28:52,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv1.weight              loaded from layer2.1.conv1.weight        of shape (128, 512, 1, 1)\n",
            "2023-02-03 13:28:52,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv2.weight              loaded from layer2.1.conv2.weight        of shape (128, 128, 3, 3)\n",
            "2023-02-03 13:28:52,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv3.weight              loaded from layer2.1.conv3.weight        of shape (512, 128, 1, 1)\n",
            "2023-02-03 13:28:52,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.bias                  loaded from layer2.2.bn1.bias            of shape (128,)\n",
            "2023-02-03 13:28:52,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.weight                loaded from layer2.2.bn1.weight          of shape (128,)\n",
            "2023-02-03 13:28:52,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.bias                  loaded from layer2.2.bn2.bias            of shape (128,)\n",
            "2023-02-03 13:28:52,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.weight                loaded from layer2.2.bn2.weight          of shape (128,)\n",
            "2023-02-03 13:28:52,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.bias                  loaded from layer2.2.bn3.bias            of shape (512,)\n",
            "2023-02-03 13:28:52,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.weight                loaded from layer2.2.bn3.weight          of shape (512,)\n",
            "2023-02-03 13:28:52,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv1.weight              loaded from layer2.2.conv1.weight        of shape (128, 512, 1, 1)\n",
            "2023-02-03 13:28:52,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv2.weight              loaded from layer2.2.conv2.weight        of shape (128, 128, 3, 3)\n",
            "2023-02-03 13:28:52,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv3.weight              loaded from layer2.2.conv3.weight        of shape (512, 128, 1, 1)\n",
            "2023-02-03 13:28:52,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.bias                  loaded from layer2.3.bn1.bias            of shape (128,)\n",
            "2023-02-03 13:28:52,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.weight                loaded from layer2.3.bn1.weight          of shape (128,)\n",
            "2023-02-03 13:28:52,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.bias                  loaded from layer2.3.bn2.bias            of shape (128,)\n",
            "2023-02-03 13:28:52,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.weight                loaded from layer2.3.bn2.weight          of shape (128,)\n",
            "2023-02-03 13:28:52,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.bias                  loaded from layer2.3.bn3.bias            of shape (512,)\n",
            "2023-02-03 13:28:52,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.weight                loaded from layer2.3.bn3.weight          of shape (512,)\n",
            "2023-02-03 13:28:52,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv1.weight              loaded from layer2.3.conv1.weight        of shape (128, 512, 1, 1)\n",
            "2023-02-03 13:28:52,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv2.weight              loaded from layer2.3.conv2.weight        of shape (128, 128, 3, 3)\n",
            "2023-02-03 13:28:52,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv3.weight              loaded from layer2.3.conv3.weight        of shape (512, 128, 1, 1)\n",
            "2023-02-03 13:28:52,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.bias                  loaded from layer3.0.bn1.bias            of shape (256,)\n",
            "2023-02-03 13:28:52,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.weight                loaded from layer3.0.bn1.weight          of shape (256,)\n",
            "2023-02-03 13:28:52,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.bias                  loaded from layer3.0.bn2.bias            of shape (256,)\n",
            "2023-02-03 13:28:52,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.weight                loaded from layer3.0.bn2.weight          of shape (256,)\n",
            "2023-02-03 13:28:52,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.bias                  loaded from layer3.0.bn3.bias            of shape (1024,)\n",
            "2023-02-03 13:28:52,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.weight                loaded from layer3.0.bn3.weight          of shape (1024,)\n",
            "2023-02-03 13:28:52,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv1.weight              loaded from layer3.0.conv1.weight        of shape (256, 512, 1, 1)\n",
            "2023-02-03 13:28:52,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv2.weight              loaded from layer3.0.conv2.weight        of shape (256, 256, 3, 3)\n",
            "2023-02-03 13:28:52,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv3.weight              loaded from layer3.0.conv3.weight        of shape (1024, 256, 1, 1)\n",
            "2023-02-03 13:28:52,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.0.weight       loaded from layer3.0.downsample.0.weight of shape (1024, 512, 1, 1)\n",
            "2023-02-03 13:28:52,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.bias         loaded from layer3.0.downsample.1.bias   of shape (1024,)\n",
            "2023-02-03 13:28:52,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.weight       loaded from layer3.0.downsample.1.weight of shape (1024,)\n",
            "2023-02-03 13:28:52,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.bias                  loaded from layer3.1.bn1.bias            of shape (256,)\n",
            "2023-02-03 13:28:52,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.weight                loaded from layer3.1.bn1.weight          of shape (256,)\n",
            "2023-02-03 13:28:52,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.bias                  loaded from layer3.1.bn2.bias            of shape (256,)\n",
            "2023-02-03 13:28:52,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.weight                loaded from layer3.1.bn2.weight          of shape (256,)\n",
            "2023-02-03 13:28:52,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.bias                  loaded from layer3.1.bn3.bias            of shape (1024,)\n",
            "2023-02-03 13:28:52,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.weight                loaded from layer3.1.bn3.weight          of shape (1024,)\n",
            "2023-02-03 13:28:52,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv1.weight              loaded from layer3.1.conv1.weight        of shape (256, 1024, 1, 1)\n",
            "2023-02-03 13:28:52,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv2.weight              loaded from layer3.1.conv2.weight        of shape (256, 256, 3, 3)\n",
            "2023-02-03 13:28:52,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv3.weight              loaded from layer3.1.conv3.weight        of shape (1024, 256, 1, 1)\n",
            "2023-02-03 13:28:52,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.bias                  loaded from layer3.2.bn1.bias            of shape (256,)\n",
            "2023-02-03 13:28:52,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.weight                loaded from layer3.2.bn1.weight          of shape (256,)\n",
            "2023-02-03 13:28:52,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.bias                  loaded from layer3.2.bn2.bias            of shape (256,)\n",
            "2023-02-03 13:28:52,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.weight                loaded from layer3.2.bn2.weight          of shape (256,)\n",
            "2023-02-03 13:28:52,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.bias                  loaded from layer3.2.bn3.bias            of shape (1024,)\n",
            "2023-02-03 13:28:52,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.weight                loaded from layer3.2.bn3.weight          of shape (1024,)\n",
            "2023-02-03 13:28:52,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv1.weight              loaded from layer3.2.conv1.weight        of shape (256, 1024, 1, 1)\n",
            "2023-02-03 13:28:52,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv2.weight              loaded from layer3.2.conv2.weight        of shape (256, 256, 3, 3)\n",
            "2023-02-03 13:28:52,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv3.weight              loaded from layer3.2.conv3.weight        of shape (1024, 256, 1, 1)\n",
            "2023-02-03 13:28:52,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.bias                  loaded from layer3.3.bn1.bias            of shape (256,)\n",
            "2023-02-03 13:28:52,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.weight                loaded from layer3.3.bn1.weight          of shape (256,)\n",
            "2023-02-03 13:28:52,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.bias                  loaded from layer3.3.bn2.bias            of shape (256,)\n",
            "2023-02-03 13:28:52,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.weight                loaded from layer3.3.bn2.weight          of shape (256,)\n",
            "2023-02-03 13:28:52,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.bias                  loaded from layer3.3.bn3.bias            of shape (1024,)\n",
            "2023-02-03 13:28:52,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.weight                loaded from layer3.3.bn3.weight          of shape (1024,)\n",
            "2023-02-03 13:28:52,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv1.weight              loaded from layer3.3.conv1.weight        of shape (256, 1024, 1, 1)\n",
            "2023-02-03 13:28:52,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv2.weight              loaded from layer3.3.conv2.weight        of shape (256, 256, 3, 3)\n",
            "2023-02-03 13:28:52,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv3.weight              loaded from layer3.3.conv3.weight        of shape (1024, 256, 1, 1)\n",
            "2023-02-03 13:28:52,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.bias                  loaded from layer3.4.bn1.bias            of shape (256,)\n",
            "2023-02-03 13:28:52,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.weight                loaded from layer3.4.bn1.weight          of shape (256,)\n",
            "2023-02-03 13:28:52,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.bias                  loaded from layer3.4.bn2.bias            of shape (256,)\n",
            "2023-02-03 13:28:52,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.weight                loaded from layer3.4.bn2.weight          of shape (256,)\n",
            "2023-02-03 13:28:52,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.bias                  loaded from layer3.4.bn3.bias            of shape (1024,)\n",
            "2023-02-03 13:28:52,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.weight                loaded from layer3.4.bn3.weight          of shape (1024,)\n",
            "2023-02-03 13:28:52,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv1.weight              loaded from layer3.4.conv1.weight        of shape (256, 1024, 1, 1)\n",
            "2023-02-03 13:28:52,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv2.weight              loaded from layer3.4.conv2.weight        of shape (256, 256, 3, 3)\n",
            "2023-02-03 13:28:52,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv3.weight              loaded from layer3.4.conv3.weight        of shape (1024, 256, 1, 1)\n",
            "2023-02-03 13:28:52,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.bias                  loaded from layer3.5.bn1.bias            of shape (256,)\n",
            "2023-02-03 13:28:52,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.weight                loaded from layer3.5.bn1.weight          of shape (256,)\n",
            "2023-02-03 13:28:52,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.bias                  loaded from layer3.5.bn2.bias            of shape (256,)\n",
            "2023-02-03 13:28:52,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.weight                loaded from layer3.5.bn2.weight          of shape (256,)\n",
            "2023-02-03 13:28:52,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.bias                  loaded from layer3.5.bn3.bias            of shape (1024,)\n",
            "2023-02-03 13:28:52,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.weight                loaded from layer3.5.bn3.weight          of shape (1024,)\n",
            "2023-02-03 13:28:52,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv1.weight              loaded from layer3.5.conv1.weight        of shape (256, 1024, 1, 1)\n",
            "2023-02-03 13:28:52,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv2.weight              loaded from layer3.5.conv2.weight        of shape (256, 256, 3, 3)\n",
            "2023-02-03 13:28:52,264 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv3.weight              loaded from layer3.5.conv3.weight        of shape (1024, 256, 1, 1)\n",
            "2023-02-03 13:28:52,264 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.bias                  loaded from layer4.0.bn1.bias            of shape (512,)\n",
            "2023-02-03 13:28:52,264 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.weight                loaded from layer4.0.bn1.weight          of shape (512,)\n",
            "2023-02-03 13:28:52,264 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.bias                  loaded from layer4.0.bn2.bias            of shape (512,)\n",
            "2023-02-03 13:28:52,264 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.weight                loaded from layer4.0.bn2.weight          of shape (512,)\n",
            "2023-02-03 13:28:52,264 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.bias                  loaded from layer4.0.bn3.bias            of shape (2048,)\n",
            "2023-02-03 13:28:52,264 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.weight                loaded from layer4.0.bn3.weight          of shape (2048,)\n",
            "2023-02-03 13:28:52,264 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv1.weight              loaded from layer4.0.conv1.weight        of shape (512, 1024, 1, 1)\n",
            "2023-02-03 13:28:52,264 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv2.weight              loaded from layer4.0.conv2.weight        of shape (512, 512, 3, 3)\n",
            "2023-02-03 13:28:52,264 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv3.weight              loaded from layer4.0.conv3.weight        of shape (2048, 512, 1, 1)\n",
            "2023-02-03 13:28:52,264 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.0.weight       loaded from layer4.0.downsample.0.weight of shape (2048, 1024, 1, 1)\n",
            "2023-02-03 13:28:52,264 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.bias         loaded from layer4.0.downsample.1.bias   of shape (2048,)\n",
            "2023-02-03 13:28:52,264 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.weight       loaded from layer4.0.downsample.1.weight of shape (2048,)\n",
            "2023-02-03 13:28:52,264 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.bias                  loaded from layer4.1.bn1.bias            of shape (512,)\n",
            "2023-02-03 13:28:52,264 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.weight                loaded from layer4.1.bn1.weight          of shape (512,)\n",
            "2023-02-03 13:28:52,264 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.bias                  loaded from layer4.1.bn2.bias            of shape (512,)\n",
            "2023-02-03 13:28:52,264 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.weight                loaded from layer4.1.bn2.weight          of shape (512,)\n",
            "2023-02-03 13:28:52,264 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.bias                  loaded from layer4.1.bn3.bias            of shape (2048,)\n",
            "2023-02-03 13:28:52,265 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.weight                loaded from layer4.1.bn3.weight          of shape (2048,)\n",
            "2023-02-03 13:28:52,265 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv1.weight              loaded from layer4.1.conv1.weight        of shape (512, 2048, 1, 1)\n",
            "2023-02-03 13:28:52,265 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv2.weight              loaded from layer4.1.conv2.weight        of shape (512, 512, 3, 3)\n",
            "2023-02-03 13:28:52,265 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv3.weight              loaded from layer4.1.conv3.weight        of shape (2048, 512, 1, 1)\n",
            "2023-02-03 13:28:52,265 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.bias                  loaded from layer4.2.bn1.bias            of shape (512,)\n",
            "2023-02-03 13:28:52,265 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.weight                loaded from layer4.2.bn1.weight          of shape (512,)\n",
            "2023-02-03 13:28:52,265 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.bias                  loaded from layer4.2.bn2.bias            of shape (512,)\n",
            "2023-02-03 13:28:52,265 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.weight                loaded from layer4.2.bn2.weight          of shape (512,)\n",
            "2023-02-03 13:28:52,265 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.bias                  loaded from layer4.2.bn3.bias            of shape (2048,)\n",
            "2023-02-03 13:28:52,265 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.weight                loaded from layer4.2.bn3.weight          of shape (2048,)\n",
            "2023-02-03 13:28:52,265 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv1.weight              loaded from layer4.2.conv1.weight        of shape (512, 2048, 1, 1)\n",
            "2023-02-03 13:28:52,265 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv2.weight              loaded from layer4.2.conv2.weight        of shape (512, 512, 3, 3)\n",
            "2023-02-03 13:28:52,265 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv3.weight              loaded from layer4.2.conv3.weight        of shape (2048, 512, 1, 1)\n",
            "2023-02-03 13:28:52,265 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.bias                      loaded from bn1.bias                     of shape (64,)\n",
            "2023-02-03 13:28:52,265 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.weight                    loaded from bn1.weight                   of shape (64,)\n",
            "2023-02-03 13:28:52,266 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.conv1.weight                  loaded from conv1.weight                 of shape (64, 3, 7, 7)\n",
            "loading annotations into memory...\n",
            "Done (t=0.34s)\n",
            "creating index...\n",
            "index created!\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loading annotations into memory...\n",
            "Done (t=2.18s)\n",
            "creating index...\n",
            "index created!\n",
            "[Masking] Use color augmentation.\n",
            "2023-02-03 13:28:55,763 maskrcnn_benchmark.trainer INFO: Start training\n",
            "2023-02-03 13:28:55,763 maskrcnn_benchmark.trainer INFO: with_MIC: On\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/content/MIC/det/maskrcnn_benchmark/structures/bounding_box.py:206: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:27.)\n",
            "  bbox = BoxList(self.bbox[item], self.size, self.mode)\n",
            "/content/MIC/det/maskrcnn_benchmark/structures/bounding_box.py:208: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:27.)\n",
            "  bbox.add_field(k, v[item])\n",
            "/content/MIC/det/maskrcnn_benchmark/modeling/roi_heads/box_head/loss.py:195: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:27.)\n",
            "  class_logits = class_logits[domain_masks, :]\n",
            "/content/MIC/det/maskrcnn_benchmark/modeling/roi_heads/box_head/loss.py:196: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:27.)\n",
            "  box_regression = box_regression[domain_masks, :]\n",
            "/content/MIC/det/maskrcnn_benchmark/modeling/roi_heads/box_head/loss.py:197: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:27.)\n",
            "  labels = labels[domain_masks]\n",
            "/content/MIC/det/maskrcnn_benchmark/modeling/roi_heads/box_head/loss.py:198: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:27.)\n",
            "  regression_targets = regression_targets[domain_masks, :]\n",
            "/content/MIC/det/maskrcnn_benchmark/modeling/da_heads/loss.py:92: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/cuda/Indexing.cu:1239.)\n",
            "  da_img_label_per_level[masks, :] = 1\n",
            "/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py:173: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:27.)\n",
            "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "2023-02-03 13:29:00,607 maskrcnn_benchmark.trainer INFO: eta: 3 days, 8:41:03 iter: 0 loss: 3.1396 (3.1396) loss_classifier: 0.7745 (0.7745) loss_box_reg: 0.0001 (0.0001) loss_objectness: 0.6955 (0.6955) loss_rpn_box_reg: 0.2745 (0.2745) loss_da_image: 0.6931 (0.6931) loss_da_instance: 0.6925 (0.6925) loss_da_consistency: 0.0093 (0.0093) time: 4.8411 (4.8411) data: 1.9779 (1.9779) lr: 0.000334 max mem: 3647\n",
            "2023-02-03 13:29:23,901 maskrcnn_benchmark.trainer INFO: eta: 22:19:23 iter: 20 loss: 2.3959 (2.5363) loss_classifier: 0.1655 (0.2736) loss_box_reg: 0.0026 (0.0168) loss_objectness: 0.6602 (0.6555) loss_rpn_box_reg: 0.1941 (0.1957) loss_da_image: 0.6931 (0.6931) loss_da_instance: 0.6937 (0.6939) loss_da_consistency: 0.0073 (0.0077) time: 1.1647 (1.3398) data: 0.3450 (0.4239) lr: 0.000347 max mem: 3987\n",
            "2023-02-03 13:29:47,770 maskrcnn_benchmark.trainer INFO: eta: 21:07:33 iter: 40 loss: 2.1932 (2.3808) loss_classifier: 0.1441 (0.2289) loss_box_reg: 0.0002 (0.0177) loss_objectness: 0.4967 (0.5857) loss_rpn_box_reg: 0.0650 (0.1561) loss_da_image: 0.6931 (0.6931) loss_da_instance: 0.6926 (0.6934) loss_da_consistency: 0.0037 (0.0059) time: 1.1911 (1.2684) data: 0.3612 (0.3937) lr: 0.000361 max mem: 3987\n",
            "2023-02-03 13:30:12,268 maskrcnn_benchmark.trainer INFO: eta: 20:52:53 iter: 60 loss: 2.0066 (2.2678) loss_classifier: 0.0934 (0.1901) loss_box_reg: 0.0001 (0.0167) loss_objectness: 0.3781 (0.5228) loss_rpn_box_reg: 0.1055 (0.1474) loss_da_image: 0.6931 (0.6931) loss_da_instance: 0.6927 (0.6932) loss_da_consistency: 0.0019 (0.0046) time: 1.2238 (1.2541) data: 0.3639 (0.3854) lr: 0.000374 max mem: 3987\n",
            "2023-02-03 13:30:37,983 maskrcnn_benchmark.trainer INFO: eta: 21:00:15 iter: 80 loss: 1.8642 (2.1734) loss_classifier: 0.1086 (0.1710) loss_box_reg: 0.0158 (0.0180) loss_objectness: 0.2867 (0.4612) loss_rpn_box_reg: 0.0825 (0.1329) loss_da_image: 0.6931 (0.6931) loss_da_instance: 0.6914 (0.6928) loss_da_consistency: 0.0032 (0.0043) time: 1.2704 (1.2619) data: 0.3831 (0.3856) lr: 0.000387 max mem: 3987\n",
            "2023-02-03 13:31:02,943 maskrcnn_benchmark.trainer INFO: eta: 20:57:05 iter: 100 loss: 1.8495 (2.1318) loss_classifier: 0.1460 (0.1733) loss_box_reg: 0.0609 (0.0293) loss_objectness: 0.1763 (0.4129) loss_rpn_box_reg: 0.0605 (0.1259) loss_da_image: 0.6931 (0.6931) loss_da_instance: 0.6919 (0.6927) loss_da_consistency: 0.0055 (0.0045) time: 1.2501 (1.2592) data: 0.3769 (0.3840) lr: 0.000401 max mem: 3987\n",
            "2023-02-03 13:31:27,525 maskrcnn_benchmark.trainer INFO: eta: 20:51:42 iter: 120 loss: 1.6825 (2.0770) loss_classifier: 0.0992 (0.1646) loss_box_reg: 0.0001 (0.0277) loss_objectness: 0.1491 (0.3728) loss_rpn_box_reg: 0.0390 (0.1214) loss_da_image: 0.6930 (0.6931) loss_da_instance: 0.6925 (0.6926) loss_da_consistency: 0.0064 (0.0048) time: 1.2278 (1.2542) data: 0.3710 (0.3820) lr: 0.000414 max mem: 3987\n",
            "2023-02-03 13:31:52,590 maskrcnn_benchmark.trainer INFO: eta: 20:51:09 iter: 140 loss: 1.7325 (2.0460) loss_classifier: 0.1008 (0.1619) loss_box_reg: 0.0000 (0.0308) loss_objectness: 0.1091 (0.3421) loss_rpn_box_reg: 0.0801 (0.1206) loss_da_image: 0.6929 (0.6931) loss_da_instance: 0.6910 (0.6924) loss_da_consistency: 0.0062 (0.0050) time: 1.2464 (1.2541) data: 0.3752 (0.3818) lr: 0.000427 max mem: 3987\n",
            "2023-02-03 13:32:17,527 maskrcnn_benchmark.trainer INFO: eta: 20:49:50 iter: 160 loss: 1.7263 (2.0174) loss_classifier: 0.1320 (0.1592) loss_box_reg: 0.0002 (0.0315) loss_objectness: 0.1093 (0.3176) loss_rpn_box_reg: 0.0712 (0.1187) loss_da_image: 0.6928 (0.6930) loss_da_instance: 0.6911 (0.6922) loss_da_consistency: 0.0063 (0.0052) time: 1.2434 (1.2532) data: 0.3749 (0.3814) lr: 0.000441 max mem: 3987\n",
            "2023-02-03 13:32:42,296 maskrcnn_benchmark.trainer INFO: eta: 20:47:47 iter: 180 loss: 1.8398 (1.9962) loss_classifier: 0.1397 (0.1580) loss_box_reg: 0.0625 (0.0349) loss_objectness: 0.1187 (0.2973) loss_rpn_box_reg: 0.0706 (0.1156) loss_da_image: 0.6928 (0.6930) loss_da_instance: 0.6906 (0.6921) loss_da_consistency: 0.0060 (0.0053) time: 1.2369 (1.2516) data: 0.3746 (0.3806) lr: 0.000454 max mem: 3987\n",
            "2023-02-03 13:33:07,268 maskrcnn_benchmark.trainer INFO: eta: 20:47:05 iter: 200 loss: 1.7382 (1.9821) loss_classifier: 0.1273 (0.1573) loss_box_reg: 0.0492 (0.0378) loss_objectness: 0.1330 (0.2817) loss_rpn_box_reg: 0.0521 (0.1151) loss_da_image: 0.6925 (0.6930) loss_da_instance: 0.6906 (0.6919) loss_da_consistency: 0.0062 (0.0054) time: 1.2469 (1.2513) data: 0.3782 (0.3805) lr: 0.000467 max mem: 3987\n",
            "2023-02-03 13:33:32,248 maskrcnn_benchmark.trainer INFO: eta: 20:46:27 iter: 220 loss: 2.0230 (1.9789) loss_classifier: 0.1949 (0.1615) loss_box_reg: 0.1054 (0.0454) loss_objectness: 0.1021 (0.2670) loss_rpn_box_reg: 0.0871 (0.1147) loss_da_image: 0.6925 (0.6929) loss_da_instance: 0.6907 (0.6918) loss_da_consistency: 0.0059 (0.0055) time: 1.2465 (1.2511) data: 0.3763 (0.3803) lr: 0.000481 max mem: 3987\n",
            "2023-02-03 13:33:57,348 maskrcnn_benchmark.trainer INFO: eta: 20:46:22 iter: 240 loss: 1.8260 (1.9705) loss_classifier: 0.1320 (0.1617) loss_box_reg: 0.0826 (0.0502) loss_objectness: 0.0974 (0.2556) loss_rpn_box_reg: 0.0783 (0.1130) loss_da_image: 0.6920 (0.6929) loss_da_instance: 0.6894 (0.6917) loss_da_consistency: 0.0058 (0.0055) time: 1.2378 (1.2514) data: 0.3742 (0.3799) lr: 0.000494 max mem: 3987\n",
            "2023-02-03 13:34:22,883 maskrcnn_benchmark.trainer INFO: eta: 20:47:53 iter: 260 loss: 1.8620 (1.9669) loss_classifier: 0.1625 (0.1638) loss_box_reg: 0.0972 (0.0567) loss_objectness: 0.0941 (0.2437) loss_rpn_box_reg: 0.1007 (0.1129) loss_da_image: 0.6921 (0.6928) loss_da_instance: 0.6900 (0.6915) loss_da_consistency: 0.0058 (0.0055) time: 1.2640 (1.2533) data: 0.3738 (0.3799) lr: 0.000507 max mem: 3987\n",
            "2023-02-03 13:34:47,993 maskrcnn_benchmark.trainer INFO: eta: 20:47:37 iter: 280 loss: 1.8456 (1.9613) loss_classifier: 0.1826 (0.1650) loss_box_reg: 0.1066 (0.0609) loss_objectness: 0.0895 (0.2346) loss_rpn_box_reg: 0.0762 (0.1110) loss_da_image: 0.6915 (0.6927) loss_da_instance: 0.6894 (0.6914) loss_da_consistency: 0.0059 (0.0055) time: 1.2503 (1.2535) data: 0.3747 (0.3800) lr: 0.000521 max mem: 3987\n",
            "2023-02-03 13:35:12,835 maskrcnn_benchmark.trainer INFO: eta: 20:46:27 iter: 300 loss: 1.8218 (1.9573) loss_classifier: 0.1471 (0.1681) loss_box_reg: 0.0637 (0.0660) loss_objectness: 0.0758 (0.2242) loss_rpn_box_reg: 0.0497 (0.1094) loss_da_image: 0.6913 (0.6926) loss_da_instance: 0.6893 (0.6913) loss_da_consistency: 0.0055 (0.0055) time: 1.2361 (1.2527) data: 0.3743 (0.3799) lr: 0.000534 max mem: 3987\n",
            "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "2023-02-03 13:35:38,213 maskrcnn_benchmark.trainer INFO: eta: 20:47:02 iter: 320 loss: 1.8731 (1.9539) loss_classifier: 0.1439 (0.1683) loss_box_reg: 0.1059 (0.0709) loss_objectness: 0.0803 (0.2159) loss_rpn_box_reg: 0.1128 (0.1093) loss_da_image: 0.6912 (0.6926) loss_da_instance: 0.6892 (0.6911) loss_da_consistency: 0.0056 (0.0055) time: 1.2534 (1.2537) data: 0.3784 (0.3799) loss_classifier_mask: 0.0688 (0.0688) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0097 (0.0097) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.000547 max mem: 4826\n",
            "2023-02-03 13:36:03,223 maskrcnn_benchmark.trainer INFO: eta: 20:46:26 iter: 340 loss: 1.7027 (1.9438) loss_classifier: 0.1090 (0.1674) loss_box_reg: 0.0767 (0.0732) loss_objectness: 0.0479 (0.2064) loss_rpn_box_reg: 0.0427 (0.1075) loss_da_image: 0.6902 (0.6924) loss_da_instance: 0.6885 (0.6910) loss_da_consistency: 0.0061 (0.0056) time: 1.2439 (1.2535) data: 0.3731 (0.3799) loss_classifier_mask: 0.0688 (0.0688) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0097 (0.0097) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.000561 max mem: 4826\n",
            "2023-02-03 13:36:28,057 maskrcnn_benchmark.trainer INFO: eta: 20:45:22 iter: 360 loss: 1.7479 (1.9372) loss_classifier: 0.1542 (0.1685) loss_box_reg: 0.1008 (0.0769) loss_objectness: 0.0397 (0.1977) loss_rpn_box_reg: 0.0230 (0.1052) loss_da_image: 0.6908 (0.6923) loss_da_instance: 0.6894 (0.6909) loss_da_consistency: 0.0054 (0.0056) time: 1.2353 (1.2529) data: 0.3719 (0.3797) loss_classifier_mask: 0.0688 (0.0688) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0097 (0.0097) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.000574 max mem: 4826\n",
            "2023-02-03 13:36:53,299 maskrcnn_benchmark.trainer INFO: eta: 20:45:25 iter: 380 loss: 1.7040 (1.9348) loss_classifier: 0.1372 (0.1695) loss_box_reg: 0.1086 (0.0815) loss_objectness: 0.0465 (0.1925) loss_rpn_box_reg: 0.0275 (0.1022) loss_da_image: 0.6888 (0.6922) loss_da_instance: 0.6886 (0.6908) loss_da_consistency: 0.0052 (0.0056) time: 1.2362 (1.2534) data: 0.3730 (0.3796) loss_classifier_mask: 0.0688 (0.0817) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0097 (0.0113) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.000587 max mem: 4832\n",
            "2023-02-03 13:37:20,633 maskrcnn_benchmark.trainer INFO: eta: 20:50:37 iter: 400 loss: 1.8672 (1.9405) loss_classifier: 0.1809 (0.1713) loss_box_reg: 0.1298 (0.0867) loss_objectness: 0.0726 (0.1879) loss_rpn_box_reg: 0.0893 (0.1031) loss_da_image: 0.6907 (0.6921) loss_da_instance: 0.6878 (0.6906) loss_da_consistency: 0.0055 (0.0056) time: 1.2537 (1.2590) data: 0.3754 (0.3794) loss_classifier_mask: 0.0919 (0.1222) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0181 (0.0185) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.000601 max mem: 4832\n",
            "2023-02-03 13:37:49,224 maskrcnn_benchmark.trainer INFO: eta: 20:58:15 iter: 420 loss: 2.1217 (1.9540) loss_classifier: 0.2733 (0.1772) loss_box_reg: 0.2221 (0.0958) loss_objectness: 0.0949 (0.1837) loss_rpn_box_reg: 0.0940 (0.1044) loss_da_image: 0.6902 (0.6920) loss_da_instance: 0.6883 (0.6905) loss_da_consistency: 0.0052 (0.0055) time: 1.3144 (1.2671) data: 0.3740 (0.3793) loss_classifier_mask: 0.0688 (0.0932) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0142 (0.0160) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.000614 max mem: 4832\n",
            "2023-02-03 13:38:16,482 maskrcnn_benchmark.trainer INFO: eta: 21:02:08 iter: 440 loss: 1.8876 (1.9537) loss_classifier: 0.1787 (0.1786) loss_box_reg: 0.1267 (0.0996) loss_objectness: 0.0630 (0.1788) loss_rpn_box_reg: 0.0601 (0.1033) loss_da_image: 0.6897 (0.6919) loss_da_instance: 0.6882 (0.6905) loss_da_consistency: 0.0056 (0.0055) time: 1.2554 (1.2715) data: 0.3658 (0.3790) loss_classifier_mask: 0.0547 (0.0799) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0091 (0.0137) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.000627 max mem: 4832\n",
            "2023-02-03 13:38:44,384 maskrcnn_benchmark.trainer INFO: eta: 21:07:02 iter: 460 loss: 1.9542 (1.9569) loss_classifier: 0.1584 (0.1796) loss_box_reg: 0.1513 (0.1028) loss_objectness: 0.0978 (0.1758) loss_rpn_box_reg: 0.0964 (0.1040) loss_da_image: 0.6885 (0.6918) loss_da_instance: 0.6883 (0.6904) loss_da_consistency: 0.0056 (0.0055) time: 1.2598 (1.2768) data: 0.3725 (0.3788) loss_classifier_mask: 0.0588 (0.0802) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0080 (0.0125) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.000641 max mem: 4832\n",
            "2023-02-03 13:39:13,692 maskrcnn_benchmark.trainer INFO: eta: 21:14:23 iter: 480 loss: 1.8529 (1.9547) loss_classifier: 0.1515 (0.1791) loss_box_reg: 0.1221 (0.1048) loss_objectness: 0.0591 (0.1711) loss_rpn_box_reg: 0.0440 (0.1023) loss_da_image: 0.6894 (0.6917) loss_da_instance: 0.6881 (0.6903) loss_da_consistency: 0.0055 (0.0055) time: 1.5547 (1.2847) data: 0.3663 (0.3784) loss_classifier_mask: 0.0884 (0.0854) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0087 (0.0114) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.000654 max mem: 4832\n",
            "2023-02-03 13:39:44,835 maskrcnn_benchmark.trainer INFO: eta: 21:24:45 iter: 500 loss: 1.8287 (1.9529) loss_classifier: 0.1224 (0.1777) loss_box_reg: 0.0857 (0.1058) loss_objectness: 0.0558 (0.1672) loss_rpn_box_reg: 0.0467 (0.1009) loss_da_image: 0.6878 (0.6915) loss_da_instance: 0.6880 (0.6902) loss_da_consistency: 0.0055 (0.0055) time: 1.5688 (1.2955) data: 0.3725 (0.3781) loss_classifier_mask: 0.0928 (0.0927) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0086 (0.0112) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.000667 max mem: 4832\n",
            "2023-02-03 13:40:15,344 maskrcnn_benchmark.trainer INFO: eta: 21:33:04 iter: 520 loss: 2.2619 (1.9648) loss_classifier: 0.2504 (0.1813) loss_box_reg: 0.3100 (0.1127) loss_objectness: 0.0670 (0.1637) loss_rpn_box_reg: 0.1108 (0.1017) loss_da_image: 0.6868 (0.6914) loss_da_instance: 0.6876 (0.6901) loss_da_consistency: 0.0054 (0.0055) time: 1.5686 (1.3044) data: 0.3716 (0.3780) loss_classifier_mask: 0.1269 (0.1008) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0148 (0.0124) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.000681 max mem: 4832\n",
            "2023-02-03 13:40:45,348 maskrcnn_benchmark.trainer INFO: eta: 21:39:48 iter: 540 loss: 1.9812 (1.9667) loss_classifier: 0.1980 (0.1819) loss_box_reg: 0.1472 (0.1163) loss_objectness: 0.0517 (0.1598) loss_rpn_box_reg: 0.0431 (0.1003) loss_da_image: 0.6860 (0.6912) loss_da_instance: 0.6866 (0.6900) loss_da_consistency: 0.0059 (0.0056) time: 1.5571 (1.3116) data: 0.3673 (0.3776) loss_classifier_mask: 0.0971 (0.1033) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0126 (0.0130) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.000694 max mem: 4832\n",
            "2023-02-03 13:41:16,752 maskrcnn_benchmark.trainer INFO: eta: 21:48:30 iter: 560 loss: 2.0232 (1.9722) loss_classifier: 0.1870 (0.1828) loss_box_reg: 0.1818 (0.1196) loss_objectness: 0.0576 (0.1575) loss_rpn_box_reg: 0.0588 (0.0999) loss_da_image: 0.6885 (0.6911) loss_da_instance: 0.6873 (0.6899) loss_da_consistency: 0.0058 (0.0056) time: 1.5788 (1.3208) data: 0.3724 (0.3775) loss_classifier_mask: 0.1070 (0.1084) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0101 (0.0126) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.000707 max mem: 4832\n",
            "2023-02-03 13:41:48,551 maskrcnn_benchmark.trainer INFO: eta: 21:57:14 iter: 580 loss: 2.0602 (1.9763) loss_classifier: 0.1784 (0.1832) loss_box_reg: 0.2006 (0.1229) loss_objectness: 0.0478 (0.1547) loss_rpn_box_reg: 0.0987 (0.1002) loss_da_image: 0.6883 (0.6910) loss_da_instance: 0.6866 (0.6898) loss_da_consistency: 0.0059 (0.0056) time: 1.5821 (1.3301) data: 0.3684 (0.3774) loss_classifier_mask: 0.0983 (0.1076) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0096 (0.0125) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.000721 max mem: 4832\n",
            "2023-02-03 13:42:19,766 maskrcnn_benchmark.trainer INFO: eta: 22:04:23 iter: 600 loss: 1.9829 (1.9791) loss_classifier: 0.2120 (0.1845) loss_box_reg: 0.2254 (0.1263) loss_objectness: 0.0372 (0.1511) loss_rpn_box_reg: 0.0424 (0.0991) loss_da_image: 0.6865 (0.6909) loss_da_instance: 0.6869 (0.6897) loss_da_consistency: 0.0060 (0.0056) time: 1.5761 (1.3378) data: 0.3707 (0.3772) loss_classifier_mask: 0.0823 (0.1083) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0094 (0.0125) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.000734 max mem: 4832\n",
            "2023-02-03 13:42:49,652 maskrcnn_benchmark.trainer INFO: eta: 22:08:56 iter: 620 loss: 2.0215 (1.9809) loss_classifier: 0.1746 (0.1850) loss_box_reg: 0.1856 (0.1286) loss_objectness: 0.0343 (0.1485) loss_rpn_box_reg: 0.0480 (0.0991) loss_da_image: 0.6832 (0.6906) loss_da_instance: 0.6867 (0.6896) loss_da_consistency: 0.0058 (0.0056) time: 1.5645 (1.3428) data: 0.3726 (0.3770) loss_classifier_mask: 0.0834 (0.1089) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0056 (0.0123) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.000747 max mem: 4832\n",
            "2023-02-03 13:43:19,985 maskrcnn_benchmark.trainer INFO: eta: 22:13:51 iter: 640 loss: 2.0332 (1.9872) loss_classifier: 0.1891 (0.1863) loss_box_reg: 0.1868 (0.1325) loss_objectness: 0.0668 (0.1459) loss_rpn_box_reg: 0.0902 (0.0996) loss_da_image: 0.6863 (0.6905) loss_da_instance: 0.6865 (0.6895) loss_da_consistency: 0.0057 (0.0056) time: 1.5637 (1.3482) data: 0.3669 (0.3768) loss_classifier_mask: 0.1162 (0.1125) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0137 (0.0126) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.000761 max mem: 4832\n",
            "2023-02-03 13:43:51,276 maskrcnn_benchmark.trainer INFO: eta: 22:19:52 iter: 660 loss: 2.0048 (1.9900) loss_classifier: 0.2045 (0.1869) loss_box_reg: 0.1740 (0.1344) loss_objectness: 0.0431 (0.1439) loss_rpn_box_reg: 0.0538 (0.0994) loss_da_image: 0.6809 (0.6902) loss_da_instance: 0.6868 (0.6894) loss_da_consistency: 0.0056 (0.0056) time: 1.5795 (1.3548) data: 0.3659 (0.3766) loss_classifier_mask: 0.1193 (0.1137) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0115 (0.0129) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.000774 max mem: 4832\n",
            "2023-02-03 13:44:20,979 maskrcnn_benchmark.trainer INFO: eta: 22:23:12 iter: 680 loss: 2.0226 (1.9947) loss_classifier: 0.1662 (0.1868) loss_box_reg: 0.1925 (0.1367) loss_objectness: 0.1004 (0.1438) loss_rpn_box_reg: 0.0429 (0.0999) loss_da_image: 0.6844 (0.6901) loss_da_instance: 0.6878 (0.6894) loss_da_consistency: 0.0054 (0.0056) time: 1.5679 (1.3586) data: 0.3664 (0.3764) loss_classifier_mask: 0.1284 (0.1145) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0164 (0.0138) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.000787 max mem: 4832\n",
            "2023-02-03 13:44:52,674 maskrcnn_benchmark.trainer INFO: eta: 22:29:08 iter: 700 loss: 1.9847 (1.9980) loss_classifier: 0.2234 (0.1879) loss_box_reg: 0.2288 (0.1396) loss_objectness: 0.0485 (0.1413) loss_rpn_box_reg: 0.0442 (0.0988) loss_da_image: 0.6846 (0.6899) loss_da_instance: 0.6882 (0.6893) loss_da_consistency: 0.0057 (0.0056) time: 1.5870 (1.3651) data: 0.3727 (0.3764) loss_classifier_mask: 0.1305 (0.1163) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0109 (0.0141) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.000801 max mem: 4832\n",
            "2023-02-03 13:45:23,495 maskrcnn_benchmark.trainer INFO: eta: 22:33:30 iter: 720 loss: 1.9816 (1.9981) loss_classifier: 0.1290 (0.1874) loss_box_reg: 0.1546 (0.1406) loss_objectness: 0.0403 (0.1391) loss_rpn_box_reg: 0.0310 (0.0978) loss_da_image: 0.6789 (0.6897) loss_da_instance: 0.6862 (0.6893) loss_da_consistency: 0.0059 (0.0057) time: 1.5697 (1.3699) data: 0.3657 (0.3762) loss_classifier_mask: 0.1723 (0.1194) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0152 (0.0144) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.000814 max mem: 4832\n",
            "2023-02-03 13:45:54,432 maskrcnn_benchmark.trainer INFO: eta: 22:37:45 iter: 740 loss: 1.9503 (2.0002) loss_classifier: 0.1576 (0.1880) loss_box_reg: 0.1994 (0.1428) loss_objectness: 0.0430 (0.1367) loss_rpn_box_reg: 0.0226 (0.0972) loss_da_image: 0.6834 (0.6895) loss_da_instance: 0.6867 (0.6892) loss_da_consistency: 0.0057 (0.0057) time: 1.5601 (1.3747) data: 0.3632 (0.3759) loss_classifier_mask: 0.1204 (0.1203) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0105 (0.0144) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.000827 max mem: 4832\n",
            "2023-02-03 13:46:26,018 maskrcnn_benchmark.trainer INFO: eta: 22:42:36 iter: 760 loss: 1.8971 (1.9997) loss_classifier: 0.1419 (0.1875) loss_box_reg: 0.1340 (0.1436) loss_objectness: 0.0377 (0.1346) loss_rpn_box_reg: 0.0352 (0.0964) loss_da_image: 0.6768 (0.6892) loss_da_instance: 0.6845 (0.6891) loss_da_consistency: 0.0059 (0.0057) time: 1.5708 (1.3801) data: 0.3676 (0.3757) loss_classifier_mask: 0.1281 (0.1213) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0157 (0.0145) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.000841 max mem: 4832\n",
            "2023-02-03 13:46:57,063 maskrcnn_benchmark.trainer INFO: eta: 22:46:30 iter: 780 loss: 1.9906 (2.0021) loss_classifier: 0.2020 (0.1882) loss_box_reg: 0.1690 (0.1454) loss_objectness: 0.0348 (0.1322) loss_rpn_box_reg: 0.0399 (0.0961) loss_da_image: 0.6797 (0.6889) loss_da_instance: 0.6867 (0.6890) loss_da_consistency: 0.0058 (0.0057) time: 1.5672 (1.3845) data: 0.3670 (0.3755) loss_classifier_mask: 0.1516 (0.1239) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0188 (0.0147) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.000854 max mem: 4832\n",
            "2023-02-03 13:47:28,254 maskrcnn_benchmark.trainer INFO: eta: 22:50:21 iter: 800 loss: 2.1310 (2.0047) loss_classifier: 0.2113 (0.1888) loss_box_reg: 0.2329 (0.1474) loss_objectness: 0.0291 (0.1298) loss_rpn_box_reg: 0.0497 (0.0955) loss_da_image: 0.6770 (0.6886) loss_da_instance: 0.6841 (0.6889) loss_da_consistency: 0.0059 (0.0057) time: 1.5725 (1.3889) data: 0.3701 (0.3754) loss_classifier_mask: 0.1766 (0.1267) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0145 (0.0148) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.000867 max mem: 4832\n",
            "2023-02-03 13:47:59,466 maskrcnn_benchmark.trainer INFO: eta: 22:54:01 iter: 820 loss: 1.9545 (2.0040) loss_classifier: 0.1395 (0.1882) loss_box_reg: 0.1294 (0.1478) loss_objectness: 0.0375 (0.1278) loss_rpn_box_reg: 0.0738 (0.0951) loss_da_image: 0.6723 (0.6883) loss_da_instance: 0.6847 (0.6888) loss_da_consistency: 0.0066 (0.0057) time: 1.5753 (1.3931) data: 0.3677 (0.3753) loss_classifier_mask: 0.1534 (0.1283) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0104 (0.0147) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.000881 max mem: 4832\n",
            "2023-02-03 13:48:30,827 maskrcnn_benchmark.trainer INFO: eta: 22:57:39 iter: 840 loss: 2.2224 (2.0083) loss_classifier: 0.2209 (0.1894) loss_box_reg: 0.2242 (0.1500) loss_objectness: 0.0533 (0.1265) loss_rpn_box_reg: 0.0687 (0.0951) loss_da_image: 0.6744 (0.6880) loss_da_instance: 0.6836 (0.6886) loss_da_consistency: 0.0065 (0.0057) time: 1.5614 (1.3972) data: 0.3656 (0.3751) loss_classifier_mask: 0.1559 (0.1298) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0169 (0.0148) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.000894 max mem: 4832\n",
            "2023-02-03 13:49:02,716 maskrcnn_benchmark.trainer INFO: eta: 23:01:42 iter: 860 loss: 2.0012 (2.0099) loss_classifier: 0.1828 (0.1896) loss_box_reg: 0.1538 (0.1512) loss_objectness: 0.0408 (0.1251) loss_rpn_box_reg: 0.0563 (0.0952) loss_da_image: 0.6739 (0.6877) loss_da_instance: 0.6837 (0.6885) loss_da_consistency: 0.0070 (0.0058) time: 1.5819 (1.4018) data: 0.3665 (0.3750) loss_classifier_mask: 0.1321 (0.1296) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0060 (0.0146) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.000907 max mem: 4832\n",
            "2023-02-03 13:49:34,094 maskrcnn_benchmark.trainer INFO: eta: 23:04:58 iter: 880 loss: 1.9726 (2.0099) loss_classifier: 0.1625 (0.1897) loss_box_reg: 0.1821 (0.1523) loss_objectness: 0.0403 (0.1235) loss_rpn_box_reg: 0.0312 (0.0944) loss_da_image: 0.6735 (0.6874) loss_da_instance: 0.6812 (0.6883) loss_da_consistency: 0.0069 (0.0058) time: 1.5631 (1.4056) data: 0.3673 (0.3749) loss_classifier_mask: 0.1274 (0.1297) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0123 (0.0145) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.000921 max mem: 4832\n",
            "2023-02-03 13:50:05,439 maskrcnn_benchmark.trainer INFO: eta: 23:08:02 iter: 900 loss: 1.8077 (2.0096) loss_classifier: 0.1190 (0.1896) loss_box_reg: 0.1236 (0.1530) loss_objectness: 0.0305 (0.1220) loss_rpn_box_reg: 0.0224 (0.0937) loss_da_image: 0.6717 (0.6871) loss_da_instance: 0.6787 (0.6881) loss_da_consistency: 0.0074 (0.0058) time: 1.5609 (1.4092) data: 0.3672 (0.3748) loss_classifier_mask: 0.1437 (0.1301) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0092 (0.0143) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.000934 max mem: 4832\n",
            "2023-02-03 13:50:36,398 maskrcnn_benchmark.trainer INFO: eta: 23:10:32 iter: 920 loss: 1.9034 (2.0093) loss_classifier: 0.1649 (0.1894) loss_box_reg: 0.1371 (0.1538) loss_objectness: 0.0318 (0.1203) loss_rpn_box_reg: 0.0373 (0.0932) loss_da_image: 0.6700 (0.6867) loss_da_instance: 0.6815 (0.6880) loss_da_consistency: 0.0071 (0.0059) time: 1.5772 (1.4122) data: 0.3713 (0.3748) loss_classifier_mask: 0.1577 (0.1312) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0111 (0.0143) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.000947 max mem: 4832\n",
            "2023-02-03 13:51:07,500 maskrcnn_benchmark.trainer INFO: eta: 23:13:03 iter: 940 loss: 1.9383 (2.0080) loss_classifier: 0.1643 (0.1891) loss_box_reg: 0.1480 (0.1542) loss_objectness: 0.0363 (0.1186) loss_rpn_box_reg: 0.0365 (0.0925) loss_da_image: 0.6662 (0.6864) loss_da_instance: 0.6774 (0.6878) loss_da_consistency: 0.0077 (0.0059) time: 1.5661 (1.4152) data: 0.3662 (0.3747) loss_classifier_mask: 0.1207 (0.1314) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0080 (0.0141) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.000961 max mem: 4832\n",
            "2023-02-03 13:51:38,873 maskrcnn_benchmark.trainer INFO: eta: 23:15:43 iter: 960 loss: 2.0145 (2.0092) loss_classifier: 0.1708 (0.1895) loss_box_reg: 0.1906 (0.1555) loss_objectness: 0.0263 (0.1174) loss_rpn_box_reg: 0.0304 (0.0918) loss_da_image: 0.6714 (0.6861) loss_da_instance: 0.6805 (0.6877) loss_da_consistency: 0.0076 (0.0060) time: 1.5664 (1.4184) data: 0.3704 (0.3746) loss_classifier_mask: 0.1769 (0.1323) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0107 (0.0140) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.000974 max mem: 4832\n",
            "2023-02-03 13:52:10,129 maskrcnn_benchmark.trainer INFO: eta: 23:18:09 iter: 980 loss: 2.0563 (2.0101) loss_classifier: 0.1762 (0.1896) loss_box_reg: 0.1844 (0.1566) loss_objectness: 0.0511 (0.1163) loss_rpn_box_reg: 0.0589 (0.0915) loss_da_image: 0.6706 (0.6857) loss_da_instance: 0.6801 (0.6876) loss_da_consistency: 0.0081 (0.0060) time: 1.5720 (1.4214) data: 0.3739 (0.3745) loss_classifier_mask: 0.1293 (0.1326) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0099 (0.0140) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.000987 max mem: 4832\n",
            "2023-02-03 13:52:41,369 maskrcnn_benchmark.trainer INFO: eta: 23:20:26 iter: 1000 loss: 1.8719 (2.0105) loss_classifier: 0.1477 (0.1897) loss_box_reg: 0.1520 (0.1577) loss_objectness: 0.0351 (0.1148) loss_rpn_box_reg: 0.0248 (0.0913) loss_da_image: 0.6640 (0.6854) loss_da_instance: 0.6778 (0.6874) loss_da_consistency: 0.0085 (0.0061) time: 1.5701 (1.4242) data: 0.3669 (0.3745) loss_classifier_mask: 0.1481 (0.1330) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0049 (0.0139) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 13:52:41,372 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./model_0001000.pth\n",
            "2023-02-03 13:53:13,768 maskrcnn_benchmark.trainer INFO: eta: 23:23:44 iter: 1020 loss: 1.9370 (2.0106) loss_classifier: 0.1360 (0.1896) loss_box_reg: 0.1556 (0.1586) loss_objectness: 0.0292 (0.1133) loss_rpn_box_reg: 0.0399 (0.0911) loss_da_image: 0.6624 (0.6850) loss_da_instance: 0.6746 (0.6872) loss_da_consistency: 0.0095 (0.0061) time: 1.5839 (1.4280) data: 0.3695 (0.3757) loss_classifier_mask: 0.1737 (0.1341) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0054 (0.0138) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 13:53:45,405 maskrcnn_benchmark.trainer INFO: eta: 23:26:09 iter: 1040 loss: 2.1853 (2.0139) loss_classifier: 0.2540 (0.1907) loss_box_reg: 0.2911 (0.1607) loss_objectness: 0.0322 (0.1121) loss_rpn_box_reg: 0.0540 (0.0912) loss_da_image: 0.6643 (0.6846) loss_da_instance: 0.6787 (0.6871) loss_da_consistency: 0.0084 (0.0062) time: 1.5781 (1.4310) data: 0.3666 (0.3756) loss_classifier_mask: 0.1491 (0.1349) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0096 (0.0137) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 13:54:16,722 maskrcnn_benchmark.trainer INFO: eta: 23:28:11 iter: 1060 loss: 1.8254 (2.0128) loss_classifier: 0.1532 (0.1902) loss_box_reg: 0.1384 (0.1608) loss_objectness: 0.0359 (0.1111) loss_rpn_box_reg: 0.0412 (0.0907) loss_da_image: 0.6631 (0.6842) loss_da_instance: 0.6795 (0.6869) loss_da_consistency: 0.0102 (0.0063) time: 1.5671 (1.4335) data: 0.3633 (0.3754) loss_classifier_mask: 0.1492 (0.1348) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0087 (0.0136) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 13:54:48,129 maskrcnn_benchmark.trainer INFO: eta: 23:30:11 iter: 1080 loss: 1.9559 (2.0149) loss_classifier: 0.1767 (0.1908) loss_box_reg: 0.2078 (0.1617) loss_objectness: 0.0312 (0.1107) loss_rpn_box_reg: 0.0710 (0.0912) loss_da_image: 0.6585 (0.6838) loss_da_instance: 0.6817 (0.6868) loss_da_consistency: 0.0101 (0.0064) time: 1.5662 (1.4360) data: 0.3635 (0.3753) loss_classifier_mask: 0.0961 (0.1346) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0105 (0.0136) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 13:55:19,386 maskrcnn_benchmark.trainer INFO: eta: 23:31:58 iter: 1100 loss: 1.9775 (2.0144) loss_classifier: 0.1714 (0.1907) loss_box_reg: 0.1712 (0.1621) loss_objectness: 0.0566 (0.1100) loss_rpn_box_reg: 0.0562 (0.0908) loss_da_image: 0.6535 (0.6833) loss_da_instance: 0.6766 (0.6866) loss_da_consistency: 0.0104 (0.0064) time: 1.5774 (1.4383) data: 0.3675 (0.3752) loss_classifier_mask: 0.1393 (0.1345) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0094 (0.0135) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 13:55:50,504 maskrcnn_benchmark.trainer INFO: eta: 23:33:33 iter: 1120 loss: 2.0006 (2.0162) loss_classifier: 0.1762 (0.1912) loss_box_reg: 0.1984 (0.1636) loss_objectness: 0.0344 (0.1089) loss_rpn_box_reg: 0.0719 (0.0908) loss_da_image: 0.6560 (0.6828) loss_da_instance: 0.6756 (0.6865) loss_da_consistency: 0.0096 (0.0065) time: 1.5691 (1.4404) data: 0.3703 (0.3751) loss_classifier_mask: 0.1573 (0.1351) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0109 (0.0135) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 13:56:21,733 maskrcnn_benchmark.trainer INFO: eta: 23:35:09 iter: 1140 loss: 2.0505 (2.0164) loss_classifier: 0.2193 (0.1918) loss_box_reg: 0.2492 (0.1645) loss_objectness: 0.0399 (0.1079) loss_rpn_box_reg: 0.0292 (0.0901) loss_da_image: 0.6579 (0.6824) loss_da_instance: 0.6764 (0.6863) loss_da_consistency: 0.0103 (0.0066) time: 1.5772 (1.4426) data: 0.3666 (0.3750) loss_classifier_mask: 0.0894 (0.1349) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0058 (0.0134) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 13:56:53,230 maskrcnn_benchmark.trainer INFO: eta: 23:36:54 iter: 1160 loss: 1.9888 (2.0162) loss_classifier: 0.1854 (0.1918) loss_box_reg: 0.1945 (0.1652) loss_objectness: 0.0295 (0.1069) loss_rpn_box_reg: 0.0361 (0.0898) loss_da_image: 0.6533 (0.6820) loss_da_instance: 0.6738 (0.6861) loss_da_consistency: 0.0111 (0.0067) time: 1.5712 (1.4448) data: 0.3659 (0.3749) loss_classifier_mask: 0.1274 (0.1352) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0108 (0.0133) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 13:57:24,679 maskrcnn_benchmark.trainer INFO: eta: 23:38:32 iter: 1180 loss: 2.0579 (2.0172) loss_classifier: 0.1837 (0.1917) loss_box_reg: 0.2307 (0.1663) loss_objectness: 0.0511 (0.1067) loss_rpn_box_reg: 0.0698 (0.0896) loss_da_image: 0.6490 (0.6815) loss_da_instance: 0.6736 (0.6860) loss_da_consistency: 0.0115 (0.0067) time: 1.5661 (1.4470) data: 0.3693 (0.3749) loss_classifier_mask: 0.1403 (0.1353) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0079 (0.0133) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 13:57:56,361 maskrcnn_benchmark.trainer INFO: eta: 23:40:18 iter: 1200 loss: 2.0583 (2.0184) loss_classifier: 0.2078 (0.1921) loss_box_reg: 0.2250 (0.1675) loss_objectness: 0.0415 (0.1058) loss_rpn_box_reg: 0.0613 (0.0895) loss_da_image: 0.6495 (0.6810) loss_da_instance: 0.6791 (0.6858) loss_da_consistency: 0.0110 (0.0068) time: 1.5841 (1.4493) data: 0.3729 (0.3749) loss_classifier_mask: 0.1456 (0.1357) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0082 (0.0132) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 13:58:27,717 maskrcnn_benchmark.trainer INFO: eta: 23:41:43 iter: 1220 loss: 2.1591 (2.0196) loss_classifier: 0.2285 (0.1925) loss_box_reg: 0.2255 (0.1683) loss_objectness: 0.0299 (0.1053) loss_rpn_box_reg: 0.0762 (0.0896) loss_da_image: 0.6545 (0.6806) loss_da_instance: 0.6751 (0.6857) loss_da_consistency: 0.0116 (0.0069) time: 1.5647 (1.4512) data: 0.3659 (0.3748) loss_classifier_mask: 0.1218 (0.1354) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0051 (0.0130) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 13:58:59,072 maskrcnn_benchmark.trainer INFO: eta: 23:43:04 iter: 1240 loss: 2.0984 (2.0202) loss_classifier: 0.2287 (0.1928) loss_box_reg: 0.2330 (0.1691) loss_objectness: 0.0372 (0.1043) loss_rpn_box_reg: 0.0750 (0.0896) loss_da_image: 0.6469 (0.6800) loss_da_instance: 0.6747 (0.6855) loss_da_consistency: 0.0111 (0.0070) time: 1.5802 (1.4531) data: 0.3675 (0.3748) loss_classifier_mask: 0.1588 (0.1362) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0076 (0.0129) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 13:59:30,653 maskrcnn_benchmark.trainer INFO: eta: 23:44:32 iter: 1260 loss: 1.9507 (2.0202) loss_classifier: 0.1806 (0.1930) loss_box_reg: 0.2063 (0.1695) loss_objectness: 0.0242 (0.1032) loss_rpn_box_reg: 0.0450 (0.0897) loss_da_image: 0.6410 (0.6794) loss_da_instance: 0.6768 (0.6853) loss_da_consistency: 0.0128 (0.0071) time: 1.5770 (1.4551) data: 0.3733 (0.3748) loss_classifier_mask: 0.1646 (0.1367) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0070 (0.0128) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:00:01,811 maskrcnn_benchmark.trainer INFO: eta: 23:45:37 iter: 1280 loss: 2.0438 (2.0201) loss_classifier: 0.1963 (0.1932) loss_box_reg: 0.2090 (0.1701) loss_objectness: 0.0362 (0.1023) loss_rpn_box_reg: 0.0558 (0.0895) loss_da_image: 0.6372 (0.6788) loss_da_instance: 0.6726 (0.6852) loss_da_consistency: 0.0140 (0.0072) time: 1.5730 (1.4567) data: 0.3657 (0.3746) loss_classifier_mask: 0.1434 (0.1367) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0085 (0.0128) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:00:33,398 maskrcnn_benchmark.trainer INFO: eta: 23:46:59 iter: 1300 loss: 1.9584 (2.0205) loss_classifier: 0.1978 (0.1936) loss_box_reg: 0.1812 (0.1707) loss_objectness: 0.0372 (0.1016) loss_rpn_box_reg: 0.0551 (0.0894) loss_da_image: 0.6396 (0.6783) loss_da_instance: 0.6784 (0.6851) loss_da_consistency: 0.0139 (0.0073) time: 1.5784 (1.4586) data: 0.3669 (0.3746) loss_classifier_mask: 0.1434 (0.1368) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0082 (0.0127) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:01:04,640 maskrcnn_benchmark.trainer INFO: eta: 23:48:02 iter: 1320 loss: 2.0598 (2.0211) loss_classifier: 0.2371 (0.1941) loss_box_reg: 0.2551 (0.1716) loss_objectness: 0.0370 (0.1006) loss_rpn_box_reg: 0.0624 (0.0892) loss_da_image: 0.6370 (0.6777) loss_da_instance: 0.6746 (0.6849) loss_da_consistency: 0.0143 (0.0074) time: 1.5710 (1.4602) data: 0.3650 (0.3746) loss_classifier_mask: 0.1750 (0.1372) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0079 (0.0127) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:01:35,068 maskrcnn_benchmark.trainer INFO: eta: 23:48:26 iter: 1340 loss: 1.9919 (2.0211) loss_classifier: 0.2067 (0.1943) loss_box_reg: 0.1925 (0.1720) loss_objectness: 0.0342 (0.0999) loss_rpn_box_reg: 0.0455 (0.0892) loss_da_image: 0.6336 (0.6771) loss_da_instance: 0.6779 (0.6848) loss_da_consistency: 0.0149 (0.0076) time: 1.5762 (1.4611) data: 0.3687 (0.3745) loss_classifier_mask: 0.1608 (0.1378) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0087 (0.0126) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:02:06,531 maskrcnn_benchmark.trainer INFO: eta: 23:49:34 iter: 1360 loss: 1.9469 (2.0203) loss_classifier: 0.1921 (0.1943) loss_box_reg: 0.1796 (0.1724) loss_objectness: 0.0339 (0.0991) loss_rpn_box_reg: 0.0620 (0.0890) loss_da_image: 0.6330 (0.6765) loss_da_instance: 0.6738 (0.6846) loss_da_consistency: 0.0148 (0.0077) time: 1.5669 (1.4627) data: 0.3647 (0.3744) loss_classifier_mask: 0.1231 (0.1373) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0064 (0.0126) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:02:38,111 maskrcnn_benchmark.trainer INFO: eta: 23:50:43 iter: 1380 loss: 1.9718 (2.0205) loss_classifier: 0.1629 (0.1940) loss_box_reg: 0.1585 (0.1725) loss_objectness: 0.0555 (0.0987) loss_rpn_box_reg: 0.0661 (0.0892) loss_da_image: 0.6318 (0.6759) loss_da_instance: 0.6725 (0.6845) loss_da_consistency: 0.0138 (0.0078) time: 1.5724 (1.4644) data: 0.3681 (0.3744) loss_classifier_mask: 0.1519 (0.1380) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0090 (0.0126) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:03:09,663 maskrcnn_benchmark.trainer INFO: eta: 23:51:48 iter: 1400 loss: 1.9995 (2.0199) loss_classifier: 0.1809 (0.1939) loss_box_reg: 0.1791 (0.1727) loss_objectness: 0.0372 (0.0979) loss_rpn_box_reg: 0.0773 (0.0892) loss_da_image: 0.6345 (0.6754) loss_da_instance: 0.6740 (0.6843) loss_da_consistency: 0.0150 (0.0079) time: 1.5753 (1.4660) data: 0.3643 (0.3744) loss_classifier_mask: 0.1360 (0.1380) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0059 (0.0125) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:03:41,060 maskrcnn_benchmark.trainer INFO: eta: 23:52:45 iter: 1420 loss: 2.0543 (2.0199) loss_classifier: 0.1977 (0.1942) loss_box_reg: 0.2030 (0.1732) loss_objectness: 0.0411 (0.0973) loss_rpn_box_reg: 0.0575 (0.0891) loss_da_image: 0.6386 (0.6749) loss_da_instance: 0.6724 (0.6841) loss_da_consistency: 0.0167 (0.0080) time: 1.5667 (1.4675) data: 0.3599 (0.3743) loss_classifier_mask: 0.1048 (0.1377) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0050 (0.0124) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:04:12,302 maskrcnn_benchmark.trainer INFO: eta: 23:53:32 iter: 1440 loss: 1.9563 (2.0200) loss_classifier: 0.1885 (0.1945) loss_box_reg: 0.1737 (0.1735) loss_objectness: 0.0446 (0.0970) loss_rpn_box_reg: 0.0595 (0.0892) loss_da_image: 0.6308 (0.6743) loss_da_instance: 0.6726 (0.6840) loss_da_consistency: 0.0150 (0.0081) time: 1.5744 (1.4688) data: 0.3674 (0.3742) loss_classifier_mask: 0.1188 (0.1373) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0055 (0.0123) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:04:44,309 maskrcnn_benchmark.trainer INFO: eta: 23:54:48 iter: 1460 loss: 2.0471 (2.0207) loss_classifier: 0.1958 (0.1946) loss_box_reg: 0.2443 (0.1744) loss_objectness: 0.0508 (0.0967) loss_rpn_box_reg: 0.0421 (0.0890) loss_da_image: 0.6366 (0.6737) loss_da_instance: 0.6724 (0.6839) loss_da_consistency: 0.0176 (0.0083) time: 1.5907 (1.4706) data: 0.3695 (0.3742) loss_classifier_mask: 0.1565 (0.1373) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0120 (0.0123) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:05:15,715 maskrcnn_benchmark.trainer INFO: eta: 23:55:38 iter: 1480 loss: 1.8962 (2.0192) loss_classifier: 0.1616 (0.1943) loss_box_reg: 0.1622 (0.1745) loss_objectness: 0.0426 (0.0962) loss_rpn_box_reg: 0.0347 (0.0885) loss_da_image: 0.6296 (0.6731) loss_da_instance: 0.6654 (0.6837) loss_da_consistency: 0.0178 (0.0084) time: 1.5668 (1.4719) data: 0.3651 (0.3741) loss_classifier_mask: 0.1371 (0.1372) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0071 (0.0122) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:05:46,587 maskrcnn_benchmark.trainer INFO: eta: 23:56:04 iter: 1500 loss: 1.9393 (2.0184) loss_classifier: 0.2249 (0.1945) loss_box_reg: 0.2066 (0.1749) loss_objectness: 0.0361 (0.0955) loss_rpn_box_reg: 0.0620 (0.0882) loss_da_image: 0.6114 (0.6723) loss_da_instance: 0.6621 (0.6834) loss_da_consistency: 0.0184 (0.0085) time: 1.5679 (1.4729) data: 0.3679 (0.3741) loss_classifier_mask: 0.1394 (0.1372) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0057 (0.0121) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:06:17,964 maskrcnn_benchmark.trainer INFO: eta: 23:56:48 iter: 1520 loss: 1.7480 (2.0163) loss_classifier: 0.1509 (0.1943) loss_box_reg: 0.0964 (0.1747) loss_objectness: 0.0377 (0.0948) loss_rpn_box_reg: 0.0330 (0.0877) loss_da_image: 0.6235 (0.6717) loss_da_instance: 0.6636 (0.6832) loss_da_consistency: 0.0186 (0.0087) time: 1.5811 (1.4742) data: 0.3697 (0.3741) loss_classifier_mask: 0.1167 (0.1368) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0053 (0.0120) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:06:49,092 maskrcnn_benchmark.trainer INFO: eta: 23:57:21 iter: 1540 loss: 1.7835 (2.0146) loss_classifier: 0.1516 (0.1941) loss_box_reg: 0.1480 (0.1747) loss_objectness: 0.0345 (0.0942) loss_rpn_box_reg: 0.0255 (0.0874) loss_da_image: 0.6088 (0.6709) loss_da_instance: 0.6661 (0.6830) loss_da_consistency: 0.0199 (0.0088) time: 1.5679 (1.4752) data: 0.3630 (0.3740) loss_classifier_mask: 0.1108 (0.1365) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0095 (0.0120) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:07:20,426 maskrcnn_benchmark.trainer INFO: eta: 23:58:00 iter: 1560 loss: 1.9668 (2.0138) loss_classifier: 0.1750 (0.1942) loss_box_reg: 0.2198 (0.1751) loss_objectness: 0.0307 (0.0935) loss_rpn_box_reg: 0.0268 (0.0872) loss_da_image: 0.6085 (0.6702) loss_da_instance: 0.6678 (0.6828) loss_da_consistency: 0.0186 (0.0090) time: 1.5809 (1.4764) data: 0.3694 (0.3739) loss_classifier_mask: 0.1272 (0.1363) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0057 (0.0119) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:07:51,661 maskrcnn_benchmark.trainer INFO: eta: 23:58:34 iter: 1580 loss: 1.9064 (2.0134) loss_classifier: 0.1804 (0.1945) loss_box_reg: 0.2132 (0.1754) loss_objectness: 0.0363 (0.0930) loss_rpn_box_reg: 0.0309 (0.0872) loss_da_image: 0.6199 (0.6695) loss_da_instance: 0.6683 (0.6827) loss_da_consistency: 0.0204 (0.0091) time: 1.5757 (1.4775) data: 0.3675 (0.3739) loss_classifier_mask: 0.1176 (0.1360) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0062 (0.0118) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:08:23,755 maskrcnn_benchmark.trainer INFO: eta: 23:59:37 iter: 1600 loss: 1.9128 (2.0122) loss_classifier: 0.1556 (0.1941) loss_box_reg: 0.1462 (0.1752) loss_objectness: 0.0488 (0.0926) loss_rpn_box_reg: 0.0433 (0.0870) loss_da_image: 0.6090 (0.6688) loss_da_instance: 0.6724 (0.6826) loss_da_consistency: 0.0195 (0.0093) time: 1.5916 (1.4791) data: 0.3700 (0.3739) loss_classifier_mask: 0.1354 (0.1363) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0105 (0.0118) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:08:54,864 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:00:03 iter: 1620 loss: 2.0326 (2.0126) loss_classifier: 0.2241 (0.1944) loss_box_reg: 0.2156 (0.1758) loss_objectness: 0.0417 (0.0921) loss_rpn_box_reg: 0.0988 (0.0873) loss_da_image: 0.6063 (0.6680) loss_da_instance: 0.6705 (0.6824) loss_da_consistency: 0.0198 (0.0094) time: 1.5660 (1.4800) data: 0.3720 (0.3739) loss_classifier_mask: 0.1301 (0.1363) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0071 (0.0117) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:09:26,391 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:00:41 iter: 1640 loss: 1.9145 (2.0117) loss_classifier: 0.1794 (0.1942) loss_box_reg: 0.1827 (0.1759) loss_objectness: 0.0260 (0.0915) loss_rpn_box_reg: 0.0348 (0.0868) loss_da_image: 0.6090 (0.6673) loss_da_instance: 0.6717 (0.6823) loss_da_consistency: 0.0215 (0.0095) time: 1.5709 (1.4812) data: 0.3687 (0.3739) loss_classifier_mask: 0.1869 (0.1370) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0104 (0.0117) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:09:58,053 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:01:23 iter: 1660 loss: 2.0331 (2.0113) loss_classifier: 0.2116 (0.1944) loss_box_reg: 0.2175 (0.1763) loss_objectness: 0.0128 (0.0907) loss_rpn_box_reg: 0.0411 (0.0863) loss_da_image: 0.6013 (0.6665) loss_da_instance: 0.6727 (0.6821) loss_da_consistency: 0.0241 (0.0097) time: 1.5817 (1.4824) data: 0.3721 (0.3739) loss_classifier_mask: 0.1457 (0.1374) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0053 (0.0117) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:10:29,789 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:02:06 iter: 1680 loss: 1.9586 (2.0108) loss_classifier: 0.1893 (0.1944) loss_box_reg: 0.2275 (0.1767) loss_objectness: 0.0323 (0.0902) loss_rpn_box_reg: 0.0698 (0.0863) loss_da_image: 0.6028 (0.6658) loss_da_instance: 0.6678 (0.6820) loss_da_consistency: 0.0200 (0.0099) time: 1.5640 (1.4837) data: 0.3686 (0.3739) loss_classifier_mask: 0.1480 (0.1374) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0049 (0.0116) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:11:01,239 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:02:37 iter: 1700 loss: 1.9463 (2.0102) loss_classifier: 0.1851 (0.1944) loss_box_reg: 0.1763 (0.1769) loss_objectness: 0.0346 (0.0898) loss_rpn_box_reg: 0.0788 (0.0865) loss_da_image: 0.5974 (0.6650) loss_da_instance: 0.6687 (0.6818) loss_da_consistency: 0.0239 (0.0100) time: 1.5697 (1.4847) data: 0.3681 (0.3738) loss_classifier_mask: 0.1200 (0.1373) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0050 (0.0115) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:11:31,780 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:02:36 iter: 1720 loss: 1.8965 (2.0096) loss_classifier: 0.1825 (0.1945) loss_box_reg: 0.1915 (0.1772) loss_objectness: 0.0261 (0.0893) loss_rpn_box_reg: 0.0388 (0.0863) loss_da_image: 0.5949 (0.6642) loss_da_instance: 0.6772 (0.6818) loss_da_consistency: 0.0217 (0.0102) time: 1.5694 (1.4852) data: 0.3657 (0.3738) loss_classifier_mask: 0.1469 (0.1374) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0068 (0.0115) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:12:03,032 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:02:59 iter: 1740 loss: 1.8741 (2.0083) loss_classifier: 0.1793 (0.1943) loss_box_reg: 0.1572 (0.1772) loss_objectness: 0.0259 (0.0886) loss_rpn_box_reg: 0.0413 (0.0863) loss_da_image: 0.5889 (0.6634) loss_da_instance: 0.6726 (0.6816) loss_da_consistency: 0.0253 (0.0104) time: 1.5540 (1.4861) data: 0.3667 (0.3737) loss_classifier_mask: 0.1395 (0.1373) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0024 (0.0114) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:12:34,394 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:03:23 iter: 1760 loss: 1.8712 (2.0072) loss_classifier: 0.1466 (0.1940) loss_box_reg: 0.1738 (0.1771) loss_objectness: 0.0366 (0.0882) loss_rpn_box_reg: 0.0522 (0.0863) loss_da_image: 0.5945 (0.6626) loss_da_instance: 0.6684 (0.6815) loss_da_consistency: 0.0233 (0.0105) time: 1.5818 (1.4870) data: 0.3710 (0.3737) loss_classifier_mask: 0.1439 (0.1373) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0068 (0.0114) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:13:05,828 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:03:49 iter: 1780 loss: 1.9634 (2.0064) loss_classifier: 0.2078 (0.1942) loss_box_reg: 0.2313 (0.1777) loss_objectness: 0.0284 (0.0877) loss_rpn_box_reg: 0.0355 (0.0861) loss_da_image: 0.5850 (0.6618) loss_da_instance: 0.6694 (0.6814) loss_da_consistency: 0.0216 (0.0107) time: 1.5633 (1.4880) data: 0.3627 (0.3737) loss_classifier_mask: 0.1050 (0.1370) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0049 (0.0113) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:13:37,485 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:04:20 iter: 1800 loss: 1.9527 (2.0053) loss_classifier: 0.1984 (0.1942) loss_box_reg: 0.2171 (0.1778) loss_objectness: 0.0264 (0.0871) loss_rpn_box_reg: 0.0561 (0.0860) loss_da_image: 0.5703 (0.6609) loss_da_instance: 0.6754 (0.6813) loss_da_consistency: 0.0243 (0.0109) time: 1.5803 (1.4890) data: 0.3671 (0.3737) loss_classifier_mask: 0.1060 (0.1368) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0034 (0.0112) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:14:09,022 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:04:47 iter: 1820 loss: 2.0162 (2.0056) loss_classifier: 0.2011 (0.1944) loss_box_reg: 0.2341 (0.1783) loss_objectness: 0.0340 (0.0867) loss_rpn_box_reg: 0.0668 (0.0861) loss_da_image: 0.5679 (0.6599) loss_da_instance: 0.6712 (0.6812) loss_da_consistency: 0.0234 (0.0110) time: 1.5778 (1.4900) data: 0.3668 (0.3736) loss_classifier_mask: 0.1501 (0.1372) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0104 (0.0112) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:14:39,604 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:04:42 iter: 1840 loss: 1.8583 (2.0052) loss_classifier: 0.1708 (0.1941) loss_box_reg: 0.1946 (0.1785) loss_objectness: 0.0585 (0.0870) loss_rpn_box_reg: 0.0688 (0.0862) loss_da_image: 0.5748 (0.6589) loss_da_instance: 0.6739 (0.6811) loss_da_consistency: 0.0255 (0.0112) time: 1.5721 (1.4904) data: 0.3632 (0.3736) loss_classifier_mask: 0.1366 (0.1371) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0092 (0.0112) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:15:10,957 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:05:00 iter: 1860 loss: 1.7995 (2.0039) loss_classifier: 0.1226 (0.1937) loss_box_reg: 0.1543 (0.1785) loss_objectness: 0.0439 (0.0867) loss_rpn_box_reg: 0.0301 (0.0859) loss_da_image: 0.5651 (0.6580) loss_da_instance: 0.6775 (0.6811) loss_da_consistency: 0.0238 (0.0114) time: 1.5809 (1.4912) data: 0.3693 (0.3736) loss_classifier_mask: 0.1492 (0.1375) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0089 (0.0112) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:15:41,399 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:04:49 iter: 1880 loss: 1.8860 (2.0034) loss_classifier: 0.1862 (0.1938) loss_box_reg: 0.2353 (0.1791) loss_objectness: 0.0227 (0.0861) loss_rpn_box_reg: 0.0638 (0.0859) loss_da_image: 0.5686 (0.6571) loss_da_instance: 0.6734 (0.6810) loss_da_consistency: 0.0299 (0.0116) time: 1.5710 (1.4916) data: 0.3655 (0.3736) loss_classifier_mask: 0.1280 (0.1373) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0089 (0.0111) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:16:12,760 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:05:06 iter: 1900 loss: 1.7256 (2.0012) loss_classifier: 0.1265 (0.1933) loss_box_reg: 0.1252 (0.1787) loss_objectness: 0.0244 (0.0858) loss_rpn_box_reg: 0.0378 (0.0856) loss_da_image: 0.5703 (0.6561) loss_da_instance: 0.6766 (0.6810) loss_da_consistency: 0.0220 (0.0117) time: 1.5776 (1.4924) data: 0.3696 (0.3735) loss_classifier_mask: 0.1094 (0.1373) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0069 (0.0111) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:16:44,484 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:05:33 iter: 1920 loss: 1.8988 (2.0005) loss_classifier: 0.1870 (0.1932) loss_box_reg: 0.1808 (0.1789) loss_objectness: 0.0340 (0.0854) loss_rpn_box_reg: 0.0467 (0.0855) loss_da_image: 0.5752 (0.6553) loss_da_instance: 0.6752 (0.6810) loss_da_consistency: 0.0208 (0.0118) time: 1.5701 (1.4933) data: 0.3672 (0.3735) loss_classifier_mask: 0.1272 (0.1372) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0087 (0.0111) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:17:15,468 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:05:37 iter: 1940 loss: 1.9856 (2.0003) loss_classifier: 0.2038 (0.1934) loss_box_reg: 0.2216 (0.1793) loss_objectness: 0.0378 (0.0850) loss_rpn_box_reg: 0.0763 (0.0856) loss_da_image: 0.5738 (0.6544) loss_da_instance: 0.6754 (0.6809) loss_da_consistency: 0.0233 (0.0119) time: 1.5624 (1.4939) data: 0.3665 (0.3735) loss_classifier_mask: 0.0989 (0.1371) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0067 (0.0111) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:17:47,039 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:05:57 iter: 1960 loss: 1.8354 (1.9993) loss_classifier: 0.1597 (0.1933) loss_box_reg: 0.1447 (0.1792) loss_objectness: 0.0247 (0.0847) loss_rpn_box_reg: 0.0345 (0.0855) loss_da_image: 0.5658 (0.6536) loss_da_instance: 0.6754 (0.6809) loss_da_consistency: 0.0238 (0.0121) time: 1.5771 (1.4948) data: 0.3648 (0.3734) loss_classifier_mask: 0.1214 (0.1370) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0068 (0.0110) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:18:18,521 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:06:13 iter: 1980 loss: 1.8311 (1.9979) loss_classifier: 0.1617 (0.1931) loss_box_reg: 0.1482 (0.1791) loss_objectness: 0.0318 (0.0842) loss_rpn_box_reg: 0.0528 (0.0854) loss_da_image: 0.5707 (0.6528) loss_da_instance: 0.6767 (0.6809) loss_da_consistency: 0.0229 (0.0122) time: 1.5720 (1.4956) data: 0.3714 (0.3734) loss_classifier_mask: 0.1225 (0.1369) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0101 (0.0110) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:18:49,956 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:06:28 iter: 2000 loss: 1.8309 (1.9970) loss_classifier: 0.1703 (0.1931) loss_box_reg: 0.1639 (0.1791) loss_objectness: 0.0187 (0.0837) loss_rpn_box_reg: 0.0301 (0.0853) loss_da_image: 0.5690 (0.6520) loss_da_instance: 0.6797 (0.6808) loss_da_consistency: 0.0266 (0.0123) time: 1.5682 (1.4963) data: 0.3638 (0.3734) loss_classifier_mask: 0.1178 (0.1369) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0087 (0.0110) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:18:49,958 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./model_0002000.pth\n",
            "2023-02-03 14:19:22,599 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:07:16 iter: 2020 loss: 1.8742 (1.9959) loss_classifier: 0.1588 (0.1930) loss_box_reg: 0.1571 (0.1791) loss_objectness: 0.0307 (0.0834) loss_rpn_box_reg: 0.0452 (0.0851) loss_da_image: 0.5742 (0.6512) loss_da_instance: 0.6761 (0.6808) loss_da_consistency: 0.0247 (0.0125) time: 1.5740 (1.4977) data: 0.3708 (0.3739) loss_classifier_mask: 0.1281 (0.1369) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0056 (0.0109) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:19:54,215 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:07:33 iter: 2040 loss: 1.9509 (1.9955) loss_classifier: 0.1716 (0.1930) loss_box_reg: 0.2027 (0.1793) loss_objectness: 0.0300 (0.0829) loss_rpn_box_reg: 0.0316 (0.0850) loss_da_image: 0.5706 (0.6504) loss_da_instance: 0.6767 (0.6808) loss_da_consistency: 0.0242 (0.0126) time: 1.5764 (1.4985) data: 0.3709 (0.3739) loss_classifier_mask: 0.1524 (0.1373) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0070 (0.0109) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:20:25,879 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:07:51 iter: 2060 loss: 1.9882 (1.9956) loss_classifier: 0.1800 (0.1931) loss_box_reg: 0.2187 (0.1798) loss_objectness: 0.0337 (0.0825) loss_rpn_box_reg: 0.0586 (0.0849) loss_da_image: 0.5664 (0.6496) loss_da_instance: 0.6767 (0.6807) loss_da_consistency: 0.0244 (0.0127) time: 1.5835 (1.4993) data: 0.3692 (0.3738) loss_classifier_mask: 0.1698 (0.1377) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0107 (0.0110) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:20:57,258 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:07:59 iter: 2080 loss: 1.7953 (1.9944) loss_classifier: 0.1511 (0.1929) loss_box_reg: 0.1489 (0.1796) loss_objectness: 0.0166 (0.0820) loss_rpn_box_reg: 0.0271 (0.0847) loss_da_image: 0.5665 (0.6489) loss_da_instance: 0.6822 (0.6808) loss_da_consistency: 0.0274 (0.0129) time: 1.5858 (1.5000) data: 0.3679 (0.3739) loss_classifier_mask: 0.1731 (0.1380) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0134 (0.0110) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:21:27,928 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:07:48 iter: 2100 loss: 2.1050 (1.9950) loss_classifier: 0.2532 (0.1933) loss_box_reg: 0.2205 (0.1798) loss_objectness: 0.0423 (0.0817) loss_rpn_box_reg: 0.0643 (0.0850) loss_da_image: 0.5734 (0.6482) loss_da_instance: 0.6726 (0.6807) loss_da_consistency: 0.0260 (0.0130) time: 1.5622 (1.5003) data: 0.3614 (0.3738) loss_classifier_mask: 0.1512 (0.1383) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0080 (0.0110) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:21:59,621 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:08:04 iter: 2120 loss: 1.9548 (1.9945) loss_classifier: 0.1906 (0.1933) loss_box_reg: 0.1902 (0.1798) loss_objectness: 0.0336 (0.0814) loss_rpn_box_reg: 0.0675 (0.0850) loss_da_image: 0.5586 (0.6475) loss_da_instance: 0.6780 (0.6807) loss_da_consistency: 0.0235 (0.0131) time: 1.5899 (1.5011) data: 0.3674 (0.3738) loss_classifier_mask: 0.1425 (0.1385) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0063 (0.0110) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:22:31,123 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:08:14 iter: 2140 loss: 1.8310 (1.9936) loss_classifier: 0.1544 (0.1932) loss_box_reg: 0.2026 (0.1800) loss_objectness: 0.0268 (0.0810) loss_rpn_box_reg: 0.0572 (0.0850) loss_da_image: 0.5647 (0.6466) loss_da_instance: 0.6802 (0.6807) loss_da_consistency: 0.0224 (0.0132) time: 1.5734 (1.5018) data: 0.3675 (0.3737) loss_classifier_mask: 0.1323 (0.1384) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0057 (0.0109) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:23:02,261 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:08:13 iter: 2160 loss: 1.8789 (1.9927) loss_classifier: 0.1513 (0.1930) loss_box_reg: 0.1639 (0.1799) loss_objectness: 0.0311 (0.0807) loss_rpn_box_reg: 0.0572 (0.0849) loss_da_image: 0.5641 (0.6460) loss_da_instance: 0.6790 (0.6807) loss_da_consistency: 0.0220 (0.0133) time: 1.5727 (1.5023) data: 0.3637 (0.3737) loss_classifier_mask: 0.1537 (0.1386) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0057 (0.0109) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:23:33,802 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:08:23 iter: 2180 loss: 1.7170 (1.9913) loss_classifier: 0.1028 (0.1927) loss_box_reg: 0.1153 (0.1798) loss_objectness: 0.0179 (0.0802) loss_rpn_box_reg: 0.0319 (0.0845) loss_da_image: 0.5516 (0.6451) loss_da_instance: 0.6788 (0.6807) loss_da_consistency: 0.0222 (0.0134) time: 1.5728 (1.5030) data: 0.3694 (0.3737) loss_classifier_mask: 0.1698 (0.1389) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0090 (0.0109) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:24:05,308 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:08:31 iter: 2200 loss: 1.9138 (1.9906) loss_classifier: 0.1949 (0.1928) loss_box_reg: 0.1985 (0.1799) loss_objectness: 0.0314 (0.0799) loss_rpn_box_reg: 0.0625 (0.0844) loss_da_image: 0.5663 (0.6444) loss_da_instance: 0.6791 (0.6806) loss_da_consistency: 0.0228 (0.0135) time: 1.5756 (1.5037) data: 0.3685 (0.3737) loss_classifier_mask: 0.1329 (0.1389) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0043 (0.0108) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:24:37,478 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:08:55 iter: 2220 loss: 1.7268 (1.9898) loss_classifier: 0.1542 (0.1926) loss_box_reg: 0.1682 (0.1800) loss_objectness: 0.0254 (0.0795) loss_rpn_box_reg: 0.0248 (0.0843) loss_da_image: 0.5572 (0.6436) loss_da_instance: 0.6773 (0.6806) loss_da_consistency: 0.0263 (0.0137) time: 1.5910 (1.5046) data: 0.3725 (0.3737) loss_classifier_mask: 0.1612 (0.1392) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0109 (0.0108) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:25:09,393 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:09:12 iter: 2240 loss: 1.7451 (1.9884) loss_classifier: 0.1086 (0.1922) loss_box_reg: 0.0930 (0.1796) loss_objectness: 0.0296 (0.0794) loss_rpn_box_reg: 0.0258 (0.0841) loss_da_image: 0.5617 (0.6428) loss_da_instance: 0.6763 (0.6806) loss_da_consistency: 0.0224 (0.0138) time: 1.5816 (1.5054) data: 0.3756 (0.3737) loss_classifier_mask: 0.1320 (0.1392) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0073 (0.0108) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:25:40,888 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:09:17 iter: 2260 loss: 1.7856 (1.9870) loss_classifier: 0.1555 (0.1918) loss_box_reg: 0.1103 (0.1793) loss_objectness: 0.0343 (0.0791) loss_rpn_box_reg: 0.0333 (0.0837) loss_da_image: 0.5711 (0.6422) loss_da_instance: 0.6840 (0.6807) loss_da_consistency: 0.0226 (0.0138) time: 1.5682 (1.5060) data: 0.3642 (0.3737) loss_classifier_mask: 0.1444 (0.1393) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0118 (0.0109) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:26:12,576 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:09:27 iter: 2280 loss: 1.7980 (1.9861) loss_classifier: 0.1664 (0.1918) loss_box_reg: 0.1624 (0.1791) loss_objectness: 0.0321 (0.0788) loss_rpn_box_reg: 0.0367 (0.0837) loss_da_image: 0.5631 (0.6416) loss_da_instance: 0.6833 (0.6807) loss_da_consistency: 0.0219 (0.0139) time: 1.5805 (1.5067) data: 0.3728 (0.3737) loss_classifier_mask: 0.1367 (0.1393) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0056 (0.0108) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:26:43,629 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:09:20 iter: 2300 loss: 1.7027 (1.9847) loss_classifier: 0.1361 (0.1916) loss_box_reg: 0.1541 (0.1790) loss_objectness: 0.0242 (0.0784) loss_rpn_box_reg: 0.0463 (0.0835) loss_da_image: 0.5680 (0.6410) loss_da_instance: 0.6832 (0.6807) loss_da_consistency: 0.0233 (0.0140) time: 1.5615 (1.5071) data: 0.3670 (0.3737) loss_classifier_mask: 0.0977 (0.1389) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0044 (0.0108) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:27:14,881 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:09:17 iter: 2320 loss: 1.8558 (1.9840) loss_classifier: 0.1660 (0.1914) loss_box_reg: 0.1729 (0.1792) loss_objectness: 0.0294 (0.0780) loss_rpn_box_reg: 0.0345 (0.0834) loss_da_image: 0.5711 (0.6404) loss_da_instance: 0.6852 (0.6807) loss_da_consistency: 0.0180 (0.0141) time: 1.5785 (1.5076) data: 0.3715 (0.3736) loss_classifier_mask: 0.1390 (0.1390) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0078 (0.0108) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:27:46,298 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:09:18 iter: 2340 loss: 1.8029 (1.9831) loss_classifier: 0.1664 (0.1912) loss_box_reg: 0.1545 (0.1792) loss_objectness: 0.0256 (0.0777) loss_rpn_box_reg: 0.0457 (0.0832) loss_da_image: 0.5603 (0.6398) loss_da_instance: 0.6820 (0.6808) loss_da_consistency: 0.0193 (0.0141) time: 1.5643 (1.5081) data: 0.3701 (0.3736) loss_classifier_mask: 0.1426 (0.1391) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0077 (0.0108) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:28:18,234 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:09:31 iter: 2360 loss: 1.8214 (1.9818) loss_classifier: 0.1677 (0.1911) loss_box_reg: 0.1437 (0.1789) loss_objectness: 0.0323 (0.0774) loss_rpn_box_reg: 0.0325 (0.0829) loss_da_image: 0.5623 (0.6392) loss_da_instance: 0.6837 (0.6808) loss_da_consistency: 0.0222 (0.0142) time: 1.5834 (1.5089) data: 0.3676 (0.3736) loss_classifier_mask: 0.1384 (0.1390) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0053 (0.0107) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:28:50,297 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:09:47 iter: 2380 loss: 1.8348 (1.9807) loss_classifier: 0.1606 (0.1908) loss_box_reg: 0.1926 (0.1788) loss_objectness: 0.0226 (0.0771) loss_rpn_box_reg: 0.0248 (0.0827) loss_da_image: 0.5581 (0.6386) loss_da_instance: 0.6812 (0.6808) loss_da_consistency: 0.0225 (0.0143) time: 1.5937 (1.5097) data: 0.3679 (0.3736) loss_classifier_mask: 0.1471 (0.1390) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0065 (0.0107) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:29:22,129 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:09:56 iter: 2400 loss: 1.7887 (1.9794) loss_classifier: 0.1413 (0.1906) loss_box_reg: 0.1356 (0.1786) loss_objectness: 0.0307 (0.0768) loss_rpn_box_reg: 0.0511 (0.0827) loss_da_image: 0.5622 (0.6379) loss_da_instance: 0.6796 (0.6808) loss_da_consistency: 0.0194 (0.0144) time: 1.5896 (1.5104) data: 0.3656 (0.3736) loss_classifier_mask: 0.1204 (0.1389) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0061 (0.0107) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:29:53,421 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:09:52 iter: 2420 loss: 1.8588 (1.9786) loss_classifier: 0.1849 (0.1906) loss_box_reg: 0.2025 (0.1788) loss_objectness: 0.0222 (0.0764) loss_rpn_box_reg: 0.0439 (0.0825) loss_da_image: 0.5674 (0.6374) loss_da_instance: 0.6771 (0.6808) loss_da_consistency: 0.0261 (0.0145) time: 1.5746 (1.5108) data: 0.3660 (0.3736) loss_classifier_mask: 0.1127 (0.1387) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0047 (0.0106) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:30:24,964 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:09:53 iter: 2440 loss: 1.8406 (1.9779) loss_classifier: 0.1398 (0.1905) loss_box_reg: 0.1780 (0.1788) loss_objectness: 0.0183 (0.0760) loss_rpn_box_reg: 0.0300 (0.0824) loss_da_image: 0.5645 (0.6369) loss_da_instance: 0.6791 (0.6808) loss_da_consistency: 0.0263 (0.0146) time: 1.5713 (1.5113) data: 0.3659 (0.3736) loss_classifier_mask: 0.1353 (0.1387) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0049 (0.0106) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:30:56,375 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:09:50 iter: 2460 loss: 1.8207 (1.9766) loss_classifier: 0.1395 (0.1902) loss_box_reg: 0.1487 (0.1786) loss_objectness: 0.0241 (0.0756) loss_rpn_box_reg: 0.0511 (0.0822) loss_da_image: 0.5708 (0.6363) loss_da_instance: 0.6852 (0.6808) loss_da_consistency: 0.0205 (0.0147) time: 1.5648 (1.5118) data: 0.3681 (0.3736) loss_classifier_mask: 0.1233 (0.1388) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0053 (0.0106) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:31:27,935 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:09:51 iter: 2480 loss: 1.7772 (1.9754) loss_classifier: 0.1293 (0.1898) loss_box_reg: 0.1361 (0.1783) loss_objectness: 0.0246 (0.0753) loss_rpn_box_reg: 0.0258 (0.0822) loss_da_image: 0.5719 (0.6358) loss_da_instance: 0.6803 (0.6808) loss_da_consistency: 0.0238 (0.0147) time: 1.5742 (1.5124) data: 0.3626 (0.3735) loss_classifier_mask: 0.1221 (0.1387) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0025 (0.0106) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:31:59,462 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:09:50 iter: 2500 loss: 2.0681 (1.9758) loss_classifier: 0.2060 (0.1900) loss_box_reg: 0.2179 (0.1785) loss_objectness: 0.0315 (0.0752) loss_rpn_box_reg: 0.0989 (0.0824) loss_da_image: 0.5794 (0.6354) loss_da_instance: 0.6857 (0.6808) loss_da_consistency: 0.0182 (0.0148) time: 1.5767 (1.5129) data: 0.3701 (0.3735) loss_classifier_mask: 0.1364 (0.1387) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0090 (0.0106) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:32:30,911 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:09:47 iter: 2520 loss: 1.7815 (1.9744) loss_classifier: 0.1626 (0.1898) loss_box_reg: 0.1267 (0.1782) loss_objectness: 0.0262 (0.0750) loss_rpn_box_reg: 0.0285 (0.0820) loss_da_image: 0.5672 (0.6349) loss_da_instance: 0.6849 (0.6809) loss_da_consistency: 0.0188 (0.0148) time: 1.5701 (1.5133) data: 0.3660 (0.3735) loss_classifier_mask: 0.1262 (0.1387) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0059 (0.0105) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:33:02,581 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:09:48 iter: 2540 loss: 1.9500 (1.9747) loss_classifier: 0.2127 (0.1900) loss_box_reg: 0.2171 (0.1785) loss_objectness: 0.0274 (0.0747) loss_rpn_box_reg: 0.0532 (0.0821) loss_da_image: 0.5671 (0.6344) loss_da_instance: 0.6776 (0.6809) loss_da_consistency: 0.0241 (0.0149) time: 1.5805 (1.5139) data: 0.3662 (0.3735) loss_classifier_mask: 0.1429 (0.1389) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0114 (0.0106) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:33:34,201 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:09:48 iter: 2560 loss: 1.8707 (1.9743) loss_classifier: 0.2096 (0.1903) loss_box_reg: 0.2289 (0.1788) loss_objectness: 0.0281 (0.0745) loss_rpn_box_reg: 0.0495 (0.0819) loss_da_image: 0.5459 (0.6337) loss_da_instance: 0.6748 (0.6808) loss_da_consistency: 0.0214 (0.0150) time: 1.5670 (1.5144) data: 0.3630 (0.3734) loss_classifier_mask: 0.1265 (0.1387) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0051 (0.0105) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:34:05,764 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:09:46 iter: 2580 loss: 1.8709 (1.9737) loss_classifier: 0.1690 (0.1902) loss_box_reg: 0.1747 (0.1790) loss_objectness: 0.0350 (0.0743) loss_rpn_box_reg: 0.0530 (0.0819) loss_da_image: 0.5459 (0.6330) loss_da_instance: 0.6809 (0.6809) loss_da_consistency: 0.0203 (0.0150) time: 1.5806 (1.5149) data: 0.3706 (0.3734) loss_classifier_mask: 0.1166 (0.1387) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0071 (0.0105) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:34:37,294 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:09:43 iter: 2600 loss: 1.8100 (1.9730) loss_classifier: 0.1603 (0.1901) loss_box_reg: 0.1322 (0.1788) loss_objectness: 0.0291 (0.0740) loss_rpn_box_reg: 0.0335 (0.0819) loss_da_image: 0.5570 (0.6324) loss_da_instance: 0.6819 (0.6809) loss_da_consistency: 0.0223 (0.0151) time: 1.5703 (1.5154) data: 0.3662 (0.3734) loss_classifier_mask: 0.1074 (0.1387) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0067 (0.0105) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:35:08,806 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:09:39 iter: 2620 loss: 1.7335 (1.9712) loss_classifier: 0.1351 (0.1897) loss_box_reg: 0.1270 (0.1784) loss_objectness: 0.0166 (0.0736) loss_rpn_box_reg: 0.0100 (0.0815) loss_da_image: 0.5609 (0.6319) loss_da_instance: 0.6809 (0.6809) loss_da_consistency: 0.0202 (0.0152) time: 1.5690 (1.5158) data: 0.3684 (0.3734) loss_classifier_mask: 0.1309 (0.1387) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0065 (0.0104) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:35:40,122 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:09:30 iter: 2640 loss: 1.7428 (1.9699) loss_classifier: 0.1367 (0.1895) loss_box_reg: 0.1439 (0.1782) loss_objectness: 0.0192 (0.0733) loss_rpn_box_reg: 0.0226 (0.0813) loss_da_image: 0.5569 (0.6314) loss_da_instance: 0.6843 (0.6809) loss_da_consistency: 0.0208 (0.0152) time: 1.5811 (1.5162) data: 0.3689 (0.3734) loss_classifier_mask: 0.1135 (0.1387) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0069 (0.0104) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:36:11,548 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:09:24 iter: 2660 loss: 1.8680 (1.9698) loss_classifier: 0.1689 (0.1895) loss_box_reg: 0.1856 (0.1782) loss_objectness: 0.0438 (0.0732) loss_rpn_box_reg: 0.1007 (0.0814) loss_da_image: 0.5648 (0.6309) loss_da_instance: 0.6841 (0.6809) loss_da_consistency: 0.0163 (0.0153) time: 1.5687 (1.5166) data: 0.3646 (0.3734) loss_classifier_mask: 0.1262 (0.1387) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0083 (0.0104) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:36:42,877 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:09:15 iter: 2680 loss: 1.7636 (1.9686) loss_classifier: 0.1452 (0.1893) loss_box_reg: 0.1491 (0.1781) loss_objectness: 0.0323 (0.0730) loss_rpn_box_reg: 0.0399 (0.0812) loss_da_image: 0.5630 (0.6304) loss_da_instance: 0.6847 (0.6810) loss_da_consistency: 0.0185 (0.0153) time: 1.5755 (1.5170) data: 0.3697 (0.3733) loss_classifier_mask: 0.0971 (0.1385) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0038 (0.0104) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:37:14,236 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:09:06 iter: 2700 loss: 1.7828 (1.9677) loss_classifier: 0.1451 (0.1892) loss_box_reg: 0.1179 (0.1780) loss_objectness: 0.0293 (0.0727) loss_rpn_box_reg: 0.0437 (0.0811) loss_da_image: 0.5663 (0.6299) loss_da_instance: 0.6839 (0.6810) loss_da_consistency: 0.0189 (0.0153) time: 1.5567 (1.5174) data: 0.3704 (0.3733) loss_classifier_mask: 0.1365 (0.1385) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0051 (0.0103) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:37:46,653 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:09:19 iter: 2720 loss: 1.8989 (1.9676) loss_classifier: 0.1748 (0.1891) loss_box_reg: 0.1605 (0.1779) loss_objectness: 0.0345 (0.0725) loss_rpn_box_reg: 0.0574 (0.0812) loss_da_image: 0.5720 (0.6296) loss_da_instance: 0.6853 (0.6810) loss_da_consistency: 0.0168 (0.0154) time: 1.6002 (1.5182) data: 0.3767 (0.3734) loss_classifier_mask: 0.1719 (0.1388) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0072 (0.0103) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:38:18,176 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:09:13 iter: 2740 loss: 1.8002 (1.9668) loss_classifier: 0.1377 (0.1889) loss_box_reg: 0.1439 (0.1778) loss_objectness: 0.0225 (0.0723) loss_rpn_box_reg: 0.0374 (0.0810) loss_da_image: 0.5580 (0.6291) loss_da_instance: 0.6830 (0.6811) loss_da_consistency: 0.0221 (0.0154) time: 1.5741 (1.5186) data: 0.3728 (0.3734) loss_classifier_mask: 0.1488 (0.1389) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0046 (0.0103) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:38:49,409 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:09:00 iter: 2760 loss: 1.9040 (1.9662) loss_classifier: 0.1598 (0.1888) loss_box_reg: 0.1650 (0.1778) loss_objectness: 0.0337 (0.0721) loss_rpn_box_reg: 0.0413 (0.0809) loss_da_image: 0.5704 (0.6287) loss_da_instance: 0.6833 (0.6811) loss_da_consistency: 0.0196 (0.0155) time: 1.5735 (1.5189) data: 0.3679 (0.3733) loss_classifier_mask: 0.1405 (0.1389) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0097 (0.0103) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:39:21,043 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:08:56 iter: 2780 loss: 1.8653 (1.9655) loss_classifier: 0.1641 (0.1887) loss_box_reg: 0.1773 (0.1778) loss_objectness: 0.0262 (0.0718) loss_rpn_box_reg: 0.0413 (0.0808) loss_da_image: 0.5577 (0.6282) loss_da_instance: 0.6808 (0.6811) loss_da_consistency: 0.0235 (0.0155) time: 1.5800 (1.5193) data: 0.3652 (0.3733) loss_classifier_mask: 0.1474 (0.1390) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0034 (0.0103) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:39:52,491 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:08:47 iter: 2800 loss: 1.7596 (1.9647) loss_classifier: 0.1343 (0.1884) loss_box_reg: 0.1426 (0.1775) loss_objectness: 0.0392 (0.0718) loss_rpn_box_reg: 0.0326 (0.0807) loss_da_image: 0.5662 (0.6278) loss_da_instance: 0.6841 (0.6811) loss_da_consistency: 0.0254 (0.0156) time: 1.5664 (1.5197) data: 0.3651 (0.3733) loss_classifier_mask: 0.1307 (0.1389) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0059 (0.0103) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:40:24,250 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:08:45 iter: 2820 loss: 1.8723 (1.9639) loss_classifier: 0.1409 (0.1881) loss_box_reg: 0.1764 (0.1774) loss_objectness: 0.0236 (0.0716) loss_rpn_box_reg: 0.0753 (0.0807) loss_da_image: 0.5612 (0.6273) loss_da_instance: 0.6850 (0.6811) loss_da_consistency: 0.0258 (0.0157) time: 1.5829 (1.5202) data: 0.3696 (0.3733) loss_classifier_mask: 0.1256 (0.1389) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0107 (0.0103) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:40:55,793 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:08:37 iter: 2840 loss: 1.8742 (1.9631) loss_classifier: 0.1755 (0.1879) loss_box_reg: 0.1776 (0.1774) loss_objectness: 0.0273 (0.0714) loss_rpn_box_reg: 0.0610 (0.0807) loss_da_image: 0.5621 (0.6269) loss_da_instance: 0.6810 (0.6811) loss_da_consistency: 0.0218 (0.0158) time: 1.5725 (1.5206) data: 0.3704 (0.3733) loss_classifier_mask: 0.1370 (0.1388) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0062 (0.0103) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:41:27,339 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:08:29 iter: 2860 loss: 1.8749 (1.9627) loss_classifier: 0.1676 (0.1879) loss_box_reg: 0.1588 (0.1773) loss_objectness: 0.0326 (0.0713) loss_rpn_box_reg: 0.0514 (0.0806) loss_da_image: 0.5690 (0.6265) loss_da_instance: 0.6831 (0.6812) loss_da_consistency: 0.0173 (0.0158) time: 1.5780 (1.5210) data: 0.3694 (0.3733) loss_classifier_mask: 0.1254 (0.1387) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0051 (0.0103) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:41:58,865 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:08:21 iter: 2880 loss: 1.8124 (1.9618) loss_classifier: 0.1573 (0.1877) loss_box_reg: 0.1649 (0.1772) loss_objectness: 0.0254 (0.0711) loss_rpn_box_reg: 0.0356 (0.0804) loss_da_image: 0.5740 (0.6262) loss_da_instance: 0.6830 (0.6812) loss_da_consistency: 0.0224 (0.0159) time: 1.5744 (1.5214) data: 0.3662 (0.3733) loss_classifier_mask: 0.1066 (0.1385) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0057 (0.0103) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:42:30,453 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:08:13 iter: 2900 loss: 2.0090 (1.9619) loss_classifier: 0.2211 (0.1879) loss_box_reg: 0.1979 (0.1773) loss_objectness: 0.0406 (0.0710) loss_rpn_box_reg: 0.0642 (0.0805) loss_da_image: 0.5679 (0.6258) loss_da_instance: 0.6813 (0.6812) loss_da_consistency: 0.0177 (0.0160) time: 1.5958 (1.5218) data: 0.3706 (0.3733) loss_classifier_mask: 0.1476 (0.1387) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0054 (0.0103) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:43:02,058 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:08:06 iter: 2920 loss: 1.7733 (1.9611) loss_classifier: 0.1358 (0.1878) loss_box_reg: 0.1376 (0.1772) loss_objectness: 0.0260 (0.0707) loss_rpn_box_reg: 0.0604 (0.0805) loss_da_image: 0.5523 (0.6252) loss_da_instance: 0.6801 (0.6812) loss_da_consistency: 0.0277 (0.0160) time: 1.5768 (1.5222) data: 0.3673 (0.3732) loss_classifier_mask: 0.1242 (0.1386) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0038 (0.0102) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:43:33,142 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:07:48 iter: 2940 loss: 1.8123 (1.9603) loss_classifier: 0.1548 (0.1877) loss_box_reg: 0.1363 (0.1771) loss_objectness: 0.0299 (0.0705) loss_rpn_box_reg: 0.0374 (0.0804) loss_da_image: 0.5377 (0.6247) loss_da_instance: 0.6799 (0.6812) loss_da_consistency: 0.0208 (0.0161) time: 1.5676 (1.5224) data: 0.3701 (0.3732) loss_classifier_mask: 0.1301 (0.1386) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0061 (0.0102) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:44:04,355 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:07:32 iter: 2960 loss: 1.8454 (1.9598) loss_classifier: 0.2075 (0.1876) loss_box_reg: 0.1690 (0.1771) loss_objectness: 0.0340 (0.0704) loss_rpn_box_reg: 0.0411 (0.0803) loss_da_image: 0.5608 (0.6243) loss_da_instance: 0.6789 (0.6812) loss_da_consistency: 0.0265 (0.0162) time: 1.5774 (1.5227) data: 0.3693 (0.3732) loss_classifier_mask: 0.1218 (0.1385) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0008 (0.0102) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:44:36,019 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:07:25 iter: 2980 loss: 1.7602 (1.9592) loss_classifier: 0.1608 (0.1875) loss_box_reg: 0.1226 (0.1769) loss_objectness: 0.0244 (0.0703) loss_rpn_box_reg: 0.0555 (0.0804) loss_da_image: 0.5577 (0.6239) loss_da_instance: 0.6832 (0.6812) loss_da_consistency: 0.0190 (0.0162) time: 1.5805 (1.5231) data: 0.3749 (0.3732) loss_classifier_mask: 0.1450 (0.1385) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0033 (0.0101) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:45:07,529 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:07:14 iter: 3000 loss: 1.8833 (1.9589) loss_classifier: 0.1941 (0.1876) loss_box_reg: 0.1707 (0.1769) loss_objectness: 0.0376 (0.0702) loss_rpn_box_reg: 0.0360 (0.0803) loss_da_image: 0.5680 (0.6235) loss_da_instance: 0.6835 (0.6812) loss_da_consistency: 0.0181 (0.0162) time: 1.5708 (1.5234) data: 0.3677 (0.3732) loss_classifier_mask: 0.1434 (0.1385) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0048 (0.0101) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:45:07,531 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./model_0003000.pth\n",
            "2023-02-03 14:45:40,109 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:07:23 iter: 3020 loss: 1.7214 (1.9580) loss_classifier: 0.1425 (0.1874) loss_box_reg: 0.1511 (0.1769) loss_objectness: 0.0291 (0.0700) loss_rpn_box_reg: 0.0323 (0.0801) loss_da_image: 0.5656 (0.6231) loss_da_instance: 0.6781 (0.6812) loss_da_consistency: 0.0227 (0.0163) time: 1.5716 (1.5241) data: 0.3654 (0.3735) loss_classifier_mask: 0.1391 (0.1385) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0034 (0.0101) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "2023-02-03 14:46:11,840 maskrcnn_benchmark.trainer INFO: eta: 1 day, 0:07:16 iter: 3040 loss: 1.8119 (1.9577) loss_classifier: 0.1509 (0.1873) loss_box_reg: 0.1573 (0.1768) loss_objectness: 0.0349 (0.0698) loss_rpn_box_reg: 0.0466 (0.0801) loss_da_image: 0.5627 (0.6228) loss_da_instance: 0.6786 (0.6812) loss_da_consistency: 0.0228 (0.0163) time: 1.5912 (1.5245) data: 0.3779 (0.3736) loss_classifier_mask: 0.1528 (0.1387) loss_box_reg_mask: 0.0000 (0.0000) loss_objectness_mask: 0.0071 (0.0101) loss_rpn_box_reg_mask: 0.0000 (0.0000) lr: 0.001000 max mem: 4832\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f3a2cf02e50>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 1445, in _shutdown_workers\n",
            "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 149, in join\n",
            "    res = self._popen.wait(timeout)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/popen_fork.py\", line 44, in wait\n",
            "    if not wait([self.sentinel], timeout):\n",
            "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 931, in wait\n",
            "    ready = selector.select(timeout)\n",
            "  File \"/usr/lib/python3.8/selectors.py\", line 415, in select\n",
            "    fd_event_list = self._selector.poll(timeout)\n",
            "KeyboardInterrupt: \n",
            "Traceback (most recent call last):\n",
            "  File \"tools/train_net.py\", line 270, in <module>\n",
            "    main()\n",
            "  File \"tools/train_net.py\", line 263, in main\n",
            "    model = train(cfg, args.local_rank, args.distributed)\n",
            "  File \"tools/train_net.py\", line 114, in train\n",
            "    do_mask_da_train(\n",
            "  File \"/content/MIC/det/maskrcnn_benchmark/engine/trainer.py\", line 240, in do_mask_da_train\n",
            "    record_dict = model(images, targets)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/MIC/det/maskrcnn_benchmark/modeling/detector/generalized_rcnn.py\", line 52, in forward\n",
            "    features = self.backbone(images.tensors)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py\", line 139, in forward\n",
            "    input = module(input)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/MIC/det/maskrcnn_benchmark/modeling/backbone/resnet.py\", line 143, in forward\n",
            "    x = getattr(self, stage_name)(x)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py\", line 139, in forward\n",
            "    input = module(input)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/MIC/det/maskrcnn_benchmark/modeling/backbone/resnet.py\", line 302, in forward\n",
            "    out = self.conv2(out)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/MIC/det/maskrcnn_benchmark/layers/misc.py\", line 33, in forward\n",
            "    return super(Conv2d, self).forward(x)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py\", line 457, in forward\n",
            "    return self._conv_forward(input, self.weight, self.bias)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py\", line 453, in _conv_forward\n",
            "    return F.conv2d(input, weight, bias, self.stride,\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/MIC/det"
      ],
      "metadata": {
        "id": "OFBdJU6Mrjl7",
        "outputId": "df068100-fb35-42d6-c21b-2aa5102e9fa0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MIC/det\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/test_net.py --config-file \"/content/MIC/det/configs/fff.yaml\" MODEL.WEIGHT /content/drive/MyDrive/AI/mic/model_0006000.pth\n"
      ],
      "metadata": {
        "id": "VR46mHI7fA0e",
        "outputId": "6073e3af-5433-4c71-fd9c-ecd9214baf9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-04 17:32:29,860 maskrcnn_benchmark INFO: Using 1 GPUs\n",
            "2023-02-04 17:32:29,860 maskrcnn_benchmark INFO: DATALOADER:\n",
            "  ASPECT_RATIO_GROUPING: True\n",
            "  NUM_WORKERS: 4\n",
            "  SIZE_DIVISIBILITY: 32\n",
            "DATASETS:\n",
            "  SOURCE_TRAIN: ('sim10k_cocostyle',)\n",
            "  TARGET_TRAIN: ('cityscapes_only_car_train_cocostyle',)\n",
            "  TEST: ('cityscapes_only_car_val_cocostyle',)\n",
            "  TRAIN: ()\n",
            "INPUT:\n",
            "  MAX_SIZE_TEST: 1600\n",
            "  MAX_SIZE_TRAIN: 1600\n",
            "  MIN_SIZE_TEST: 800\n",
            "  MIN_SIZE_TRAIN: (800,)\n",
            "  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]\n",
            "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
            "  TO_BGR255: True\n",
            "MODEL:\n",
            "  BACKBONE:\n",
            "    CONV_BODY: R-50-FPN\n",
            "    FREEZE_CONV_BODY_AT: 2\n",
            "    OUT_CHANNELS: 256\n",
            "    USE_GN: False\n",
            "  CLS_AGNOSTIC_BBOX_REG: False\n",
            "  DA_HEADS:\n",
            "    COS_WEIGHT: 0.1\n",
            "    DA_IMG_GRL_WEIGHT: 0.01\n",
            "    DA_INS_GRL_WEIGHT: 0.1\n",
            "  DEVICE: cuda\n",
            "  DOMAIN_ADAPTATION_ON: True\n",
            "  FPN:\n",
            "    USE_GN: False\n",
            "    USE_RELU: False\n",
            "  GROUP_NORM:\n",
            "    DIM_PER_GP: -1\n",
            "    EPSILON: 1e-05\n",
            "    NUM_GROUPS: 32\n",
            "  KEYPOINT_ON: False\n",
            "  MASKING_AUGMENTATION: True\n",
            "  MASKING_BLOCK_SIZE: 32\n",
            "  MASKING_RATIO: 0.5\n",
            "  MASK_ON: False\n",
            "  META_ARCHITECTURE: GeneralizedRCNN\n",
            "  MIC_ON: True\n",
            "  PSEUDO_LABEL_LAMBDA: 1.0\n",
            "  PSEUDO_LABEL_THRESHOLD: 0.8\n",
            "  PSEUDO_LABEL_WEIGHT: prob\n",
            "  RESNETS:\n",
            "    NUM_GROUPS: 1\n",
            "    RES2_OUT_CHANNELS: 256\n",
            "    RES5_DILATION: 1\n",
            "    STEM_FUNC: StemWithFixedBatchNorm\n",
            "    STEM_OUT_CHANNELS: 64\n",
            "    STRIDE_IN_1X1: True\n",
            "    TRANS_FUNC: BottleneckWithFixedBatchNorm\n",
            "    WIDTH_PER_GROUP: 64\n",
            "  RETINANET:\n",
            "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
            "    ANCHOR_STRIDES: (8, 16, 32, 64, 128)\n",
            "    ASPECT_RATIOS: (0.5, 1.0, 2.0)\n",
            "    BBOX_REG_BETA: 0.11\n",
            "    BBOX_REG_WEIGHT: 4.0\n",
            "    BG_IOU_THRESHOLD: 0.4\n",
            "    FG_IOU_THRESHOLD: 0.5\n",
            "    INFERENCE_TH: 0.05\n",
            "    LOSS_ALPHA: 0.25\n",
            "    LOSS_GAMMA: 2.0\n",
            "    NMS_TH: 0.4\n",
            "    NUM_CLASSES: 81\n",
            "    NUM_CONVS: 4\n",
            "    OCTAVE: 2.0\n",
            "    PRE_NMS_TOP_N: 1000\n",
            "    PRIOR_PROB: 0.01\n",
            "    SCALES_PER_OCTAVE: 3\n",
            "    STRADDLE_THRESH: 0\n",
            "    USE_C5: True\n",
            "  RETINANET_ON: False\n",
            "  ROI_BOX_HEAD:\n",
            "    CONV_HEAD_DIM: 256\n",
            "    DILATION: 1\n",
            "    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n",
            "    MLP_HEAD_DIM: 1024\n",
            "    NUM_CLASSES: 2\n",
            "    NUM_STACKED_CONVS: 4\n",
            "    POOLER_RESOLUTION: 7\n",
            "    POOLER_SAMPLING_RATIO: 2\n",
            "    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n",
            "    PREDICTOR: FPNPredictor\n",
            "    USE_GN: False\n",
            "  ROI_HEADS:\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
            "    BG_IOU_THRESHOLD: 0.5\n",
            "    DETECTIONS_PER_IMG: 100\n",
            "    FG_IOU_THRESHOLD: 0.5\n",
            "    NMS: 0.5\n",
            "    POSITIVE_FRACTION: 0.25\n",
            "    SCORE_THRESH: 0.05\n",
            "    USE_FPN: True\n",
            "  ROI_KEYPOINT_HEAD:\n",
            "    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
            "    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor\n",
            "    MLP_HEAD_DIM: 1024\n",
            "    NUM_CLASSES: 17\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_SCALES: (0.0625,)\n",
            "    PREDICTOR: KeypointRCNNPredictor\n",
            "    RESOLUTION: 14\n",
            "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
            "  ROI_MASK_HEAD:\n",
            "    CONV_LAYERS: (256, 256, 256, 256)\n",
            "    DILATION: 1\n",
            "    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor\n",
            "    MLP_HEAD_DIM: 1024\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_SCALES: (0.0625,)\n",
            "    POSTPROCESS_MASKS: False\n",
            "    POSTPROCESS_MASKS_THRESHOLD: 0.5\n",
            "    PREDICTOR: MaskRCNNC4Predictor\n",
            "    RESOLUTION: 14\n",
            "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
            "    USE_GN: False\n",
            "  RPN:\n",
            "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
            "    ANCHOR_STRIDE: (4, 8, 16, 32, 64)\n",
            "    ASPECT_RATIOS: (0.5, 1.0, 2.0)\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "    BG_IOU_THRESHOLD: 0.3\n",
            "    FG_IOU_THRESHOLD: 0.7\n",
            "    FPN_POST_NMS_TOP_N_TEST: 1000\n",
            "    FPN_POST_NMS_TOP_N_TRAIN: 2000\n",
            "    MIN_SIZE: 0\n",
            "    NMS_THRESH: 0.7\n",
            "    POSITIVE_FRACTION: 0.5\n",
            "    POST_NMS_TOP_N_TEST: 1000\n",
            "    POST_NMS_TOP_N_TRAIN: 2000\n",
            "    PRE_NMS_TOP_N_TEST: 1000\n",
            "    PRE_NMS_TOP_N_TRAIN: 2000\n",
            "    RPN_HEAD: SingleConvRPNHead\n",
            "    STRADDLE_THRESH: 0\n",
            "    USE_FPN: True\n",
            "  RPN_ONLY: False\n",
            "  TEACHER_ALPHA: 0.9\n",
            "  WEIGHT: /content/drive/MyDrive/AI/mic/model_0006000.pth\n",
            "OUTPUT_DIR: /content/drive/MyDrive/AI/mic\n",
            "PATHS_CATALOG: /content/MIC/det/maskrcnn_benchmark/config/paths_catalog.py\n",
            "SOLVER:\n",
            "  BASE_LR: 0.001\n",
            "  BIAS_LR_FACTOR: 2\n",
            "  CHECKPOINT_PERIOD: 1000\n",
            "  GAMMA: 0.1\n",
            "  IMS_PER_BATCH: 2\n",
            "  MAX_ITER: 60000\n",
            "  MOMENTUM: 0.9\n",
            "  STEPS: (30000, 40000)\n",
            "  WARMUP_FACTOR: 0.3333333333333333\n",
            "  WARMUP_ITERS: 1000\n",
            "  WARMUP_METHOD: linear\n",
            "  WEIGHT_DECAY: 0.0001\n",
            "  WEIGHT_DECAY_BIAS: 0\n",
            "TEST:\n",
            "  DETECTIONS_PER_IMG: 100\n",
            "  EXPECTED_RESULTS: []\n",
            "  EXPECTED_RESULTS_SIGMA_TOL: 4\n",
            "  IMS_PER_BATCH: 1\n",
            "2023-02-04 17:32:29,860 maskrcnn_benchmark INFO: Collecting env info (might take some time)\n",
            "2023-02-04 17:32:32,773 maskrcnn_benchmark INFO: \n",
            "PyTorch version: 1.12.0+cu113\n",
            "Is debug build: False\n",
            "CUDA used to build PyTorch: 11.3\n",
            "ROCM used to build PyTorch: N/A\n",
            "\n",
            "OS: Ubuntu 20.04.5 LTS (x86_64)\n",
            "GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n",
            "Clang version: 10.0.0-4ubuntu1 \n",
            "CMake version: version 3.22.6\n",
            "Libc version: glibc-2.31\n",
            "\n",
            "Python version: 3.8.10 (default, Nov 14 2022, 12:59:47)  [GCC 9.4.0] (64-bit runtime)\n",
            "Python platform: Linux-5.10.147+-x86_64-with-glibc2.29\n",
            "Is CUDA available: True\n",
            "CUDA runtime version: 11.2.152\n",
            "GPU models and configuration: GPU 0: Tesla T4\n",
            "Nvidia driver version: 510.47.03\n",
            "cuDNN version: Probably one of the following:\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.1.1\n",
            "HIP runtime version: N/A\n",
            "MIOpen runtime version: N/A\n",
            "Is XNNPACK available: True\n",
            "\n",
            "Versions of relevant libraries:\n",
            "[pip3] numpy==1.21.6\n",
            "[pip3] torch==1.12.0+cu113\n",
            "[pip3] torchaudio==0.12.0+cu113\n",
            "[pip3] torchsummary==1.5.1\n",
            "[pip3] torchtext==0.14.1\n",
            "[pip3] torchvision==0.13.0+cu113\n",
            "[conda] Could not collect\n",
            "        Pillow (7.1.2)\n",
            "2023-02-04 17:32:35,600 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from /content/drive/MyDrive/AI/mic/model_0006000.pth\n",
            "2023-02-04 17:32:36,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.bias                  loaded from backbone.body.layer1.0.bn1.bias                  of shape (64,)\n",
            "2023-02-04 17:32:36,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.running_mean          loaded from backbone.body.layer1.0.bn1.running_mean          of shape (64,)\n",
            "2023-02-04 17:32:36,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.running_var           loaded from backbone.body.layer1.0.bn1.running_var           of shape (64,)\n",
            "2023-02-04 17:32:36,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.weight                loaded from backbone.body.layer1.0.bn1.weight                of shape (64,)\n",
            "2023-02-04 17:32:36,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.bias                  loaded from backbone.body.layer1.0.bn2.bias                  of shape (64,)\n",
            "2023-02-04 17:32:36,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.running_mean          loaded from backbone.body.layer1.0.bn2.running_mean          of shape (64,)\n",
            "2023-02-04 17:32:36,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.running_var           loaded from backbone.body.layer1.0.bn2.running_var           of shape (64,)\n",
            "2023-02-04 17:32:36,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.weight                loaded from backbone.body.layer1.0.bn2.weight                of shape (64,)\n",
            "2023-02-04 17:32:36,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.bias                  loaded from backbone.body.layer1.0.bn3.bias                  of shape (256,)\n",
            "2023-02-04 17:32:36,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.running_mean          loaded from backbone.body.layer1.0.bn3.running_mean          of shape (256,)\n",
            "2023-02-04 17:32:36,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.running_var           loaded from backbone.body.layer1.0.bn3.running_var           of shape (256,)\n",
            "2023-02-04 17:32:36,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.weight                loaded from backbone.body.layer1.0.bn3.weight                of shape (256,)\n",
            "2023-02-04 17:32:36,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv1.weight              loaded from backbone.body.layer1.0.conv1.weight              of shape (64, 64, 1, 1)\n",
            "2023-02-04 17:32:36,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv2.weight              loaded from backbone.body.layer1.0.conv2.weight              of shape (64, 64, 3, 3)\n",
            "2023-02-04 17:32:36,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv3.weight              loaded from backbone.body.layer1.0.conv3.weight              of shape (256, 64, 1, 1)\n",
            "2023-02-04 17:32:36,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.0.weight       loaded from backbone.body.layer1.0.downsample.0.weight       of shape (256, 64, 1, 1)\n",
            "2023-02-04 17:32:36,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.bias         loaded from backbone.body.layer1.0.downsample.1.bias         of shape (256,)\n",
            "2023-02-04 17:32:36,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.running_mean loaded from backbone.body.layer1.0.downsample.1.running_mean of shape (256,)\n",
            "2023-02-04 17:32:36,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.running_var  loaded from backbone.body.layer1.0.downsample.1.running_var  of shape (256,)\n",
            "2023-02-04 17:32:36,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.weight       loaded from backbone.body.layer1.0.downsample.1.weight       of shape (256,)\n",
            "2023-02-04 17:32:36,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.bias                  loaded from backbone.body.layer1.1.bn1.bias                  of shape (64,)\n",
            "2023-02-04 17:32:36,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.running_mean          loaded from backbone.body.layer1.1.bn1.running_mean          of shape (64,)\n",
            "2023-02-04 17:32:36,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.running_var           loaded from backbone.body.layer1.1.bn1.running_var           of shape (64,)\n",
            "2023-02-04 17:32:36,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.weight                loaded from backbone.body.layer1.1.bn1.weight                of shape (64,)\n",
            "2023-02-04 17:32:36,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.bias                  loaded from backbone.body.layer1.1.bn2.bias                  of shape (64,)\n",
            "2023-02-04 17:32:36,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.running_mean          loaded from backbone.body.layer1.1.bn2.running_mean          of shape (64,)\n",
            "2023-02-04 17:32:36,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.running_var           loaded from backbone.body.layer1.1.bn2.running_var           of shape (64,)\n",
            "2023-02-04 17:32:36,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.weight                loaded from backbone.body.layer1.1.bn2.weight                of shape (64,)\n",
            "2023-02-04 17:32:36,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.bias                  loaded from backbone.body.layer1.1.bn3.bias                  of shape (256,)\n",
            "2023-02-04 17:32:36,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.running_mean          loaded from backbone.body.layer1.1.bn3.running_mean          of shape (256,)\n",
            "2023-02-04 17:32:36,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.running_var           loaded from backbone.body.layer1.1.bn3.running_var           of shape (256,)\n",
            "2023-02-04 17:32:36,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.weight                loaded from backbone.body.layer1.1.bn3.weight                of shape (256,)\n",
            "2023-02-04 17:32:36,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv1.weight              loaded from backbone.body.layer1.1.conv1.weight              of shape (64, 256, 1, 1)\n",
            "2023-02-04 17:32:36,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv2.weight              loaded from backbone.body.layer1.1.conv2.weight              of shape (64, 64, 3, 3)\n",
            "2023-02-04 17:32:36,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv3.weight              loaded from backbone.body.layer1.1.conv3.weight              of shape (256, 64, 1, 1)\n",
            "2023-02-04 17:32:36,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.bias                  loaded from backbone.body.layer1.2.bn1.bias                  of shape (64,)\n",
            "2023-02-04 17:32:36,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.running_mean          loaded from backbone.body.layer1.2.bn1.running_mean          of shape (64,)\n",
            "2023-02-04 17:32:36,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.running_var           loaded from backbone.body.layer1.2.bn1.running_var           of shape (64,)\n",
            "2023-02-04 17:32:36,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.weight                loaded from backbone.body.layer1.2.bn1.weight                of shape (64,)\n",
            "2023-02-04 17:32:36,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.bias                  loaded from backbone.body.layer1.2.bn2.bias                  of shape (64,)\n",
            "2023-02-04 17:32:36,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.running_mean          loaded from backbone.body.layer1.2.bn2.running_mean          of shape (64,)\n",
            "2023-02-04 17:32:36,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.running_var           loaded from backbone.body.layer1.2.bn2.running_var           of shape (64,)\n",
            "2023-02-04 17:32:36,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.weight                loaded from backbone.body.layer1.2.bn2.weight                of shape (64,)\n",
            "2023-02-04 17:32:36,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.bias                  loaded from backbone.body.layer1.2.bn3.bias                  of shape (256,)\n",
            "2023-02-04 17:32:36,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.running_mean          loaded from backbone.body.layer1.2.bn3.running_mean          of shape (256,)\n",
            "2023-02-04 17:32:36,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.running_var           loaded from backbone.body.layer1.2.bn3.running_var           of shape (256,)\n",
            "2023-02-04 17:32:36,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.weight                loaded from backbone.body.layer1.2.bn3.weight                of shape (256,)\n",
            "2023-02-04 17:32:36,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv1.weight              loaded from backbone.body.layer1.2.conv1.weight              of shape (64, 256, 1, 1)\n",
            "2023-02-04 17:32:36,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv2.weight              loaded from backbone.body.layer1.2.conv2.weight              of shape (64, 64, 3, 3)\n",
            "2023-02-04 17:32:36,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv3.weight              loaded from backbone.body.layer1.2.conv3.weight              of shape (256, 64, 1, 1)\n",
            "2023-02-04 17:32:36,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.bias                  loaded from backbone.body.layer2.0.bn1.bias                  of shape (128,)\n",
            "2023-02-04 17:32:36,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.running_mean          loaded from backbone.body.layer2.0.bn1.running_mean          of shape (128,)\n",
            "2023-02-04 17:32:36,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.running_var           loaded from backbone.body.layer2.0.bn1.running_var           of shape (128,)\n",
            "2023-02-04 17:32:36,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.weight                loaded from backbone.body.layer2.0.bn1.weight                of shape (128,)\n",
            "2023-02-04 17:32:36,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.bias                  loaded from backbone.body.layer2.0.bn2.bias                  of shape (128,)\n",
            "2023-02-04 17:32:36,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.running_mean          loaded from backbone.body.layer2.0.bn2.running_mean          of shape (128,)\n",
            "2023-02-04 17:32:36,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.running_var           loaded from backbone.body.layer2.0.bn2.running_var           of shape (128,)\n",
            "2023-02-04 17:32:36,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.weight                loaded from backbone.body.layer2.0.bn2.weight                of shape (128,)\n",
            "2023-02-04 17:32:36,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.bias                  loaded from backbone.body.layer2.0.bn3.bias                  of shape (512,)\n",
            "2023-02-04 17:32:36,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.running_mean          loaded from backbone.body.layer2.0.bn3.running_mean          of shape (512,)\n",
            "2023-02-04 17:32:36,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.running_var           loaded from backbone.body.layer2.0.bn3.running_var           of shape (512,)\n",
            "2023-02-04 17:32:36,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.weight                loaded from backbone.body.layer2.0.bn3.weight                of shape (512,)\n",
            "2023-02-04 17:32:36,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv1.weight              loaded from backbone.body.layer2.0.conv1.weight              of shape (128, 256, 1, 1)\n",
            "2023-02-04 17:32:36,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv2.weight              loaded from backbone.body.layer2.0.conv2.weight              of shape (128, 128, 3, 3)\n",
            "2023-02-04 17:32:36,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv3.weight              loaded from backbone.body.layer2.0.conv3.weight              of shape (512, 128, 1, 1)\n",
            "2023-02-04 17:32:36,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.0.weight       loaded from backbone.body.layer2.0.downsample.0.weight       of shape (512, 256, 1, 1)\n",
            "2023-02-04 17:32:36,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.bias         loaded from backbone.body.layer2.0.downsample.1.bias         of shape (512,)\n",
            "2023-02-04 17:32:36,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.running_mean loaded from backbone.body.layer2.0.downsample.1.running_mean of shape (512,)\n",
            "2023-02-04 17:32:36,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.running_var  loaded from backbone.body.layer2.0.downsample.1.running_var  of shape (512,)\n",
            "2023-02-04 17:32:36,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.weight       loaded from backbone.body.layer2.0.downsample.1.weight       of shape (512,)\n",
            "2023-02-04 17:32:36,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.bias                  loaded from backbone.body.layer2.1.bn1.bias                  of shape (128,)\n",
            "2023-02-04 17:32:36,184 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.running_mean          loaded from backbone.body.layer2.1.bn1.running_mean          of shape (128,)\n",
            "2023-02-04 17:32:36,184 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.running_var           loaded from backbone.body.layer2.1.bn1.running_var           of shape (128,)\n",
            "2023-02-04 17:32:36,184 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.weight                loaded from backbone.body.layer2.1.bn1.weight                of shape (128,)\n",
            "2023-02-04 17:32:36,184 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.bias                  loaded from backbone.body.layer2.1.bn2.bias                  of shape (128,)\n",
            "2023-02-04 17:32:36,184 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.running_mean          loaded from backbone.body.layer2.1.bn2.running_mean          of shape (128,)\n",
            "2023-02-04 17:32:36,184 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.running_var           loaded from backbone.body.layer2.1.bn2.running_var           of shape (128,)\n",
            "2023-02-04 17:32:36,184 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.weight                loaded from backbone.body.layer2.1.bn2.weight                of shape (128,)\n",
            "2023-02-04 17:32:36,184 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.bias                  loaded from backbone.body.layer2.1.bn3.bias                  of shape (512,)\n",
            "2023-02-04 17:32:36,184 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.running_mean          loaded from backbone.body.layer2.1.bn3.running_mean          of shape (512,)\n",
            "2023-02-04 17:32:36,184 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.running_var           loaded from backbone.body.layer2.1.bn3.running_var           of shape (512,)\n",
            "2023-02-04 17:32:36,184 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.weight                loaded from backbone.body.layer2.1.bn3.weight                of shape (512,)\n",
            "2023-02-04 17:32:36,184 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv1.weight              loaded from backbone.body.layer2.1.conv1.weight              of shape (128, 512, 1, 1)\n",
            "2023-02-04 17:32:36,249 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv2.weight              loaded from backbone.body.layer2.1.conv2.weight              of shape (128, 128, 3, 3)\n",
            "2023-02-04 17:32:36,249 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv3.weight              loaded from backbone.body.layer2.1.conv3.weight              of shape (512, 128, 1, 1)\n",
            "2023-02-04 17:32:36,249 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.bias                  loaded from backbone.body.layer2.2.bn1.bias                  of shape (128,)\n",
            "2023-02-04 17:32:36,249 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.running_mean          loaded from backbone.body.layer2.2.bn1.running_mean          of shape (128,)\n",
            "2023-02-04 17:32:36,249 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.running_var           loaded from backbone.body.layer2.2.bn1.running_var           of shape (128,)\n",
            "2023-02-04 17:32:36,249 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.weight                loaded from backbone.body.layer2.2.bn1.weight                of shape (128,)\n",
            "2023-02-04 17:32:36,249 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.bias                  loaded from backbone.body.layer2.2.bn2.bias                  of shape (128,)\n",
            "2023-02-04 17:32:36,249 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.running_mean          loaded from backbone.body.layer2.2.bn2.running_mean          of shape (128,)\n",
            "2023-02-04 17:32:36,250 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.running_var           loaded from backbone.body.layer2.2.bn2.running_var           of shape (128,)\n",
            "2023-02-04 17:32:36,250 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.weight                loaded from backbone.body.layer2.2.bn2.weight                of shape (128,)\n",
            "2023-02-04 17:32:36,250 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.bias                  loaded from backbone.body.layer2.2.bn3.bias                  of shape (512,)\n",
            "2023-02-04 17:32:36,250 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.running_mean          loaded from backbone.body.layer2.2.bn3.running_mean          of shape (512,)\n",
            "2023-02-04 17:32:36,250 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.running_var           loaded from backbone.body.layer2.2.bn3.running_var           of shape (512,)\n",
            "2023-02-04 17:32:36,250 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.weight                loaded from backbone.body.layer2.2.bn3.weight                of shape (512,)\n",
            "2023-02-04 17:32:36,250 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv1.weight              loaded from backbone.body.layer2.2.conv1.weight              of shape (128, 512, 1, 1)\n",
            "2023-02-04 17:32:36,250 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv2.weight              loaded from backbone.body.layer2.2.conv2.weight              of shape (128, 128, 3, 3)\n",
            "2023-02-04 17:32:36,250 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv3.weight              loaded from backbone.body.layer2.2.conv3.weight              of shape (512, 128, 1, 1)\n",
            "2023-02-04 17:32:36,250 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.bias                  loaded from backbone.body.layer2.3.bn1.bias                  of shape (128,)\n",
            "2023-02-04 17:32:36,250 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.running_mean          loaded from backbone.body.layer2.3.bn1.running_mean          of shape (128,)\n",
            "2023-02-04 17:32:36,250 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.running_var           loaded from backbone.body.layer2.3.bn1.running_var           of shape (128,)\n",
            "2023-02-04 17:32:36,250 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.weight                loaded from backbone.body.layer2.3.bn1.weight                of shape (128,)\n",
            "2023-02-04 17:32:36,250 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.bias                  loaded from backbone.body.layer2.3.bn2.bias                  of shape (128,)\n",
            "2023-02-04 17:32:36,250 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.running_mean          loaded from backbone.body.layer2.3.bn2.running_mean          of shape (128,)\n",
            "2023-02-04 17:32:36,250 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.running_var           loaded from backbone.body.layer2.3.bn2.running_var           of shape (128,)\n",
            "2023-02-04 17:32:36,250 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.weight                loaded from backbone.body.layer2.3.bn2.weight                of shape (128,)\n",
            "2023-02-04 17:32:36,250 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.bias                  loaded from backbone.body.layer2.3.bn3.bias                  of shape (512,)\n",
            "2023-02-04 17:32:36,250 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.running_mean          loaded from backbone.body.layer2.3.bn3.running_mean          of shape (512,)\n",
            "2023-02-04 17:32:36,250 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.running_var           loaded from backbone.body.layer2.3.bn3.running_var           of shape (512,)\n",
            "2023-02-04 17:32:36,250 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.weight                loaded from backbone.body.layer2.3.bn3.weight                of shape (512,)\n",
            "2023-02-04 17:32:36,251 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv1.weight              loaded from backbone.body.layer2.3.conv1.weight              of shape (128, 512, 1, 1)\n",
            "2023-02-04 17:32:36,251 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv2.weight              loaded from backbone.body.layer2.3.conv2.weight              of shape (128, 128, 3, 3)\n",
            "2023-02-04 17:32:36,251 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv3.weight              loaded from backbone.body.layer2.3.conv3.weight              of shape (512, 128, 1, 1)\n",
            "2023-02-04 17:32:36,251 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.bias                  loaded from backbone.body.layer3.0.bn1.bias                  of shape (256,)\n",
            "2023-02-04 17:32:36,251 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.running_mean          loaded from backbone.body.layer3.0.bn1.running_mean          of shape (256,)\n",
            "2023-02-04 17:32:36,251 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.running_var           loaded from backbone.body.layer3.0.bn1.running_var           of shape (256,)\n",
            "2023-02-04 17:32:36,251 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.weight                loaded from backbone.body.layer3.0.bn1.weight                of shape (256,)\n",
            "2023-02-04 17:32:36,251 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.bias                  loaded from backbone.body.layer3.0.bn2.bias                  of shape (256,)\n",
            "2023-02-04 17:32:36,251 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.running_mean          loaded from backbone.body.layer3.0.bn2.running_mean          of shape (256,)\n",
            "2023-02-04 17:32:36,251 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.running_var           loaded from backbone.body.layer3.0.bn2.running_var           of shape (256,)\n",
            "2023-02-04 17:32:36,251 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.weight                loaded from backbone.body.layer3.0.bn2.weight                of shape (256,)\n",
            "2023-02-04 17:32:36,251 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.bias                  loaded from backbone.body.layer3.0.bn3.bias                  of shape (1024,)\n",
            "2023-02-04 17:32:36,251 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.running_mean          loaded from backbone.body.layer3.0.bn3.running_mean          of shape (1024,)\n",
            "2023-02-04 17:32:36,251 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.running_var           loaded from backbone.body.layer3.0.bn3.running_var           of shape (1024,)\n",
            "2023-02-04 17:32:36,251 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.weight                loaded from backbone.body.layer3.0.bn3.weight                of shape (1024,)\n",
            "2023-02-04 17:32:36,251 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv1.weight              loaded from backbone.body.layer3.0.conv1.weight              of shape (256, 512, 1, 1)\n",
            "2023-02-04 17:32:36,251 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv2.weight              loaded from backbone.body.layer3.0.conv2.weight              of shape (256, 256, 3, 3)\n",
            "2023-02-04 17:32:36,251 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv3.weight              loaded from backbone.body.layer3.0.conv3.weight              of shape (1024, 256, 1, 1)\n",
            "2023-02-04 17:32:36,251 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.0.weight       loaded from backbone.body.layer3.0.downsample.0.weight       of shape (1024, 512, 1, 1)\n",
            "2023-02-04 17:32:36,251 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.bias         loaded from backbone.body.layer3.0.downsample.1.bias         of shape (1024,)\n",
            "2023-02-04 17:32:36,252 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.running_mean loaded from backbone.body.layer3.0.downsample.1.running_mean of shape (1024,)\n",
            "2023-02-04 17:32:36,252 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.running_var  loaded from backbone.body.layer3.0.downsample.1.running_var  of shape (1024,)\n",
            "2023-02-04 17:32:36,252 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.weight       loaded from backbone.body.layer3.0.downsample.1.weight       of shape (1024,)\n",
            "2023-02-04 17:32:36,252 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.bias                  loaded from backbone.body.layer3.1.bn1.bias                  of shape (256,)\n",
            "2023-02-04 17:32:36,252 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.running_mean          loaded from backbone.body.layer3.1.bn1.running_mean          of shape (256,)\n",
            "2023-02-04 17:32:36,252 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.running_var           loaded from backbone.body.layer3.1.bn1.running_var           of shape (256,)\n",
            "2023-02-04 17:32:36,252 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.weight                loaded from backbone.body.layer3.1.bn1.weight                of shape (256,)\n",
            "2023-02-04 17:32:36,252 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.bias                  loaded from backbone.body.layer3.1.bn2.bias                  of shape (256,)\n",
            "2023-02-04 17:32:36,252 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.running_mean          loaded from backbone.body.layer3.1.bn2.running_mean          of shape (256,)\n",
            "2023-02-04 17:32:36,252 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.running_var           loaded from backbone.body.layer3.1.bn2.running_var           of shape (256,)\n",
            "2023-02-04 17:32:36,252 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.weight                loaded from backbone.body.layer3.1.bn2.weight                of shape (256,)\n",
            "2023-02-04 17:32:36,252 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.bias                  loaded from backbone.body.layer3.1.bn3.bias                  of shape (1024,)\n",
            "2023-02-04 17:32:36,252 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.running_mean          loaded from backbone.body.layer3.1.bn3.running_mean          of shape (1024,)\n",
            "2023-02-04 17:32:36,252 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.running_var           loaded from backbone.body.layer3.1.bn3.running_var           of shape (1024,)\n",
            "2023-02-04 17:32:36,252 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.weight                loaded from backbone.body.layer3.1.bn3.weight                of shape (1024,)\n",
            "2023-02-04 17:32:36,252 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv1.weight              loaded from backbone.body.layer3.1.conv1.weight              of shape (256, 1024, 1, 1)\n",
            "2023-02-04 17:32:36,252 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv2.weight              loaded from backbone.body.layer3.1.conv2.weight              of shape (256, 256, 3, 3)\n",
            "2023-02-04 17:32:36,252 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv3.weight              loaded from backbone.body.layer3.1.conv3.weight              of shape (1024, 256, 1, 1)\n",
            "2023-02-04 17:32:36,252 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.bias                  loaded from backbone.body.layer3.2.bn1.bias                  of shape (256,)\n",
            "2023-02-04 17:32:36,252 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.running_mean          loaded from backbone.body.layer3.2.bn1.running_mean          of shape (256,)\n",
            "2023-02-04 17:32:36,253 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.running_var           loaded from backbone.body.layer3.2.bn1.running_var           of shape (256,)\n",
            "2023-02-04 17:32:36,253 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.weight                loaded from backbone.body.layer3.2.bn1.weight                of shape (256,)\n",
            "2023-02-04 17:32:36,253 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.bias                  loaded from backbone.body.layer3.2.bn2.bias                  of shape (256,)\n",
            "2023-02-04 17:32:36,253 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.running_mean          loaded from backbone.body.layer3.2.bn2.running_mean          of shape (256,)\n",
            "2023-02-04 17:32:36,253 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.running_var           loaded from backbone.body.layer3.2.bn2.running_var           of shape (256,)\n",
            "2023-02-04 17:32:36,253 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.weight                loaded from backbone.body.layer3.2.bn2.weight                of shape (256,)\n",
            "2023-02-04 17:32:36,253 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.bias                  loaded from backbone.body.layer3.2.bn3.bias                  of shape (1024,)\n",
            "2023-02-04 17:32:36,253 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.running_mean          loaded from backbone.body.layer3.2.bn3.running_mean          of shape (1024,)\n",
            "2023-02-04 17:32:36,253 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.running_var           loaded from backbone.body.layer3.2.bn3.running_var           of shape (1024,)\n",
            "2023-02-04 17:32:36,253 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.weight                loaded from backbone.body.layer3.2.bn3.weight                of shape (1024,)\n",
            "2023-02-04 17:32:36,253 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv1.weight              loaded from backbone.body.layer3.2.conv1.weight              of shape (256, 1024, 1, 1)\n",
            "2023-02-04 17:32:36,253 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv2.weight              loaded from backbone.body.layer3.2.conv2.weight              of shape (256, 256, 3, 3)\n",
            "2023-02-04 17:32:36,253 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv3.weight              loaded from backbone.body.layer3.2.conv3.weight              of shape (1024, 256, 1, 1)\n",
            "2023-02-04 17:32:36,253 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.bias                  loaded from backbone.body.layer3.3.bn1.bias                  of shape (256,)\n",
            "2023-02-04 17:32:36,254 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.running_mean          loaded from backbone.body.layer3.3.bn1.running_mean          of shape (256,)\n",
            "2023-02-04 17:32:36,254 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.running_var           loaded from backbone.body.layer3.3.bn1.running_var           of shape (256,)\n",
            "2023-02-04 17:32:36,254 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.weight                loaded from backbone.body.layer3.3.bn1.weight                of shape (256,)\n",
            "2023-02-04 17:32:36,254 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.bias                  loaded from backbone.body.layer3.3.bn2.bias                  of shape (256,)\n",
            "2023-02-04 17:32:36,254 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.running_mean          loaded from backbone.body.layer3.3.bn2.running_mean          of shape (256,)\n",
            "2023-02-04 17:32:36,254 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.running_var           loaded from backbone.body.layer3.3.bn2.running_var           of shape (256,)\n",
            "2023-02-04 17:32:36,254 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.weight                loaded from backbone.body.layer3.3.bn2.weight                of shape (256,)\n",
            "2023-02-04 17:32:36,254 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.bias                  loaded from backbone.body.layer3.3.bn3.bias                  of shape (1024,)\n",
            "2023-02-04 17:32:36,254 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.running_mean          loaded from backbone.body.layer3.3.bn3.running_mean          of shape (1024,)\n",
            "2023-02-04 17:32:36,254 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.running_var           loaded from backbone.body.layer3.3.bn3.running_var           of shape (1024,)\n",
            "2023-02-04 17:32:36,254 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.weight                loaded from backbone.body.layer3.3.bn3.weight                of shape (1024,)\n",
            "2023-02-04 17:32:36,254 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv1.weight              loaded from backbone.body.layer3.3.conv1.weight              of shape (256, 1024, 1, 1)\n",
            "2023-02-04 17:32:36,254 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv2.weight              loaded from backbone.body.layer3.3.conv2.weight              of shape (256, 256, 3, 3)\n",
            "2023-02-04 17:32:36,254 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv3.weight              loaded from backbone.body.layer3.3.conv3.weight              of shape (1024, 256, 1, 1)\n",
            "2023-02-04 17:32:36,254 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.bias                  loaded from backbone.body.layer3.4.bn1.bias                  of shape (256,)\n",
            "2023-02-04 17:32:36,254 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.running_mean          loaded from backbone.body.layer3.4.bn1.running_mean          of shape (256,)\n",
            "2023-02-04 17:32:36,254 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.running_var           loaded from backbone.body.layer3.4.bn1.running_var           of shape (256,)\n",
            "2023-02-04 17:32:36,254 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.weight                loaded from backbone.body.layer3.4.bn1.weight                of shape (256,)\n",
            "2023-02-04 17:32:36,254 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.bias                  loaded from backbone.body.layer3.4.bn2.bias                  of shape (256,)\n",
            "2023-02-04 17:32:36,255 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.running_mean          loaded from backbone.body.layer3.4.bn2.running_mean          of shape (256,)\n",
            "2023-02-04 17:32:36,255 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.running_var           loaded from backbone.body.layer3.4.bn2.running_var           of shape (256,)\n",
            "2023-02-04 17:32:36,255 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.weight                loaded from backbone.body.layer3.4.bn2.weight                of shape (256,)\n",
            "2023-02-04 17:32:36,255 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.bias                  loaded from backbone.body.layer3.4.bn3.bias                  of shape (1024,)\n",
            "2023-02-04 17:32:36,255 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.running_mean          loaded from backbone.body.layer3.4.bn3.running_mean          of shape (1024,)\n",
            "2023-02-04 17:32:36,255 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.running_var           loaded from backbone.body.layer3.4.bn3.running_var           of shape (1024,)\n",
            "2023-02-04 17:32:36,255 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.weight                loaded from backbone.body.layer3.4.bn3.weight                of shape (1024,)\n",
            "2023-02-04 17:32:36,255 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv1.weight              loaded from backbone.body.layer3.4.conv1.weight              of shape (256, 1024, 1, 1)\n",
            "2023-02-04 17:32:36,255 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv2.weight              loaded from backbone.body.layer3.4.conv2.weight              of shape (256, 256, 3, 3)\n",
            "2023-02-04 17:32:36,255 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv3.weight              loaded from backbone.body.layer3.4.conv3.weight              of shape (1024, 256, 1, 1)\n",
            "2023-02-04 17:32:36,255 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.bias                  loaded from backbone.body.layer3.5.bn1.bias                  of shape (256,)\n",
            "2023-02-04 17:32:36,255 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.running_mean          loaded from backbone.body.layer3.5.bn1.running_mean          of shape (256,)\n",
            "2023-02-04 17:32:36,255 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.running_var           loaded from backbone.body.layer3.5.bn1.running_var           of shape (256,)\n",
            "2023-02-04 17:32:36,255 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.weight                loaded from backbone.body.layer3.5.bn1.weight                of shape (256,)\n",
            "2023-02-04 17:32:36,255 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.bias                  loaded from backbone.body.layer3.5.bn2.bias                  of shape (256,)\n",
            "2023-02-04 17:32:36,255 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.running_mean          loaded from backbone.body.layer3.5.bn2.running_mean          of shape (256,)\n",
            "2023-02-04 17:32:36,255 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.running_var           loaded from backbone.body.layer3.5.bn2.running_var           of shape (256,)\n",
            "2023-02-04 17:32:36,256 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.weight                loaded from backbone.body.layer3.5.bn2.weight                of shape (256,)\n",
            "2023-02-04 17:32:36,256 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.bias                  loaded from backbone.body.layer3.5.bn3.bias                  of shape (1024,)\n",
            "2023-02-04 17:32:36,256 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.running_mean          loaded from backbone.body.layer3.5.bn3.running_mean          of shape (1024,)\n",
            "2023-02-04 17:32:36,256 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.running_var           loaded from backbone.body.layer3.5.bn3.running_var           of shape (1024,)\n",
            "2023-02-04 17:32:36,256 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.weight                loaded from backbone.body.layer3.5.bn3.weight                of shape (1024,)\n",
            "2023-02-04 17:32:36,256 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv1.weight              loaded from backbone.body.layer3.5.conv1.weight              of shape (256, 1024, 1, 1)\n",
            "2023-02-04 17:32:36,256 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv2.weight              loaded from backbone.body.layer3.5.conv2.weight              of shape (256, 256, 3, 3)\n",
            "2023-02-04 17:32:36,256 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv3.weight              loaded from backbone.body.layer3.5.conv3.weight              of shape (1024, 256, 1, 1)\n",
            "2023-02-04 17:32:36,256 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.bias                  loaded from backbone.body.layer4.0.bn1.bias                  of shape (512,)\n",
            "2023-02-04 17:32:36,256 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.running_mean          loaded from backbone.body.layer4.0.bn1.running_mean          of shape (512,)\n",
            "2023-02-04 17:32:36,256 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.running_var           loaded from backbone.body.layer4.0.bn1.running_var           of shape (512,)\n",
            "2023-02-04 17:32:36,256 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.weight                loaded from backbone.body.layer4.0.bn1.weight                of shape (512,)\n",
            "2023-02-04 17:32:36,256 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.bias                  loaded from backbone.body.layer4.0.bn2.bias                  of shape (512,)\n",
            "2023-02-04 17:32:36,256 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.running_mean          loaded from backbone.body.layer4.0.bn2.running_mean          of shape (512,)\n",
            "2023-02-04 17:32:36,256 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.running_var           loaded from backbone.body.layer4.0.bn2.running_var           of shape (512,)\n",
            "2023-02-04 17:32:36,256 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.weight                loaded from backbone.body.layer4.0.bn2.weight                of shape (512,)\n",
            "2023-02-04 17:32:36,256 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.bias                  loaded from backbone.body.layer4.0.bn3.bias                  of shape (2048,)\n",
            "2023-02-04 17:32:36,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.running_mean          loaded from backbone.body.layer4.0.bn3.running_mean          of shape (2048,)\n",
            "2023-02-04 17:32:36,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.running_var           loaded from backbone.body.layer4.0.bn3.running_var           of shape (2048,)\n",
            "2023-02-04 17:32:36,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.weight                loaded from backbone.body.layer4.0.bn3.weight                of shape (2048,)\n",
            "2023-02-04 17:32:36,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv1.weight              loaded from backbone.body.layer4.0.conv1.weight              of shape (512, 1024, 1, 1)\n",
            "2023-02-04 17:32:36,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv2.weight              loaded from backbone.body.layer4.0.conv2.weight              of shape (512, 512, 3, 3)\n",
            "2023-02-04 17:32:36,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv3.weight              loaded from backbone.body.layer4.0.conv3.weight              of shape (2048, 512, 1, 1)\n",
            "2023-02-04 17:32:36,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.0.weight       loaded from backbone.body.layer4.0.downsample.0.weight       of shape (2048, 1024, 1, 1)\n",
            "2023-02-04 17:32:36,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.bias         loaded from backbone.body.layer4.0.downsample.1.bias         of shape (2048,)\n",
            "2023-02-04 17:32:36,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.running_mean loaded from backbone.body.layer4.0.downsample.1.running_mean of shape (2048,)\n",
            "2023-02-04 17:32:36,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.running_var  loaded from backbone.body.layer4.0.downsample.1.running_var  of shape (2048,)\n",
            "2023-02-04 17:32:36,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.weight       loaded from backbone.body.layer4.0.downsample.1.weight       of shape (2048,)\n",
            "2023-02-04 17:32:36,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.bias                  loaded from backbone.body.layer4.1.bn1.bias                  of shape (512,)\n",
            "2023-02-04 17:32:36,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.running_mean          loaded from backbone.body.layer4.1.bn1.running_mean          of shape (512,)\n",
            "2023-02-04 17:32:36,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.running_var           loaded from backbone.body.layer4.1.bn1.running_var           of shape (512,)\n",
            "2023-02-04 17:32:36,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.weight                loaded from backbone.body.layer4.1.bn1.weight                of shape (512,)\n",
            "2023-02-04 17:32:36,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.bias                  loaded from backbone.body.layer4.1.bn2.bias                  of shape (512,)\n",
            "2023-02-04 17:32:36,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.running_mean          loaded from backbone.body.layer4.1.bn2.running_mean          of shape (512,)\n",
            "2023-02-04 17:32:36,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.running_var           loaded from backbone.body.layer4.1.bn2.running_var           of shape (512,)\n",
            "2023-02-04 17:32:36,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.weight                loaded from backbone.body.layer4.1.bn2.weight                of shape (512,)\n",
            "2023-02-04 17:32:36,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.bias                  loaded from backbone.body.layer4.1.bn3.bias                  of shape (2048,)\n",
            "2023-02-04 17:32:36,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.running_mean          loaded from backbone.body.layer4.1.bn3.running_mean          of shape (2048,)\n",
            "2023-02-04 17:32:36,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.running_var           loaded from backbone.body.layer4.1.bn3.running_var           of shape (2048,)\n",
            "2023-02-04 17:32:36,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.weight                loaded from backbone.body.layer4.1.bn3.weight                of shape (2048,)\n",
            "2023-02-04 17:32:36,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv1.weight              loaded from backbone.body.layer4.1.conv1.weight              of shape (512, 2048, 1, 1)\n",
            "2023-02-04 17:32:36,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv2.weight              loaded from backbone.body.layer4.1.conv2.weight              of shape (512, 512, 3, 3)\n",
            "2023-02-04 17:32:36,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv3.weight              loaded from backbone.body.layer4.1.conv3.weight              of shape (2048, 512, 1, 1)\n",
            "2023-02-04 17:32:36,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.bias                  loaded from backbone.body.layer4.2.bn1.bias                  of shape (512,)\n",
            "2023-02-04 17:32:36,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.running_mean          loaded from backbone.body.layer4.2.bn1.running_mean          of shape (512,)\n",
            "2023-02-04 17:32:36,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.running_var           loaded from backbone.body.layer4.2.bn1.running_var           of shape (512,)\n",
            "2023-02-04 17:32:36,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.weight                loaded from backbone.body.layer4.2.bn1.weight                of shape (512,)\n",
            "2023-02-04 17:32:36,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.bias                  loaded from backbone.body.layer4.2.bn2.bias                  of shape (512,)\n",
            "2023-02-04 17:32:36,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.running_mean          loaded from backbone.body.layer4.2.bn2.running_mean          of shape (512,)\n",
            "2023-02-04 17:32:36,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.running_var           loaded from backbone.body.layer4.2.bn2.running_var           of shape (512,)\n",
            "2023-02-04 17:32:36,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.weight                loaded from backbone.body.layer4.2.bn2.weight                of shape (512,)\n",
            "2023-02-04 17:32:36,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.bias                  loaded from backbone.body.layer4.2.bn3.bias                  of shape (2048,)\n",
            "2023-02-04 17:32:36,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.running_mean          loaded from backbone.body.layer4.2.bn3.running_mean          of shape (2048,)\n",
            "2023-02-04 17:32:36,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.running_var           loaded from backbone.body.layer4.2.bn3.running_var           of shape (2048,)\n",
            "2023-02-04 17:32:36,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.weight                loaded from backbone.body.layer4.2.bn3.weight                of shape (2048,)\n",
            "2023-02-04 17:32:36,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv1.weight              loaded from backbone.body.layer4.2.conv1.weight              of shape (512, 2048, 1, 1)\n",
            "2023-02-04 17:32:36,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv2.weight              loaded from backbone.body.layer4.2.conv2.weight              of shape (512, 512, 3, 3)\n",
            "2023-02-04 17:32:36,259 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv3.weight              loaded from backbone.body.layer4.2.conv3.weight              of shape (2048, 512, 1, 1)\n",
            "2023-02-04 17:32:36,259 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.bias                      loaded from backbone.body.stem.bn1.bias                      of shape (64,)\n",
            "2023-02-04 17:32:36,259 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.running_mean              loaded from backbone.body.stem.bn1.running_mean              of shape (64,)\n",
            "2023-02-04 17:32:36,259 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.running_var               loaded from backbone.body.stem.bn1.running_var               of shape (64,)\n",
            "2023-02-04 17:32:36,259 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.weight                    loaded from backbone.body.stem.bn1.weight                    of shape (64,)\n",
            "2023-02-04 17:32:36,259 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.conv1.weight                  loaded from backbone.body.stem.conv1.weight                  of shape (64, 3, 7, 7)\n",
            "2023-02-04 17:32:36,259 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner1.bias                     loaded from backbone.fpn.fpn_inner1.bias                     of shape (256,)\n",
            "2023-02-04 17:32:36,259 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner1.weight                   loaded from backbone.fpn.fpn_inner1.weight                   of shape (256, 256, 1, 1)\n",
            "2023-02-04 17:32:36,259 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner2.bias                     loaded from backbone.fpn.fpn_inner2.bias                     of shape (256,)\n",
            "2023-02-04 17:32:36,259 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner2.weight                   loaded from backbone.fpn.fpn_inner2.weight                   of shape (256, 512, 1, 1)\n",
            "2023-02-04 17:32:36,259 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner3.bias                     loaded from backbone.fpn.fpn_inner3.bias                     of shape (256,)\n",
            "2023-02-04 17:32:36,259 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner3.weight                   loaded from backbone.fpn.fpn_inner3.weight                   of shape (256, 1024, 1, 1)\n",
            "2023-02-04 17:32:36,259 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner4.bias                     loaded from backbone.fpn.fpn_inner4.bias                     of shape (256,)\n",
            "2023-02-04 17:32:36,259 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner4.weight                   loaded from backbone.fpn.fpn_inner4.weight                   of shape (256, 2048, 1, 1)\n",
            "2023-02-04 17:32:36,259 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer1.bias                     loaded from backbone.fpn.fpn_layer1.bias                     of shape (256,)\n",
            "2023-02-04 17:32:36,259 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer1.weight                   loaded from backbone.fpn.fpn_layer1.weight                   of shape (256, 256, 3, 3)\n",
            "2023-02-04 17:32:36,259 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer2.bias                     loaded from backbone.fpn.fpn_layer2.bias                     of shape (256,)\n",
            "2023-02-04 17:32:36,259 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer2.weight                   loaded from backbone.fpn.fpn_layer2.weight                   of shape (256, 256, 3, 3)\n",
            "2023-02-04 17:32:36,260 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer3.bias                     loaded from backbone.fpn.fpn_layer3.bias                     of shape (256,)\n",
            "2023-02-04 17:32:36,260 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer3.weight                   loaded from backbone.fpn.fpn_layer3.weight                   of shape (256, 256, 3, 3)\n",
            "2023-02-04 17:32:36,260 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer4.bias                     loaded from backbone.fpn.fpn_layer4.bias                     of shape (256,)\n",
            "2023-02-04 17:32:36,260 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer4.weight                   loaded from backbone.fpn.fpn_layer4.weight                   of shape (256, 256, 3, 3)\n",
            "2023-02-04 17:32:36,260 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level0.bias        loaded from da_heads.imghead.da_img_conv1_level0.bias        of shape (512,)\n",
            "2023-02-04 17:32:36,260 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level0.weight      loaded from da_heads.imghead.da_img_conv1_level0.weight      of shape (512, 256, 1, 1)\n",
            "2023-02-04 17:32:36,260 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level1.bias        loaded from da_heads.imghead.da_img_conv1_level1.bias        of shape (512,)\n",
            "2023-02-04 17:32:36,260 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level1.weight      loaded from da_heads.imghead.da_img_conv1_level1.weight      of shape (512, 256, 1, 1)\n",
            "2023-02-04 17:32:36,260 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level2.bias        loaded from da_heads.imghead.da_img_conv1_level2.bias        of shape (512,)\n",
            "2023-02-04 17:32:36,260 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level2.weight      loaded from da_heads.imghead.da_img_conv1_level2.weight      of shape (512, 256, 1, 1)\n",
            "2023-02-04 17:32:36,260 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level3.bias        loaded from da_heads.imghead.da_img_conv1_level3.bias        of shape (512,)\n",
            "2023-02-04 17:32:36,260 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level3.weight      loaded from da_heads.imghead.da_img_conv1_level3.weight      of shape (512, 256, 1, 1)\n",
            "2023-02-04 17:32:36,260 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level4.bias        loaded from da_heads.imghead.da_img_conv1_level4.bias        of shape (512,)\n",
            "2023-02-04 17:32:36,260 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level4.weight      loaded from da_heads.imghead.da_img_conv1_level4.weight      of shape (512, 256, 1, 1)\n",
            "2023-02-04 17:32:36,261 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level0.bias        loaded from da_heads.imghead.da_img_conv2_level0.bias        of shape (1,)\n",
            "2023-02-04 17:32:36,261 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level0.weight      loaded from da_heads.imghead.da_img_conv2_level0.weight      of shape (1, 512, 1, 1)\n",
            "2023-02-04 17:32:36,261 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level1.bias        loaded from da_heads.imghead.da_img_conv2_level1.bias        of shape (1,)\n",
            "2023-02-04 17:32:36,261 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level1.weight      loaded from da_heads.imghead.da_img_conv2_level1.weight      of shape (1, 512, 1, 1)\n",
            "2023-02-04 17:32:36,261 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level2.bias        loaded from da_heads.imghead.da_img_conv2_level2.bias        of shape (1,)\n",
            "2023-02-04 17:32:36,261 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level2.weight      loaded from da_heads.imghead.da_img_conv2_level2.weight      of shape (1, 512, 1, 1)\n",
            "2023-02-04 17:32:36,261 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level3.bias        loaded from da_heads.imghead.da_img_conv2_level3.bias        of shape (1,)\n",
            "2023-02-04 17:32:36,261 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level3.weight      loaded from da_heads.imghead.da_img_conv2_level3.weight      of shape (1, 512, 1, 1)\n",
            "2023-02-04 17:32:36,261 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level4.bias        loaded from da_heads.imghead.da_img_conv2_level4.bias        of shape (1,)\n",
            "2023-02-04 17:32:36,261 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level4.weight      loaded from da_heads.imghead.da_img_conv2_level4.weight      of shape (1, 512, 1, 1)\n",
            "2023-02-04 17:32:36,261 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc1_level0.bias          loaded from da_heads.inshead.da_ins_fc1_level0.bias          of shape (1024,)\n",
            "2023-02-04 17:32:36,261 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc1_level0.weight        loaded from da_heads.inshead.da_ins_fc1_level0.weight        of shape (1024, 1024)\n",
            "2023-02-04 17:32:36,261 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc1_level1.bias          loaded from da_heads.inshead.da_ins_fc1_level1.bias          of shape (1024,)\n",
            "2023-02-04 17:32:36,261 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc1_level1.weight        loaded from da_heads.inshead.da_ins_fc1_level1.weight        of shape (1024, 1024)\n",
            "2023-02-04 17:32:36,261 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc1_level2.bias          loaded from da_heads.inshead.da_ins_fc1_level2.bias          of shape (1024,)\n",
            "2023-02-04 17:32:36,261 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc1_level2.weight        loaded from da_heads.inshead.da_ins_fc1_level2.weight        of shape (1024, 1024)\n",
            "2023-02-04 17:32:36,262 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc1_level3.bias          loaded from da_heads.inshead.da_ins_fc1_level3.bias          of shape (1024,)\n",
            "2023-02-04 17:32:36,262 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc1_level3.weight        loaded from da_heads.inshead.da_ins_fc1_level3.weight        of shape (1024, 1024)\n",
            "2023-02-04 17:32:36,262 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc2_level0.bias          loaded from da_heads.inshead.da_ins_fc2_level0.bias          of shape (1024,)\n",
            "2023-02-04 17:32:36,262 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc2_level0.weight        loaded from da_heads.inshead.da_ins_fc2_level0.weight        of shape (1024, 1024)\n",
            "2023-02-04 17:32:36,262 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc2_level1.bias          loaded from da_heads.inshead.da_ins_fc2_level1.bias          of shape (1024,)\n",
            "2023-02-04 17:32:36,262 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc2_level1.weight        loaded from da_heads.inshead.da_ins_fc2_level1.weight        of shape (1024, 1024)\n",
            "2023-02-04 17:32:36,262 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc2_level2.bias          loaded from da_heads.inshead.da_ins_fc2_level2.bias          of shape (1024,)\n",
            "2023-02-04 17:32:36,262 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc2_level2.weight        loaded from da_heads.inshead.da_ins_fc2_level2.weight        of shape (1024, 1024)\n",
            "2023-02-04 17:32:36,262 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc2_level3.bias          loaded from da_heads.inshead.da_ins_fc2_level3.bias          of shape (1024,)\n",
            "2023-02-04 17:32:36,262 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc2_level3.weight        loaded from da_heads.inshead.da_ins_fc2_level3.weight        of shape (1024, 1024)\n",
            "2023-02-04 17:32:36,262 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc3_level0.bias          loaded from da_heads.inshead.da_ins_fc3_level0.bias          of shape (1,)\n",
            "2023-02-04 17:32:36,262 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc3_level0.weight        loaded from da_heads.inshead.da_ins_fc3_level0.weight        of shape (1, 1024)\n",
            "2023-02-04 17:32:36,262 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc3_level1.bias          loaded from da_heads.inshead.da_ins_fc3_level1.bias          of shape (1,)\n",
            "2023-02-04 17:32:36,262 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc3_level1.weight        loaded from da_heads.inshead.da_ins_fc3_level1.weight        of shape (1, 1024)\n",
            "2023-02-04 17:32:36,262 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc3_level2.bias          loaded from da_heads.inshead.da_ins_fc3_level2.bias          of shape (1,)\n",
            "2023-02-04 17:32:36,262 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc3_level2.weight        loaded from da_heads.inshead.da_ins_fc3_level2.weight        of shape (1, 1024)\n",
            "2023-02-04 17:32:36,262 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc3_level3.bias          loaded from da_heads.inshead.da_ins_fc3_level3.bias          of shape (1,)\n",
            "2023-02-04 17:32:36,263 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc3_level3.weight        loaded from da_heads.inshead.da_ins_fc3_level3.weight        of shape (1, 1024)\n",
            "2023-02-04 17:32:36,263 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc6.bias         loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (1024,)\n",
            "2023-02-04 17:32:36,263 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc6.weight       loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (1024, 12544)\n",
            "2023-02-04 17:32:36,263 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc7.bias         loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (1024,)\n",
            "2023-02-04 17:32:36,263 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc7.weight       loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (1024, 1024)\n",
            "2023-02-04 17:32:36,263 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.bbox_pred.bias           loaded from roi_heads.box.predictor.bbox_pred.bias           of shape (8,)\n",
            "2023-02-04 17:32:36,263 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.bbox_pred.weight         loaded from roi_heads.box.predictor.bbox_pred.weight         of shape (8, 1024)\n",
            "2023-02-04 17:32:36,263 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.cls_score.bias           loaded from roi_heads.box.predictor.cls_score.bias           of shape (2,)\n",
            "2023-02-04 17:32:36,263 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.cls_score.weight         loaded from roi_heads.box.predictor.cls_score.weight         of shape (2, 1024)\n",
            "2023-02-04 17:32:36,263 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.0              loaded from rpn.anchor_generator.cell_anchors.0              of shape (3, 4)\n",
            "2023-02-04 17:32:36,263 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.1              loaded from rpn.anchor_generator.cell_anchors.1              of shape (3, 4)\n",
            "2023-02-04 17:32:36,263 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.2              loaded from rpn.anchor_generator.cell_anchors.2              of shape (3, 4)\n",
            "2023-02-04 17:32:36,263 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.3              loaded from rpn.anchor_generator.cell_anchors.3              of shape (3, 4)\n",
            "2023-02-04 17:32:36,263 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.4              loaded from rpn.anchor_generator.cell_anchors.4              of shape (3, 4)\n",
            "2023-02-04 17:32:36,263 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bbox_pred.bias                          loaded from rpn.head.bbox_pred.bias                          of shape (12,)\n",
            "2023-02-04 17:32:36,263 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bbox_pred.weight                        loaded from rpn.head.bbox_pred.weight                        of shape (12, 256, 1, 1)\n",
            "2023-02-04 17:32:36,263 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.cls_logits.bias                         loaded from rpn.head.cls_logits.bias                         of shape (3,)\n",
            "2023-02-04 17:32:36,263 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.cls_logits.weight                       loaded from rpn.head.cls_logits.weight                       of shape (3, 256, 1, 1)\n",
            "2023-02-04 17:32:36,263 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.conv.bias                               loaded from rpn.head.conv.bias                               of shape (256,)\n",
            "2023-02-04 17:32:36,264 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.conv.weight                             loaded from rpn.head.conv.weight                             of shape (256, 256, 3, 3)\n",
            "loading annotations into memory...\n",
            "Done (t=0.46s)\n",
            "creating index...\n",
            "index created!\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "2023-02-04 17:32:36,809 maskrcnn_benchmark.inference INFO: Start evaluation on cityscapes_only_car_val_cocostyle dataset(500 images).\n",
            "  0% 0/500 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "100% 500/500 [01:57<00:00,  4.26it/s]\n",
            "2023-02-04 17:34:34,273 maskrcnn_benchmark.inference INFO: Total inference time: 0:01:57.463363 (0.2349267258644104 s / img per device, on 1 devices)\n",
            "2023-02-04 17:34:34,361 maskrcnn_benchmark.inference INFO: Preparing results for COCO format\n",
            "2023-02-04 17:34:34,361 maskrcnn_benchmark.inference INFO: Preparing bbox results\n",
            "2023-02-04 17:34:34,452 maskrcnn_benchmark.inference INFO: Evaluating predictions\n",
            "Category: 1 {'id': 1, 'name': 'car'}\n",
            "Loading and preparing results...\n",
            "DONE (t=0.26s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=5.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.20s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.249\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.524\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.217\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.081\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.289\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.465\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.065\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.269\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.353\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.165\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.389\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.587\n",
            "Loading and preparing results...\n",
            "DONE (t=0.22s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=4.73s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.20s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.249\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.524\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.217\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.081\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.289\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.465\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.065\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.269\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.353\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.165\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.389\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.587\n",
            "2023-02-04 17:34:45,975 maskrcnn_benchmark.inference INFO: OrderedDict([('bbox', OrderedDict([('AP', -1), ('AP50', -1), ('AP75', -1), ('APs', -1), ('APm', -1), ('APl', -1), (1, {'AP': 0.24902703768459475, 'AP50': 0.5241155914022596, 'AP75': 0.21742468689645286, 'APs': 0.08114805404136236, 'APm': 0.2888338058498031, 'APl': 0.46542018022807924})]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/test_net.py --config-file \"/content/MIC/det/configs/fff.yaml\" MODEL.WEIGHT /content/drive/MyDrive/AI/mic/model_0005000.pth\n"
      ],
      "metadata": {
        "id": "LyhOppqnf0n1",
        "outputId": "71d6aa17-c0b9-4b68-eefd-07aa74718771",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-04 17:36:19,618 maskrcnn_benchmark INFO: Using 1 GPUs\n",
            "2023-02-04 17:36:19,618 maskrcnn_benchmark INFO: DATALOADER:\n",
            "  ASPECT_RATIO_GROUPING: True\n",
            "  NUM_WORKERS: 4\n",
            "  SIZE_DIVISIBILITY: 32\n",
            "DATASETS:\n",
            "  SOURCE_TRAIN: ('sim10k_cocostyle',)\n",
            "  TARGET_TRAIN: ('cityscapes_only_car_train_cocostyle',)\n",
            "  TEST: ('cityscapes_only_car_val_cocostyle',)\n",
            "  TRAIN: ()\n",
            "INPUT:\n",
            "  MAX_SIZE_TEST: 1600\n",
            "  MAX_SIZE_TRAIN: 1600\n",
            "  MIN_SIZE_TEST: 800\n",
            "  MIN_SIZE_TRAIN: (800,)\n",
            "  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]\n",
            "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
            "  TO_BGR255: True\n",
            "MODEL:\n",
            "  BACKBONE:\n",
            "    CONV_BODY: R-50-FPN\n",
            "    FREEZE_CONV_BODY_AT: 2\n",
            "    OUT_CHANNELS: 256\n",
            "    USE_GN: False\n",
            "  CLS_AGNOSTIC_BBOX_REG: False\n",
            "  DA_HEADS:\n",
            "    COS_WEIGHT: 0.1\n",
            "    DA_IMG_GRL_WEIGHT: 0.01\n",
            "    DA_INS_GRL_WEIGHT: 0.1\n",
            "  DEVICE: cuda\n",
            "  DOMAIN_ADAPTATION_ON: True\n",
            "  FPN:\n",
            "    USE_GN: False\n",
            "    USE_RELU: False\n",
            "  GROUP_NORM:\n",
            "    DIM_PER_GP: -1\n",
            "    EPSILON: 1e-05\n",
            "    NUM_GROUPS: 32\n",
            "  KEYPOINT_ON: False\n",
            "  MASKING_AUGMENTATION: True\n",
            "  MASKING_BLOCK_SIZE: 32\n",
            "  MASKING_RATIO: 0.5\n",
            "  MASK_ON: False\n",
            "  META_ARCHITECTURE: GeneralizedRCNN\n",
            "  MIC_ON: True\n",
            "  PSEUDO_LABEL_LAMBDA: 1.0\n",
            "  PSEUDO_LABEL_THRESHOLD: 0.8\n",
            "  PSEUDO_LABEL_WEIGHT: prob\n",
            "  RESNETS:\n",
            "    NUM_GROUPS: 1\n",
            "    RES2_OUT_CHANNELS: 256\n",
            "    RES5_DILATION: 1\n",
            "    STEM_FUNC: StemWithFixedBatchNorm\n",
            "    STEM_OUT_CHANNELS: 64\n",
            "    STRIDE_IN_1X1: True\n",
            "    TRANS_FUNC: BottleneckWithFixedBatchNorm\n",
            "    WIDTH_PER_GROUP: 64\n",
            "  RETINANET:\n",
            "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
            "    ANCHOR_STRIDES: (8, 16, 32, 64, 128)\n",
            "    ASPECT_RATIOS: (0.5, 1.0, 2.0)\n",
            "    BBOX_REG_BETA: 0.11\n",
            "    BBOX_REG_WEIGHT: 4.0\n",
            "    BG_IOU_THRESHOLD: 0.4\n",
            "    FG_IOU_THRESHOLD: 0.5\n",
            "    INFERENCE_TH: 0.05\n",
            "    LOSS_ALPHA: 0.25\n",
            "    LOSS_GAMMA: 2.0\n",
            "    NMS_TH: 0.4\n",
            "    NUM_CLASSES: 81\n",
            "    NUM_CONVS: 4\n",
            "    OCTAVE: 2.0\n",
            "    PRE_NMS_TOP_N: 1000\n",
            "    PRIOR_PROB: 0.01\n",
            "    SCALES_PER_OCTAVE: 3\n",
            "    STRADDLE_THRESH: 0\n",
            "    USE_C5: True\n",
            "  RETINANET_ON: False\n",
            "  ROI_BOX_HEAD:\n",
            "    CONV_HEAD_DIM: 256\n",
            "    DILATION: 1\n",
            "    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n",
            "    MLP_HEAD_DIM: 1024\n",
            "    NUM_CLASSES: 2\n",
            "    NUM_STACKED_CONVS: 4\n",
            "    POOLER_RESOLUTION: 7\n",
            "    POOLER_SAMPLING_RATIO: 2\n",
            "    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n",
            "    PREDICTOR: FPNPredictor\n",
            "    USE_GN: False\n",
            "  ROI_HEADS:\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
            "    BG_IOU_THRESHOLD: 0.5\n",
            "    DETECTIONS_PER_IMG: 100\n",
            "    FG_IOU_THRESHOLD: 0.5\n",
            "    NMS: 0.5\n",
            "    POSITIVE_FRACTION: 0.25\n",
            "    SCORE_THRESH: 0.05\n",
            "    USE_FPN: True\n",
            "  ROI_KEYPOINT_HEAD:\n",
            "    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
            "    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor\n",
            "    MLP_HEAD_DIM: 1024\n",
            "    NUM_CLASSES: 17\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_SCALES: (0.0625,)\n",
            "    PREDICTOR: KeypointRCNNPredictor\n",
            "    RESOLUTION: 14\n",
            "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
            "  ROI_MASK_HEAD:\n",
            "    CONV_LAYERS: (256, 256, 256, 256)\n",
            "    DILATION: 1\n",
            "    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor\n",
            "    MLP_HEAD_DIM: 1024\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_SCALES: (0.0625,)\n",
            "    POSTPROCESS_MASKS: False\n",
            "    POSTPROCESS_MASKS_THRESHOLD: 0.5\n",
            "    PREDICTOR: MaskRCNNC4Predictor\n",
            "    RESOLUTION: 14\n",
            "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
            "    USE_GN: False\n",
            "  RPN:\n",
            "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
            "    ANCHOR_STRIDE: (4, 8, 16, 32, 64)\n",
            "    ASPECT_RATIOS: (0.5, 1.0, 2.0)\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "    BG_IOU_THRESHOLD: 0.3\n",
            "    FG_IOU_THRESHOLD: 0.7\n",
            "    FPN_POST_NMS_TOP_N_TEST: 1000\n",
            "    FPN_POST_NMS_TOP_N_TRAIN: 2000\n",
            "    MIN_SIZE: 0\n",
            "    NMS_THRESH: 0.7\n",
            "    POSITIVE_FRACTION: 0.5\n",
            "    POST_NMS_TOP_N_TEST: 1000\n",
            "    POST_NMS_TOP_N_TRAIN: 2000\n",
            "    PRE_NMS_TOP_N_TEST: 1000\n",
            "    PRE_NMS_TOP_N_TRAIN: 2000\n",
            "    RPN_HEAD: SingleConvRPNHead\n",
            "    STRADDLE_THRESH: 0\n",
            "    USE_FPN: True\n",
            "  RPN_ONLY: False\n",
            "  TEACHER_ALPHA: 0.9\n",
            "  WEIGHT: /content/drive/MyDrive/AI/mic/model_0005000.pth\n",
            "OUTPUT_DIR: /content/drive/MyDrive/AI/mic\n",
            "PATHS_CATALOG: /content/MIC/det/maskrcnn_benchmark/config/paths_catalog.py\n",
            "SOLVER:\n",
            "  BASE_LR: 0.001\n",
            "  BIAS_LR_FACTOR: 2\n",
            "  CHECKPOINT_PERIOD: 1000\n",
            "  GAMMA: 0.1\n",
            "  IMS_PER_BATCH: 2\n",
            "  MAX_ITER: 60000\n",
            "  MOMENTUM: 0.9\n",
            "  STEPS: (30000, 40000)\n",
            "  WARMUP_FACTOR: 0.3333333333333333\n",
            "  WARMUP_ITERS: 1000\n",
            "  WARMUP_METHOD: linear\n",
            "  WEIGHT_DECAY: 0.0001\n",
            "  WEIGHT_DECAY_BIAS: 0\n",
            "TEST:\n",
            "  DETECTIONS_PER_IMG: 100\n",
            "  EXPECTED_RESULTS: []\n",
            "  EXPECTED_RESULTS_SIGMA_TOL: 4\n",
            "  IMS_PER_BATCH: 1\n",
            "2023-02-04 17:36:19,619 maskrcnn_benchmark INFO: Collecting env info (might take some time)\n",
            "2023-02-04 17:36:21,067 maskrcnn_benchmark INFO: \n",
            "PyTorch version: 1.12.0+cu113\n",
            "Is debug build: False\n",
            "CUDA used to build PyTorch: 11.3\n",
            "ROCM used to build PyTorch: N/A\n",
            "\n",
            "OS: Ubuntu 20.04.5 LTS (x86_64)\n",
            "GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n",
            "Clang version: 10.0.0-4ubuntu1 \n",
            "CMake version: version 3.22.6\n",
            "Libc version: glibc-2.31\n",
            "\n",
            "Python version: 3.8.10 (default, Nov 14 2022, 12:59:47)  [GCC 9.4.0] (64-bit runtime)\n",
            "Python platform: Linux-5.10.147+-x86_64-with-glibc2.29\n",
            "Is CUDA available: True\n",
            "CUDA runtime version: 11.2.152\n",
            "GPU models and configuration: GPU 0: Tesla T4\n",
            "Nvidia driver version: 510.47.03\n",
            "cuDNN version: Probably one of the following:\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.1.1\n",
            "HIP runtime version: N/A\n",
            "MIOpen runtime version: N/A\n",
            "Is XNNPACK available: True\n",
            "\n",
            "Versions of relevant libraries:\n",
            "[pip3] numpy==1.21.6\n",
            "[pip3] torch==1.12.0+cu113\n",
            "[pip3] torchaudio==0.12.0+cu113\n",
            "[pip3] torchsummary==1.5.1\n",
            "[pip3] torchtext==0.14.1\n",
            "[pip3] torchvision==0.13.0+cu113\n",
            "[conda] Could not collect\n",
            "        Pillow (7.1.2)\n",
            "2023-02-04 17:36:23,953 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from /content/drive/MyDrive/AI/mic/model_0005000.pth\n",
            "2023-02-04 17:36:26,497 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.bias                  loaded from backbone.body.layer1.0.bn1.bias                  of shape (64,)\n",
            "2023-02-04 17:36:26,497 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.running_mean          loaded from backbone.body.layer1.0.bn1.running_mean          of shape (64,)\n",
            "2023-02-04 17:36:26,497 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.running_var           loaded from backbone.body.layer1.0.bn1.running_var           of shape (64,)\n",
            "2023-02-04 17:36:26,497 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.weight                loaded from backbone.body.layer1.0.bn1.weight                of shape (64,)\n",
            "2023-02-04 17:36:26,498 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.bias                  loaded from backbone.body.layer1.0.bn2.bias                  of shape (64,)\n",
            "2023-02-04 17:36:26,498 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.running_mean          loaded from backbone.body.layer1.0.bn2.running_mean          of shape (64,)\n",
            "2023-02-04 17:36:26,498 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.running_var           loaded from backbone.body.layer1.0.bn2.running_var           of shape (64,)\n",
            "2023-02-04 17:36:26,498 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.weight                loaded from backbone.body.layer1.0.bn2.weight                of shape (64,)\n",
            "2023-02-04 17:36:26,498 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.bias                  loaded from backbone.body.layer1.0.bn3.bias                  of shape (256,)\n",
            "2023-02-04 17:36:26,498 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.running_mean          loaded from backbone.body.layer1.0.bn3.running_mean          of shape (256,)\n",
            "2023-02-04 17:36:26,498 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.running_var           loaded from backbone.body.layer1.0.bn3.running_var           of shape (256,)\n",
            "2023-02-04 17:36:26,498 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.weight                loaded from backbone.body.layer1.0.bn3.weight                of shape (256,)\n",
            "2023-02-04 17:36:26,498 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv1.weight              loaded from backbone.body.layer1.0.conv1.weight              of shape (64, 64, 1, 1)\n",
            "2023-02-04 17:36:26,498 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv2.weight              loaded from backbone.body.layer1.0.conv2.weight              of shape (64, 64, 3, 3)\n",
            "2023-02-04 17:36:26,498 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv3.weight              loaded from backbone.body.layer1.0.conv3.weight              of shape (256, 64, 1, 1)\n",
            "2023-02-04 17:36:26,498 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.0.weight       loaded from backbone.body.layer1.0.downsample.0.weight       of shape (256, 64, 1, 1)\n",
            "2023-02-04 17:36:26,498 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.bias         loaded from backbone.body.layer1.0.downsample.1.bias         of shape (256,)\n",
            "2023-02-04 17:36:26,498 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.running_mean loaded from backbone.body.layer1.0.downsample.1.running_mean of shape (256,)\n",
            "2023-02-04 17:36:26,498 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.running_var  loaded from backbone.body.layer1.0.downsample.1.running_var  of shape (256,)\n",
            "2023-02-04 17:36:26,498 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.weight       loaded from backbone.body.layer1.0.downsample.1.weight       of shape (256,)\n",
            "2023-02-04 17:36:26,498 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.bias                  loaded from backbone.body.layer1.1.bn1.bias                  of shape (64,)\n",
            "2023-02-04 17:36:26,498 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.running_mean          loaded from backbone.body.layer1.1.bn1.running_mean          of shape (64,)\n",
            "2023-02-04 17:36:26,498 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.running_var           loaded from backbone.body.layer1.1.bn1.running_var           of shape (64,)\n",
            "2023-02-04 17:36:26,498 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.weight                loaded from backbone.body.layer1.1.bn1.weight                of shape (64,)\n",
            "2023-02-04 17:36:26,498 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.bias                  loaded from backbone.body.layer1.1.bn2.bias                  of shape (64,)\n",
            "2023-02-04 17:36:26,498 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.running_mean          loaded from backbone.body.layer1.1.bn2.running_mean          of shape (64,)\n",
            "2023-02-04 17:36:26,498 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.running_var           loaded from backbone.body.layer1.1.bn2.running_var           of shape (64,)\n",
            "2023-02-04 17:36:26,498 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.weight                loaded from backbone.body.layer1.1.bn2.weight                of shape (64,)\n",
            "2023-02-04 17:36:26,498 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.bias                  loaded from backbone.body.layer1.1.bn3.bias                  of shape (256,)\n",
            "2023-02-04 17:36:26,498 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.running_mean          loaded from backbone.body.layer1.1.bn3.running_mean          of shape (256,)\n",
            "2023-02-04 17:36:26,498 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.running_var           loaded from backbone.body.layer1.1.bn3.running_var           of shape (256,)\n",
            "2023-02-04 17:36:26,499 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.weight                loaded from backbone.body.layer1.1.bn3.weight                of shape (256,)\n",
            "2023-02-04 17:36:26,499 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv1.weight              loaded from backbone.body.layer1.1.conv1.weight              of shape (64, 256, 1, 1)\n",
            "2023-02-04 17:36:26,499 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv2.weight              loaded from backbone.body.layer1.1.conv2.weight              of shape (64, 64, 3, 3)\n",
            "2023-02-04 17:36:26,499 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv3.weight              loaded from backbone.body.layer1.1.conv3.weight              of shape (256, 64, 1, 1)\n",
            "2023-02-04 17:36:26,499 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.bias                  loaded from backbone.body.layer1.2.bn1.bias                  of shape (64,)\n",
            "2023-02-04 17:36:26,499 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.running_mean          loaded from backbone.body.layer1.2.bn1.running_mean          of shape (64,)\n",
            "2023-02-04 17:36:26,499 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.running_var           loaded from backbone.body.layer1.2.bn1.running_var           of shape (64,)\n",
            "2023-02-04 17:36:26,499 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.weight                loaded from backbone.body.layer1.2.bn1.weight                of shape (64,)\n",
            "2023-02-04 17:36:26,499 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.bias                  loaded from backbone.body.layer1.2.bn2.bias                  of shape (64,)\n",
            "2023-02-04 17:36:26,499 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.running_mean          loaded from backbone.body.layer1.2.bn2.running_mean          of shape (64,)\n",
            "2023-02-04 17:36:26,499 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.running_var           loaded from backbone.body.layer1.2.bn2.running_var           of shape (64,)\n",
            "2023-02-04 17:36:26,499 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.weight                loaded from backbone.body.layer1.2.bn2.weight                of shape (64,)\n",
            "2023-02-04 17:36:26,499 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.bias                  loaded from backbone.body.layer1.2.bn3.bias                  of shape (256,)\n",
            "2023-02-04 17:36:26,499 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.running_mean          loaded from backbone.body.layer1.2.bn3.running_mean          of shape (256,)\n",
            "2023-02-04 17:36:26,499 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.running_var           loaded from backbone.body.layer1.2.bn3.running_var           of shape (256,)\n",
            "2023-02-04 17:36:26,499 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.weight                loaded from backbone.body.layer1.2.bn3.weight                of shape (256,)\n",
            "2023-02-04 17:36:26,499 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv1.weight              loaded from backbone.body.layer1.2.conv1.weight              of shape (64, 256, 1, 1)\n",
            "2023-02-04 17:36:26,499 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv2.weight              loaded from backbone.body.layer1.2.conv2.weight              of shape (64, 64, 3, 3)\n",
            "2023-02-04 17:36:26,499 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv3.weight              loaded from backbone.body.layer1.2.conv3.weight              of shape (256, 64, 1, 1)\n",
            "2023-02-04 17:36:26,499 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.bias                  loaded from backbone.body.layer2.0.bn1.bias                  of shape (128,)\n",
            "2023-02-04 17:36:26,499 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.running_mean          loaded from backbone.body.layer2.0.bn1.running_mean          of shape (128,)\n",
            "2023-02-04 17:36:26,499 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.running_var           loaded from backbone.body.layer2.0.bn1.running_var           of shape (128,)\n",
            "2023-02-04 17:36:26,499 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.weight                loaded from backbone.body.layer2.0.bn1.weight                of shape (128,)\n",
            "2023-02-04 17:36:26,499 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.bias                  loaded from backbone.body.layer2.0.bn2.bias                  of shape (128,)\n",
            "2023-02-04 17:36:26,499 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.running_mean          loaded from backbone.body.layer2.0.bn2.running_mean          of shape (128,)\n",
            "2023-02-04 17:36:26,499 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.running_var           loaded from backbone.body.layer2.0.bn2.running_var           of shape (128,)\n",
            "2023-02-04 17:36:26,500 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.weight                loaded from backbone.body.layer2.0.bn2.weight                of shape (128,)\n",
            "2023-02-04 17:36:26,500 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.bias                  loaded from backbone.body.layer2.0.bn3.bias                  of shape (512,)\n",
            "2023-02-04 17:36:26,500 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.running_mean          loaded from backbone.body.layer2.0.bn3.running_mean          of shape (512,)\n",
            "2023-02-04 17:36:26,500 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.running_var           loaded from backbone.body.layer2.0.bn3.running_var           of shape (512,)\n",
            "2023-02-04 17:36:26,500 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.weight                loaded from backbone.body.layer2.0.bn3.weight                of shape (512,)\n",
            "2023-02-04 17:36:26,500 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv1.weight              loaded from backbone.body.layer2.0.conv1.weight              of shape (128, 256, 1, 1)\n",
            "2023-02-04 17:36:26,500 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv2.weight              loaded from backbone.body.layer2.0.conv2.weight              of shape (128, 128, 3, 3)\n",
            "2023-02-04 17:36:26,500 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv3.weight              loaded from backbone.body.layer2.0.conv3.weight              of shape (512, 128, 1, 1)\n",
            "2023-02-04 17:36:26,500 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.0.weight       loaded from backbone.body.layer2.0.downsample.0.weight       of shape (512, 256, 1, 1)\n",
            "2023-02-04 17:36:26,500 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.bias         loaded from backbone.body.layer2.0.downsample.1.bias         of shape (512,)\n",
            "2023-02-04 17:36:26,500 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.running_mean loaded from backbone.body.layer2.0.downsample.1.running_mean of shape (512,)\n",
            "2023-02-04 17:36:26,500 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.running_var  loaded from backbone.body.layer2.0.downsample.1.running_var  of shape (512,)\n",
            "2023-02-04 17:36:26,500 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.weight       loaded from backbone.body.layer2.0.downsample.1.weight       of shape (512,)\n",
            "2023-02-04 17:36:26,500 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.bias                  loaded from backbone.body.layer2.1.bn1.bias                  of shape (128,)\n",
            "2023-02-04 17:36:26,500 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.running_mean          loaded from backbone.body.layer2.1.bn1.running_mean          of shape (128,)\n",
            "2023-02-04 17:36:26,500 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.running_var           loaded from backbone.body.layer2.1.bn1.running_var           of shape (128,)\n",
            "2023-02-04 17:36:26,500 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.weight                loaded from backbone.body.layer2.1.bn1.weight                of shape (128,)\n",
            "2023-02-04 17:36:26,500 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.bias                  loaded from backbone.body.layer2.1.bn2.bias                  of shape (128,)\n",
            "2023-02-04 17:36:26,500 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.running_mean          loaded from backbone.body.layer2.1.bn2.running_mean          of shape (128,)\n",
            "2023-02-04 17:36:26,500 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.running_var           loaded from backbone.body.layer2.1.bn2.running_var           of shape (128,)\n",
            "2023-02-04 17:36:26,500 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.weight                loaded from backbone.body.layer2.1.bn2.weight                of shape (128,)\n",
            "2023-02-04 17:36:26,500 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.bias                  loaded from backbone.body.layer2.1.bn3.bias                  of shape (512,)\n",
            "2023-02-04 17:36:26,500 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.running_mean          loaded from backbone.body.layer2.1.bn3.running_mean          of shape (512,)\n",
            "2023-02-04 17:36:26,500 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.running_var           loaded from backbone.body.layer2.1.bn3.running_var           of shape (512,)\n",
            "2023-02-04 17:36:26,501 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.weight                loaded from backbone.body.layer2.1.bn3.weight                of shape (512,)\n",
            "2023-02-04 17:36:26,501 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv1.weight              loaded from backbone.body.layer2.1.conv1.weight              of shape (128, 512, 1, 1)\n",
            "2023-02-04 17:36:26,565 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv2.weight              loaded from backbone.body.layer2.1.conv2.weight              of shape (128, 128, 3, 3)\n",
            "2023-02-04 17:36:26,566 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv3.weight              loaded from backbone.body.layer2.1.conv3.weight              of shape (512, 128, 1, 1)\n",
            "2023-02-04 17:36:26,566 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.bias                  loaded from backbone.body.layer2.2.bn1.bias                  of shape (128,)\n",
            "2023-02-04 17:36:26,566 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.running_mean          loaded from backbone.body.layer2.2.bn1.running_mean          of shape (128,)\n",
            "2023-02-04 17:36:26,566 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.running_var           loaded from backbone.body.layer2.2.bn1.running_var           of shape (128,)\n",
            "2023-02-04 17:36:26,566 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.weight                loaded from backbone.body.layer2.2.bn1.weight                of shape (128,)\n",
            "2023-02-04 17:36:26,567 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.bias                  loaded from backbone.body.layer2.2.bn2.bias                  of shape (128,)\n",
            "2023-02-04 17:36:26,567 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.running_mean          loaded from backbone.body.layer2.2.bn2.running_mean          of shape (128,)\n",
            "2023-02-04 17:36:26,567 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.running_var           loaded from backbone.body.layer2.2.bn2.running_var           of shape (128,)\n",
            "2023-02-04 17:36:26,567 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.weight                loaded from backbone.body.layer2.2.bn2.weight                of shape (128,)\n",
            "2023-02-04 17:36:26,567 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.bias                  loaded from backbone.body.layer2.2.bn3.bias                  of shape (512,)\n",
            "2023-02-04 17:36:26,567 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.running_mean          loaded from backbone.body.layer2.2.bn3.running_mean          of shape (512,)\n",
            "2023-02-04 17:36:26,568 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.running_var           loaded from backbone.body.layer2.2.bn3.running_var           of shape (512,)\n",
            "2023-02-04 17:36:26,568 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.weight                loaded from backbone.body.layer2.2.bn3.weight                of shape (512,)\n",
            "2023-02-04 17:36:26,568 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv1.weight              loaded from backbone.body.layer2.2.conv1.weight              of shape (128, 512, 1, 1)\n",
            "2023-02-04 17:36:26,568 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv2.weight              loaded from backbone.body.layer2.2.conv2.weight              of shape (128, 128, 3, 3)\n",
            "2023-02-04 17:36:26,568 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv3.weight              loaded from backbone.body.layer2.2.conv3.weight              of shape (512, 128, 1, 1)\n",
            "2023-02-04 17:36:26,568 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.bias                  loaded from backbone.body.layer2.3.bn1.bias                  of shape (128,)\n",
            "2023-02-04 17:36:26,568 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.running_mean          loaded from backbone.body.layer2.3.bn1.running_mean          of shape (128,)\n",
            "2023-02-04 17:36:26,568 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.running_var           loaded from backbone.body.layer2.3.bn1.running_var           of shape (128,)\n",
            "2023-02-04 17:36:26,569 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.weight                loaded from backbone.body.layer2.3.bn1.weight                of shape (128,)\n",
            "2023-02-04 17:36:26,569 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.bias                  loaded from backbone.body.layer2.3.bn2.bias                  of shape (128,)\n",
            "2023-02-04 17:36:26,569 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.running_mean          loaded from backbone.body.layer2.3.bn2.running_mean          of shape (128,)\n",
            "2023-02-04 17:36:26,569 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.running_var           loaded from backbone.body.layer2.3.bn2.running_var           of shape (128,)\n",
            "2023-02-04 17:36:26,569 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.weight                loaded from backbone.body.layer2.3.bn2.weight                of shape (128,)\n",
            "2023-02-04 17:36:26,569 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.bias                  loaded from backbone.body.layer2.3.bn3.bias                  of shape (512,)\n",
            "2023-02-04 17:36:26,569 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.running_mean          loaded from backbone.body.layer2.3.bn3.running_mean          of shape (512,)\n",
            "2023-02-04 17:36:26,569 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.running_var           loaded from backbone.body.layer2.3.bn3.running_var           of shape (512,)\n",
            "2023-02-04 17:36:26,569 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.weight                loaded from backbone.body.layer2.3.bn3.weight                of shape (512,)\n",
            "2023-02-04 17:36:26,569 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv1.weight              loaded from backbone.body.layer2.3.conv1.weight              of shape (128, 512, 1, 1)\n",
            "2023-02-04 17:36:26,569 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv2.weight              loaded from backbone.body.layer2.3.conv2.weight              of shape (128, 128, 3, 3)\n",
            "2023-02-04 17:36:26,569 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv3.weight              loaded from backbone.body.layer2.3.conv3.weight              of shape (512, 128, 1, 1)\n",
            "2023-02-04 17:36:26,569 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.bias                  loaded from backbone.body.layer3.0.bn1.bias                  of shape (256,)\n",
            "2023-02-04 17:36:26,569 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.running_mean          loaded from backbone.body.layer3.0.bn1.running_mean          of shape (256,)\n",
            "2023-02-04 17:36:26,569 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.running_var           loaded from backbone.body.layer3.0.bn1.running_var           of shape (256,)\n",
            "2023-02-04 17:36:26,569 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.weight                loaded from backbone.body.layer3.0.bn1.weight                of shape (256,)\n",
            "2023-02-04 17:36:26,569 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.bias                  loaded from backbone.body.layer3.0.bn2.bias                  of shape (256,)\n",
            "2023-02-04 17:36:26,569 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.running_mean          loaded from backbone.body.layer3.0.bn2.running_mean          of shape (256,)\n",
            "2023-02-04 17:36:26,569 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.running_var           loaded from backbone.body.layer3.0.bn2.running_var           of shape (256,)\n",
            "2023-02-04 17:36:26,569 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.weight                loaded from backbone.body.layer3.0.bn2.weight                of shape (256,)\n",
            "2023-02-04 17:36:26,569 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.bias                  loaded from backbone.body.layer3.0.bn3.bias                  of shape (1024,)\n",
            "2023-02-04 17:36:26,569 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.running_mean          loaded from backbone.body.layer3.0.bn3.running_mean          of shape (1024,)\n",
            "2023-02-04 17:36:26,569 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.running_var           loaded from backbone.body.layer3.0.bn3.running_var           of shape (1024,)\n",
            "2023-02-04 17:36:26,569 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.weight                loaded from backbone.body.layer3.0.bn3.weight                of shape (1024,)\n",
            "2023-02-04 17:36:26,569 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv1.weight              loaded from backbone.body.layer3.0.conv1.weight              of shape (256, 512, 1, 1)\n",
            "2023-02-04 17:36:26,570 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv2.weight              loaded from backbone.body.layer3.0.conv2.weight              of shape (256, 256, 3, 3)\n",
            "2023-02-04 17:36:26,570 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv3.weight              loaded from backbone.body.layer3.0.conv3.weight              of shape (1024, 256, 1, 1)\n",
            "2023-02-04 17:36:26,570 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.0.weight       loaded from backbone.body.layer3.0.downsample.0.weight       of shape (1024, 512, 1, 1)\n",
            "2023-02-04 17:36:26,570 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.bias         loaded from backbone.body.layer3.0.downsample.1.bias         of shape (1024,)\n",
            "2023-02-04 17:36:26,570 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.running_mean loaded from backbone.body.layer3.0.downsample.1.running_mean of shape (1024,)\n",
            "2023-02-04 17:36:26,570 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.running_var  loaded from backbone.body.layer3.0.downsample.1.running_var  of shape (1024,)\n",
            "2023-02-04 17:36:26,570 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.weight       loaded from backbone.body.layer3.0.downsample.1.weight       of shape (1024,)\n",
            "2023-02-04 17:36:26,570 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.bias                  loaded from backbone.body.layer3.1.bn1.bias                  of shape (256,)\n",
            "2023-02-04 17:36:26,570 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.running_mean          loaded from backbone.body.layer3.1.bn1.running_mean          of shape (256,)\n",
            "2023-02-04 17:36:26,570 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.running_var           loaded from backbone.body.layer3.1.bn1.running_var           of shape (256,)\n",
            "2023-02-04 17:36:26,570 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.weight                loaded from backbone.body.layer3.1.bn1.weight                of shape (256,)\n",
            "2023-02-04 17:36:26,570 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.bias                  loaded from backbone.body.layer3.1.bn2.bias                  of shape (256,)\n",
            "2023-02-04 17:36:26,570 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.running_mean          loaded from backbone.body.layer3.1.bn2.running_mean          of shape (256,)\n",
            "2023-02-04 17:36:26,570 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.running_var           loaded from backbone.body.layer3.1.bn2.running_var           of shape (256,)\n",
            "2023-02-04 17:36:26,570 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.weight                loaded from backbone.body.layer3.1.bn2.weight                of shape (256,)\n",
            "2023-02-04 17:36:26,570 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.bias                  loaded from backbone.body.layer3.1.bn3.bias                  of shape (1024,)\n",
            "2023-02-04 17:36:26,570 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.running_mean          loaded from backbone.body.layer3.1.bn3.running_mean          of shape (1024,)\n",
            "2023-02-04 17:36:26,570 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.running_var           loaded from backbone.body.layer3.1.bn3.running_var           of shape (1024,)\n",
            "2023-02-04 17:36:26,570 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.weight                loaded from backbone.body.layer3.1.bn3.weight                of shape (1024,)\n",
            "2023-02-04 17:36:26,570 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv1.weight              loaded from backbone.body.layer3.1.conv1.weight              of shape (256, 1024, 1, 1)\n",
            "2023-02-04 17:36:26,570 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv2.weight              loaded from backbone.body.layer3.1.conv2.weight              of shape (256, 256, 3, 3)\n",
            "2023-02-04 17:36:26,570 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv3.weight              loaded from backbone.body.layer3.1.conv3.weight              of shape (1024, 256, 1, 1)\n",
            "2023-02-04 17:36:26,570 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.bias                  loaded from backbone.body.layer3.2.bn1.bias                  of shape (256,)\n",
            "2023-02-04 17:36:26,570 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.running_mean          loaded from backbone.body.layer3.2.bn1.running_mean          of shape (256,)\n",
            "2023-02-04 17:36:26,570 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.running_var           loaded from backbone.body.layer3.2.bn1.running_var           of shape (256,)\n",
            "2023-02-04 17:36:26,570 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.weight                loaded from backbone.body.layer3.2.bn1.weight                of shape (256,)\n",
            "2023-02-04 17:36:26,571 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.bias                  loaded from backbone.body.layer3.2.bn2.bias                  of shape (256,)\n",
            "2023-02-04 17:36:26,571 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.running_mean          loaded from backbone.body.layer3.2.bn2.running_mean          of shape (256,)\n",
            "2023-02-04 17:36:26,571 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.running_var           loaded from backbone.body.layer3.2.bn2.running_var           of shape (256,)\n",
            "2023-02-04 17:36:26,571 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.weight                loaded from backbone.body.layer3.2.bn2.weight                of shape (256,)\n",
            "2023-02-04 17:36:26,571 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.bias                  loaded from backbone.body.layer3.2.bn3.bias                  of shape (1024,)\n",
            "2023-02-04 17:36:26,571 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.running_mean          loaded from backbone.body.layer3.2.bn3.running_mean          of shape (1024,)\n",
            "2023-02-04 17:36:26,571 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.running_var           loaded from backbone.body.layer3.2.bn3.running_var           of shape (1024,)\n",
            "2023-02-04 17:36:26,571 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.weight                loaded from backbone.body.layer3.2.bn3.weight                of shape (1024,)\n",
            "2023-02-04 17:36:26,571 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv1.weight              loaded from backbone.body.layer3.2.conv1.weight              of shape (256, 1024, 1, 1)\n",
            "2023-02-04 17:36:26,571 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv2.weight              loaded from backbone.body.layer3.2.conv2.weight              of shape (256, 256, 3, 3)\n",
            "2023-02-04 17:36:26,571 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv3.weight              loaded from backbone.body.layer3.2.conv3.weight              of shape (1024, 256, 1, 1)\n",
            "2023-02-04 17:36:26,571 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.bias                  loaded from backbone.body.layer3.3.bn1.bias                  of shape (256,)\n",
            "2023-02-04 17:36:26,571 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.running_mean          loaded from backbone.body.layer3.3.bn1.running_mean          of shape (256,)\n",
            "2023-02-04 17:36:26,571 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.running_var           loaded from backbone.body.layer3.3.bn1.running_var           of shape (256,)\n",
            "2023-02-04 17:36:26,571 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.weight                loaded from backbone.body.layer3.3.bn1.weight                of shape (256,)\n",
            "2023-02-04 17:36:26,571 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.bias                  loaded from backbone.body.layer3.3.bn2.bias                  of shape (256,)\n",
            "2023-02-04 17:36:26,571 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.running_mean          loaded from backbone.body.layer3.3.bn2.running_mean          of shape (256,)\n",
            "2023-02-04 17:36:26,571 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.running_var           loaded from backbone.body.layer3.3.bn2.running_var           of shape (256,)\n",
            "2023-02-04 17:36:26,571 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.weight                loaded from backbone.body.layer3.3.bn2.weight                of shape (256,)\n",
            "2023-02-04 17:36:26,668 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.bias                  loaded from backbone.body.layer3.3.bn3.bias                  of shape (1024,)\n",
            "2023-02-04 17:36:26,668 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.running_mean          loaded from backbone.body.layer3.3.bn3.running_mean          of shape (1024,)\n",
            "2023-02-04 17:36:26,669 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.running_var           loaded from backbone.body.layer3.3.bn3.running_var           of shape (1024,)\n",
            "2023-02-04 17:36:26,669 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.weight                loaded from backbone.body.layer3.3.bn3.weight                of shape (1024,)\n",
            "2023-02-04 17:36:26,670 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv1.weight              loaded from backbone.body.layer3.3.conv1.weight              of shape (256, 1024, 1, 1)\n",
            "2023-02-04 17:36:26,670 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv2.weight              loaded from backbone.body.layer3.3.conv2.weight              of shape (256, 256, 3, 3)\n",
            "2023-02-04 17:36:26,670 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv3.weight              loaded from backbone.body.layer3.3.conv3.weight              of shape (1024, 256, 1, 1)\n",
            "2023-02-04 17:36:26,671 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.bias                  loaded from backbone.body.layer3.4.bn1.bias                  of shape (256,)\n",
            "2023-02-04 17:36:26,671 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.running_mean          loaded from backbone.body.layer3.4.bn1.running_mean          of shape (256,)\n",
            "2023-02-04 17:36:26,671 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.running_var           loaded from backbone.body.layer3.4.bn1.running_var           of shape (256,)\n",
            "2023-02-04 17:36:26,671 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.weight                loaded from backbone.body.layer3.4.bn1.weight                of shape (256,)\n",
            "2023-02-04 17:36:26,671 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.bias                  loaded from backbone.body.layer3.4.bn2.bias                  of shape (256,)\n",
            "2023-02-04 17:36:26,671 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.running_mean          loaded from backbone.body.layer3.4.bn2.running_mean          of shape (256,)\n",
            "2023-02-04 17:36:26,671 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.running_var           loaded from backbone.body.layer3.4.bn2.running_var           of shape (256,)\n",
            "2023-02-04 17:36:26,671 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.weight                loaded from backbone.body.layer3.4.bn2.weight                of shape (256,)\n",
            "2023-02-04 17:36:26,671 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.bias                  loaded from backbone.body.layer3.4.bn3.bias                  of shape (1024,)\n",
            "2023-02-04 17:36:26,671 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.running_mean          loaded from backbone.body.layer3.4.bn3.running_mean          of shape (1024,)\n",
            "2023-02-04 17:36:26,671 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.running_var           loaded from backbone.body.layer3.4.bn3.running_var           of shape (1024,)\n",
            "2023-02-04 17:36:26,671 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.weight                loaded from backbone.body.layer3.4.bn3.weight                of shape (1024,)\n",
            "2023-02-04 17:36:26,671 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv1.weight              loaded from backbone.body.layer3.4.conv1.weight              of shape (256, 1024, 1, 1)\n",
            "2023-02-04 17:36:26,671 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv2.weight              loaded from backbone.body.layer3.4.conv2.weight              of shape (256, 256, 3, 3)\n",
            "2023-02-04 17:36:26,671 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv3.weight              loaded from backbone.body.layer3.4.conv3.weight              of shape (1024, 256, 1, 1)\n",
            "2023-02-04 17:36:26,671 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.bias                  loaded from backbone.body.layer3.5.bn1.bias                  of shape (256,)\n",
            "2023-02-04 17:36:26,671 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.running_mean          loaded from backbone.body.layer3.5.bn1.running_mean          of shape (256,)\n",
            "2023-02-04 17:36:26,671 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.running_var           loaded from backbone.body.layer3.5.bn1.running_var           of shape (256,)\n",
            "2023-02-04 17:36:26,671 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.weight                loaded from backbone.body.layer3.5.bn1.weight                of shape (256,)\n",
            "2023-02-04 17:36:26,671 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.bias                  loaded from backbone.body.layer3.5.bn2.bias                  of shape (256,)\n",
            "2023-02-04 17:36:26,672 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.running_mean          loaded from backbone.body.layer3.5.bn2.running_mean          of shape (256,)\n",
            "2023-02-04 17:36:26,672 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.running_var           loaded from backbone.body.layer3.5.bn2.running_var           of shape (256,)\n",
            "2023-02-04 17:36:26,672 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.weight                loaded from backbone.body.layer3.5.bn2.weight                of shape (256,)\n",
            "2023-02-04 17:36:26,672 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.bias                  loaded from backbone.body.layer3.5.bn3.bias                  of shape (1024,)\n",
            "2023-02-04 17:36:26,672 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.running_mean          loaded from backbone.body.layer3.5.bn3.running_mean          of shape (1024,)\n",
            "2023-02-04 17:36:26,672 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.running_var           loaded from backbone.body.layer3.5.bn3.running_var           of shape (1024,)\n",
            "2023-02-04 17:36:26,672 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.weight                loaded from backbone.body.layer3.5.bn3.weight                of shape (1024,)\n",
            "2023-02-04 17:36:26,672 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv1.weight              loaded from backbone.body.layer3.5.conv1.weight              of shape (256, 1024, 1, 1)\n",
            "2023-02-04 17:36:26,672 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv2.weight              loaded from backbone.body.layer3.5.conv2.weight              of shape (256, 256, 3, 3)\n",
            "2023-02-04 17:36:26,672 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv3.weight              loaded from backbone.body.layer3.5.conv3.weight              of shape (1024, 256, 1, 1)\n",
            "2023-02-04 17:36:26,672 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.bias                  loaded from backbone.body.layer4.0.bn1.bias                  of shape (512,)\n",
            "2023-02-04 17:36:26,672 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.running_mean          loaded from backbone.body.layer4.0.bn1.running_mean          of shape (512,)\n",
            "2023-02-04 17:36:26,672 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.running_var           loaded from backbone.body.layer4.0.bn1.running_var           of shape (512,)\n",
            "2023-02-04 17:36:26,672 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.weight                loaded from backbone.body.layer4.0.bn1.weight                of shape (512,)\n",
            "2023-02-04 17:36:26,672 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.bias                  loaded from backbone.body.layer4.0.bn2.bias                  of shape (512,)\n",
            "2023-02-04 17:36:26,672 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.running_mean          loaded from backbone.body.layer4.0.bn2.running_mean          of shape (512,)\n",
            "2023-02-04 17:36:26,672 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.running_var           loaded from backbone.body.layer4.0.bn2.running_var           of shape (512,)\n",
            "2023-02-04 17:36:26,672 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.weight                loaded from backbone.body.layer4.0.bn2.weight                of shape (512,)\n",
            "2023-02-04 17:36:26,672 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.bias                  loaded from backbone.body.layer4.0.bn3.bias                  of shape (2048,)\n",
            "2023-02-04 17:36:26,672 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.running_mean          loaded from backbone.body.layer4.0.bn3.running_mean          of shape (2048,)\n",
            "2023-02-04 17:36:26,672 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.running_var           loaded from backbone.body.layer4.0.bn3.running_var           of shape (2048,)\n",
            "2023-02-04 17:36:26,672 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.weight                loaded from backbone.body.layer4.0.bn3.weight                of shape (2048,)\n",
            "2023-02-04 17:36:26,672 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv1.weight              loaded from backbone.body.layer4.0.conv1.weight              of shape (512, 1024, 1, 1)\n",
            "2023-02-04 17:36:26,672 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv2.weight              loaded from backbone.body.layer4.0.conv2.weight              of shape (512, 512, 3, 3)\n",
            "2023-02-04 17:36:26,672 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv3.weight              loaded from backbone.body.layer4.0.conv3.weight              of shape (2048, 512, 1, 1)\n",
            "2023-02-04 17:36:26,672 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.0.weight       loaded from backbone.body.layer4.0.downsample.0.weight       of shape (2048, 1024, 1, 1)\n",
            "2023-02-04 17:36:26,673 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.bias         loaded from backbone.body.layer4.0.downsample.1.bias         of shape (2048,)\n",
            "2023-02-04 17:36:26,673 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.running_mean loaded from backbone.body.layer4.0.downsample.1.running_mean of shape (2048,)\n",
            "2023-02-04 17:36:26,673 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.running_var  loaded from backbone.body.layer4.0.downsample.1.running_var  of shape (2048,)\n",
            "2023-02-04 17:36:26,673 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.weight       loaded from backbone.body.layer4.0.downsample.1.weight       of shape (2048,)\n",
            "2023-02-04 17:36:26,673 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.bias                  loaded from backbone.body.layer4.1.bn1.bias                  of shape (512,)\n",
            "2023-02-04 17:36:26,673 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.running_mean          loaded from backbone.body.layer4.1.bn1.running_mean          of shape (512,)\n",
            "2023-02-04 17:36:26,673 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.running_var           loaded from backbone.body.layer4.1.bn1.running_var           of shape (512,)\n",
            "2023-02-04 17:36:26,673 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.weight                loaded from backbone.body.layer4.1.bn1.weight                of shape (512,)\n",
            "2023-02-04 17:36:26,673 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.bias                  loaded from backbone.body.layer4.1.bn2.bias                  of shape (512,)\n",
            "2023-02-04 17:36:26,673 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.running_mean          loaded from backbone.body.layer4.1.bn2.running_mean          of shape (512,)\n",
            "2023-02-04 17:36:26,673 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.running_var           loaded from backbone.body.layer4.1.bn2.running_var           of shape (512,)\n",
            "2023-02-04 17:36:26,673 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.weight                loaded from backbone.body.layer4.1.bn2.weight                of shape (512,)\n",
            "2023-02-04 17:36:26,673 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.bias                  loaded from backbone.body.layer4.1.bn3.bias                  of shape (2048,)\n",
            "2023-02-04 17:36:26,673 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.running_mean          loaded from backbone.body.layer4.1.bn3.running_mean          of shape (2048,)\n",
            "2023-02-04 17:36:26,673 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.running_var           loaded from backbone.body.layer4.1.bn3.running_var           of shape (2048,)\n",
            "2023-02-04 17:36:26,673 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.weight                loaded from backbone.body.layer4.1.bn3.weight                of shape (2048,)\n",
            "2023-02-04 17:36:26,673 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv1.weight              loaded from backbone.body.layer4.1.conv1.weight              of shape (512, 2048, 1, 1)\n",
            "2023-02-04 17:36:26,673 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv2.weight              loaded from backbone.body.layer4.1.conv2.weight              of shape (512, 512, 3, 3)\n",
            "2023-02-04 17:36:26,673 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv3.weight              loaded from backbone.body.layer4.1.conv3.weight              of shape (2048, 512, 1, 1)\n",
            "2023-02-04 17:36:26,673 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.bias                  loaded from backbone.body.layer4.2.bn1.bias                  of shape (512,)\n",
            "2023-02-04 17:36:26,673 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.running_mean          loaded from backbone.body.layer4.2.bn1.running_mean          of shape (512,)\n",
            "2023-02-04 17:36:26,673 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.running_var           loaded from backbone.body.layer4.2.bn1.running_var           of shape (512,)\n",
            "2023-02-04 17:36:26,673 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.weight                loaded from backbone.body.layer4.2.bn1.weight                of shape (512,)\n",
            "2023-02-04 17:36:26,673 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.bias                  loaded from backbone.body.layer4.2.bn2.bias                  of shape (512,)\n",
            "2023-02-04 17:36:26,673 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.running_mean          loaded from backbone.body.layer4.2.bn2.running_mean          of shape (512,)\n",
            "2023-02-04 17:36:26,673 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.running_var           loaded from backbone.body.layer4.2.bn2.running_var           of shape (512,)\n",
            "2023-02-04 17:36:26,674 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.weight                loaded from backbone.body.layer4.2.bn2.weight                of shape (512,)\n",
            "2023-02-04 17:36:26,674 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.bias                  loaded from backbone.body.layer4.2.bn3.bias                  of shape (2048,)\n",
            "2023-02-04 17:36:26,674 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.running_mean          loaded from backbone.body.layer4.2.bn3.running_mean          of shape (2048,)\n",
            "2023-02-04 17:36:26,674 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.running_var           loaded from backbone.body.layer4.2.bn3.running_var           of shape (2048,)\n",
            "2023-02-04 17:36:26,674 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.weight                loaded from backbone.body.layer4.2.bn3.weight                of shape (2048,)\n",
            "2023-02-04 17:36:26,674 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv1.weight              loaded from backbone.body.layer4.2.conv1.weight              of shape (512, 2048, 1, 1)\n",
            "2023-02-04 17:36:26,674 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv2.weight              loaded from backbone.body.layer4.2.conv2.weight              of shape (512, 512, 3, 3)\n",
            "2023-02-04 17:36:26,674 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv3.weight              loaded from backbone.body.layer4.2.conv3.weight              of shape (2048, 512, 1, 1)\n",
            "2023-02-04 17:36:26,674 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.bias                      loaded from backbone.body.stem.bn1.bias                      of shape (64,)\n",
            "2023-02-04 17:36:26,770 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.running_mean              loaded from backbone.body.stem.bn1.running_mean              of shape (64,)\n",
            "2023-02-04 17:36:26,771 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.running_var               loaded from backbone.body.stem.bn1.running_var               of shape (64,)\n",
            "2023-02-04 17:36:26,771 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.weight                    loaded from backbone.body.stem.bn1.weight                    of shape (64,)\n",
            "2023-02-04 17:36:26,771 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.conv1.weight                  loaded from backbone.body.stem.conv1.weight                  of shape (64, 3, 7, 7)\n",
            "2023-02-04 17:36:26,771 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner1.bias                     loaded from backbone.fpn.fpn_inner1.bias                     of shape (256,)\n",
            "2023-02-04 17:36:26,771 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner1.weight                   loaded from backbone.fpn.fpn_inner1.weight                   of shape (256, 256, 1, 1)\n",
            "2023-02-04 17:36:26,771 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner2.bias                     loaded from backbone.fpn.fpn_inner2.bias                     of shape (256,)\n",
            "2023-02-04 17:36:26,772 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner2.weight                   loaded from backbone.fpn.fpn_inner2.weight                   of shape (256, 512, 1, 1)\n",
            "2023-02-04 17:36:26,772 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner3.bias                     loaded from backbone.fpn.fpn_inner3.bias                     of shape (256,)\n",
            "2023-02-04 17:36:26,772 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner3.weight                   loaded from backbone.fpn.fpn_inner3.weight                   of shape (256, 1024, 1, 1)\n",
            "2023-02-04 17:36:26,772 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner4.bias                     loaded from backbone.fpn.fpn_inner4.bias                     of shape (256,)\n",
            "2023-02-04 17:36:26,772 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner4.weight                   loaded from backbone.fpn.fpn_inner4.weight                   of shape (256, 2048, 1, 1)\n",
            "2023-02-04 17:36:26,772 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer1.bias                     loaded from backbone.fpn.fpn_layer1.bias                     of shape (256,)\n",
            "2023-02-04 17:36:26,772 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer1.weight                   loaded from backbone.fpn.fpn_layer1.weight                   of shape (256, 256, 3, 3)\n",
            "2023-02-04 17:36:26,772 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer2.bias                     loaded from backbone.fpn.fpn_layer2.bias                     of shape (256,)\n",
            "2023-02-04 17:36:26,772 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer2.weight                   loaded from backbone.fpn.fpn_layer2.weight                   of shape (256, 256, 3, 3)\n",
            "2023-02-04 17:36:26,772 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer3.bias                     loaded from backbone.fpn.fpn_layer3.bias                     of shape (256,)\n",
            "2023-02-04 17:36:26,772 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer3.weight                   loaded from backbone.fpn.fpn_layer3.weight                   of shape (256, 256, 3, 3)\n",
            "2023-02-04 17:36:26,772 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer4.bias                     loaded from backbone.fpn.fpn_layer4.bias                     of shape (256,)\n",
            "2023-02-04 17:36:26,772 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer4.weight                   loaded from backbone.fpn.fpn_layer4.weight                   of shape (256, 256, 3, 3)\n",
            "2023-02-04 17:36:26,772 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level0.bias        loaded from da_heads.imghead.da_img_conv1_level0.bias        of shape (512,)\n",
            "2023-02-04 17:36:26,772 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level0.weight      loaded from da_heads.imghead.da_img_conv1_level0.weight      of shape (512, 256, 1, 1)\n",
            "2023-02-04 17:36:26,772 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level1.bias        loaded from da_heads.imghead.da_img_conv1_level1.bias        of shape (512,)\n",
            "2023-02-04 17:36:26,772 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level1.weight      loaded from da_heads.imghead.da_img_conv1_level1.weight      of shape (512, 256, 1, 1)\n",
            "2023-02-04 17:36:26,772 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level2.bias        loaded from da_heads.imghead.da_img_conv1_level2.bias        of shape (512,)\n",
            "2023-02-04 17:36:26,772 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level2.weight      loaded from da_heads.imghead.da_img_conv1_level2.weight      of shape (512, 256, 1, 1)\n",
            "2023-02-04 17:36:26,772 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level3.bias        loaded from da_heads.imghead.da_img_conv1_level3.bias        of shape (512,)\n",
            "2023-02-04 17:36:26,772 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level3.weight      loaded from da_heads.imghead.da_img_conv1_level3.weight      of shape (512, 256, 1, 1)\n",
            "2023-02-04 17:36:26,772 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level4.bias        loaded from da_heads.imghead.da_img_conv1_level4.bias        of shape (512,)\n",
            "2023-02-04 17:36:26,772 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level4.weight      loaded from da_heads.imghead.da_img_conv1_level4.weight      of shape (512, 256, 1, 1)\n",
            "2023-02-04 17:36:26,772 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level0.bias        loaded from da_heads.imghead.da_img_conv2_level0.bias        of shape (1,)\n",
            "2023-02-04 17:36:26,772 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level0.weight      loaded from da_heads.imghead.da_img_conv2_level0.weight      of shape (1, 512, 1, 1)\n",
            "2023-02-04 17:36:26,772 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level1.bias        loaded from da_heads.imghead.da_img_conv2_level1.bias        of shape (1,)\n",
            "2023-02-04 17:36:26,772 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level1.weight      loaded from da_heads.imghead.da_img_conv2_level1.weight      of shape (1, 512, 1, 1)\n",
            "2023-02-04 17:36:26,773 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level2.bias        loaded from da_heads.imghead.da_img_conv2_level2.bias        of shape (1,)\n",
            "2023-02-04 17:36:26,773 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level2.weight      loaded from da_heads.imghead.da_img_conv2_level2.weight      of shape (1, 512, 1, 1)\n",
            "2023-02-04 17:36:26,773 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level3.bias        loaded from da_heads.imghead.da_img_conv2_level3.bias        of shape (1,)\n",
            "2023-02-04 17:36:26,776 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level3.weight      loaded from da_heads.imghead.da_img_conv2_level3.weight      of shape (1, 512, 1, 1)\n",
            "2023-02-04 17:36:26,776 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level4.bias        loaded from da_heads.imghead.da_img_conv2_level4.bias        of shape (1,)\n",
            "2023-02-04 17:36:26,776 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level4.weight      loaded from da_heads.imghead.da_img_conv2_level4.weight      of shape (1, 512, 1, 1)\n",
            "2023-02-04 17:36:26,776 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc1_level0.bias          loaded from da_heads.inshead.da_ins_fc1_level0.bias          of shape (1024,)\n",
            "2023-02-04 17:36:26,776 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc1_level0.weight        loaded from da_heads.inshead.da_ins_fc1_level0.weight        of shape (1024, 1024)\n",
            "2023-02-04 17:36:26,776 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc1_level1.bias          loaded from da_heads.inshead.da_ins_fc1_level1.bias          of shape (1024,)\n",
            "2023-02-04 17:36:26,776 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc1_level1.weight        loaded from da_heads.inshead.da_ins_fc1_level1.weight        of shape (1024, 1024)\n",
            "2023-02-04 17:36:26,776 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc1_level2.bias          loaded from da_heads.inshead.da_ins_fc1_level2.bias          of shape (1024,)\n",
            "2023-02-04 17:36:26,776 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc1_level2.weight        loaded from da_heads.inshead.da_ins_fc1_level2.weight        of shape (1024, 1024)\n",
            "2023-02-04 17:36:26,776 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc1_level3.bias          loaded from da_heads.inshead.da_ins_fc1_level3.bias          of shape (1024,)\n",
            "2023-02-04 17:36:26,776 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc1_level3.weight        loaded from da_heads.inshead.da_ins_fc1_level3.weight        of shape (1024, 1024)\n",
            "2023-02-04 17:36:26,776 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc2_level0.bias          loaded from da_heads.inshead.da_ins_fc2_level0.bias          of shape (1024,)\n",
            "2023-02-04 17:36:26,776 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc2_level0.weight        loaded from da_heads.inshead.da_ins_fc2_level0.weight        of shape (1024, 1024)\n",
            "2023-02-04 17:36:26,776 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc2_level1.bias          loaded from da_heads.inshead.da_ins_fc2_level1.bias          of shape (1024,)\n",
            "2023-02-04 17:36:26,777 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc2_level1.weight        loaded from da_heads.inshead.da_ins_fc2_level1.weight        of shape (1024, 1024)\n",
            "2023-02-04 17:36:26,777 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc2_level2.bias          loaded from da_heads.inshead.da_ins_fc2_level2.bias          of shape (1024,)\n",
            "2023-02-04 17:36:26,777 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc2_level2.weight        loaded from da_heads.inshead.da_ins_fc2_level2.weight        of shape (1024, 1024)\n",
            "2023-02-04 17:36:26,777 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc2_level3.bias          loaded from da_heads.inshead.da_ins_fc2_level3.bias          of shape (1024,)\n",
            "2023-02-04 17:36:26,777 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc2_level3.weight        loaded from da_heads.inshead.da_ins_fc2_level3.weight        of shape (1024, 1024)\n",
            "2023-02-04 17:36:26,777 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc3_level0.bias          loaded from da_heads.inshead.da_ins_fc3_level0.bias          of shape (1,)\n",
            "2023-02-04 17:36:26,777 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc3_level0.weight        loaded from da_heads.inshead.da_ins_fc3_level0.weight        of shape (1, 1024)\n",
            "2023-02-04 17:36:26,777 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc3_level1.bias          loaded from da_heads.inshead.da_ins_fc3_level1.bias          of shape (1,)\n",
            "2023-02-04 17:36:26,777 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc3_level1.weight        loaded from da_heads.inshead.da_ins_fc3_level1.weight        of shape (1, 1024)\n",
            "2023-02-04 17:36:26,777 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc3_level2.bias          loaded from da_heads.inshead.da_ins_fc3_level2.bias          of shape (1,)\n",
            "2023-02-04 17:36:26,777 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc3_level2.weight        loaded from da_heads.inshead.da_ins_fc3_level2.weight        of shape (1, 1024)\n",
            "2023-02-04 17:36:26,777 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc3_level3.bias          loaded from da_heads.inshead.da_ins_fc3_level3.bias          of shape (1,)\n",
            "2023-02-04 17:36:26,777 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc3_level3.weight        loaded from da_heads.inshead.da_ins_fc3_level3.weight        of shape (1, 1024)\n",
            "2023-02-04 17:36:26,777 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc6.bias         loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (1024,)\n",
            "2023-02-04 17:36:26,777 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc6.weight       loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (1024, 12544)\n",
            "2023-02-04 17:36:26,777 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc7.bias         loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (1024,)\n",
            "2023-02-04 17:36:26,777 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc7.weight       loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (1024, 1024)\n",
            "2023-02-04 17:36:26,777 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.bbox_pred.bias           loaded from roi_heads.box.predictor.bbox_pred.bias           of shape (8,)\n",
            "2023-02-04 17:36:26,777 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.bbox_pred.weight         loaded from roi_heads.box.predictor.bbox_pred.weight         of shape (8, 1024)\n",
            "2023-02-04 17:36:26,777 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.cls_score.bias           loaded from roi_heads.box.predictor.cls_score.bias           of shape (2,)\n",
            "2023-02-04 17:36:26,777 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.cls_score.weight         loaded from roi_heads.box.predictor.cls_score.weight         of shape (2, 1024)\n",
            "2023-02-04 17:36:26,777 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.0              loaded from rpn.anchor_generator.cell_anchors.0              of shape (3, 4)\n",
            "2023-02-04 17:36:26,777 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.1              loaded from rpn.anchor_generator.cell_anchors.1              of shape (3, 4)\n",
            "2023-02-04 17:36:26,777 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.2              loaded from rpn.anchor_generator.cell_anchors.2              of shape (3, 4)\n",
            "2023-02-04 17:36:26,778 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.3              loaded from rpn.anchor_generator.cell_anchors.3              of shape (3, 4)\n",
            "2023-02-04 17:36:26,778 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.4              loaded from rpn.anchor_generator.cell_anchors.4              of shape (3, 4)\n",
            "2023-02-04 17:36:26,778 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bbox_pred.bias                          loaded from rpn.head.bbox_pred.bias                          of shape (12,)\n",
            "2023-02-04 17:36:26,778 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bbox_pred.weight                        loaded from rpn.head.bbox_pred.weight                        of shape (12, 256, 1, 1)\n",
            "2023-02-04 17:36:26,778 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.cls_logits.bias                         loaded from rpn.head.cls_logits.bias                         of shape (3,)\n",
            "2023-02-04 17:36:26,778 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.cls_logits.weight                       loaded from rpn.head.cls_logits.weight                       of shape (3, 256, 1, 1)\n",
            "2023-02-04 17:36:26,778 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.conv.bias                               loaded from rpn.head.conv.bias                               of shape (256,)\n",
            "2023-02-04 17:36:26,778 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.conv.weight                             loaded from rpn.head.conv.weight                             of shape (256, 256, 3, 3)\n",
            "loading annotations into memory...\n",
            "Done (t=0.79s)\n",
            "creating index...\n",
            "index created!\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "2023-02-04 17:36:27,705 maskrcnn_benchmark.inference INFO: Start evaluation on cityscapes_only_car_val_cocostyle dataset(500 images).\n",
            "  0% 0/500 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "100% 500/500 [01:59<00:00,  4.19it/s]\n",
            "2023-02-04 17:38:27,025 maskrcnn_benchmark.inference INFO: Total inference time: 0:01:59.319567 (0.23863913345336915 s / img per device, on 1 devices)\n",
            "2023-02-04 17:38:27,080 maskrcnn_benchmark.inference INFO: Preparing results for COCO format\n",
            "2023-02-04 17:38:27,080 maskrcnn_benchmark.inference INFO: Preparing bbox results\n",
            "2023-02-04 17:38:27,126 maskrcnn_benchmark.inference INFO: Evaluating predictions\n",
            "Category: 1 {'id': 1, 'name': 'car'}\n",
            "Loading and preparing results...\n",
            "DONE (t=0.16s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=4.26s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.17s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.259\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.523\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.227\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.069\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.308\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.487\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.069\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.279\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.356\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.143\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.408\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.602\n",
            "Loading and preparing results...\n",
            "DONE (t=0.18s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=4.79s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.32s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.259\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.523\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.227\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.069\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.308\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.487\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.069\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.279\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.356\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.143\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.408\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.602\n",
            "2023-02-04 17:38:37,479 maskrcnn_benchmark.inference INFO: OrderedDict([('bbox', OrderedDict([('AP', -1), ('AP50', -1), ('AP75', -1), ('APs', -1), ('APm', -1), ('APl', -1), (1, {'AP': 0.25878645785578974, 'AP50': 0.5227215280002961, 'AP75': 0.227401667579565, 'APs': 0.06874599084149842, 'APm': 0.3079744118028338, 'APl': 0.48709141664161887})]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/test_net.py --config-file \"/content/MIC/det/configs/fff.yaml\" MODEL.WEIGHT /content/drive/MyDrive/AI/mic/model_0004000.pth\n"
      ],
      "metadata": {
        "id": "Gyk_OnfXgq4s",
        "outputId": "aa383439-07f0-4c02-bac1-993e71da4246",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-04 17:39:14,860 maskrcnn_benchmark INFO: Using 1 GPUs\n",
            "2023-02-04 17:39:14,861 maskrcnn_benchmark INFO: DATALOADER:\n",
            "  ASPECT_RATIO_GROUPING: True\n",
            "  NUM_WORKERS: 4\n",
            "  SIZE_DIVISIBILITY: 32\n",
            "DATASETS:\n",
            "  SOURCE_TRAIN: ('sim10k_cocostyle',)\n",
            "  TARGET_TRAIN: ('cityscapes_only_car_train_cocostyle',)\n",
            "  TEST: ('cityscapes_only_car_val_cocostyle',)\n",
            "  TRAIN: ()\n",
            "INPUT:\n",
            "  MAX_SIZE_TEST: 1600\n",
            "  MAX_SIZE_TRAIN: 1600\n",
            "  MIN_SIZE_TEST: 800\n",
            "  MIN_SIZE_TRAIN: (800,)\n",
            "  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]\n",
            "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
            "  TO_BGR255: True\n",
            "MODEL:\n",
            "  BACKBONE:\n",
            "    CONV_BODY: R-50-FPN\n",
            "    FREEZE_CONV_BODY_AT: 2\n",
            "    OUT_CHANNELS: 256\n",
            "    USE_GN: False\n",
            "  CLS_AGNOSTIC_BBOX_REG: False\n",
            "  DA_HEADS:\n",
            "    COS_WEIGHT: 0.1\n",
            "    DA_IMG_GRL_WEIGHT: 0.01\n",
            "    DA_INS_GRL_WEIGHT: 0.1\n",
            "  DEVICE: cuda\n",
            "  DOMAIN_ADAPTATION_ON: True\n",
            "  FPN:\n",
            "    USE_GN: False\n",
            "    USE_RELU: False\n",
            "  GROUP_NORM:\n",
            "    DIM_PER_GP: -1\n",
            "    EPSILON: 1e-05\n",
            "    NUM_GROUPS: 32\n",
            "  KEYPOINT_ON: False\n",
            "  MASKING_AUGMENTATION: True\n",
            "  MASKING_BLOCK_SIZE: 32\n",
            "  MASKING_RATIO: 0.5\n",
            "  MASK_ON: False\n",
            "  META_ARCHITECTURE: GeneralizedRCNN\n",
            "  MIC_ON: True\n",
            "  PSEUDO_LABEL_LAMBDA: 1.0\n",
            "  PSEUDO_LABEL_THRESHOLD: 0.8\n",
            "  PSEUDO_LABEL_WEIGHT: prob\n",
            "  RESNETS:\n",
            "    NUM_GROUPS: 1\n",
            "    RES2_OUT_CHANNELS: 256\n",
            "    RES5_DILATION: 1\n",
            "    STEM_FUNC: StemWithFixedBatchNorm\n",
            "    STEM_OUT_CHANNELS: 64\n",
            "    STRIDE_IN_1X1: True\n",
            "    TRANS_FUNC: BottleneckWithFixedBatchNorm\n",
            "    WIDTH_PER_GROUP: 64\n",
            "  RETINANET:\n",
            "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
            "    ANCHOR_STRIDES: (8, 16, 32, 64, 128)\n",
            "    ASPECT_RATIOS: (0.5, 1.0, 2.0)\n",
            "    BBOX_REG_BETA: 0.11\n",
            "    BBOX_REG_WEIGHT: 4.0\n",
            "    BG_IOU_THRESHOLD: 0.4\n",
            "    FG_IOU_THRESHOLD: 0.5\n",
            "    INFERENCE_TH: 0.05\n",
            "    LOSS_ALPHA: 0.25\n",
            "    LOSS_GAMMA: 2.0\n",
            "    NMS_TH: 0.4\n",
            "    NUM_CLASSES: 81\n",
            "    NUM_CONVS: 4\n",
            "    OCTAVE: 2.0\n",
            "    PRE_NMS_TOP_N: 1000\n",
            "    PRIOR_PROB: 0.01\n",
            "    SCALES_PER_OCTAVE: 3\n",
            "    STRADDLE_THRESH: 0\n",
            "    USE_C5: True\n",
            "  RETINANET_ON: False\n",
            "  ROI_BOX_HEAD:\n",
            "    CONV_HEAD_DIM: 256\n",
            "    DILATION: 1\n",
            "    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n",
            "    MLP_HEAD_DIM: 1024\n",
            "    NUM_CLASSES: 2\n",
            "    NUM_STACKED_CONVS: 4\n",
            "    POOLER_RESOLUTION: 7\n",
            "    POOLER_SAMPLING_RATIO: 2\n",
            "    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n",
            "    PREDICTOR: FPNPredictor\n",
            "    USE_GN: False\n",
            "  ROI_HEADS:\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
            "    BG_IOU_THRESHOLD: 0.5\n",
            "    DETECTIONS_PER_IMG: 100\n",
            "    FG_IOU_THRESHOLD: 0.5\n",
            "    NMS: 0.5\n",
            "    POSITIVE_FRACTION: 0.25\n",
            "    SCORE_THRESH: 0.05\n",
            "    USE_FPN: True\n",
            "  ROI_KEYPOINT_HEAD:\n",
            "    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
            "    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor\n",
            "    MLP_HEAD_DIM: 1024\n",
            "    NUM_CLASSES: 17\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_SCALES: (0.0625,)\n",
            "    PREDICTOR: KeypointRCNNPredictor\n",
            "    RESOLUTION: 14\n",
            "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
            "  ROI_MASK_HEAD:\n",
            "    CONV_LAYERS: (256, 256, 256, 256)\n",
            "    DILATION: 1\n",
            "    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor\n",
            "    MLP_HEAD_DIM: 1024\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_SCALES: (0.0625,)\n",
            "    POSTPROCESS_MASKS: False\n",
            "    POSTPROCESS_MASKS_THRESHOLD: 0.5\n",
            "    PREDICTOR: MaskRCNNC4Predictor\n",
            "    RESOLUTION: 14\n",
            "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
            "    USE_GN: False\n",
            "  RPN:\n",
            "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
            "    ANCHOR_STRIDE: (4, 8, 16, 32, 64)\n",
            "    ASPECT_RATIOS: (0.5, 1.0, 2.0)\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "    BG_IOU_THRESHOLD: 0.3\n",
            "    FG_IOU_THRESHOLD: 0.7\n",
            "    FPN_POST_NMS_TOP_N_TEST: 1000\n",
            "    FPN_POST_NMS_TOP_N_TRAIN: 2000\n",
            "    MIN_SIZE: 0\n",
            "    NMS_THRESH: 0.7\n",
            "    POSITIVE_FRACTION: 0.5\n",
            "    POST_NMS_TOP_N_TEST: 1000\n",
            "    POST_NMS_TOP_N_TRAIN: 2000\n",
            "    PRE_NMS_TOP_N_TEST: 1000\n",
            "    PRE_NMS_TOP_N_TRAIN: 2000\n",
            "    RPN_HEAD: SingleConvRPNHead\n",
            "    STRADDLE_THRESH: 0\n",
            "    USE_FPN: True\n",
            "  RPN_ONLY: False\n",
            "  TEACHER_ALPHA: 0.9\n",
            "  WEIGHT: /content/drive/MyDrive/AI/mic/model_0004000.pth\n",
            "OUTPUT_DIR: /content/drive/MyDrive/AI/mic\n",
            "PATHS_CATALOG: /content/MIC/det/maskrcnn_benchmark/config/paths_catalog.py\n",
            "SOLVER:\n",
            "  BASE_LR: 0.001\n",
            "  BIAS_LR_FACTOR: 2\n",
            "  CHECKPOINT_PERIOD: 1000\n",
            "  GAMMA: 0.1\n",
            "  IMS_PER_BATCH: 2\n",
            "  MAX_ITER: 60000\n",
            "  MOMENTUM: 0.9\n",
            "  STEPS: (30000, 40000)\n",
            "  WARMUP_FACTOR: 0.3333333333333333\n",
            "  WARMUP_ITERS: 1000\n",
            "  WARMUP_METHOD: linear\n",
            "  WEIGHT_DECAY: 0.0001\n",
            "  WEIGHT_DECAY_BIAS: 0\n",
            "TEST:\n",
            "  DETECTIONS_PER_IMG: 100\n",
            "  EXPECTED_RESULTS: []\n",
            "  EXPECTED_RESULTS_SIGMA_TOL: 4\n",
            "  IMS_PER_BATCH: 1\n",
            "2023-02-04 17:39:14,861 maskrcnn_benchmark INFO: Collecting env info (might take some time)\n",
            "2023-02-04 17:39:16,241 maskrcnn_benchmark INFO: \n",
            "PyTorch version: 1.12.0+cu113\n",
            "Is debug build: False\n",
            "CUDA used to build PyTorch: 11.3\n",
            "ROCM used to build PyTorch: N/A\n",
            "\n",
            "OS: Ubuntu 20.04.5 LTS (x86_64)\n",
            "GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n",
            "Clang version: 10.0.0-4ubuntu1 \n",
            "CMake version: version 3.22.6\n",
            "Libc version: glibc-2.31\n",
            "\n",
            "Python version: 3.8.10 (default, Nov 14 2022, 12:59:47)  [GCC 9.4.0] (64-bit runtime)\n",
            "Python platform: Linux-5.10.147+-x86_64-with-glibc2.29\n",
            "Is CUDA available: True\n",
            "CUDA runtime version: 11.2.152\n",
            "GPU models and configuration: GPU 0: Tesla T4\n",
            "Nvidia driver version: 510.47.03\n",
            "cuDNN version: Probably one of the following:\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.1.1\n",
            "HIP runtime version: N/A\n",
            "MIOpen runtime version: N/A\n",
            "Is XNNPACK available: True\n",
            "\n",
            "Versions of relevant libraries:\n",
            "[pip3] numpy==1.21.6\n",
            "[pip3] torch==1.12.0+cu113\n",
            "[pip3] torchaudio==0.12.0+cu113\n",
            "[pip3] torchsummary==1.5.1\n",
            "[pip3] torchtext==0.14.1\n",
            "[pip3] torchvision==0.13.0+cu113\n",
            "[conda] Could not collect\n",
            "        Pillow (7.1.2)\n",
            "2023-02-04 17:39:18,840 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from /content/drive/MyDrive/AI/mic/model_0004000.pth\n",
            "2023-02-04 17:39:20,892 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.bias                  loaded from backbone.body.layer1.0.bn1.bias                  of shape (64,)\n",
            "2023-02-04 17:39:20,892 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.running_mean          loaded from backbone.body.layer1.0.bn1.running_mean          of shape (64,)\n",
            "2023-02-04 17:39:20,892 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.running_var           loaded from backbone.body.layer1.0.bn1.running_var           of shape (64,)\n",
            "2023-02-04 17:39:20,892 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.weight                loaded from backbone.body.layer1.0.bn1.weight                of shape (64,)\n",
            "2023-02-04 17:39:20,892 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.bias                  loaded from backbone.body.layer1.0.bn2.bias                  of shape (64,)\n",
            "2023-02-04 17:39:20,892 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.running_mean          loaded from backbone.body.layer1.0.bn2.running_mean          of shape (64,)\n",
            "2023-02-04 17:39:20,892 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.running_var           loaded from backbone.body.layer1.0.bn2.running_var           of shape (64,)\n",
            "2023-02-04 17:39:20,892 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.weight                loaded from backbone.body.layer1.0.bn2.weight                of shape (64,)\n",
            "2023-02-04 17:39:20,892 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.bias                  loaded from backbone.body.layer1.0.bn3.bias                  of shape (256,)\n",
            "2023-02-04 17:39:20,893 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.running_mean          loaded from backbone.body.layer1.0.bn3.running_mean          of shape (256,)\n",
            "2023-02-04 17:39:20,893 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.running_var           loaded from backbone.body.layer1.0.bn3.running_var           of shape (256,)\n",
            "2023-02-04 17:39:20,893 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.weight                loaded from backbone.body.layer1.0.bn3.weight                of shape (256,)\n",
            "2023-02-04 17:39:20,893 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv1.weight              loaded from backbone.body.layer1.0.conv1.weight              of shape (64, 64, 1, 1)\n",
            "2023-02-04 17:39:20,893 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv2.weight              loaded from backbone.body.layer1.0.conv2.weight              of shape (64, 64, 3, 3)\n",
            "2023-02-04 17:39:20,893 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv3.weight              loaded from backbone.body.layer1.0.conv3.weight              of shape (256, 64, 1, 1)\n",
            "2023-02-04 17:39:20,893 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.0.weight       loaded from backbone.body.layer1.0.downsample.0.weight       of shape (256, 64, 1, 1)\n",
            "2023-02-04 17:39:20,893 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.bias         loaded from backbone.body.layer1.0.downsample.1.bias         of shape (256,)\n",
            "2023-02-04 17:39:20,893 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.running_mean loaded from backbone.body.layer1.0.downsample.1.running_mean of shape (256,)\n",
            "2023-02-04 17:39:20,893 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.running_var  loaded from backbone.body.layer1.0.downsample.1.running_var  of shape (256,)\n",
            "2023-02-04 17:39:20,893 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.weight       loaded from backbone.body.layer1.0.downsample.1.weight       of shape (256,)\n",
            "2023-02-04 17:39:20,893 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.bias                  loaded from backbone.body.layer1.1.bn1.bias                  of shape (64,)\n",
            "2023-02-04 17:39:20,893 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.running_mean          loaded from backbone.body.layer1.1.bn1.running_mean          of shape (64,)\n",
            "2023-02-04 17:39:20,893 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.running_var           loaded from backbone.body.layer1.1.bn1.running_var           of shape (64,)\n",
            "2023-02-04 17:39:20,893 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.weight                loaded from backbone.body.layer1.1.bn1.weight                of shape (64,)\n",
            "2023-02-04 17:39:20,893 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.bias                  loaded from backbone.body.layer1.1.bn2.bias                  of shape (64,)\n",
            "2023-02-04 17:39:20,893 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.running_mean          loaded from backbone.body.layer1.1.bn2.running_mean          of shape (64,)\n",
            "2023-02-04 17:39:20,893 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.running_var           loaded from backbone.body.layer1.1.bn2.running_var           of shape (64,)\n",
            "2023-02-04 17:39:20,893 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.weight                loaded from backbone.body.layer1.1.bn2.weight                of shape (64,)\n",
            "2023-02-04 17:39:20,893 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.bias                  loaded from backbone.body.layer1.1.bn3.bias                  of shape (256,)\n",
            "2023-02-04 17:39:20,893 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.running_mean          loaded from backbone.body.layer1.1.bn3.running_mean          of shape (256,)\n",
            "2023-02-04 17:39:20,893 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.running_var           loaded from backbone.body.layer1.1.bn3.running_var           of shape (256,)\n",
            "2023-02-04 17:39:20,893 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.weight                loaded from backbone.body.layer1.1.bn3.weight                of shape (256,)\n",
            "2023-02-04 17:39:20,893 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv1.weight              loaded from backbone.body.layer1.1.conv1.weight              of shape (64, 256, 1, 1)\n",
            "2023-02-04 17:39:20,893 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv2.weight              loaded from backbone.body.layer1.1.conv2.weight              of shape (64, 64, 3, 3)\n",
            "2023-02-04 17:39:20,893 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv3.weight              loaded from backbone.body.layer1.1.conv3.weight              of shape (256, 64, 1, 1)\n",
            "2023-02-04 17:39:20,893 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.bias                  loaded from backbone.body.layer1.2.bn1.bias                  of shape (64,)\n",
            "2023-02-04 17:39:20,893 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.running_mean          loaded from backbone.body.layer1.2.bn1.running_mean          of shape (64,)\n",
            "2023-02-04 17:39:20,894 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.running_var           loaded from backbone.body.layer1.2.bn1.running_var           of shape (64,)\n",
            "2023-02-04 17:39:20,894 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.weight                loaded from backbone.body.layer1.2.bn1.weight                of shape (64,)\n",
            "2023-02-04 17:39:20,894 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.bias                  loaded from backbone.body.layer1.2.bn2.bias                  of shape (64,)\n",
            "2023-02-04 17:39:20,894 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.running_mean          loaded from backbone.body.layer1.2.bn2.running_mean          of shape (64,)\n",
            "2023-02-04 17:39:20,894 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.running_var           loaded from backbone.body.layer1.2.bn2.running_var           of shape (64,)\n",
            "2023-02-04 17:39:20,894 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.weight                loaded from backbone.body.layer1.2.bn2.weight                of shape (64,)\n",
            "2023-02-04 17:39:20,894 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.bias                  loaded from backbone.body.layer1.2.bn3.bias                  of shape (256,)\n",
            "2023-02-04 17:39:20,894 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.running_mean          loaded from backbone.body.layer1.2.bn3.running_mean          of shape (256,)\n",
            "2023-02-04 17:39:20,894 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.running_var           loaded from backbone.body.layer1.2.bn3.running_var           of shape (256,)\n",
            "2023-02-04 17:39:20,894 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.weight                loaded from backbone.body.layer1.2.bn3.weight                of shape (256,)\n",
            "2023-02-04 17:39:20,894 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv1.weight              loaded from backbone.body.layer1.2.conv1.weight              of shape (64, 256, 1, 1)\n",
            "2023-02-04 17:39:20,894 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv2.weight              loaded from backbone.body.layer1.2.conv2.weight              of shape (64, 64, 3, 3)\n",
            "2023-02-04 17:39:20,894 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv3.weight              loaded from backbone.body.layer1.2.conv3.weight              of shape (256, 64, 1, 1)\n",
            "2023-02-04 17:39:20,894 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.bias                  loaded from backbone.body.layer2.0.bn1.bias                  of shape (128,)\n",
            "2023-02-04 17:39:20,894 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.running_mean          loaded from backbone.body.layer2.0.bn1.running_mean          of shape (128,)\n",
            "2023-02-04 17:39:20,894 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.running_var           loaded from backbone.body.layer2.0.bn1.running_var           of shape (128,)\n",
            "2023-02-04 17:39:20,894 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.weight                loaded from backbone.body.layer2.0.bn1.weight                of shape (128,)\n",
            "2023-02-04 17:39:20,894 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.bias                  loaded from backbone.body.layer2.0.bn2.bias                  of shape (128,)\n",
            "2023-02-04 17:39:20,894 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.running_mean          loaded from backbone.body.layer2.0.bn2.running_mean          of shape (128,)\n",
            "2023-02-04 17:39:20,894 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.running_var           loaded from backbone.body.layer2.0.bn2.running_var           of shape (128,)\n",
            "2023-02-04 17:39:20,894 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.weight                loaded from backbone.body.layer2.0.bn2.weight                of shape (128,)\n",
            "2023-02-04 17:39:20,894 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.bias                  loaded from backbone.body.layer2.0.bn3.bias                  of shape (512,)\n",
            "2023-02-04 17:39:20,894 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.running_mean          loaded from backbone.body.layer2.0.bn3.running_mean          of shape (512,)\n",
            "2023-02-04 17:39:20,894 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.running_var           loaded from backbone.body.layer2.0.bn3.running_var           of shape (512,)\n",
            "2023-02-04 17:39:20,894 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.weight                loaded from backbone.body.layer2.0.bn3.weight                of shape (512,)\n",
            "2023-02-04 17:39:20,894 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv1.weight              loaded from backbone.body.layer2.0.conv1.weight              of shape (128, 256, 1, 1)\n",
            "2023-02-04 17:39:20,894 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv2.weight              loaded from backbone.body.layer2.0.conv2.weight              of shape (128, 128, 3, 3)\n",
            "2023-02-04 17:39:20,894 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv3.weight              loaded from backbone.body.layer2.0.conv3.weight              of shape (512, 128, 1, 1)\n",
            "2023-02-04 17:39:20,895 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.0.weight       loaded from backbone.body.layer2.0.downsample.0.weight       of shape (512, 256, 1, 1)\n",
            "2023-02-04 17:39:20,895 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.bias         loaded from backbone.body.layer2.0.downsample.1.bias         of shape (512,)\n",
            "2023-02-04 17:39:20,895 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.running_mean loaded from backbone.body.layer2.0.downsample.1.running_mean of shape (512,)\n",
            "2023-02-04 17:39:20,895 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.running_var  loaded from backbone.body.layer2.0.downsample.1.running_var  of shape (512,)\n",
            "2023-02-04 17:39:20,895 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.weight       loaded from backbone.body.layer2.0.downsample.1.weight       of shape (512,)\n",
            "2023-02-04 17:39:20,895 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.bias                  loaded from backbone.body.layer2.1.bn1.bias                  of shape (128,)\n",
            "2023-02-04 17:39:20,895 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.running_mean          loaded from backbone.body.layer2.1.bn1.running_mean          of shape (128,)\n",
            "2023-02-04 17:39:20,895 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.running_var           loaded from backbone.body.layer2.1.bn1.running_var           of shape (128,)\n",
            "2023-02-04 17:39:20,895 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.weight                loaded from backbone.body.layer2.1.bn1.weight                of shape (128,)\n",
            "2023-02-04 17:39:20,895 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.bias                  loaded from backbone.body.layer2.1.bn2.bias                  of shape (128,)\n",
            "2023-02-04 17:39:20,895 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.running_mean          loaded from backbone.body.layer2.1.bn2.running_mean          of shape (128,)\n",
            "2023-02-04 17:39:20,895 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.running_var           loaded from backbone.body.layer2.1.bn2.running_var           of shape (128,)\n",
            "2023-02-04 17:39:20,895 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.weight                loaded from backbone.body.layer2.1.bn2.weight                of shape (128,)\n",
            "2023-02-04 17:39:20,895 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.bias                  loaded from backbone.body.layer2.1.bn3.bias                  of shape (512,)\n",
            "2023-02-04 17:39:20,895 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.running_mean          loaded from backbone.body.layer2.1.bn3.running_mean          of shape (512,)\n",
            "2023-02-04 17:39:20,895 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.running_var           loaded from backbone.body.layer2.1.bn3.running_var           of shape (512,)\n",
            "2023-02-04 17:39:20,895 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.weight                loaded from backbone.body.layer2.1.bn3.weight                of shape (512,)\n",
            "2023-02-04 17:39:20,895 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv1.weight              loaded from backbone.body.layer2.1.conv1.weight              of shape (128, 512, 1, 1)\n",
            "2023-02-04 17:39:20,973 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv2.weight              loaded from backbone.body.layer2.1.conv2.weight              of shape (128, 128, 3, 3)\n",
            "2023-02-04 17:39:20,973 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv3.weight              loaded from backbone.body.layer2.1.conv3.weight              of shape (512, 128, 1, 1)\n",
            "2023-02-04 17:39:20,973 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.bias                  loaded from backbone.body.layer2.2.bn1.bias                  of shape (128,)\n",
            "2023-02-04 17:39:20,973 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.running_mean          loaded from backbone.body.layer2.2.bn1.running_mean          of shape (128,)\n",
            "2023-02-04 17:39:20,973 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.running_var           loaded from backbone.body.layer2.2.bn1.running_var           of shape (128,)\n",
            "2023-02-04 17:39:20,973 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.weight                loaded from backbone.body.layer2.2.bn1.weight                of shape (128,)\n",
            "2023-02-04 17:39:20,973 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.bias                  loaded from backbone.body.layer2.2.bn2.bias                  of shape (128,)\n",
            "2023-02-04 17:39:20,973 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.running_mean          loaded from backbone.body.layer2.2.bn2.running_mean          of shape (128,)\n",
            "2023-02-04 17:39:20,973 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.running_var           loaded from backbone.body.layer2.2.bn2.running_var           of shape (128,)\n",
            "2023-02-04 17:39:20,973 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.weight                loaded from backbone.body.layer2.2.bn2.weight                of shape (128,)\n",
            "2023-02-04 17:39:20,973 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.bias                  loaded from backbone.body.layer2.2.bn3.bias                  of shape (512,)\n",
            "2023-02-04 17:39:20,974 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.running_mean          loaded from backbone.body.layer2.2.bn3.running_mean          of shape (512,)\n",
            "2023-02-04 17:39:20,974 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.running_var           loaded from backbone.body.layer2.2.bn3.running_var           of shape (512,)\n",
            "2023-02-04 17:39:20,974 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.weight                loaded from backbone.body.layer2.2.bn3.weight                of shape (512,)\n",
            "2023-02-04 17:39:20,974 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv1.weight              loaded from backbone.body.layer2.2.conv1.weight              of shape (128, 512, 1, 1)\n",
            "2023-02-04 17:39:20,974 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv2.weight              loaded from backbone.body.layer2.2.conv2.weight              of shape (128, 128, 3, 3)\n",
            "2023-02-04 17:39:20,974 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv3.weight              loaded from backbone.body.layer2.2.conv3.weight              of shape (512, 128, 1, 1)\n",
            "2023-02-04 17:39:20,974 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.bias                  loaded from backbone.body.layer2.3.bn1.bias                  of shape (128,)\n",
            "2023-02-04 17:39:20,974 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.running_mean          loaded from backbone.body.layer2.3.bn1.running_mean          of shape (128,)\n",
            "2023-02-04 17:39:20,974 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.running_var           loaded from backbone.body.layer2.3.bn1.running_var           of shape (128,)\n",
            "2023-02-04 17:39:20,974 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.weight                loaded from backbone.body.layer2.3.bn1.weight                of shape (128,)\n",
            "2023-02-04 17:39:20,974 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.bias                  loaded from backbone.body.layer2.3.bn2.bias                  of shape (128,)\n",
            "2023-02-04 17:39:20,974 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.running_mean          loaded from backbone.body.layer2.3.bn2.running_mean          of shape (128,)\n",
            "2023-02-04 17:39:20,974 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.running_var           loaded from backbone.body.layer2.3.bn2.running_var           of shape (128,)\n",
            "2023-02-04 17:39:20,974 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.weight                loaded from backbone.body.layer2.3.bn2.weight                of shape (128,)\n",
            "2023-02-04 17:39:20,974 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.bias                  loaded from backbone.body.layer2.3.bn3.bias                  of shape (512,)\n",
            "2023-02-04 17:39:20,974 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.running_mean          loaded from backbone.body.layer2.3.bn3.running_mean          of shape (512,)\n",
            "2023-02-04 17:39:20,975 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.running_var           loaded from backbone.body.layer2.3.bn3.running_var           of shape (512,)\n",
            "2023-02-04 17:39:20,975 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.weight                loaded from backbone.body.layer2.3.bn3.weight                of shape (512,)\n",
            "2023-02-04 17:39:20,975 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv1.weight              loaded from backbone.body.layer2.3.conv1.weight              of shape (128, 512, 1, 1)\n",
            "2023-02-04 17:39:20,975 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv2.weight              loaded from backbone.body.layer2.3.conv2.weight              of shape (128, 128, 3, 3)\n",
            "2023-02-04 17:39:20,975 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv3.weight              loaded from backbone.body.layer2.3.conv3.weight              of shape (512, 128, 1, 1)\n",
            "2023-02-04 17:39:20,975 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.bias                  loaded from backbone.body.layer3.0.bn1.bias                  of shape (256,)\n",
            "2023-02-04 17:39:20,975 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.running_mean          loaded from backbone.body.layer3.0.bn1.running_mean          of shape (256,)\n",
            "2023-02-04 17:39:20,975 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.running_var           loaded from backbone.body.layer3.0.bn1.running_var           of shape (256,)\n",
            "2023-02-04 17:39:20,975 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.weight                loaded from backbone.body.layer3.0.bn1.weight                of shape (256,)\n",
            "2023-02-04 17:39:20,975 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.bias                  loaded from backbone.body.layer3.0.bn2.bias                  of shape (256,)\n",
            "2023-02-04 17:39:20,975 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.running_mean          loaded from backbone.body.layer3.0.bn2.running_mean          of shape (256,)\n",
            "2023-02-04 17:39:20,975 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.running_var           loaded from backbone.body.layer3.0.bn2.running_var           of shape (256,)\n",
            "2023-02-04 17:39:20,975 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.weight                loaded from backbone.body.layer3.0.bn2.weight                of shape (256,)\n",
            "2023-02-04 17:39:20,975 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.bias                  loaded from backbone.body.layer3.0.bn3.bias                  of shape (1024,)\n",
            "2023-02-04 17:39:20,975 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.running_mean          loaded from backbone.body.layer3.0.bn3.running_mean          of shape (1024,)\n",
            "2023-02-04 17:39:20,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.running_var           loaded from backbone.body.layer3.0.bn3.running_var           of shape (1024,)\n",
            "2023-02-04 17:39:20,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.weight                loaded from backbone.body.layer3.0.bn3.weight                of shape (1024,)\n",
            "2023-02-04 17:39:20,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv1.weight              loaded from backbone.body.layer3.0.conv1.weight              of shape (256, 512, 1, 1)\n",
            "2023-02-04 17:39:20,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv2.weight              loaded from backbone.body.layer3.0.conv2.weight              of shape (256, 256, 3, 3)\n",
            "2023-02-04 17:39:20,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv3.weight              loaded from backbone.body.layer3.0.conv3.weight              of shape (1024, 256, 1, 1)\n",
            "2023-02-04 17:39:20,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.0.weight       loaded from backbone.body.layer3.0.downsample.0.weight       of shape (1024, 512, 1, 1)\n",
            "2023-02-04 17:39:20,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.bias         loaded from backbone.body.layer3.0.downsample.1.bias         of shape (1024,)\n",
            "2023-02-04 17:39:20,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.running_mean loaded from backbone.body.layer3.0.downsample.1.running_mean of shape (1024,)\n",
            "2023-02-04 17:39:20,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.running_var  loaded from backbone.body.layer3.0.downsample.1.running_var  of shape (1024,)\n",
            "2023-02-04 17:39:20,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.weight       loaded from backbone.body.layer3.0.downsample.1.weight       of shape (1024,)\n",
            "2023-02-04 17:39:20,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.bias                  loaded from backbone.body.layer3.1.bn1.bias                  of shape (256,)\n",
            "2023-02-04 17:39:20,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.running_mean          loaded from backbone.body.layer3.1.bn1.running_mean          of shape (256,)\n",
            "2023-02-04 17:39:20,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.running_var           loaded from backbone.body.layer3.1.bn1.running_var           of shape (256,)\n",
            "2023-02-04 17:39:20,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.weight                loaded from backbone.body.layer3.1.bn1.weight                of shape (256,)\n",
            "2023-02-04 17:39:20,976 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.bias                  loaded from backbone.body.layer3.1.bn2.bias                  of shape (256,)\n",
            "2023-02-04 17:39:20,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.running_mean          loaded from backbone.body.layer3.1.bn2.running_mean          of shape (256,)\n",
            "2023-02-04 17:39:20,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.running_var           loaded from backbone.body.layer3.1.bn2.running_var           of shape (256,)\n",
            "2023-02-04 17:39:20,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.weight                loaded from backbone.body.layer3.1.bn2.weight                of shape (256,)\n",
            "2023-02-04 17:39:20,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.bias                  loaded from backbone.body.layer3.1.bn3.bias                  of shape (1024,)\n",
            "2023-02-04 17:39:20,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.running_mean          loaded from backbone.body.layer3.1.bn3.running_mean          of shape (1024,)\n",
            "2023-02-04 17:39:20,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.running_var           loaded from backbone.body.layer3.1.bn3.running_var           of shape (1024,)\n",
            "2023-02-04 17:39:20,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.weight                loaded from backbone.body.layer3.1.bn3.weight                of shape (1024,)\n",
            "2023-02-04 17:39:20,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv1.weight              loaded from backbone.body.layer3.1.conv1.weight              of shape (256, 1024, 1, 1)\n",
            "2023-02-04 17:39:20,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv2.weight              loaded from backbone.body.layer3.1.conv2.weight              of shape (256, 256, 3, 3)\n",
            "2023-02-04 17:39:20,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv3.weight              loaded from backbone.body.layer3.1.conv3.weight              of shape (1024, 256, 1, 1)\n",
            "2023-02-04 17:39:20,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.bias                  loaded from backbone.body.layer3.2.bn1.bias                  of shape (256,)\n",
            "2023-02-04 17:39:20,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.running_mean          loaded from backbone.body.layer3.2.bn1.running_mean          of shape (256,)\n",
            "2023-02-04 17:39:20,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.running_var           loaded from backbone.body.layer3.2.bn1.running_var           of shape (256,)\n",
            "2023-02-04 17:39:20,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.weight                loaded from backbone.body.layer3.2.bn1.weight                of shape (256,)\n",
            "2023-02-04 17:39:20,977 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.bias                  loaded from backbone.body.layer3.2.bn2.bias                  of shape (256,)\n",
            "2023-02-04 17:39:20,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.running_mean          loaded from backbone.body.layer3.2.bn2.running_mean          of shape (256,)\n",
            "2023-02-04 17:39:20,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.running_var           loaded from backbone.body.layer3.2.bn2.running_var           of shape (256,)\n",
            "2023-02-04 17:39:20,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.weight                loaded from backbone.body.layer3.2.bn2.weight                of shape (256,)\n",
            "2023-02-04 17:39:20,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.bias                  loaded from backbone.body.layer3.2.bn3.bias                  of shape (1024,)\n",
            "2023-02-04 17:39:20,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.running_mean          loaded from backbone.body.layer3.2.bn3.running_mean          of shape (1024,)\n",
            "2023-02-04 17:39:20,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.running_var           loaded from backbone.body.layer3.2.bn3.running_var           of shape (1024,)\n",
            "2023-02-04 17:39:20,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.weight                loaded from backbone.body.layer3.2.bn3.weight                of shape (1024,)\n",
            "2023-02-04 17:39:20,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv1.weight              loaded from backbone.body.layer3.2.conv1.weight              of shape (256, 1024, 1, 1)\n",
            "2023-02-04 17:39:20,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv2.weight              loaded from backbone.body.layer3.2.conv2.weight              of shape (256, 256, 3, 3)\n",
            "2023-02-04 17:39:20,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv3.weight              loaded from backbone.body.layer3.2.conv3.weight              of shape (1024, 256, 1, 1)\n",
            "2023-02-04 17:39:20,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.bias                  loaded from backbone.body.layer3.3.bn1.bias                  of shape (256,)\n",
            "2023-02-04 17:39:20,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.running_mean          loaded from backbone.body.layer3.3.bn1.running_mean          of shape (256,)\n",
            "2023-02-04 17:39:20,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.running_var           loaded from backbone.body.layer3.3.bn1.running_var           of shape (256,)\n",
            "2023-02-04 17:39:20,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.weight                loaded from backbone.body.layer3.3.bn1.weight                of shape (256,)\n",
            "2023-02-04 17:39:20,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.bias                  loaded from backbone.body.layer3.3.bn2.bias                  of shape (256,)\n",
            "2023-02-04 17:39:20,978 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.running_mean          loaded from backbone.body.layer3.3.bn2.running_mean          of shape (256,)\n",
            "2023-02-04 17:39:20,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.running_var           loaded from backbone.body.layer3.3.bn2.running_var           of shape (256,)\n",
            "2023-02-04 17:39:20,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.weight                loaded from backbone.body.layer3.3.bn2.weight                of shape (256,)\n",
            "2023-02-04 17:39:20,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.bias                  loaded from backbone.body.layer3.3.bn3.bias                  of shape (1024,)\n",
            "2023-02-04 17:39:20,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.running_mean          loaded from backbone.body.layer3.3.bn3.running_mean          of shape (1024,)\n",
            "2023-02-04 17:39:20,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.running_var           loaded from backbone.body.layer3.3.bn3.running_var           of shape (1024,)\n",
            "2023-02-04 17:39:20,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.weight                loaded from backbone.body.layer3.3.bn3.weight                of shape (1024,)\n",
            "2023-02-04 17:39:20,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv1.weight              loaded from backbone.body.layer3.3.conv1.weight              of shape (256, 1024, 1, 1)\n",
            "2023-02-04 17:39:20,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv2.weight              loaded from backbone.body.layer3.3.conv2.weight              of shape (256, 256, 3, 3)\n",
            "2023-02-04 17:39:20,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv3.weight              loaded from backbone.body.layer3.3.conv3.weight              of shape (1024, 256, 1, 1)\n",
            "2023-02-04 17:39:20,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.bias                  loaded from backbone.body.layer3.4.bn1.bias                  of shape (256,)\n",
            "2023-02-04 17:39:20,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.running_mean          loaded from backbone.body.layer3.4.bn1.running_mean          of shape (256,)\n",
            "2023-02-04 17:39:20,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.running_var           loaded from backbone.body.layer3.4.bn1.running_var           of shape (256,)\n",
            "2023-02-04 17:39:20,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.weight                loaded from backbone.body.layer3.4.bn1.weight                of shape (256,)\n",
            "2023-02-04 17:39:20,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.bias                  loaded from backbone.body.layer3.4.bn2.bias                  of shape (256,)\n",
            "2023-02-04 17:39:20,979 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.running_mean          loaded from backbone.body.layer3.4.bn2.running_mean          of shape (256,)\n",
            "2023-02-04 17:39:20,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.running_var           loaded from backbone.body.layer3.4.bn2.running_var           of shape (256,)\n",
            "2023-02-04 17:39:20,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.weight                loaded from backbone.body.layer3.4.bn2.weight                of shape (256,)\n",
            "2023-02-04 17:39:20,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.bias                  loaded from backbone.body.layer3.4.bn3.bias                  of shape (1024,)\n",
            "2023-02-04 17:39:20,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.running_mean          loaded from backbone.body.layer3.4.bn3.running_mean          of shape (1024,)\n",
            "2023-02-04 17:39:20,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.running_var           loaded from backbone.body.layer3.4.bn3.running_var           of shape (1024,)\n",
            "2023-02-04 17:39:20,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.weight                loaded from backbone.body.layer3.4.bn3.weight                of shape (1024,)\n",
            "2023-02-04 17:39:20,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv1.weight              loaded from backbone.body.layer3.4.conv1.weight              of shape (256, 1024, 1, 1)\n",
            "2023-02-04 17:39:20,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv2.weight              loaded from backbone.body.layer3.4.conv2.weight              of shape (256, 256, 3, 3)\n",
            "2023-02-04 17:39:20,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv3.weight              loaded from backbone.body.layer3.4.conv3.weight              of shape (1024, 256, 1, 1)\n",
            "2023-02-04 17:39:20,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.bias                  loaded from backbone.body.layer3.5.bn1.bias                  of shape (256,)\n",
            "2023-02-04 17:39:20,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.running_mean          loaded from backbone.body.layer3.5.bn1.running_mean          of shape (256,)\n",
            "2023-02-04 17:39:20,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.running_var           loaded from backbone.body.layer3.5.bn1.running_var           of shape (256,)\n",
            "2023-02-04 17:39:20,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.weight                loaded from backbone.body.layer3.5.bn1.weight                of shape (256,)\n",
            "2023-02-04 17:39:20,980 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.bias                  loaded from backbone.body.layer3.5.bn2.bias                  of shape (256,)\n",
            "2023-02-04 17:39:20,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.running_mean          loaded from backbone.body.layer3.5.bn2.running_mean          of shape (256,)\n",
            "2023-02-04 17:39:20,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.running_var           loaded from backbone.body.layer3.5.bn2.running_var           of shape (256,)\n",
            "2023-02-04 17:39:20,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.weight                loaded from backbone.body.layer3.5.bn2.weight                of shape (256,)\n",
            "2023-02-04 17:39:20,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.bias                  loaded from backbone.body.layer3.5.bn3.bias                  of shape (1024,)\n",
            "2023-02-04 17:39:20,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.running_mean          loaded from backbone.body.layer3.5.bn3.running_mean          of shape (1024,)\n",
            "2023-02-04 17:39:20,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.running_var           loaded from backbone.body.layer3.5.bn3.running_var           of shape (1024,)\n",
            "2023-02-04 17:39:20,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.weight                loaded from backbone.body.layer3.5.bn3.weight                of shape (1024,)\n",
            "2023-02-04 17:39:20,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv1.weight              loaded from backbone.body.layer3.5.conv1.weight              of shape (256, 1024, 1, 1)\n",
            "2023-02-04 17:39:20,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv2.weight              loaded from backbone.body.layer3.5.conv2.weight              of shape (256, 256, 3, 3)\n",
            "2023-02-04 17:39:20,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv3.weight              loaded from backbone.body.layer3.5.conv3.weight              of shape (1024, 256, 1, 1)\n",
            "2023-02-04 17:39:20,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.bias                  loaded from backbone.body.layer4.0.bn1.bias                  of shape (512,)\n",
            "2023-02-04 17:39:20,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.running_mean          loaded from backbone.body.layer4.0.bn1.running_mean          of shape (512,)\n",
            "2023-02-04 17:39:20,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.running_var           loaded from backbone.body.layer4.0.bn1.running_var           of shape (512,)\n",
            "2023-02-04 17:39:20,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.weight                loaded from backbone.body.layer4.0.bn1.weight                of shape (512,)\n",
            "2023-02-04 17:39:20,981 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.bias                  loaded from backbone.body.layer4.0.bn2.bias                  of shape (512,)\n",
            "2023-02-04 17:39:20,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.running_mean          loaded from backbone.body.layer4.0.bn2.running_mean          of shape (512,)\n",
            "2023-02-04 17:39:20,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.running_var           loaded from backbone.body.layer4.0.bn2.running_var           of shape (512,)\n",
            "2023-02-04 17:39:20,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.weight                loaded from backbone.body.layer4.0.bn2.weight                of shape (512,)\n",
            "2023-02-04 17:39:20,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.bias                  loaded from backbone.body.layer4.0.bn3.bias                  of shape (2048,)\n",
            "2023-02-04 17:39:20,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.running_mean          loaded from backbone.body.layer4.0.bn3.running_mean          of shape (2048,)\n",
            "2023-02-04 17:39:20,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.running_var           loaded from backbone.body.layer4.0.bn3.running_var           of shape (2048,)\n",
            "2023-02-04 17:39:20,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.weight                loaded from backbone.body.layer4.0.bn3.weight                of shape (2048,)\n",
            "2023-02-04 17:39:20,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv1.weight              loaded from backbone.body.layer4.0.conv1.weight              of shape (512, 1024, 1, 1)\n",
            "2023-02-04 17:39:20,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv2.weight              loaded from backbone.body.layer4.0.conv2.weight              of shape (512, 512, 3, 3)\n",
            "2023-02-04 17:39:20,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv3.weight              loaded from backbone.body.layer4.0.conv3.weight              of shape (2048, 512, 1, 1)\n",
            "2023-02-04 17:39:20,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.0.weight       loaded from backbone.body.layer4.0.downsample.0.weight       of shape (2048, 1024, 1, 1)\n",
            "2023-02-04 17:39:20,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.bias         loaded from backbone.body.layer4.0.downsample.1.bias         of shape (2048,)\n",
            "2023-02-04 17:39:20,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.running_mean loaded from backbone.body.layer4.0.downsample.1.running_mean of shape (2048,)\n",
            "2023-02-04 17:39:20,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.running_var  loaded from backbone.body.layer4.0.downsample.1.running_var  of shape (2048,)\n",
            "2023-02-04 17:39:20,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.weight       loaded from backbone.body.layer4.0.downsample.1.weight       of shape (2048,)\n",
            "2023-02-04 17:39:20,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.bias                  loaded from backbone.body.layer4.1.bn1.bias                  of shape (512,)\n",
            "2023-02-04 17:39:20,982 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.running_mean          loaded from backbone.body.layer4.1.bn1.running_mean          of shape (512,)\n",
            "2023-02-04 17:39:20,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.running_var           loaded from backbone.body.layer4.1.bn1.running_var           of shape (512,)\n",
            "2023-02-04 17:39:20,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.weight                loaded from backbone.body.layer4.1.bn1.weight                of shape (512,)\n",
            "2023-02-04 17:39:20,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.bias                  loaded from backbone.body.layer4.1.bn2.bias                  of shape (512,)\n",
            "2023-02-04 17:39:20,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.running_mean          loaded from backbone.body.layer4.1.bn2.running_mean          of shape (512,)\n",
            "2023-02-04 17:39:20,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.running_var           loaded from backbone.body.layer4.1.bn2.running_var           of shape (512,)\n",
            "2023-02-04 17:39:20,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.weight                loaded from backbone.body.layer4.1.bn2.weight                of shape (512,)\n",
            "2023-02-04 17:39:20,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.bias                  loaded from backbone.body.layer4.1.bn3.bias                  of shape (2048,)\n",
            "2023-02-04 17:39:20,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.running_mean          loaded from backbone.body.layer4.1.bn3.running_mean          of shape (2048,)\n",
            "2023-02-04 17:39:20,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.running_var           loaded from backbone.body.layer4.1.bn3.running_var           of shape (2048,)\n",
            "2023-02-04 17:39:20,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.weight                loaded from backbone.body.layer4.1.bn3.weight                of shape (2048,)\n",
            "2023-02-04 17:39:20,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv1.weight              loaded from backbone.body.layer4.1.conv1.weight              of shape (512, 2048, 1, 1)\n",
            "2023-02-04 17:39:20,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv2.weight              loaded from backbone.body.layer4.1.conv2.weight              of shape (512, 512, 3, 3)\n",
            "2023-02-04 17:39:20,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv3.weight              loaded from backbone.body.layer4.1.conv3.weight              of shape (2048, 512, 1, 1)\n",
            "2023-02-04 17:39:20,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.bias                  loaded from backbone.body.layer4.2.bn1.bias                  of shape (512,)\n",
            "2023-02-04 17:39:20,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.running_mean          loaded from backbone.body.layer4.2.bn1.running_mean          of shape (512,)\n",
            "2023-02-04 17:39:20,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.running_var           loaded from backbone.body.layer4.2.bn1.running_var           of shape (512,)\n",
            "2023-02-04 17:39:20,983 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.weight                loaded from backbone.body.layer4.2.bn1.weight                of shape (512,)\n",
            "2023-02-04 17:39:20,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.bias                  loaded from backbone.body.layer4.2.bn2.bias                  of shape (512,)\n",
            "2023-02-04 17:39:20,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.running_mean          loaded from backbone.body.layer4.2.bn2.running_mean          of shape (512,)\n",
            "2023-02-04 17:39:20,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.running_var           loaded from backbone.body.layer4.2.bn2.running_var           of shape (512,)\n",
            "2023-02-04 17:39:20,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.weight                loaded from backbone.body.layer4.2.bn2.weight                of shape (512,)\n",
            "2023-02-04 17:39:20,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.bias                  loaded from backbone.body.layer4.2.bn3.bias                  of shape (2048,)\n",
            "2023-02-04 17:39:20,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.running_mean          loaded from backbone.body.layer4.2.bn3.running_mean          of shape (2048,)\n",
            "2023-02-04 17:39:20,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.running_var           loaded from backbone.body.layer4.2.bn3.running_var           of shape (2048,)\n",
            "2023-02-04 17:39:20,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.weight                loaded from backbone.body.layer4.2.bn3.weight                of shape (2048,)\n",
            "2023-02-04 17:39:20,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv1.weight              loaded from backbone.body.layer4.2.conv1.weight              of shape (512, 2048, 1, 1)\n",
            "2023-02-04 17:39:20,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv2.weight              loaded from backbone.body.layer4.2.conv2.weight              of shape (512, 512, 3, 3)\n",
            "2023-02-04 17:39:20,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv3.weight              loaded from backbone.body.layer4.2.conv3.weight              of shape (2048, 512, 1, 1)\n",
            "2023-02-04 17:39:20,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.bias                      loaded from backbone.body.stem.bn1.bias                      of shape (64,)\n",
            "2023-02-04 17:39:20,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.running_mean              loaded from backbone.body.stem.bn1.running_mean              of shape (64,)\n",
            "2023-02-04 17:39:20,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.running_var               loaded from backbone.body.stem.bn1.running_var               of shape (64,)\n",
            "2023-02-04 17:39:20,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.weight                    loaded from backbone.body.stem.bn1.weight                    of shape (64,)\n",
            "2023-02-04 17:39:20,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.conv1.weight                  loaded from backbone.body.stem.conv1.weight                  of shape (64, 3, 7, 7)\n",
            "2023-02-04 17:39:20,984 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner1.bias                     loaded from backbone.fpn.fpn_inner1.bias                     of shape (256,)\n",
            "2023-02-04 17:39:20,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner1.weight                   loaded from backbone.fpn.fpn_inner1.weight                   of shape (256, 256, 1, 1)\n",
            "2023-02-04 17:39:20,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner2.bias                     loaded from backbone.fpn.fpn_inner2.bias                     of shape (256,)\n",
            "2023-02-04 17:39:20,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner2.weight                   loaded from backbone.fpn.fpn_inner2.weight                   of shape (256, 512, 1, 1)\n",
            "2023-02-04 17:39:20,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner3.bias                     loaded from backbone.fpn.fpn_inner3.bias                     of shape (256,)\n",
            "2023-02-04 17:39:20,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner3.weight                   loaded from backbone.fpn.fpn_inner3.weight                   of shape (256, 1024, 1, 1)\n",
            "2023-02-04 17:39:20,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner4.bias                     loaded from backbone.fpn.fpn_inner4.bias                     of shape (256,)\n",
            "2023-02-04 17:39:20,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner4.weight                   loaded from backbone.fpn.fpn_inner4.weight                   of shape (256, 2048, 1, 1)\n",
            "2023-02-04 17:39:20,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer1.bias                     loaded from backbone.fpn.fpn_layer1.bias                     of shape (256,)\n",
            "2023-02-04 17:39:20,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer1.weight                   loaded from backbone.fpn.fpn_layer1.weight                   of shape (256, 256, 3, 3)\n",
            "2023-02-04 17:39:20,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer2.bias                     loaded from backbone.fpn.fpn_layer2.bias                     of shape (256,)\n",
            "2023-02-04 17:39:20,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer2.weight                   loaded from backbone.fpn.fpn_layer2.weight                   of shape (256, 256, 3, 3)\n",
            "2023-02-04 17:39:20,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer3.bias                     loaded from backbone.fpn.fpn_layer3.bias                     of shape (256,)\n",
            "2023-02-04 17:39:20,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer3.weight                   loaded from backbone.fpn.fpn_layer3.weight                   of shape (256, 256, 3, 3)\n",
            "2023-02-04 17:39:20,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer4.bias                     loaded from backbone.fpn.fpn_layer4.bias                     of shape (256,)\n",
            "2023-02-04 17:39:20,985 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer4.weight                   loaded from backbone.fpn.fpn_layer4.weight                   of shape (256, 256, 3, 3)\n",
            "2023-02-04 17:39:20,985 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level0.bias        loaded from da_heads.imghead.da_img_conv1_level0.bias        of shape (512,)\n",
            "2023-02-04 17:39:20,985 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level0.weight      loaded from da_heads.imghead.da_img_conv1_level0.weight      of shape (512, 256, 1, 1)\n",
            "2023-02-04 17:39:20,985 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level1.bias        loaded from da_heads.imghead.da_img_conv1_level1.bias        of shape (512,)\n",
            "2023-02-04 17:39:20,986 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level1.weight      loaded from da_heads.imghead.da_img_conv1_level1.weight      of shape (512, 256, 1, 1)\n",
            "2023-02-04 17:39:20,986 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level2.bias        loaded from da_heads.imghead.da_img_conv1_level2.bias        of shape (512,)\n",
            "2023-02-04 17:39:20,986 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level2.weight      loaded from da_heads.imghead.da_img_conv1_level2.weight      of shape (512, 256, 1, 1)\n",
            "2023-02-04 17:39:20,986 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level3.bias        loaded from da_heads.imghead.da_img_conv1_level3.bias        of shape (512,)\n",
            "2023-02-04 17:39:20,986 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level3.weight      loaded from da_heads.imghead.da_img_conv1_level3.weight      of shape (512, 256, 1, 1)\n",
            "2023-02-04 17:39:20,986 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level4.bias        loaded from da_heads.imghead.da_img_conv1_level4.bias        of shape (512,)\n",
            "2023-02-04 17:39:20,986 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level4.weight      loaded from da_heads.imghead.da_img_conv1_level4.weight      of shape (512, 256, 1, 1)\n",
            "2023-02-04 17:39:20,986 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level0.bias        loaded from da_heads.imghead.da_img_conv2_level0.bias        of shape (1,)\n",
            "2023-02-04 17:39:20,986 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level0.weight      loaded from da_heads.imghead.da_img_conv2_level0.weight      of shape (1, 512, 1, 1)\n",
            "2023-02-04 17:39:20,986 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level1.bias        loaded from da_heads.imghead.da_img_conv2_level1.bias        of shape (1,)\n",
            "2023-02-04 17:39:20,986 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level1.weight      loaded from da_heads.imghead.da_img_conv2_level1.weight      of shape (1, 512, 1, 1)\n",
            "2023-02-04 17:39:20,986 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level2.bias        loaded from da_heads.imghead.da_img_conv2_level2.bias        of shape (1,)\n",
            "2023-02-04 17:39:20,986 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level2.weight      loaded from da_heads.imghead.da_img_conv2_level2.weight      of shape (1, 512, 1, 1)\n",
            "2023-02-04 17:39:20,986 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level3.bias        loaded from da_heads.imghead.da_img_conv2_level3.bias        of shape (1,)\n",
            "2023-02-04 17:39:20,986 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level3.weight      loaded from da_heads.imghead.da_img_conv2_level3.weight      of shape (1, 512, 1, 1)\n",
            "2023-02-04 17:39:20,986 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level4.bias        loaded from da_heads.imghead.da_img_conv2_level4.bias        of shape (1,)\n",
            "2023-02-04 17:39:20,986 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level4.weight      loaded from da_heads.imghead.da_img_conv2_level4.weight      of shape (1, 512, 1, 1)\n",
            "2023-02-04 17:39:20,987 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc1_level0.bias          loaded from da_heads.inshead.da_ins_fc1_level0.bias          of shape (1024,)\n",
            "2023-02-04 17:39:20,987 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc1_level0.weight        loaded from da_heads.inshead.da_ins_fc1_level0.weight        of shape (1024, 1024)\n",
            "2023-02-04 17:39:20,987 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc1_level1.bias          loaded from da_heads.inshead.da_ins_fc1_level1.bias          of shape (1024,)\n",
            "2023-02-04 17:39:20,987 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc1_level1.weight        loaded from da_heads.inshead.da_ins_fc1_level1.weight        of shape (1024, 1024)\n",
            "2023-02-04 17:39:20,987 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc1_level2.bias          loaded from da_heads.inshead.da_ins_fc1_level2.bias          of shape (1024,)\n",
            "2023-02-04 17:39:20,987 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc1_level2.weight        loaded from da_heads.inshead.da_ins_fc1_level2.weight        of shape (1024, 1024)\n",
            "2023-02-04 17:39:20,987 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc1_level3.bias          loaded from da_heads.inshead.da_ins_fc1_level3.bias          of shape (1024,)\n",
            "2023-02-04 17:39:20,987 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc1_level3.weight        loaded from da_heads.inshead.da_ins_fc1_level3.weight        of shape (1024, 1024)\n",
            "2023-02-04 17:39:20,987 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc2_level0.bias          loaded from da_heads.inshead.da_ins_fc2_level0.bias          of shape (1024,)\n",
            "2023-02-04 17:39:20,987 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc2_level0.weight        loaded from da_heads.inshead.da_ins_fc2_level0.weight        of shape (1024, 1024)\n",
            "2023-02-04 17:39:20,987 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc2_level1.bias          loaded from da_heads.inshead.da_ins_fc2_level1.bias          of shape (1024,)\n",
            "2023-02-04 17:39:20,987 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc2_level1.weight        loaded from da_heads.inshead.da_ins_fc2_level1.weight        of shape (1024, 1024)\n",
            "2023-02-04 17:39:20,987 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc2_level2.bias          loaded from da_heads.inshead.da_ins_fc2_level2.bias          of shape (1024,)\n",
            "2023-02-04 17:39:20,987 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc2_level2.weight        loaded from da_heads.inshead.da_ins_fc2_level2.weight        of shape (1024, 1024)\n",
            "2023-02-04 17:39:20,987 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc2_level3.bias          loaded from da_heads.inshead.da_ins_fc2_level3.bias          of shape (1024,)\n",
            "2023-02-04 17:39:20,987 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc2_level3.weight        loaded from da_heads.inshead.da_ins_fc2_level3.weight        of shape (1024, 1024)\n",
            "2023-02-04 17:39:20,987 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc3_level0.bias          loaded from da_heads.inshead.da_ins_fc3_level0.bias          of shape (1,)\n",
            "2023-02-04 17:39:20,987 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc3_level0.weight        loaded from da_heads.inshead.da_ins_fc3_level0.weight        of shape (1, 1024)\n",
            "2023-02-04 17:39:20,988 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc3_level1.bias          loaded from da_heads.inshead.da_ins_fc3_level1.bias          of shape (1,)\n",
            "2023-02-04 17:39:20,988 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc3_level1.weight        loaded from da_heads.inshead.da_ins_fc3_level1.weight        of shape (1, 1024)\n",
            "2023-02-04 17:39:20,988 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc3_level2.bias          loaded from da_heads.inshead.da_ins_fc3_level2.bias          of shape (1,)\n",
            "2023-02-04 17:39:20,988 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc3_level2.weight        loaded from da_heads.inshead.da_ins_fc3_level2.weight        of shape (1, 1024)\n",
            "2023-02-04 17:39:20,988 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc3_level3.bias          loaded from da_heads.inshead.da_ins_fc3_level3.bias          of shape (1,)\n",
            "2023-02-04 17:39:20,988 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc3_level3.weight        loaded from da_heads.inshead.da_ins_fc3_level3.weight        of shape (1, 1024)\n",
            "2023-02-04 17:39:20,988 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc6.bias         loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (1024,)\n",
            "2023-02-04 17:39:20,988 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc6.weight       loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (1024, 12544)\n",
            "2023-02-04 17:39:20,988 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc7.bias         loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (1024,)\n",
            "2023-02-04 17:39:20,988 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc7.weight       loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (1024, 1024)\n",
            "2023-02-04 17:39:20,988 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.bbox_pred.bias           loaded from roi_heads.box.predictor.bbox_pred.bias           of shape (8,)\n",
            "2023-02-04 17:39:20,988 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.bbox_pred.weight         loaded from roi_heads.box.predictor.bbox_pred.weight         of shape (8, 1024)\n",
            "2023-02-04 17:39:20,988 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.cls_score.bias           loaded from roi_heads.box.predictor.cls_score.bias           of shape (2,)\n",
            "2023-02-04 17:39:20,988 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.cls_score.weight         loaded from roi_heads.box.predictor.cls_score.weight         of shape (2, 1024)\n",
            "2023-02-04 17:39:20,988 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.0              loaded from rpn.anchor_generator.cell_anchors.0              of shape (3, 4)\n",
            "2023-02-04 17:39:20,988 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.1              loaded from rpn.anchor_generator.cell_anchors.1              of shape (3, 4)\n",
            "2023-02-04 17:39:20,988 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.2              loaded from rpn.anchor_generator.cell_anchors.2              of shape (3, 4)\n",
            "2023-02-04 17:39:20,988 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.3              loaded from rpn.anchor_generator.cell_anchors.3              of shape (3, 4)\n",
            "2023-02-04 17:39:20,988 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.4              loaded from rpn.anchor_generator.cell_anchors.4              of shape (3, 4)\n",
            "2023-02-04 17:39:20,989 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bbox_pred.bias                          loaded from rpn.head.bbox_pred.bias                          of shape (12,)\n",
            "2023-02-04 17:39:20,989 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bbox_pred.weight                        loaded from rpn.head.bbox_pred.weight                        of shape (12, 256, 1, 1)\n",
            "2023-02-04 17:39:20,989 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.cls_logits.bias                         loaded from rpn.head.cls_logits.bias                         of shape (3,)\n",
            "2023-02-04 17:39:20,989 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.cls_logits.weight                       loaded from rpn.head.cls_logits.weight                       of shape (3, 256, 1, 1)\n",
            "2023-02-04 17:39:20,989 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.conv.bias                               loaded from rpn.head.conv.bias                               of shape (256,)\n",
            "2023-02-04 17:39:20,989 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.conv.weight                             loaded from rpn.head.conv.weight                             of shape (256, 256, 3, 3)\n",
            "loading annotations into memory...\n",
            "Done (t=0.38s)\n",
            "creating index...\n",
            "index created!\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "2023-02-04 17:39:21,451 maskrcnn_benchmark.inference INFO: Start evaluation on cityscapes_only_car_val_cocostyle dataset(500 images).\n",
            "  0% 0/500 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "100% 500/500 [01:58<00:00,  4.23it/s]\n",
            "2023-02-04 17:41:19,746 maskrcnn_benchmark.inference INFO: Total inference time: 0:01:58.294337 (0.23658867406845094 s / img per device, on 1 devices)\n",
            "2023-02-04 17:41:19,810 maskrcnn_benchmark.inference INFO: Preparing results for COCO format\n",
            "2023-02-04 17:41:19,810 maskrcnn_benchmark.inference INFO: Preparing bbox results\n",
            "2023-02-04 17:41:19,853 maskrcnn_benchmark.inference INFO: Evaluating predictions\n",
            "Category: 1 {'id': 1, 'name': 'car'}\n",
            "Loading and preparing results...\n",
            "DONE (t=0.15s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=3.27s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.14s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.251\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.501\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.234\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.070\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.301\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.488\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.067\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.275\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.341\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.116\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.392\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.608\n",
            "Loading and preparing results...\n",
            "DONE (t=0.17s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=5.86s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.25s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.251\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.501\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.234\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.070\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.301\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.488\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.067\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.275\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.341\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.116\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.392\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.608\n",
            "2023-02-04 17:41:30,081 maskrcnn_benchmark.inference INFO: OrderedDict([('bbox', OrderedDict([('AP', -1), ('AP50', -1), ('AP75', -1), ('APs', -1), ('APm', -1), ('APl', -1), (1, {'AP': 0.25120233778278944, 'AP50': 0.5008855917644778, 'AP75': 0.23372656042153236, 'APs': 0.07041600494420419, 'APm': 0.30147866578364046, 'APl': 0.4876780580453613})]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/test_net.py --config-file \"/content/fff.yaml\" MODEL.WEIGHT /content/drive/MyDrive/AI/mic/model_0003000.pth\n"
      ],
      "metadata": {
        "id": "ttgVRGJbmNRE",
        "outputId": "9293b2dd-8bd8-4fb0-9730-686763026f28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-03 14:50:59,612 maskrcnn_benchmark INFO: Using 1 GPUs\n",
            "2023-02-03 14:50:59,612 maskrcnn_benchmark INFO: DATALOADER:\n",
            "  ASPECT_RATIO_GROUPING: True\n",
            "  NUM_WORKERS: 4\n",
            "  SIZE_DIVISIBILITY: 32\n",
            "DATASETS:\n",
            "  SOURCE_TRAIN: ('sim10k_cocostyle',)\n",
            "  TARGET_TRAIN: ('cityscapes_only_car_train_cocostyle',)\n",
            "  TEST: ('cityscapes_only_car_val_cocostyle',)\n",
            "  TRAIN: ()\n",
            "INPUT:\n",
            "  MAX_SIZE_TEST: 1600\n",
            "  MAX_SIZE_TRAIN: 1600\n",
            "  MIN_SIZE_TEST: 800\n",
            "  MIN_SIZE_TRAIN: (800,)\n",
            "  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]\n",
            "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
            "  TO_BGR255: True\n",
            "MODEL:\n",
            "  BACKBONE:\n",
            "    CONV_BODY: R-50-FPN\n",
            "    FREEZE_CONV_BODY_AT: 2\n",
            "    OUT_CHANNELS: 256\n",
            "    USE_GN: False\n",
            "  CLS_AGNOSTIC_BBOX_REG: False\n",
            "  DA_HEADS:\n",
            "    COS_WEIGHT: 0.1\n",
            "    DA_IMG_GRL_WEIGHT: 0.01\n",
            "    DA_INS_GRL_WEIGHT: 0.1\n",
            "  DEVICE: cuda\n",
            "  DOMAIN_ADAPTATION_ON: True\n",
            "  FPN:\n",
            "    USE_GN: False\n",
            "    USE_RELU: False\n",
            "  GROUP_NORM:\n",
            "    DIM_PER_GP: -1\n",
            "    EPSILON: 1e-05\n",
            "    NUM_GROUPS: 32\n",
            "  KEYPOINT_ON: False\n",
            "  MASKING_AUGMENTATION: True\n",
            "  MASKING_BLOCK_SIZE: 32\n",
            "  MASKING_RATIO: 0.5\n",
            "  MASK_ON: False\n",
            "  META_ARCHITECTURE: GeneralizedRCNN\n",
            "  MIC_ON: True\n",
            "  PSEUDO_LABEL_LAMBDA: 1.0\n",
            "  PSEUDO_LABEL_THRESHOLD: 0.8\n",
            "  PSEUDO_LABEL_WEIGHT: prob\n",
            "  RESNETS:\n",
            "    NUM_GROUPS: 1\n",
            "    RES2_OUT_CHANNELS: 256\n",
            "    RES5_DILATION: 1\n",
            "    STEM_FUNC: StemWithFixedBatchNorm\n",
            "    STEM_OUT_CHANNELS: 64\n",
            "    STRIDE_IN_1X1: True\n",
            "    TRANS_FUNC: BottleneckWithFixedBatchNorm\n",
            "    WIDTH_PER_GROUP: 64\n",
            "  RETINANET:\n",
            "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
            "    ANCHOR_STRIDES: (8, 16, 32, 64, 128)\n",
            "    ASPECT_RATIOS: (0.5, 1.0, 2.0)\n",
            "    BBOX_REG_BETA: 0.11\n",
            "    BBOX_REG_WEIGHT: 4.0\n",
            "    BG_IOU_THRESHOLD: 0.4\n",
            "    FG_IOU_THRESHOLD: 0.5\n",
            "    INFERENCE_TH: 0.05\n",
            "    LOSS_ALPHA: 0.25\n",
            "    LOSS_GAMMA: 2.0\n",
            "    NMS_TH: 0.4\n",
            "    NUM_CLASSES: 81\n",
            "    NUM_CONVS: 4\n",
            "    OCTAVE: 2.0\n",
            "    PRE_NMS_TOP_N: 1000\n",
            "    PRIOR_PROB: 0.01\n",
            "    SCALES_PER_OCTAVE: 3\n",
            "    STRADDLE_THRESH: 0\n",
            "    USE_C5: True\n",
            "  RETINANET_ON: False\n",
            "  ROI_BOX_HEAD:\n",
            "    CONV_HEAD_DIM: 256\n",
            "    DILATION: 1\n",
            "    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n",
            "    MLP_HEAD_DIM: 1024\n",
            "    NUM_CLASSES: 2\n",
            "    NUM_STACKED_CONVS: 4\n",
            "    POOLER_RESOLUTION: 7\n",
            "    POOLER_SAMPLING_RATIO: 2\n",
            "    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n",
            "    PREDICTOR: FPNPredictor\n",
            "    USE_GN: False\n",
            "  ROI_HEADS:\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
            "    BG_IOU_THRESHOLD: 0.5\n",
            "    DETECTIONS_PER_IMG: 100\n",
            "    FG_IOU_THRESHOLD: 0.5\n",
            "    NMS: 0.5\n",
            "    POSITIVE_FRACTION: 0.25\n",
            "    SCORE_THRESH: 0.05\n",
            "    USE_FPN: True\n",
            "  ROI_KEYPOINT_HEAD:\n",
            "    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
            "    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor\n",
            "    MLP_HEAD_DIM: 1024\n",
            "    NUM_CLASSES: 17\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_SCALES: (0.0625,)\n",
            "    PREDICTOR: KeypointRCNNPredictor\n",
            "    RESOLUTION: 14\n",
            "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
            "  ROI_MASK_HEAD:\n",
            "    CONV_LAYERS: (256, 256, 256, 256)\n",
            "    DILATION: 1\n",
            "    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor\n",
            "    MLP_HEAD_DIM: 1024\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_SCALES: (0.0625,)\n",
            "    POSTPROCESS_MASKS: False\n",
            "    POSTPROCESS_MASKS_THRESHOLD: 0.5\n",
            "    PREDICTOR: MaskRCNNC4Predictor\n",
            "    RESOLUTION: 14\n",
            "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
            "    USE_GN: False\n",
            "  RPN:\n",
            "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
            "    ANCHOR_STRIDE: (4, 8, 16, 32, 64)\n",
            "    ASPECT_RATIOS: (0.5, 1.0, 2.0)\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "    BG_IOU_THRESHOLD: 0.3\n",
            "    FG_IOU_THRESHOLD: 0.7\n",
            "    FPN_POST_NMS_TOP_N_TEST: 1000\n",
            "    FPN_POST_NMS_TOP_N_TRAIN: 2000\n",
            "    MIN_SIZE: 0\n",
            "    NMS_THRESH: 0.7\n",
            "    POSITIVE_FRACTION: 0.5\n",
            "    POST_NMS_TOP_N_TEST: 1000\n",
            "    POST_NMS_TOP_N_TRAIN: 2000\n",
            "    PRE_NMS_TOP_N_TEST: 1000\n",
            "    PRE_NMS_TOP_N_TRAIN: 2000\n",
            "    RPN_HEAD: SingleConvRPNHead\n",
            "    STRADDLE_THRESH: 0\n",
            "    USE_FPN: True\n",
            "  RPN_ONLY: False\n",
            "  TEACHER_ALPHA: 0.9\n",
            "  WEIGHT: /content/drive/MyDrive/AI/mic/model_0003000.pth\n",
            "OUTPUT_DIR: .\n",
            "PATHS_CATALOG: /content/MIC/det/maskrcnn_benchmark/config/paths_catalog.py\n",
            "SOLVER:\n",
            "  BASE_LR: 0.001\n",
            "  BIAS_LR_FACTOR: 2\n",
            "  CHECKPOINT_PERIOD: 1000\n",
            "  GAMMA: 0.1\n",
            "  IMS_PER_BATCH: 2\n",
            "  MAX_ITER: 60000\n",
            "  MOMENTUM: 0.9\n",
            "  STEPS: (30000, 40000)\n",
            "  WARMUP_FACTOR: 0.3333333333333333\n",
            "  WARMUP_ITERS: 1000\n",
            "  WARMUP_METHOD: linear\n",
            "  WEIGHT_DECAY: 0.0001\n",
            "  WEIGHT_DECAY_BIAS: 0\n",
            "TEST:\n",
            "  DETECTIONS_PER_IMG: 100\n",
            "  EXPECTED_RESULTS: []\n",
            "  EXPECTED_RESULTS_SIGMA_TOL: 4\n",
            "  IMS_PER_BATCH: 1\n",
            "2023-02-03 14:50:59,612 maskrcnn_benchmark INFO: Collecting env info (might take some time)\n",
            "2023-02-03 14:51:00,904 maskrcnn_benchmark INFO: \n",
            "PyTorch version: 1.12.0+cu113\n",
            "Is debug build: False\n",
            "CUDA used to build PyTorch: 11.3\n",
            "ROCM used to build PyTorch: N/A\n",
            "\n",
            "OS: Ubuntu 20.04.5 LTS (x86_64)\n",
            "GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n",
            "Clang version: 10.0.0-4ubuntu1 \n",
            "CMake version: version 3.22.6\n",
            "Libc version: glibc-2.31\n",
            "\n",
            "Python version: 3.8.10 (default, Nov 14 2022, 12:59:47)  [GCC 9.4.0] (64-bit runtime)\n",
            "Python platform: Linux-5.10.147+-x86_64-with-glibc2.29\n",
            "Is CUDA available: True\n",
            "CUDA runtime version: 11.2.152\n",
            "GPU models and configuration: GPU 0: Tesla T4\n",
            "Nvidia driver version: 510.47.03\n",
            "cuDNN version: Probably one of the following:\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.1.1\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.1.1\n",
            "HIP runtime version: N/A\n",
            "MIOpen runtime version: N/A\n",
            "Is XNNPACK available: True\n",
            "\n",
            "Versions of relevant libraries:\n",
            "[pip3] numpy==1.21.6\n",
            "[pip3] torch==1.12.0+cu113\n",
            "[pip3] torchaudio==0.12.0+cu113\n",
            "[pip3] torchsummary==1.5.1\n",
            "[pip3] torchtext==0.14.1\n",
            "[pip3] torchvision==0.13.0+cu113\n",
            "[conda] Could not collect\n",
            "        Pillow (7.1.2)\n",
            "2023-02-03 14:51:03,578 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from /content/drive/MyDrive/AI/mic/model_0003000.pth\n",
            "2023-02-03 14:51:04,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.bias                  loaded from backbone.body.layer1.0.bn1.bias                  of shape (64,)\n",
            "2023-02-03 14:51:04,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.running_mean          loaded from backbone.body.layer1.0.bn1.running_mean          of shape (64,)\n",
            "2023-02-03 14:51:04,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.running_var           loaded from backbone.body.layer1.0.bn1.running_var           of shape (64,)\n",
            "2023-02-03 14:51:04,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.weight                loaded from backbone.body.layer1.0.bn1.weight                of shape (64,)\n",
            "2023-02-03 14:51:04,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.bias                  loaded from backbone.body.layer1.0.bn2.bias                  of shape (64,)\n",
            "2023-02-03 14:51:04,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.running_mean          loaded from backbone.body.layer1.0.bn2.running_mean          of shape (64,)\n",
            "2023-02-03 14:51:04,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.running_var           loaded from backbone.body.layer1.0.bn2.running_var           of shape (64,)\n",
            "2023-02-03 14:51:04,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.weight                loaded from backbone.body.layer1.0.bn2.weight                of shape (64,)\n",
            "2023-02-03 14:51:04,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.bias                  loaded from backbone.body.layer1.0.bn3.bias                  of shape (256,)\n",
            "2023-02-03 14:51:04,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.running_mean          loaded from backbone.body.layer1.0.bn3.running_mean          of shape (256,)\n",
            "2023-02-03 14:51:04,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.running_var           loaded from backbone.body.layer1.0.bn3.running_var           of shape (256,)\n",
            "2023-02-03 14:51:04,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.weight                loaded from backbone.body.layer1.0.bn3.weight                of shape (256,)\n",
            "2023-02-03 14:51:04,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv1.weight              loaded from backbone.body.layer1.0.conv1.weight              of shape (64, 64, 1, 1)\n",
            "2023-02-03 14:51:04,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv2.weight              loaded from backbone.body.layer1.0.conv2.weight              of shape (64, 64, 3, 3)\n",
            "2023-02-03 14:51:04,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv3.weight              loaded from backbone.body.layer1.0.conv3.weight              of shape (256, 64, 1, 1)\n",
            "2023-02-03 14:51:04,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.0.weight       loaded from backbone.body.layer1.0.downsample.0.weight       of shape (256, 64, 1, 1)\n",
            "2023-02-03 14:51:04,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.bias         loaded from backbone.body.layer1.0.downsample.1.bias         of shape (256,)\n",
            "2023-02-03 14:51:04,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.running_mean loaded from backbone.body.layer1.0.downsample.1.running_mean of shape (256,)\n",
            "2023-02-03 14:51:04,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.running_var  loaded from backbone.body.layer1.0.downsample.1.running_var  of shape (256,)\n",
            "2023-02-03 14:51:04,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.weight       loaded from backbone.body.layer1.0.downsample.1.weight       of shape (256,)\n",
            "2023-02-03 14:51:04,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.bias                  loaded from backbone.body.layer1.1.bn1.bias                  of shape (64,)\n",
            "2023-02-03 14:51:04,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.running_mean          loaded from backbone.body.layer1.1.bn1.running_mean          of shape (64,)\n",
            "2023-02-03 14:51:04,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.running_var           loaded from backbone.body.layer1.1.bn1.running_var           of shape (64,)\n",
            "2023-02-03 14:51:04,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.weight                loaded from backbone.body.layer1.1.bn1.weight                of shape (64,)\n",
            "2023-02-03 14:51:04,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.bias                  loaded from backbone.body.layer1.1.bn2.bias                  of shape (64,)\n",
            "2023-02-03 14:51:04,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.running_mean          loaded from backbone.body.layer1.1.bn2.running_mean          of shape (64,)\n",
            "2023-02-03 14:51:04,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.running_var           loaded from backbone.body.layer1.1.bn2.running_var           of shape (64,)\n",
            "2023-02-03 14:51:04,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.weight                loaded from backbone.body.layer1.1.bn2.weight                of shape (64,)\n",
            "2023-02-03 14:51:04,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.bias                  loaded from backbone.body.layer1.1.bn3.bias                  of shape (256,)\n",
            "2023-02-03 14:51:04,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.running_mean          loaded from backbone.body.layer1.1.bn3.running_mean          of shape (256,)\n",
            "2023-02-03 14:51:04,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.running_var           loaded from backbone.body.layer1.1.bn3.running_var           of shape (256,)\n",
            "2023-02-03 14:51:04,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.weight                loaded from backbone.body.layer1.1.bn3.weight                of shape (256,)\n",
            "2023-02-03 14:51:04,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv1.weight              loaded from backbone.body.layer1.1.conv1.weight              of shape (64, 256, 1, 1)\n",
            "2023-02-03 14:51:04,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv2.weight              loaded from backbone.body.layer1.1.conv2.weight              of shape (64, 64, 3, 3)\n",
            "2023-02-03 14:51:04,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv3.weight              loaded from backbone.body.layer1.1.conv3.weight              of shape (256, 64, 1, 1)\n",
            "2023-02-03 14:51:04,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.bias                  loaded from backbone.body.layer1.2.bn1.bias                  of shape (64,)\n",
            "2023-02-03 14:51:04,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.running_mean          loaded from backbone.body.layer1.2.bn1.running_mean          of shape (64,)\n",
            "2023-02-03 14:51:04,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.running_var           loaded from backbone.body.layer1.2.bn1.running_var           of shape (64,)\n",
            "2023-02-03 14:51:04,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.weight                loaded from backbone.body.layer1.2.bn1.weight                of shape (64,)\n",
            "2023-02-03 14:51:04,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.bias                  loaded from backbone.body.layer1.2.bn2.bias                  of shape (64,)\n",
            "2023-02-03 14:51:04,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.running_mean          loaded from backbone.body.layer1.2.bn2.running_mean          of shape (64,)\n",
            "2023-02-03 14:51:04,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.running_var           loaded from backbone.body.layer1.2.bn2.running_var           of shape (64,)\n",
            "2023-02-03 14:51:04,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.weight                loaded from backbone.body.layer1.2.bn2.weight                of shape (64,)\n",
            "2023-02-03 14:51:04,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.bias                  loaded from backbone.body.layer1.2.bn3.bias                  of shape (256,)\n",
            "2023-02-03 14:51:04,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.running_mean          loaded from backbone.body.layer1.2.bn3.running_mean          of shape (256,)\n",
            "2023-02-03 14:51:04,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.running_var           loaded from backbone.body.layer1.2.bn3.running_var           of shape (256,)\n",
            "2023-02-03 14:51:04,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.weight                loaded from backbone.body.layer1.2.bn3.weight                of shape (256,)\n",
            "2023-02-03 14:51:04,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv1.weight              loaded from backbone.body.layer1.2.conv1.weight              of shape (64, 256, 1, 1)\n",
            "2023-02-03 14:51:04,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv2.weight              loaded from backbone.body.layer1.2.conv2.weight              of shape (64, 64, 3, 3)\n",
            "2023-02-03 14:51:04,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv3.weight              loaded from backbone.body.layer1.2.conv3.weight              of shape (256, 64, 1, 1)\n",
            "2023-02-03 14:51:04,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.bias                  loaded from backbone.body.layer2.0.bn1.bias                  of shape (128,)\n",
            "2023-02-03 14:51:04,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.running_mean          loaded from backbone.body.layer2.0.bn1.running_mean          of shape (128,)\n",
            "2023-02-03 14:51:04,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.running_var           loaded from backbone.body.layer2.0.bn1.running_var           of shape (128,)\n",
            "2023-02-03 14:51:04,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.weight                loaded from backbone.body.layer2.0.bn1.weight                of shape (128,)\n",
            "2023-02-03 14:51:04,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.bias                  loaded from backbone.body.layer2.0.bn2.bias                  of shape (128,)\n",
            "2023-02-03 14:51:04,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.running_mean          loaded from backbone.body.layer2.0.bn2.running_mean          of shape (128,)\n",
            "2023-02-03 14:51:04,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.running_var           loaded from backbone.body.layer2.0.bn2.running_var           of shape (128,)\n",
            "2023-02-03 14:51:04,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.weight                loaded from backbone.body.layer2.0.bn2.weight                of shape (128,)\n",
            "2023-02-03 14:51:04,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.bias                  loaded from backbone.body.layer2.0.bn3.bias                  of shape (512,)\n",
            "2023-02-03 14:51:04,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.running_mean          loaded from backbone.body.layer2.0.bn3.running_mean          of shape (512,)\n",
            "2023-02-03 14:51:04,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.running_var           loaded from backbone.body.layer2.0.bn3.running_var           of shape (512,)\n",
            "2023-02-03 14:51:04,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.weight                loaded from backbone.body.layer2.0.bn3.weight                of shape (512,)\n",
            "2023-02-03 14:51:04,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv1.weight              loaded from backbone.body.layer2.0.conv1.weight              of shape (128, 256, 1, 1)\n",
            "2023-02-03 14:51:04,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv2.weight              loaded from backbone.body.layer2.0.conv2.weight              of shape (128, 128, 3, 3)\n",
            "2023-02-03 14:51:04,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv3.weight              loaded from backbone.body.layer2.0.conv3.weight              of shape (512, 128, 1, 1)\n",
            "2023-02-03 14:51:04,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.0.weight       loaded from backbone.body.layer2.0.downsample.0.weight       of shape (512, 256, 1, 1)\n",
            "2023-02-03 14:51:04,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.bias         loaded from backbone.body.layer2.0.downsample.1.bias         of shape (512,)\n",
            "2023-02-03 14:51:04,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.running_mean loaded from backbone.body.layer2.0.downsample.1.running_mean of shape (512,)\n",
            "2023-02-03 14:51:04,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.running_var  loaded from backbone.body.layer2.0.downsample.1.running_var  of shape (512,)\n",
            "2023-02-03 14:51:04,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.weight       loaded from backbone.body.layer2.0.downsample.1.weight       of shape (512,)\n",
            "2023-02-03 14:51:04,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.bias                  loaded from backbone.body.layer2.1.bn1.bias                  of shape (128,)\n",
            "2023-02-03 14:51:04,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.running_mean          loaded from backbone.body.layer2.1.bn1.running_mean          of shape (128,)\n",
            "2023-02-03 14:51:04,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.running_var           loaded from backbone.body.layer2.1.bn1.running_var           of shape (128,)\n",
            "2023-02-03 14:51:04,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.weight                loaded from backbone.body.layer2.1.bn1.weight                of shape (128,)\n",
            "2023-02-03 14:51:04,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.bias                  loaded from backbone.body.layer2.1.bn2.bias                  of shape (128,)\n",
            "2023-02-03 14:51:04,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.running_mean          loaded from backbone.body.layer2.1.bn2.running_mean          of shape (128,)\n",
            "2023-02-03 14:51:04,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.running_var           loaded from backbone.body.layer2.1.bn2.running_var           of shape (128,)\n",
            "2023-02-03 14:51:04,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.weight                loaded from backbone.body.layer2.1.bn2.weight                of shape (128,)\n",
            "2023-02-03 14:51:04,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.bias                  loaded from backbone.body.layer2.1.bn3.bias                  of shape (512,)\n",
            "2023-02-03 14:51:04,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.running_mean          loaded from backbone.body.layer2.1.bn3.running_mean          of shape (512,)\n",
            "2023-02-03 14:51:04,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.running_var           loaded from backbone.body.layer2.1.bn3.running_var           of shape (512,)\n",
            "2023-02-03 14:51:04,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.weight                loaded from backbone.body.layer2.1.bn3.weight                of shape (512,)\n",
            "2023-02-03 14:51:04,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv1.weight              loaded from backbone.body.layer2.1.conv1.weight              of shape (128, 512, 1, 1)\n",
            "2023-02-03 14:51:04,209 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv2.weight              loaded from backbone.body.layer2.1.conv2.weight              of shape (128, 128, 3, 3)\n",
            "2023-02-03 14:51:04,210 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv3.weight              loaded from backbone.body.layer2.1.conv3.weight              of shape (512, 128, 1, 1)\n",
            "2023-02-03 14:51:04,210 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.bias                  loaded from backbone.body.layer2.2.bn1.bias                  of shape (128,)\n",
            "2023-02-03 14:51:04,210 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.running_mean          loaded from backbone.body.layer2.2.bn1.running_mean          of shape (128,)\n",
            "2023-02-03 14:51:04,210 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.running_var           loaded from backbone.body.layer2.2.bn1.running_var           of shape (128,)\n",
            "2023-02-03 14:51:04,210 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.weight                loaded from backbone.body.layer2.2.bn1.weight                of shape (128,)\n",
            "2023-02-03 14:51:04,210 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.bias                  loaded from backbone.body.layer2.2.bn2.bias                  of shape (128,)\n",
            "2023-02-03 14:51:04,210 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.running_mean          loaded from backbone.body.layer2.2.bn2.running_mean          of shape (128,)\n",
            "2023-02-03 14:51:04,210 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.running_var           loaded from backbone.body.layer2.2.bn2.running_var           of shape (128,)\n",
            "2023-02-03 14:51:04,210 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.weight                loaded from backbone.body.layer2.2.bn2.weight                of shape (128,)\n",
            "2023-02-03 14:51:04,210 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.bias                  loaded from backbone.body.layer2.2.bn3.bias                  of shape (512,)\n",
            "2023-02-03 14:51:04,210 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.running_mean          loaded from backbone.body.layer2.2.bn3.running_mean          of shape (512,)\n",
            "2023-02-03 14:51:04,210 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.running_var           loaded from backbone.body.layer2.2.bn3.running_var           of shape (512,)\n",
            "2023-02-03 14:51:04,210 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.weight                loaded from backbone.body.layer2.2.bn3.weight                of shape (512,)\n",
            "2023-02-03 14:51:04,210 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv1.weight              loaded from backbone.body.layer2.2.conv1.weight              of shape (128, 512, 1, 1)\n",
            "2023-02-03 14:51:04,210 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv2.weight              loaded from backbone.body.layer2.2.conv2.weight              of shape (128, 128, 3, 3)\n",
            "2023-02-03 14:51:04,210 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv3.weight              loaded from backbone.body.layer2.2.conv3.weight              of shape (512, 128, 1, 1)\n",
            "2023-02-03 14:51:04,210 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.bias                  loaded from backbone.body.layer2.3.bn1.bias                  of shape (128,)\n",
            "2023-02-03 14:51:04,210 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.running_mean          loaded from backbone.body.layer2.3.bn1.running_mean          of shape (128,)\n",
            "2023-02-03 14:51:04,210 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.running_var           loaded from backbone.body.layer2.3.bn1.running_var           of shape (128,)\n",
            "2023-02-03 14:51:04,210 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.weight                loaded from backbone.body.layer2.3.bn1.weight                of shape (128,)\n",
            "2023-02-03 14:51:04,211 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.bias                  loaded from backbone.body.layer2.3.bn2.bias                  of shape (128,)\n",
            "2023-02-03 14:51:04,211 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.running_mean          loaded from backbone.body.layer2.3.bn2.running_mean          of shape (128,)\n",
            "2023-02-03 14:51:04,211 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.running_var           loaded from backbone.body.layer2.3.bn2.running_var           of shape (128,)\n",
            "2023-02-03 14:51:04,211 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.weight                loaded from backbone.body.layer2.3.bn2.weight                of shape (128,)\n",
            "2023-02-03 14:51:04,211 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.bias                  loaded from backbone.body.layer2.3.bn3.bias                  of shape (512,)\n",
            "2023-02-03 14:51:04,211 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.running_mean          loaded from backbone.body.layer2.3.bn3.running_mean          of shape (512,)\n",
            "2023-02-03 14:51:04,211 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.running_var           loaded from backbone.body.layer2.3.bn3.running_var           of shape (512,)\n",
            "2023-02-03 14:51:04,211 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.weight                loaded from backbone.body.layer2.3.bn3.weight                of shape (512,)\n",
            "2023-02-03 14:51:04,211 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv1.weight              loaded from backbone.body.layer2.3.conv1.weight              of shape (128, 512, 1, 1)\n",
            "2023-02-03 14:51:04,211 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv2.weight              loaded from backbone.body.layer2.3.conv2.weight              of shape (128, 128, 3, 3)\n",
            "2023-02-03 14:51:04,211 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv3.weight              loaded from backbone.body.layer2.3.conv3.weight              of shape (512, 128, 1, 1)\n",
            "2023-02-03 14:51:04,211 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.bias                  loaded from backbone.body.layer3.0.bn1.bias                  of shape (256,)\n",
            "2023-02-03 14:51:04,211 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.running_mean          loaded from backbone.body.layer3.0.bn1.running_mean          of shape (256,)\n",
            "2023-02-03 14:51:04,211 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.running_var           loaded from backbone.body.layer3.0.bn1.running_var           of shape (256,)\n",
            "2023-02-03 14:51:04,211 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.weight                loaded from backbone.body.layer3.0.bn1.weight                of shape (256,)\n",
            "2023-02-03 14:51:04,211 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.bias                  loaded from backbone.body.layer3.0.bn2.bias                  of shape (256,)\n",
            "2023-02-03 14:51:04,211 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.running_mean          loaded from backbone.body.layer3.0.bn2.running_mean          of shape (256,)\n",
            "2023-02-03 14:51:04,211 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.running_var           loaded from backbone.body.layer3.0.bn2.running_var           of shape (256,)\n",
            "2023-02-03 14:51:04,211 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.weight                loaded from backbone.body.layer3.0.bn2.weight                of shape (256,)\n",
            "2023-02-03 14:51:04,212 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.bias                  loaded from backbone.body.layer3.0.bn3.bias                  of shape (1024,)\n",
            "2023-02-03 14:51:04,212 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.running_mean          loaded from backbone.body.layer3.0.bn3.running_mean          of shape (1024,)\n",
            "2023-02-03 14:51:04,212 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.running_var           loaded from backbone.body.layer3.0.bn3.running_var           of shape (1024,)\n",
            "2023-02-03 14:51:04,212 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.weight                loaded from backbone.body.layer3.0.bn3.weight                of shape (1024,)\n",
            "2023-02-03 14:51:04,212 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv1.weight              loaded from backbone.body.layer3.0.conv1.weight              of shape (256, 512, 1, 1)\n",
            "2023-02-03 14:51:04,212 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv2.weight              loaded from backbone.body.layer3.0.conv2.weight              of shape (256, 256, 3, 3)\n",
            "2023-02-03 14:51:04,212 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv3.weight              loaded from backbone.body.layer3.0.conv3.weight              of shape (1024, 256, 1, 1)\n",
            "2023-02-03 14:51:04,212 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.0.weight       loaded from backbone.body.layer3.0.downsample.0.weight       of shape (1024, 512, 1, 1)\n",
            "2023-02-03 14:51:04,212 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.bias         loaded from backbone.body.layer3.0.downsample.1.bias         of shape (1024,)\n",
            "2023-02-03 14:51:04,212 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.running_mean loaded from backbone.body.layer3.0.downsample.1.running_mean of shape (1024,)\n",
            "2023-02-03 14:51:04,212 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.running_var  loaded from backbone.body.layer3.0.downsample.1.running_var  of shape (1024,)\n",
            "2023-02-03 14:51:04,212 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.weight       loaded from backbone.body.layer3.0.downsample.1.weight       of shape (1024,)\n",
            "2023-02-03 14:51:04,212 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.bias                  loaded from backbone.body.layer3.1.bn1.bias                  of shape (256,)\n",
            "2023-02-03 14:51:04,212 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.running_mean          loaded from backbone.body.layer3.1.bn1.running_mean          of shape (256,)\n",
            "2023-02-03 14:51:04,212 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.running_var           loaded from backbone.body.layer3.1.bn1.running_var           of shape (256,)\n",
            "2023-02-03 14:51:04,212 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.weight                loaded from backbone.body.layer3.1.bn1.weight                of shape (256,)\n",
            "2023-02-03 14:51:04,212 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.bias                  loaded from backbone.body.layer3.1.bn2.bias                  of shape (256,)\n",
            "2023-02-03 14:51:04,212 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.running_mean          loaded from backbone.body.layer3.1.bn2.running_mean          of shape (256,)\n",
            "2023-02-03 14:51:04,212 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.running_var           loaded from backbone.body.layer3.1.bn2.running_var           of shape (256,)\n",
            "2023-02-03 14:51:04,212 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.weight                loaded from backbone.body.layer3.1.bn2.weight                of shape (256,)\n",
            "2023-02-03 14:51:04,213 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.bias                  loaded from backbone.body.layer3.1.bn3.bias                  of shape (1024,)\n",
            "2023-02-03 14:51:04,213 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.running_mean          loaded from backbone.body.layer3.1.bn3.running_mean          of shape (1024,)\n",
            "2023-02-03 14:51:04,213 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.running_var           loaded from backbone.body.layer3.1.bn3.running_var           of shape (1024,)\n",
            "2023-02-03 14:51:04,213 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.weight                loaded from backbone.body.layer3.1.bn3.weight                of shape (1024,)\n",
            "2023-02-03 14:51:04,213 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv1.weight              loaded from backbone.body.layer3.1.conv1.weight              of shape (256, 1024, 1, 1)\n",
            "2023-02-03 14:51:04,213 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv2.weight              loaded from backbone.body.layer3.1.conv2.weight              of shape (256, 256, 3, 3)\n",
            "2023-02-03 14:51:04,213 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv3.weight              loaded from backbone.body.layer3.1.conv3.weight              of shape (1024, 256, 1, 1)\n",
            "2023-02-03 14:51:04,213 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.bias                  loaded from backbone.body.layer3.2.bn1.bias                  of shape (256,)\n",
            "2023-02-03 14:51:04,213 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.running_mean          loaded from backbone.body.layer3.2.bn1.running_mean          of shape (256,)\n",
            "2023-02-03 14:51:04,213 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.running_var           loaded from backbone.body.layer3.2.bn1.running_var           of shape (256,)\n",
            "2023-02-03 14:51:04,213 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.weight                loaded from backbone.body.layer3.2.bn1.weight                of shape (256,)\n",
            "2023-02-03 14:51:04,213 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.bias                  loaded from backbone.body.layer3.2.bn2.bias                  of shape (256,)\n",
            "2023-02-03 14:51:04,213 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.running_mean          loaded from backbone.body.layer3.2.bn2.running_mean          of shape (256,)\n",
            "2023-02-03 14:51:04,213 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.running_var           loaded from backbone.body.layer3.2.bn2.running_var           of shape (256,)\n",
            "2023-02-03 14:51:04,213 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.weight                loaded from backbone.body.layer3.2.bn2.weight                of shape (256,)\n",
            "2023-02-03 14:51:04,213 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.bias                  loaded from backbone.body.layer3.2.bn3.bias                  of shape (1024,)\n",
            "2023-02-03 14:51:04,213 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.running_mean          loaded from backbone.body.layer3.2.bn3.running_mean          of shape (1024,)\n",
            "2023-02-03 14:51:04,213 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.running_var           loaded from backbone.body.layer3.2.bn3.running_var           of shape (1024,)\n",
            "2023-02-03 14:51:04,213 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.weight                loaded from backbone.body.layer3.2.bn3.weight                of shape (1024,)\n",
            "2023-02-03 14:51:04,214 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv1.weight              loaded from backbone.body.layer3.2.conv1.weight              of shape (256, 1024, 1, 1)\n",
            "2023-02-03 14:51:04,214 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv2.weight              loaded from backbone.body.layer3.2.conv2.weight              of shape (256, 256, 3, 3)\n",
            "2023-02-03 14:51:04,214 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv3.weight              loaded from backbone.body.layer3.2.conv3.weight              of shape (1024, 256, 1, 1)\n",
            "2023-02-03 14:51:04,214 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.bias                  loaded from backbone.body.layer3.3.bn1.bias                  of shape (256,)\n",
            "2023-02-03 14:51:04,214 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.running_mean          loaded from backbone.body.layer3.3.bn1.running_mean          of shape (256,)\n",
            "2023-02-03 14:51:04,214 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.running_var           loaded from backbone.body.layer3.3.bn1.running_var           of shape (256,)\n",
            "2023-02-03 14:51:04,214 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.weight                loaded from backbone.body.layer3.3.bn1.weight                of shape (256,)\n",
            "2023-02-03 14:51:04,214 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.bias                  loaded from backbone.body.layer3.3.bn2.bias                  of shape (256,)\n",
            "2023-02-03 14:51:04,214 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.running_mean          loaded from backbone.body.layer3.3.bn2.running_mean          of shape (256,)\n",
            "2023-02-03 14:51:04,214 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.running_var           loaded from backbone.body.layer3.3.bn2.running_var           of shape (256,)\n",
            "2023-02-03 14:51:04,214 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.weight                loaded from backbone.body.layer3.3.bn2.weight                of shape (256,)\n",
            "2023-02-03 14:51:04,214 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.bias                  loaded from backbone.body.layer3.3.bn3.bias                  of shape (1024,)\n",
            "2023-02-03 14:51:04,214 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.running_mean          loaded from backbone.body.layer3.3.bn3.running_mean          of shape (1024,)\n",
            "2023-02-03 14:51:04,214 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.running_var           loaded from backbone.body.layer3.3.bn3.running_var           of shape (1024,)\n",
            "2023-02-03 14:51:04,214 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.weight                loaded from backbone.body.layer3.3.bn3.weight                of shape (1024,)\n",
            "2023-02-03 14:51:04,214 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv1.weight              loaded from backbone.body.layer3.3.conv1.weight              of shape (256, 1024, 1, 1)\n",
            "2023-02-03 14:51:04,214 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv2.weight              loaded from backbone.body.layer3.3.conv2.weight              of shape (256, 256, 3, 3)\n",
            "2023-02-03 14:51:04,214 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv3.weight              loaded from backbone.body.layer3.3.conv3.weight              of shape (1024, 256, 1, 1)\n",
            "2023-02-03 14:51:04,214 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.bias                  loaded from backbone.body.layer3.4.bn1.bias                  of shape (256,)\n",
            "2023-02-03 14:51:04,214 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.running_mean          loaded from backbone.body.layer3.4.bn1.running_mean          of shape (256,)\n",
            "2023-02-03 14:51:04,215 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.running_var           loaded from backbone.body.layer3.4.bn1.running_var           of shape (256,)\n",
            "2023-02-03 14:51:04,215 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.weight                loaded from backbone.body.layer3.4.bn1.weight                of shape (256,)\n",
            "2023-02-03 14:51:04,215 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.bias                  loaded from backbone.body.layer3.4.bn2.bias                  of shape (256,)\n",
            "2023-02-03 14:51:04,215 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.running_mean          loaded from backbone.body.layer3.4.bn2.running_mean          of shape (256,)\n",
            "2023-02-03 14:51:04,215 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.running_var           loaded from backbone.body.layer3.4.bn2.running_var           of shape (256,)\n",
            "2023-02-03 14:51:04,215 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.weight                loaded from backbone.body.layer3.4.bn2.weight                of shape (256,)\n",
            "2023-02-03 14:51:04,215 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.bias                  loaded from backbone.body.layer3.4.bn3.bias                  of shape (1024,)\n",
            "2023-02-03 14:51:04,215 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.running_mean          loaded from backbone.body.layer3.4.bn3.running_mean          of shape (1024,)\n",
            "2023-02-03 14:51:04,215 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.running_var           loaded from backbone.body.layer3.4.bn3.running_var           of shape (1024,)\n",
            "2023-02-03 14:51:04,215 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.weight                loaded from backbone.body.layer3.4.bn3.weight                of shape (1024,)\n",
            "2023-02-03 14:51:04,215 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv1.weight              loaded from backbone.body.layer3.4.conv1.weight              of shape (256, 1024, 1, 1)\n",
            "2023-02-03 14:51:04,215 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv2.weight              loaded from backbone.body.layer3.4.conv2.weight              of shape (256, 256, 3, 3)\n",
            "2023-02-03 14:51:04,215 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv3.weight              loaded from backbone.body.layer3.4.conv3.weight              of shape (1024, 256, 1, 1)\n",
            "2023-02-03 14:51:04,215 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.bias                  loaded from backbone.body.layer3.5.bn1.bias                  of shape (256,)\n",
            "2023-02-03 14:51:04,215 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.running_mean          loaded from backbone.body.layer3.5.bn1.running_mean          of shape (256,)\n",
            "2023-02-03 14:51:04,215 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.running_var           loaded from backbone.body.layer3.5.bn1.running_var           of shape (256,)\n",
            "2023-02-03 14:51:04,215 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.weight                loaded from backbone.body.layer3.5.bn1.weight                of shape (256,)\n",
            "2023-02-03 14:51:04,215 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.bias                  loaded from backbone.body.layer3.5.bn2.bias                  of shape (256,)\n",
            "2023-02-03 14:51:04,215 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.running_mean          loaded from backbone.body.layer3.5.bn2.running_mean          of shape (256,)\n",
            "2023-02-03 14:51:04,215 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.running_var           loaded from backbone.body.layer3.5.bn2.running_var           of shape (256,)\n",
            "2023-02-03 14:51:04,216 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.weight                loaded from backbone.body.layer3.5.bn2.weight                of shape (256,)\n",
            "2023-02-03 14:51:04,216 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.bias                  loaded from backbone.body.layer3.5.bn3.bias                  of shape (1024,)\n",
            "2023-02-03 14:51:04,216 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.running_mean          loaded from backbone.body.layer3.5.bn3.running_mean          of shape (1024,)\n",
            "2023-02-03 14:51:04,216 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.running_var           loaded from backbone.body.layer3.5.bn3.running_var           of shape (1024,)\n",
            "2023-02-03 14:51:04,216 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.weight                loaded from backbone.body.layer3.5.bn3.weight                of shape (1024,)\n",
            "2023-02-03 14:51:04,216 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv1.weight              loaded from backbone.body.layer3.5.conv1.weight              of shape (256, 1024, 1, 1)\n",
            "2023-02-03 14:51:04,216 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv2.weight              loaded from backbone.body.layer3.5.conv2.weight              of shape (256, 256, 3, 3)\n",
            "2023-02-03 14:51:04,216 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv3.weight              loaded from backbone.body.layer3.5.conv3.weight              of shape (1024, 256, 1, 1)\n",
            "2023-02-03 14:51:04,216 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.bias                  loaded from backbone.body.layer4.0.bn1.bias                  of shape (512,)\n",
            "2023-02-03 14:51:04,216 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.running_mean          loaded from backbone.body.layer4.0.bn1.running_mean          of shape (512,)\n",
            "2023-02-03 14:51:04,216 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.running_var           loaded from backbone.body.layer4.0.bn1.running_var           of shape (512,)\n",
            "2023-02-03 14:51:04,216 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.weight                loaded from backbone.body.layer4.0.bn1.weight                of shape (512,)\n",
            "2023-02-03 14:51:04,216 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.bias                  loaded from backbone.body.layer4.0.bn2.bias                  of shape (512,)\n",
            "2023-02-03 14:51:04,216 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.running_mean          loaded from backbone.body.layer4.0.bn2.running_mean          of shape (512,)\n",
            "2023-02-03 14:51:04,216 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.running_var           loaded from backbone.body.layer4.0.bn2.running_var           of shape (512,)\n",
            "2023-02-03 14:51:04,216 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.weight                loaded from backbone.body.layer4.0.bn2.weight                of shape (512,)\n",
            "2023-02-03 14:51:04,216 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.bias                  loaded from backbone.body.layer4.0.bn3.bias                  of shape (2048,)\n",
            "2023-02-03 14:51:04,216 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.running_mean          loaded from backbone.body.layer4.0.bn3.running_mean          of shape (2048,)\n",
            "2023-02-03 14:51:04,216 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.running_var           loaded from backbone.body.layer4.0.bn3.running_var           of shape (2048,)\n",
            "2023-02-03 14:51:04,216 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.weight                loaded from backbone.body.layer4.0.bn3.weight                of shape (2048,)\n",
            "2023-02-03 14:51:04,217 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv1.weight              loaded from backbone.body.layer4.0.conv1.weight              of shape (512, 1024, 1, 1)\n",
            "2023-02-03 14:51:04,217 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv2.weight              loaded from backbone.body.layer4.0.conv2.weight              of shape (512, 512, 3, 3)\n",
            "2023-02-03 14:51:04,217 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv3.weight              loaded from backbone.body.layer4.0.conv3.weight              of shape (2048, 512, 1, 1)\n",
            "2023-02-03 14:51:04,217 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.0.weight       loaded from backbone.body.layer4.0.downsample.0.weight       of shape (2048, 1024, 1, 1)\n",
            "2023-02-03 14:51:04,217 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.bias         loaded from backbone.body.layer4.0.downsample.1.bias         of shape (2048,)\n",
            "2023-02-03 14:51:04,217 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.running_mean loaded from backbone.body.layer4.0.downsample.1.running_mean of shape (2048,)\n",
            "2023-02-03 14:51:04,217 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.running_var  loaded from backbone.body.layer4.0.downsample.1.running_var  of shape (2048,)\n",
            "2023-02-03 14:51:04,217 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.weight       loaded from backbone.body.layer4.0.downsample.1.weight       of shape (2048,)\n",
            "2023-02-03 14:51:04,217 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.bias                  loaded from backbone.body.layer4.1.bn1.bias                  of shape (512,)\n",
            "2023-02-03 14:51:04,217 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.running_mean          loaded from backbone.body.layer4.1.bn1.running_mean          of shape (512,)\n",
            "2023-02-03 14:51:04,217 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.running_var           loaded from backbone.body.layer4.1.bn1.running_var           of shape (512,)\n",
            "2023-02-03 14:51:04,217 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.weight                loaded from backbone.body.layer4.1.bn1.weight                of shape (512,)\n",
            "2023-02-03 14:51:04,217 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.bias                  loaded from backbone.body.layer4.1.bn2.bias                  of shape (512,)\n",
            "2023-02-03 14:51:04,217 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.running_mean          loaded from backbone.body.layer4.1.bn2.running_mean          of shape (512,)\n",
            "2023-02-03 14:51:04,217 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.running_var           loaded from backbone.body.layer4.1.bn2.running_var           of shape (512,)\n",
            "2023-02-03 14:51:04,217 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.weight                loaded from backbone.body.layer4.1.bn2.weight                of shape (512,)\n",
            "2023-02-03 14:51:04,217 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.bias                  loaded from backbone.body.layer4.1.bn3.bias                  of shape (2048,)\n",
            "2023-02-03 14:51:04,217 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.running_mean          loaded from backbone.body.layer4.1.bn3.running_mean          of shape (2048,)\n",
            "2023-02-03 14:51:04,217 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.running_var           loaded from backbone.body.layer4.1.bn3.running_var           of shape (2048,)\n",
            "2023-02-03 14:51:04,218 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.weight                loaded from backbone.body.layer4.1.bn3.weight                of shape (2048,)\n",
            "2023-02-03 14:51:04,218 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv1.weight              loaded from backbone.body.layer4.1.conv1.weight              of shape (512, 2048, 1, 1)\n",
            "2023-02-03 14:51:04,218 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv2.weight              loaded from backbone.body.layer4.1.conv2.weight              of shape (512, 512, 3, 3)\n",
            "2023-02-03 14:51:04,218 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv3.weight              loaded from backbone.body.layer4.1.conv3.weight              of shape (2048, 512, 1, 1)\n",
            "2023-02-03 14:51:04,218 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.bias                  loaded from backbone.body.layer4.2.bn1.bias                  of shape (512,)\n",
            "2023-02-03 14:51:04,218 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.running_mean          loaded from backbone.body.layer4.2.bn1.running_mean          of shape (512,)\n",
            "2023-02-03 14:51:04,218 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.running_var           loaded from backbone.body.layer4.2.bn1.running_var           of shape (512,)\n",
            "2023-02-03 14:51:04,218 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.weight                loaded from backbone.body.layer4.2.bn1.weight                of shape (512,)\n",
            "2023-02-03 14:51:04,218 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.bias                  loaded from backbone.body.layer4.2.bn2.bias                  of shape (512,)\n",
            "2023-02-03 14:51:04,218 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.running_mean          loaded from backbone.body.layer4.2.bn2.running_mean          of shape (512,)\n",
            "2023-02-03 14:51:04,218 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.running_var           loaded from backbone.body.layer4.2.bn2.running_var           of shape (512,)\n",
            "2023-02-03 14:51:04,218 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.weight                loaded from backbone.body.layer4.2.bn2.weight                of shape (512,)\n",
            "2023-02-03 14:51:04,218 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.bias                  loaded from backbone.body.layer4.2.bn3.bias                  of shape (2048,)\n",
            "2023-02-03 14:51:04,218 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.running_mean          loaded from backbone.body.layer4.2.bn3.running_mean          of shape (2048,)\n",
            "2023-02-03 14:51:04,218 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.running_var           loaded from backbone.body.layer4.2.bn3.running_var           of shape (2048,)\n",
            "2023-02-03 14:51:04,218 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.weight                loaded from backbone.body.layer4.2.bn3.weight                of shape (2048,)\n",
            "2023-02-03 14:51:04,218 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv1.weight              loaded from backbone.body.layer4.2.conv1.weight              of shape (512, 2048, 1, 1)\n",
            "2023-02-03 14:51:04,218 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv2.weight              loaded from backbone.body.layer4.2.conv2.weight              of shape (512, 512, 3, 3)\n",
            "2023-02-03 14:51:04,219 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv3.weight              loaded from backbone.body.layer4.2.conv3.weight              of shape (2048, 512, 1, 1)\n",
            "2023-02-03 14:51:04,219 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.bias                      loaded from backbone.body.stem.bn1.bias                      of shape (64,)\n",
            "2023-02-03 14:51:04,219 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.running_mean              loaded from backbone.body.stem.bn1.running_mean              of shape (64,)\n",
            "2023-02-03 14:51:04,219 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.running_var               loaded from backbone.body.stem.bn1.running_var               of shape (64,)\n",
            "2023-02-03 14:51:04,219 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.weight                    loaded from backbone.body.stem.bn1.weight                    of shape (64,)\n",
            "2023-02-03 14:51:04,219 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.conv1.weight                  loaded from backbone.body.stem.conv1.weight                  of shape (64, 3, 7, 7)\n",
            "2023-02-03 14:51:04,219 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner1.bias                     loaded from backbone.fpn.fpn_inner1.bias                     of shape (256,)\n",
            "2023-02-03 14:51:04,219 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner1.weight                   loaded from backbone.fpn.fpn_inner1.weight                   of shape (256, 256, 1, 1)\n",
            "2023-02-03 14:51:04,219 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner2.bias                     loaded from backbone.fpn.fpn_inner2.bias                     of shape (256,)\n",
            "2023-02-03 14:51:04,219 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner2.weight                   loaded from backbone.fpn.fpn_inner2.weight                   of shape (256, 512, 1, 1)\n",
            "2023-02-03 14:51:04,219 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner3.bias                     loaded from backbone.fpn.fpn_inner3.bias                     of shape (256,)\n",
            "2023-02-03 14:51:04,219 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner3.weight                   loaded from backbone.fpn.fpn_inner3.weight                   of shape (256, 1024, 1, 1)\n",
            "2023-02-03 14:51:04,219 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner4.bias                     loaded from backbone.fpn.fpn_inner4.bias                     of shape (256,)\n",
            "2023-02-03 14:51:04,219 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner4.weight                   loaded from backbone.fpn.fpn_inner4.weight                   of shape (256, 2048, 1, 1)\n",
            "2023-02-03 14:51:04,219 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer1.bias                     loaded from backbone.fpn.fpn_layer1.bias                     of shape (256,)\n",
            "2023-02-03 14:51:04,219 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer1.weight                   loaded from backbone.fpn.fpn_layer1.weight                   of shape (256, 256, 3, 3)\n",
            "2023-02-03 14:51:04,219 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer2.bias                     loaded from backbone.fpn.fpn_layer2.bias                     of shape (256,)\n",
            "2023-02-03 14:51:04,219 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer2.weight                   loaded from backbone.fpn.fpn_layer2.weight                   of shape (256, 256, 3, 3)\n",
            "2023-02-03 14:51:04,219 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer3.bias                     loaded from backbone.fpn.fpn_layer3.bias                     of shape (256,)\n",
            "2023-02-03 14:51:04,219 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer3.weight                   loaded from backbone.fpn.fpn_layer3.weight                   of shape (256, 256, 3, 3)\n",
            "2023-02-03 14:51:04,220 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer4.bias                     loaded from backbone.fpn.fpn_layer4.bias                     of shape (256,)\n",
            "2023-02-03 14:51:04,220 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer4.weight                   loaded from backbone.fpn.fpn_layer4.weight                   of shape (256, 256, 3, 3)\n",
            "2023-02-03 14:51:04,220 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level0.bias        loaded from da_heads.imghead.da_img_conv1_level0.bias        of shape (512,)\n",
            "2023-02-03 14:51:04,220 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level0.weight      loaded from da_heads.imghead.da_img_conv1_level0.weight      of shape (512, 256, 1, 1)\n",
            "2023-02-03 14:51:04,220 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level1.bias        loaded from da_heads.imghead.da_img_conv1_level1.bias        of shape (512,)\n",
            "2023-02-03 14:51:04,220 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level1.weight      loaded from da_heads.imghead.da_img_conv1_level1.weight      of shape (512, 256, 1, 1)\n",
            "2023-02-03 14:51:04,220 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level2.bias        loaded from da_heads.imghead.da_img_conv1_level2.bias        of shape (512,)\n",
            "2023-02-03 14:51:04,220 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level2.weight      loaded from da_heads.imghead.da_img_conv1_level2.weight      of shape (512, 256, 1, 1)\n",
            "2023-02-03 14:51:04,220 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level3.bias        loaded from da_heads.imghead.da_img_conv1_level3.bias        of shape (512,)\n",
            "2023-02-03 14:51:04,220 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level3.weight      loaded from da_heads.imghead.da_img_conv1_level3.weight      of shape (512, 256, 1, 1)\n",
            "2023-02-03 14:51:04,220 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level4.bias        loaded from da_heads.imghead.da_img_conv1_level4.bias        of shape (512,)\n",
            "2023-02-03 14:51:04,220 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv1_level4.weight      loaded from da_heads.imghead.da_img_conv1_level4.weight      of shape (512, 256, 1, 1)\n",
            "2023-02-03 14:51:04,220 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level0.bias        loaded from da_heads.imghead.da_img_conv2_level0.bias        of shape (1,)\n",
            "2023-02-03 14:51:04,220 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level0.weight      loaded from da_heads.imghead.da_img_conv2_level0.weight      of shape (1, 512, 1, 1)\n",
            "2023-02-03 14:51:04,220 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level1.bias        loaded from da_heads.imghead.da_img_conv2_level1.bias        of shape (1,)\n",
            "2023-02-03 14:51:04,220 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level1.weight      loaded from da_heads.imghead.da_img_conv2_level1.weight      of shape (1, 512, 1, 1)\n",
            "2023-02-03 14:51:04,220 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level2.bias        loaded from da_heads.imghead.da_img_conv2_level2.bias        of shape (1,)\n",
            "2023-02-03 14:51:04,220 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level2.weight      loaded from da_heads.imghead.da_img_conv2_level2.weight      of shape (1, 512, 1, 1)\n",
            "2023-02-03 14:51:04,220 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level3.bias        loaded from da_heads.imghead.da_img_conv2_level3.bias        of shape (1,)\n",
            "2023-02-03 14:51:04,221 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level3.weight      loaded from da_heads.imghead.da_img_conv2_level3.weight      of shape (1, 512, 1, 1)\n",
            "2023-02-03 14:51:04,221 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level4.bias        loaded from da_heads.imghead.da_img_conv2_level4.bias        of shape (1,)\n",
            "2023-02-03 14:51:04,221 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.imghead.da_img_conv2_level4.weight      loaded from da_heads.imghead.da_img_conv2_level4.weight      of shape (1, 512, 1, 1)\n",
            "2023-02-03 14:51:04,221 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc1_level0.bias          loaded from da_heads.inshead.da_ins_fc1_level0.bias          of shape (1024,)\n",
            "2023-02-03 14:51:04,221 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc1_level0.weight        loaded from da_heads.inshead.da_ins_fc1_level0.weight        of shape (1024, 1024)\n",
            "2023-02-03 14:51:04,221 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc1_level1.bias          loaded from da_heads.inshead.da_ins_fc1_level1.bias          of shape (1024,)\n",
            "2023-02-03 14:51:04,221 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc1_level1.weight        loaded from da_heads.inshead.da_ins_fc1_level1.weight        of shape (1024, 1024)\n",
            "2023-02-03 14:51:04,221 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc1_level2.bias          loaded from da_heads.inshead.da_ins_fc1_level2.bias          of shape (1024,)\n",
            "2023-02-03 14:51:04,221 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc1_level2.weight        loaded from da_heads.inshead.da_ins_fc1_level2.weight        of shape (1024, 1024)\n",
            "2023-02-03 14:51:04,221 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc1_level3.bias          loaded from da_heads.inshead.da_ins_fc1_level3.bias          of shape (1024,)\n",
            "2023-02-03 14:51:04,221 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc1_level3.weight        loaded from da_heads.inshead.da_ins_fc1_level3.weight        of shape (1024, 1024)\n",
            "2023-02-03 14:51:04,221 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc2_level0.bias          loaded from da_heads.inshead.da_ins_fc2_level0.bias          of shape (1024,)\n",
            "2023-02-03 14:51:04,221 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc2_level0.weight        loaded from da_heads.inshead.da_ins_fc2_level0.weight        of shape (1024, 1024)\n",
            "2023-02-03 14:51:04,221 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc2_level1.bias          loaded from da_heads.inshead.da_ins_fc2_level1.bias          of shape (1024,)\n",
            "2023-02-03 14:51:04,221 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc2_level1.weight        loaded from da_heads.inshead.da_ins_fc2_level1.weight        of shape (1024, 1024)\n",
            "2023-02-03 14:51:04,221 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc2_level2.bias          loaded from da_heads.inshead.da_ins_fc2_level2.bias          of shape (1024,)\n",
            "2023-02-03 14:51:04,221 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc2_level2.weight        loaded from da_heads.inshead.da_ins_fc2_level2.weight        of shape (1024, 1024)\n",
            "2023-02-03 14:51:04,221 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc2_level3.bias          loaded from da_heads.inshead.da_ins_fc2_level3.bias          of shape (1024,)\n",
            "2023-02-03 14:51:04,221 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc2_level3.weight        loaded from da_heads.inshead.da_ins_fc2_level3.weight        of shape (1024, 1024)\n",
            "2023-02-03 14:51:04,221 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc3_level0.bias          loaded from da_heads.inshead.da_ins_fc3_level0.bias          of shape (1,)\n",
            "2023-02-03 14:51:04,222 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc3_level0.weight        loaded from da_heads.inshead.da_ins_fc3_level0.weight        of shape (1, 1024)\n",
            "2023-02-03 14:51:04,222 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc3_level1.bias          loaded from da_heads.inshead.da_ins_fc3_level1.bias          of shape (1,)\n",
            "2023-02-03 14:51:04,222 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc3_level1.weight        loaded from da_heads.inshead.da_ins_fc3_level1.weight        of shape (1, 1024)\n",
            "2023-02-03 14:51:04,222 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc3_level2.bias          loaded from da_heads.inshead.da_ins_fc3_level2.bias          of shape (1,)\n",
            "2023-02-03 14:51:04,222 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc3_level2.weight        loaded from da_heads.inshead.da_ins_fc3_level2.weight        of shape (1, 1024)\n",
            "2023-02-03 14:51:04,222 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc3_level3.bias          loaded from da_heads.inshead.da_ins_fc3_level3.bias          of shape (1,)\n",
            "2023-02-03 14:51:04,222 maskrcnn_benchmark.utils.model_serialization INFO: da_heads.inshead.da_ins_fc3_level3.weight        loaded from da_heads.inshead.da_ins_fc3_level3.weight        of shape (1, 1024)\n",
            "2023-02-03 14:51:04,222 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc6.bias         loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (1024,)\n",
            "2023-02-03 14:51:04,222 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc6.weight       loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (1024, 12544)\n",
            "2023-02-03 14:51:04,222 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc7.bias         loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (1024,)\n",
            "2023-02-03 14:51:04,222 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc7.weight       loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (1024, 1024)\n",
            "2023-02-03 14:51:04,222 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.bbox_pred.bias           loaded from roi_heads.box.predictor.bbox_pred.bias           of shape (8,)\n",
            "2023-02-03 14:51:04,222 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.bbox_pred.weight         loaded from roi_heads.box.predictor.bbox_pred.weight         of shape (8, 1024)\n",
            "2023-02-03 14:51:04,222 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.cls_score.bias           loaded from roi_heads.box.predictor.cls_score.bias           of shape (2,)\n",
            "2023-02-03 14:51:04,222 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.cls_score.weight         loaded from roi_heads.box.predictor.cls_score.weight         of shape (2, 1024)\n",
            "2023-02-03 14:51:04,222 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.0              loaded from rpn.anchor_generator.cell_anchors.0              of shape (3, 4)\n",
            "2023-02-03 14:51:04,222 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.1              loaded from rpn.anchor_generator.cell_anchors.1              of shape (3, 4)\n",
            "2023-02-03 14:51:04,222 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.2              loaded from rpn.anchor_generator.cell_anchors.2              of shape (3, 4)\n",
            "2023-02-03 14:51:04,222 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.3              loaded from rpn.anchor_generator.cell_anchors.3              of shape (3, 4)\n",
            "2023-02-03 14:51:04,222 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.4              loaded from rpn.anchor_generator.cell_anchors.4              of shape (3, 4)\n",
            "2023-02-03 14:51:04,223 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bbox_pred.bias                          loaded from rpn.head.bbox_pred.bias                          of shape (12,)\n",
            "2023-02-03 14:51:04,223 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bbox_pred.weight                        loaded from rpn.head.bbox_pred.weight                        of shape (12, 256, 1, 1)\n",
            "2023-02-03 14:51:04,223 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.cls_logits.bias                         loaded from rpn.head.cls_logits.bias                         of shape (3,)\n",
            "2023-02-03 14:51:04,223 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.cls_logits.weight                       loaded from rpn.head.cls_logits.weight                       of shape (3, 256, 1, 1)\n",
            "2023-02-03 14:51:04,223 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.conv.bias                               loaded from rpn.head.conv.bias                               of shape (256,)\n",
            "2023-02-03 14:51:04,223 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.conv.weight                             loaded from rpn.head.conv.weight                             of shape (256, 256, 3, 3)\n",
            "loading annotations into memory...\n",
            "Done (t=0.41s)\n",
            "creating index...\n",
            "index created!\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "2023-02-03 14:51:04,709 maskrcnn_benchmark.inference INFO: Start evaluation on cityscapes_only_car_val_cocostyle dataset(500 images).\n",
            "  0% 0/500 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "100% 500/500 [01:41<00:00,  4.92it/s]\n",
            "2023-02-03 14:52:46,253 maskrcnn_benchmark.inference INFO: Total inference time: 0:01:41.543688 (0.20308737564086915 s / img per device, on 1 devices)\n",
            "2023-02-03 14:52:46,300 maskrcnn_benchmark.inference INFO: Preparing results for COCO format\n",
            "2023-02-03 14:52:46,300 maskrcnn_benchmark.inference INFO: Preparing bbox results\n",
            "2023-02-03 14:52:46,384 maskrcnn_benchmark.inference INFO: Evaluating predictions\n",
            "Category: 1 {'id': 1, 'name': 'car'}\n",
            "Loading and preparing results...\n",
            "DONE (t=0.31s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=6.33s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.25s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.221\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.473\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.183\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.065\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.262\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.429\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.062\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.248\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.333\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.147\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.368\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.565\n",
            "Loading and preparing results...\n",
            "DONE (t=0.25s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=6.19s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.26s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.221\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.473\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.183\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.065\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.262\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.429\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.062\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.248\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.333\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.147\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.368\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.565\n",
            "2023-02-03 14:53:00,704 maskrcnn_benchmark.inference INFO: OrderedDict([('bbox', OrderedDict([('AP', -1), ('AP50', -1), ('AP75', -1), ('APs', -1), ('APm', -1), ('APl', -1), (1, {'AP': 0.22105894636153584, 'AP50': 0.47316807537182126, 'AP75': 0.18344473421264318, 'APs': 0.06548861893137292, 'APm': 0.2615415033532638, 'APl': 0.42880401314029154})]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/"
      ],
      "metadata": {
        "id": "4b47h7F1U4qR",
        "outputId": "cf30058d-5bd3-4b8b-bf74-895ebeab31c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/AI/mic_det_checkpoint.zip -d /content/sample_data/content/MIC/det/configs/da_faster_rcnn"
      ],
      "metadata": {
        "id": "XdvW1PGtcGBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1AbsqakY1wtRzGYc6BBZ5W2eN0suLEDkR "
      ],
      "metadata": {
        "id": "wq3OC1gfThfb",
        "outputId": "185e9b80-5d4a-4f44-e8f6-6a1c56f20b74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Access denied with the following error:\n",
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/uc?id=1AbsqakY1wtRzGYc6BBZ5W2eN0suLEDkR \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MBGxOkbdbqIS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}